{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f9179c9-403f-4917-9a50-b86d699674ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.nn as gnn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d2d13c4-6953-4bbf-ad85-1954e8cb8109",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data = pd.read_csv('C:\\\\Users\\\\20236046\\\\brazil_energy_data\\\\brazilian_energy_data\\\\static_data.csv')\n",
    "dynamic_data = pd.read_csv(\"C:\\\\Users\\\\20236046\\\\brazil_energy_data\\\\brazilian_energy_data\\\\dynamic_df.csv\")\n",
    "grid_df = pd.read_csv(\"C:\\\\Users\\\\20236046\\\\brazil_energy_data\\\\brazilian_energy_data\\\\grid_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9f2c049-54e9-4db7-9810-c4326b5f0fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>Population</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>GDP</th>\n",
       "      <th>pv_pot</th>\n",
       "      <th>onw_pot</th>\n",
       "      <th>ofw_pot</th>\n",
       "      <th>region</th>\n",
       "      <th>plant_type_with_max_cap</th>\n",
       "      <th>plant_capacity</th>\n",
       "      <th>total_plant_capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acre</td>\n",
       "      <td>AC</td>\n",
       "      <td>894470</td>\n",
       "      <td>-7845011</td>\n",
       "      <td>-1025617.0</td>\n",
       "      <td>1.648000e+10</td>\n",
       "      <td>1.561563e+06</td>\n",
       "      <td>31793.5572</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>N</td>\n",
       "      <td>oil</td>\n",
       "      <td>71.2036</td>\n",
       "      <td>72.70360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alagoas</td>\n",
       "      <td>AL</td>\n",
       "      <td>3351543</td>\n",
       "      <td>-4077060</td>\n",
       "      <td>-1059057.0</td>\n",
       "      <td>6.320000e+10</td>\n",
       "      <td>2.537546e+06</td>\n",
       "      <td>16161.0096</td>\n",
       "      <td>9454.9429</td>\n",
       "      <td>NE</td>\n",
       "      <td>biomass</td>\n",
       "      <td>317.4620</td>\n",
       "      <td>339.91130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amapá</td>\n",
       "      <td>AP</td>\n",
       "      <td>861773</td>\n",
       "      <td>-5784386</td>\n",
       "      <td>161130.7</td>\n",
       "      <td>1.847000e+10</td>\n",
       "      <td>9.973873e+05</td>\n",
       "      <td>12213.0916</td>\n",
       "      <td>131293.0561</td>\n",
       "      <td>N</td>\n",
       "      <td>hydro</td>\n",
       "      <td>549.0000</td>\n",
       "      <td>688.94620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>AM</td>\n",
       "      <td>4207714</td>\n",
       "      <td>-7197150</td>\n",
       "      <td>-462431.9</td>\n",
       "      <td>1.160200e+11</td>\n",
       "      <td>2.906075e+06</td>\n",
       "      <td>233461.2325</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>N</td>\n",
       "      <td>gas</td>\n",
       "      <td>1102.3130</td>\n",
       "      <td>2452.72194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bahia</td>\n",
       "      <td>BA</td>\n",
       "      <td>14930634</td>\n",
       "      <td>-4644378</td>\n",
       "      <td>-1388747.0</td>\n",
       "      <td>3.053200e+11</td>\n",
       "      <td>4.396968e+07</td>\n",
       "      <td>285636.1790</td>\n",
       "      <td>92179.8293</td>\n",
       "      <td>NE</td>\n",
       "      <td>hydro</td>\n",
       "      <td>5022.2690</td>\n",
       "      <td>12576.64812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name state  Population        x          y           GDP        pv_pot  \\\n",
       "0      Acre    AC      894470 -7845011 -1025617.0  1.648000e+10  1.561563e+06   \n",
       "1   Alagoas    AL     3351543 -4077060 -1059057.0  6.320000e+10  2.537546e+06   \n",
       "2     Amapá    AP      861773 -5784386   161130.7  1.847000e+10  9.973873e+05   \n",
       "3  Amazonas    AM     4207714 -7197150  -462431.9  1.160200e+11  2.906075e+06   \n",
       "4     Bahia    BA    14930634 -4644378 -1388747.0  3.053200e+11  4.396968e+07   \n",
       "\n",
       "       onw_pot      ofw_pot region plant_type_with_max_cap  plant_capacity   \\\n",
       "0   31793.5572       0.0000      N                     oil          71.2036   \n",
       "1   16161.0096    9454.9429     NE                 biomass         317.4620   \n",
       "2   12213.0916  131293.0561      N                   hydro         549.0000   \n",
       "3  233461.2325       0.0000      N                     gas        1102.3130   \n",
       "4  285636.1790   92179.8293     NE                   hydro        5022.2690   \n",
       "\n",
       "   total_plant_capacity  \n",
       "0              72.70360  \n",
       "1             339.91130  \n",
       "2             688.94620  \n",
       "3            2452.72194  \n",
       "4           12576.64812  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e61b21e-9908-4150-b702-b9ba682d10f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data.columns = static_data.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec3a4b54-dc6d-461d-8bda-46aa368e8f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'state', 'Population', 'x', 'y', 'GDP', 'pv_pot', 'onw_pot',\n",
       "       'ofw_pot', 'region', 'plant_type_with_max_cap', 'plant_capacity',\n",
       "       'total_plant_capacity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cea40a67-9e6e-412d-9b21-eb0650078e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f076f954-7153-49cf-af89-205c90c84deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of zero values in each column:\n",
      "name                        0\n",
      "state                       0\n",
      "Population                  0\n",
      "x                           0\n",
      "y                           0\n",
      "GDP                         0\n",
      "pv_pot                      0\n",
      "onw_pot                     1\n",
      "ofw_pot                    10\n",
      "region                      0\n",
      "plant_type_with_max_cap     0\n",
      "plant_capacity              0\n",
      "total_plant_capacity        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of zero values in each column\n",
    "zero_counts = static_data.apply(lambda x: (x == 0).sum())\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nCount of zero values in each column:\")\n",
    "print(zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a13b7c-067e-4ffd-b947-32bfab4352ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>Population</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>GDP</th>\n",
       "      <th>pv_pot</th>\n",
       "      <th>onw_pot</th>\n",
       "      <th>ofw_pot</th>\n",
       "      <th>region</th>\n",
       "      <th>plant_type_with_max_cap</th>\n",
       "      <th>plant_capacity</th>\n",
       "      <th>total_plant_capacity</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acre</td>\n",
       "      <td>AC</td>\n",
       "      <td>894470</td>\n",
       "      <td>-7845011</td>\n",
       "      <td>-1025617.0</td>\n",
       "      <td>1.648000e+10</td>\n",
       "      <td>1.561563e+06</td>\n",
       "      <td>31793.5572</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>N</td>\n",
       "      <td>oil</td>\n",
       "      <td>71.2036</td>\n",
       "      <td>72.70360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alagoas</td>\n",
       "      <td>AL</td>\n",
       "      <td>3351543</td>\n",
       "      <td>-4077060</td>\n",
       "      <td>-1059057.0</td>\n",
       "      <td>6.320000e+10</td>\n",
       "      <td>2.537546e+06</td>\n",
       "      <td>16161.0096</td>\n",
       "      <td>9454.9429</td>\n",
       "      <td>NE</td>\n",
       "      <td>biomass</td>\n",
       "      <td>317.4620</td>\n",
       "      <td>339.91130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amapá</td>\n",
       "      <td>AP</td>\n",
       "      <td>861773</td>\n",
       "      <td>-5784386</td>\n",
       "      <td>161130.7</td>\n",
       "      <td>1.847000e+10</td>\n",
       "      <td>9.973873e+05</td>\n",
       "      <td>12213.0916</td>\n",
       "      <td>131293.0561</td>\n",
       "      <td>N</td>\n",
       "      <td>hydro</td>\n",
       "      <td>549.0000</td>\n",
       "      <td>688.94620</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>AM</td>\n",
       "      <td>4207714</td>\n",
       "      <td>-7197150</td>\n",
       "      <td>-462431.9</td>\n",
       "      <td>1.160200e+11</td>\n",
       "      <td>2.906075e+06</td>\n",
       "      <td>233461.2325</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>N</td>\n",
       "      <td>gas</td>\n",
       "      <td>1102.3130</td>\n",
       "      <td>2452.72194</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bahia</td>\n",
       "      <td>BA</td>\n",
       "      <td>14930634</td>\n",
       "      <td>-4644378</td>\n",
       "      <td>-1388747.0</td>\n",
       "      <td>3.053200e+11</td>\n",
       "      <td>4.396968e+07</td>\n",
       "      <td>285636.1790</td>\n",
       "      <td>92179.8293</td>\n",
       "      <td>NE</td>\n",
       "      <td>hydro</td>\n",
       "      <td>5022.2690</td>\n",
       "      <td>12576.64812</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name state  Population        x          y           GDP        pv_pot  \\\n",
       "0      Acre    AC      894470 -7845011 -1025617.0  1.648000e+10  1.561563e+06   \n",
       "1   Alagoas    AL     3351543 -4077060 -1059057.0  6.320000e+10  2.537546e+06   \n",
       "2     Amapá    AP      861773 -5784386   161130.7  1.847000e+10  9.973873e+05   \n",
       "3  Amazonas    AM     4207714 -7197150  -462431.9  1.160200e+11  2.906075e+06   \n",
       "4     Bahia    BA    14930634 -4644378 -1388747.0  3.053200e+11  4.396968e+07   \n",
       "\n",
       "       onw_pot      ofw_pot region plant_type_with_max_cap  plant_capacity  \\\n",
       "0   31793.5572       0.0000      N                     oil         71.2036   \n",
       "1   16161.0096    9454.9429     NE                 biomass        317.4620   \n",
       "2   12213.0916  131293.0561      N                   hydro        549.0000   \n",
       "3  233461.2325       0.0000      N                     gas       1102.3130   \n",
       "4  285636.1790   92179.8293     NE                   hydro       5022.2690   \n",
       "\n",
       "   total_plant_capacity  state_id  \n",
       "0              72.70360         0  \n",
       "1             339.91130         1  \n",
       "2             688.94620         2  \n",
       "3            2452.72194         3  \n",
       "4           12576.64812         4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_data['state_id'], _ = pd.factorize(static_data['state'])\n",
    "static_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "249b3878-75cd-4fa0-b137-29bd55c4754a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'state', 'value', 'pv', 'onw', 'ofw',\n",
       "       'TOTAL HOURLY RAIN (mm)(mean)', 'TOTAL HOURLY RAIN (mm)(std)',\n",
       "       'ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(mean)',\n",
       "       'ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(std)',\n",
       "       'GLOBAL RADIATION (KJ/m²)(mean)', 'GLOBAL RADIATION (KJ/m²)(std)',\n",
       "       'AIR TEMPERATURE (°C)(mean)', 'AIR TEMPERATURE (°C)(std)',\n",
       "       'DEW POINT TEMPERATURE (°C)(mean)', 'DEW POINT TEMPERATURE (°C)(std)',\n",
       "       'REL HUMIDITY FOR THE LAST HOUR (%)(mean)',\n",
       "       'REL HUMIDITY FOR THE LAST HOUR (%)(std)', 'WIND DIRECTION (gr)(mean)',\n",
       "       'WIND DIRECTION (gr)(std)', 'WIND MAXIMUM GUST (m/s)(mean)',\n",
       "       'WIND MAXIMUM GUST (m/s)(std)', 'WIND SPEED (m/s)(mean)',\n",
       "       'WIND SPEED (m/s)(std)', 'year', 'month', 'day', 'hour', 'season',\n",
       "       'is_holiday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f75f783-88b2-45df-8b0e-50e57f1b76e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>state</th>\n",
       "      <th>value</th>\n",
       "      <th>pv</th>\n",
       "      <th>onw</th>\n",
       "      <th>ofw</th>\n",
       "      <th>TOTAL HOURLY RAIN (mm)(mean)</th>\n",
       "      <th>TOTAL HOURLY RAIN (mm)(std)</th>\n",
       "      <th>ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(mean)</th>\n",
       "      <th>ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(std)</th>\n",
       "      <th>...</th>\n",
       "      <th>WIND MAXIMUM GUST (m/s)(mean)</th>\n",
       "      <th>WIND MAXIMUM GUST (m/s)(std)</th>\n",
       "      <th>WIND SPEED (m/s)(mean)</th>\n",
       "      <th>WIND SPEED (m/s)(std)</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>season</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [datetime, state, value, pv, onw, ofw, TOTAL HOURLY RAIN (mm)(mean), TOTAL HOURLY RAIN (mm)(std), ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(mean), ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(std), GLOBAL RADIATION (KJ/m²)(mean), GLOBAL RADIATION (KJ/m²)(std), AIR TEMPERATURE (°C)(mean), AIR TEMPERATURE (°C)(std), DEW POINT TEMPERATURE (°C)(mean), DEW POINT TEMPERATURE (°C)(std), REL HUMIDITY FOR THE LAST HOUR (%)(mean), REL HUMIDITY FOR THE LAST HOUR (%)(std), WIND DIRECTION (gr)(mean), WIND DIRECTION (gr)(std), WIND MAXIMUM GUST (m/s)(mean), WIND MAXIMUM GUST (m/s)(std), WIND SPEED (m/s)(mean), WIND SPEED (m/s)(std), year, month, day, hour, season, is_holiday]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for negative values in the 'pv' column\n",
    "negative_pv_values = dynamic_data[dynamic_data['pv'] < 0]\n",
    "\n",
    "# Display the rows with negative 'pv' values\n",
    "negative_pv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b4bbeb3-85a2-4e6d-8ad6-9064f648a1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State with the maximum hourly consumption: SP\n",
      "Maximum hourly consumption value: 23951.73\n"
     ]
    }
   ],
   "source": [
    "# Find the state with the maximum hourly consumption\n",
    "max_consumption_state = dynamic_data.groupby('state')['value'].max().idxmax()\n",
    "max_consumption_value = dynamic_data.groupby('state')['value'].max().max()\n",
    "\n",
    "print(f\"State with the maximum hourly consumption: {max_consumption_state}\")\n",
    "print(f\"Maximum hourly consumption value: {max_consumption_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9144d7e-0ac7-42e0-b679-80dfcf85a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime\n",
    "dynamic_data['datetime'] = pd.to_datetime(dynamic_data['datetime'], format='mixed', dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c73694c-8234-4cbb-bfb0-8cb2085d8adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>state</th>\n",
       "      <th>value</th>\n",
       "      <th>pv</th>\n",
       "      <th>onw</th>\n",
       "      <th>ofw</th>\n",
       "      <th>TOTAL HOURLY RAIN (mm)(mean)</th>\n",
       "      <th>TOTAL HOURLY RAIN (mm)(std)</th>\n",
       "      <th>ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(mean)</th>\n",
       "      <th>ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(std)</th>\n",
       "      <th>...</th>\n",
       "      <th>WIND MAXIMUM GUST (m/s)(std)</th>\n",
       "      <th>WIND SPEED (m/s)(mean)</th>\n",
       "      <th>WIND SPEED (m/s)(std)</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>season</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>AC</td>\n",
       "      <td>132.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>6.047432</td>\n",
       "      <td>985.571429</td>\n",
       "      <td>5.427005</td>\n",
       "      <td>...</td>\n",
       "      <td>1.914606</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>1.090435</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>AC</td>\n",
       "      <td>133.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>979.171429</td>\n",
       "      <td>23.096588</td>\n",
       "      <td>...</td>\n",
       "      <td>2.138869</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.528700</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>AC</td>\n",
       "      <td>131.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.075593</td>\n",
       "      <td>990.400000</td>\n",
       "      <td>6.761903</td>\n",
       "      <td>...</td>\n",
       "      <td>1.229789</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.588380</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>AC</td>\n",
       "      <td>129.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>977.900000</td>\n",
       "      <td>29.396485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916255</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.704408</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>AC</td>\n",
       "      <td>126.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.075593</td>\n",
       "      <td>991.928571</td>\n",
       "      <td>8.961718</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066146</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.820569</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime state   value   pv     onw  ofw  \\\n",
       "0 2020-01-01 00:00:00    AC  132.07  0.0  0.0178  0.0   \n",
       "1 2020-01-01 01:00:00    AC  133.11  0.0  0.0219  0.0   \n",
       "2 2020-01-01 02:00:00    AC  131.80  0.0  0.0263  0.0   \n",
       "3 2020-01-01 03:00:00    AC  129.24  0.0  0.0384  0.0   \n",
       "4 2020-01-01 04:00:00    AC  126.76  0.0  0.0468  0.0   \n",
       "\n",
       "   TOTAL HOURLY RAIN (mm)(mean)  TOTAL HOURLY RAIN (mm)(std)  \\\n",
       "0                      2.285714                     6.047432   \n",
       "1                      0.000000                     0.000000   \n",
       "2                      0.028571                     0.075593   \n",
       "3                      0.000000                     0.000000   \n",
       "4                      0.028571                     0.075593   \n",
       "\n",
       "   ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(mean)  \\\n",
       "0                                        985.571429   \n",
       "1                                        979.171429   \n",
       "2                                        990.400000   \n",
       "3                                        977.900000   \n",
       "4                                        991.928571   \n",
       "\n",
       "   ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(std)  ...  \\\n",
       "0                                         5.427005  ...   \n",
       "1                                        23.096588  ...   \n",
       "2                                         6.761903  ...   \n",
       "3                                        29.396485  ...   \n",
       "4                                         8.961718  ...   \n",
       "\n",
       "   WIND MAXIMUM GUST (m/s)(std)  WIND SPEED (m/s)(mean)  \\\n",
       "0                      1.914606                1.128571   \n",
       "1                      2.138869                0.657143   \n",
       "2                      1.229789                0.657143   \n",
       "3                      0.916255                0.757143   \n",
       "4                      1.066146                0.600000   \n",
       "\n",
       "   WIND SPEED (m/s)(std)  year  month  day  hour  season  is_holiday  state_id  \n",
       "0               1.090435  2020      1    1     0  Summer           1         0  \n",
       "1               0.528700  2020      1    1     1  Summer           1         0  \n",
       "2               0.588380  2020      1    1     2  Summer           1         0  \n",
       "3               0.704408  2020      1    1     3  Summer           1         0  \n",
       "4               0.820569  2020      1    1     4  Summer           1         0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_data['state_id'], _ = pd.factorize(dynamic_data['state'])\n",
    "dynamic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "929f036b-f205-4869-af21-bd391498793a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>state</th>\n",
       "      <th>value</th>\n",
       "      <th>pv</th>\n",
       "      <th>onw</th>\n",
       "      <th>ofw</th>\n",
       "      <th>TOTAL HOURLY RAIN (mm)(mean)</th>\n",
       "      <th>TOTAL HOURLY RAIN (mm)(std)</th>\n",
       "      <th>ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(mean)</th>\n",
       "      <th>ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(std)</th>\n",
       "      <th>...</th>\n",
       "      <th>WIND MAXIMUM GUST (m/s)(std)</th>\n",
       "      <th>WIND SPEED (m/s)(mean)</th>\n",
       "      <th>WIND SPEED (m/s)(std)</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>season</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>AC</td>\n",
       "      <td>132.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>6.047432</td>\n",
       "      <td>985.571429</td>\n",
       "      <td>5.427005</td>\n",
       "      <td>...</td>\n",
       "      <td>1.914606</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>1.090435</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>AC</td>\n",
       "      <td>133.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>979.171429</td>\n",
       "      <td>23.096588</td>\n",
       "      <td>...</td>\n",
       "      <td>2.138869</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.528700</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>AC</td>\n",
       "      <td>131.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.075593</td>\n",
       "      <td>990.400000</td>\n",
       "      <td>6.761903</td>\n",
       "      <td>...</td>\n",
       "      <td>1.229789</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.588380</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>AC</td>\n",
       "      <td>129.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>977.900000</td>\n",
       "      <td>29.396485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916255</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.704408</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>AC</td>\n",
       "      <td>126.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.075593</td>\n",
       "      <td>991.928571</td>\n",
       "      <td>8.961718</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066146</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.820569</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime state   value   pv     onw  ofw  \\\n",
       "0 2020-01-01 00:00:00    AC  132.07  0.0  0.0178  0.0   \n",
       "1 2020-01-01 01:00:00    AC  133.11  0.0  0.0219  0.0   \n",
       "2 2020-01-01 02:00:00    AC  131.80  0.0  0.0263  0.0   \n",
       "3 2020-01-01 03:00:00    AC  129.24  0.0  0.0384  0.0   \n",
       "4 2020-01-01 04:00:00    AC  126.76  0.0  0.0468  0.0   \n",
       "\n",
       "   TOTAL HOURLY RAIN (mm)(mean)  TOTAL HOURLY RAIN (mm)(std)  \\\n",
       "0                      2.285714                     6.047432   \n",
       "1                      0.000000                     0.000000   \n",
       "2                      0.028571                     0.075593   \n",
       "3                      0.000000                     0.000000   \n",
       "4                      0.028571                     0.075593   \n",
       "\n",
       "   ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(mean)  \\\n",
       "0                                        985.571429   \n",
       "1                                        979.171429   \n",
       "2                                        990.400000   \n",
       "3                                        977.900000   \n",
       "4                                        991.928571   \n",
       "\n",
       "   ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(std)  ...  \\\n",
       "0                                         5.427005  ...   \n",
       "1                                        23.096588  ...   \n",
       "2                                         6.761903  ...   \n",
       "3                                        29.396485  ...   \n",
       "4                                         8.961718  ...   \n",
       "\n",
       "   WIND MAXIMUM GUST (m/s)(std)  WIND SPEED (m/s)(mean)  \\\n",
       "0                      1.914606                1.128571   \n",
       "1                      2.138869                0.657143   \n",
       "2                      1.229789                0.657143   \n",
       "3                      0.916255                0.757143   \n",
       "4                      1.066146                0.600000   \n",
       "\n",
       "   WIND SPEED (m/s)(std)  year  month  day  hour  season  is_holiday  state_id  \n",
       "0               1.090435  2020      1    1     0       0           1         0  \n",
       "1               0.528700  2020      1    1     1       0           1         0  \n",
       "2               0.588380  2020      1    1     2       0           1         0  \n",
       "3               0.704408  2020      1    1     3       0           1         0  \n",
       "4               0.820569  2020      1    1     4       0           1         0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_data['season'], _ = pd.factorize(dynamic_data['season'])\n",
    "dynamic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0094693c-09b0-4c35-87c4-1a1e0885c80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of zero values in each column:\n",
      "datetime                                                 0\n",
      "state                                                    0\n",
      "value                                                    0\n",
      "pv                                                  118408\n",
      "onw                                                   8925\n",
      "ofw                                                  88437\n",
      "TOTAL HOURLY RAIN (mm)(mean)                        141131\n",
      "TOTAL HOURLY RAIN (mm)(std)                         141866\n",
      "ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(mean)         0\n",
      "ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(std)       8789\n",
      "GLOBAL RADIATION (KJ/m²)(mean)                       45130\n",
      "GLOBAL RADIATION (KJ/m²)(std)                        64382\n",
      "AIR TEMPERATURE (°C)(mean)                               0\n",
      "AIR TEMPERATURE (°C)(std)                             8801\n",
      "DEW POINT TEMPERATURE (°C)(mean)                         1\n",
      "DEW POINT TEMPERATURE (°C)(std)                       8825\n",
      "REL HUMIDITY FOR THE LAST HOUR (%)(mean)                 0\n",
      "REL HUMIDITY FOR THE LAST HOUR (%)(std)               8882\n",
      "WIND DIRECTION (gr)(mean)                                0\n",
      "WIND DIRECTION (gr)(std)                              8804\n",
      "WIND MAXIMUM GUST (m/s)(mean)                          207\n",
      "WIND MAXIMUM GUST (m/s)(std)                          8850\n",
      "WIND SPEED (m/s)(mean)                                 393\n",
      "WIND SPEED (m/s)(std)                                 8906\n",
      "year                                                     0\n",
      "month                                                    0\n",
      "day                                                      0\n",
      "hour                                                  9882\n",
      "season                                               58968\n",
      "is_holiday                                          228744\n",
      "state_id                                              8784\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of zero values in each column\n",
    "zero_counts = dynamic_data.apply(lambda x: (x == 0).sum())\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nCount of zero values in each column:\")\n",
    "print(zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef5b46f1-66f2-46be-8fb9-154d4f38eed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>capacity</th>\n",
       "      <th>line_eff</th>\n",
       "      <th>line_len</th>\n",
       "      <th>line_carrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC</td>\n",
       "      <td>RO</td>\n",
       "      <td>462.949833</td>\n",
       "      <td>0.997181</td>\n",
       "      <td>304.435446</td>\n",
       "      <td>ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>BA</td>\n",
       "      <td>9740.762028</td>\n",
       "      <td>0.998153</td>\n",
       "      <td>31.629925</td>\n",
       "      <td>ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>PE</td>\n",
       "      <td>6690.456467</td>\n",
       "      <td>0.997816</td>\n",
       "      <td>134.432276</td>\n",
       "      <td>ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>SE</td>\n",
       "      <td>9677.314272</td>\n",
       "      <td>0.998663</td>\n",
       "      <td>69.919940</td>\n",
       "      <td>ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP</td>\n",
       "      <td>PA</td>\n",
       "      <td>694.424749</td>\n",
       "      <td>0.997181</td>\n",
       "      <td>77.546060</td>\n",
       "      <td>ac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source Target     capacity  line_eff    line_len line_carrier\n",
       "0     AC     RO   462.949833  0.997181  304.435446           ac\n",
       "1     AL     BA  9740.762028  0.998153   31.629925           ac\n",
       "2     AL     PE  6690.456467  0.997816  134.432276           ac\n",
       "3     AL     SE  9677.314272  0.998663   69.919940           ac\n",
       "4     AP     PA   694.424749  0.997181   77.546060           ac"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57fbcb5a-499c-4a8c-8bdd-61a463af323d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>capacity</th>\n",
       "      <th>line_eff</th>\n",
       "      <th>line_len</th>\n",
       "      <th>line_carrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC</td>\n",
       "      <td>RO</td>\n",
       "      <td>462.949833</td>\n",
       "      <td>0.997181</td>\n",
       "      <td>304.435446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>BA</td>\n",
       "      <td>9740.762028</td>\n",
       "      <td>0.998153</td>\n",
       "      <td>31.629925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>PE</td>\n",
       "      <td>6690.456467</td>\n",
       "      <td>0.997816</td>\n",
       "      <td>134.432276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>SE</td>\n",
       "      <td>9677.314272</td>\n",
       "      <td>0.998663</td>\n",
       "      <td>69.919940</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP</td>\n",
       "      <td>PA</td>\n",
       "      <td>694.424749</td>\n",
       "      <td>0.997181</td>\n",
       "      <td>77.546060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source Target     capacity  line_eff    line_len  line_carrier\n",
       "0     AC     RO   462.949833  0.997181  304.435446             0\n",
       "1     AL     BA  9740.762028  0.998153   31.629925             0\n",
       "2     AL     PE  6690.456467  0.997816  134.432276             0\n",
       "3     AL     SE  9677.314272  0.998663   69.919940             0\n",
       "4     AP     PA   694.424749  0.997181   77.546060             0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df['line_carrier'], _ = pd.factorize(grid_df['line_carrier'])\n",
    "grid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15e36811-0e87-49ed-ac3c-c6831dfbbb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of zero values in each column:\n",
      "Source           0\n",
      "Target           0\n",
      "capacity         0\n",
      "line_eff         0\n",
      "line_len         0\n",
      "line_carrier    42\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of zero values in each column\n",
    "zero_counts = grid_df.apply(lambda x: (x == 0).sum())\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nCount of zero values in each column:\")\n",
    "print(zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce0e45-c880-4a56-9fb1-5893d933cf35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97dfb227-4eff-4ba9-abf8-88d3faf3728c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[27, 8], edge_index=[2, 46], edge_attr=[46, 4])\n",
      "Node features shape: torch.Size([27, 8])\n",
      "Edge index shape: torch.Size([2, 46])\n",
      "Edge attributes shape: torch.Size([46, 4])\n",
      "Edge Index Sample:\n",
      " tensor([[ 0,  1,  1,  1,  2,  3,  3,  4,  4,  4],\n",
      "        [21,  4, 16, 25, 13, 13, 22,  8, 12, 16]])\n",
      "Edge index node indices are consistent with node features.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Edge List:\n",
      "   Source Target\n",
      "0     AC     RO\n",
      "1     AL     BA\n",
      "2     AL     PE\n",
      "3     AL     SE\n",
      "4     AP     PA\n",
      "5     AM     PA\n",
      "6     AM     RR\n",
      "7     BA     GO\n",
      "8     BA     MG\n",
      "9     BA     PE\n",
      "Generated Edge Index:\n",
      " [[ 0 21]\n",
      " [ 1  4]\n",
      " [ 1 16]\n",
      " [ 1 25]\n",
      " [ 2 13]\n",
      " [ 3 13]\n",
      " [ 3 22]\n",
      " [ 4  8]\n",
      " [ 4 12]\n",
      " [ 4 16]]\n"
     ]
    }
   ],
   "source": [
    "# Create the directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add states as nodes with attributes from static_data\n",
    "for index, row in static_data.iterrows():\n",
    "    G.add_node(row['state'], **row.to_dict())\n",
    "\n",
    "# Add time series data to each node\n",
    "for state, group in dynamic_data.groupby('state'):\n",
    "    G.nodes[state]['time_series'] = group.to_dict(orient='records')\n",
    "\n",
    "# Add edges with attributes from grid_df\n",
    "for index, row in grid_df.iterrows():\n",
    "    G.add_edge(row['Source'], row['Target'], **row.to_dict())\n",
    "\n",
    "# Create a mapping from node identifier (state name) to integer index\n",
    "node_mapping = {node: idx for idx, node in enumerate(G.nodes)}\n",
    "\n",
    "# Extract node features (static features) from the graph\n",
    "node_features_list = []\n",
    "for node, data in G.nodes(data=True):\n",
    "    features = [data.get(feature) for feature in ['Population', 'x', 'y', 'pv_pot', 'onw_pot', 'ofw_pot', 'total_plant_capacity', 'GDP']]\n",
    "    node_features_list.append(features)\n",
    "\n",
    "# Convert node features to DataFrame for normalization\n",
    "node_features_df = pd.DataFrame(node_features_list, columns=['Population', 'x', 'y', 'pv_pot', 'onw_pot', 'ofw_pot', 'total_plant_capacity', 'GDP'])\n",
    "\n",
    "# Normalize the node features using standard scaler\n",
    "scaler = StandardScaler()\n",
    "normalized_node_features = scaler.fit_transform(node_features_df)\n",
    "\n",
    "# Convert normalized node features to tensor and move to the device\n",
    "node_features_tensor = torch.tensor(normalized_node_features, dtype=torch.float)\n",
    "\n",
    "\n",
    "# Extract edge index and edge attributes from the graph\n",
    "edge_index_list = []\n",
    "edge_attr_list = []\n",
    "for source, target, data in G.edges(data=True):\n",
    "    edge_index_list.append([node_mapping[source], node_mapping[target]])\n",
    "    edge_attr = [data.get(attr) for attr in ['capacity', 'line_eff', 'line_len', 'line_carrier']]\n",
    "    edge_attr_list.append(edge_attr)\n",
    "\n",
    "# Convert edge index and edge attributes to tensors and move to the device\n",
    "edge_index_tensor = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
    "edge_attr_tensor = torch.tensor(edge_attr_list, dtype=torch.float)\n",
    "\n",
    "# Create torch-geometric data object\n",
    "graph_data = Data(x=node_features_tensor, edge_index=edge_index_tensor, edge_attr=edge_attr_tensor)\n",
    "\n",
    "# Print to verify the structure\n",
    "print(graph_data)\n",
    "print(f\"Node features shape: {node_features_tensor.shape}\")\n",
    "print(f\"Edge index shape: {edge_index_tensor.shape}\")\n",
    "print(f\"Edge attributes shape: {edge_attr_tensor.shape}\")\n",
    "\n",
    "# Verification steps\n",
    "\n",
    "# Step 1: Visual Inspection\n",
    "print(\"Edge Index Sample:\\n\", edge_index_tensor[:, :10])\n",
    "\n",
    "# Step 2: Consistency Check\n",
    "num_nodes = node_features_tensor.size(0)\n",
    "if torch.max(edge_index_tensor) >= num_nodes:\n",
    "    print(\"Error: Edge index contains invalid node indices.\")\n",
    "else:\n",
    "    print(\"Edge index node indices are consistent with node features.\")\n",
    "\n",
    "# Step 3: Visualize the Graph using NetworkX\n",
    "plt.figure(figsize=(10, 8))\n",
    "pos = {node: (data['x'], data['y']) for node, data in G.nodes(data=True)}\n",
    "labels = {node: node for node in G.nodes()}\n",
    "nx.draw(G, pos, with_labels=True, labels=labels, node_color='skyblue', node_size=500, edge_color='k', linewidths=1, font_size=15, arrows=True)\n",
    "plt.title(\"Directed Network Graph of States and Grid Lines\")\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Compare with Original Data\n",
    "print(\"Original Edge List:\\n\", grid_df[['Source', 'Target']].head(10))\n",
    "print(\"Generated Edge Index:\\n\", edge_index_tensor[:, :10].numpy().T)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd72866-6092-4010-b858-dccffcf892cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a371242d-e8f3-4d07-aaef-30976217c36d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc8fff7c-8087-40ce-b523-531c5f7fce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train sequences tensor shape: torch.Size([27, 4367, 27])\n",
      "INFO:root:Validation sequences tensor shape: torch.Size([27, 2207, 27])\n",
      "INFO:root:Test sequences tensor shape: torch.Size([27, 2206, 27])\n",
      "INFO:root:Train targets tensor shape: torch.Size([27, 1])\n",
      "INFO:root:Validation targets tensor shape: torch.Size([27, 1])\n",
      "INFO:root:Test targets tensor shape: torch.Size([27, 1])\n"
     ]
    }
   ],
   "source": [
    "# Dynamic Data Preprocessing\n",
    "dynamic_data['datetime'] = pd.to_datetime(dynamic_data['datetime'])\n",
    "dynamic_data = dynamic_data.sort_values(by=['state', 'datetime'])\n",
    "dynamic_data['target_consumption'] = dynamic_data.groupby('state')['value'].shift(-1)\n",
    "dynamic_data = dynamic_data.dropna(subset=['target_consumption'])\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_data = dynamic_data[dynamic_data['datetime'] < '2020-07-01'].copy()\n",
    "val_data = dynamic_data[(dynamic_data['datetime'] >= '2020-07-01') & (dynamic_data['datetime'] < '2020-10-01')].copy()\n",
    "test_data = dynamic_data[dynamic_data['datetime'] >= '2020-10-01'].copy()\n",
    "\n",
    "# Create a time index for each dataset\n",
    "for data in [train_data, val_data, test_data]:\n",
    "    data.loc[:, 'time_index'] = (data['datetime'] - data['datetime'].min()).dt.total_seconds() // 3600\n",
    "    data.loc[:, 'time_index'] = data['time_index'].astype(int)\n",
    "\n",
    "# Determine a reasonable sequence length\n",
    "train_sequence_length = train_data.groupby('state').size().min() - 1\n",
    "val_sequence_length = val_data.groupby('state').size().min() - 1\n",
    "test_sequence_length = test_data.groupby('state').size().min() - 1\n",
    "\n",
    "# Fit a StandardScaler on the training data and transform all data sets\n",
    "scaler = StandardScaler()\n",
    "features_to_scale = ['value', 'pv', 'onw', 'ofw', 'TOTAL HOURLY RAIN (mm)(mean)', 'TOTAL HOURLY RAIN (mm)(std)',\n",
    "                     'ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(mean)', 'ATMOSPHERIC PRESSURE AT STATION LEVEL (mB)(std)',\n",
    "                     'GLOBAL RADIATION (KJ/m²)(mean)', 'GLOBAL RADIATION (KJ/m²)(std)', 'AIR TEMPERATURE (°C)(mean)', \n",
    "                     'AIR TEMPERATURE (°C)(std)', 'DEW POINT TEMPERATURE (°C)(mean)', 'DEW POINT TEMPERATURE (°C)(std)', \n",
    "                     'REL HUMIDITY FOR THE LAST HOUR (%)(mean)', 'REL HUMIDITY FOR THE LAST HOUR (%)(std)', \n",
    "                     'WIND DIRECTION (gr)(mean)', 'WIND DIRECTION (gr)(std)', 'WIND MAXIMUM GUST (m/s)(mean)', \n",
    "                     'WIND MAXIMUM GUST (m/s)(std)', 'WIND SPEED (m/s)(mean)', 'WIND SPEED (m/s)(std)', 'month', \n",
    "                     'day', 'hour', 'season', 'is_holiday', 'target_consumption']\n",
    "\n",
    "train_data[features_to_scale] = scaler.fit_transform(train_data[features_to_scale])\n",
    "val_data[features_to_scale] = scaler.transform(val_data[features_to_scale])\n",
    "test_data[features_to_scale] = scaler.transform(test_data[features_to_scale])\n",
    "\n",
    "def create_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    grouped = data.groupby('state')\n",
    "\n",
    "    for state, group in grouped:\n",
    "        group = group.sort_values(by='datetime')\n",
    "        values = group[features_to_scale[:-1]].values  # Exclude target_consumption from features\n",
    "        target_values = group['target_consumption'].values\n",
    "        if len(group) >= sequence_length + 1:  # Ensure there's enough data for at least one sequence\n",
    "            for i in range(len(group) - sequence_length):\n",
    "                seq = values[i:i + sequence_length]\n",
    "                tgt = target_values[i + sequence_length]  # Only the next hour's value as the target\n",
    "                sequences.append(seq)\n",
    "                targets.append(tgt)\n",
    "        else:\n",
    "            logging.warning(f\"Not enough data for state {state} to create sequences of length {sequence_length}\")\n",
    "\n",
    "    sequences_tensor = torch.tensor(np.array(sequences), dtype=torch.float)\n",
    "    targets_tensor = torch.tensor(np.array(targets), dtype=torch.float).unsqueeze(-1)  # Ensure targets have shape (batch_size, 1)\n",
    "\n",
    "    return sequences_tensor, targets_tensor\n",
    "\n",
    "# Create sequences and targets for train, validation, and test sets\n",
    "train_sequences_tensor, train_targets_tensor = create_sequences(train_data, train_sequence_length)\n",
    "val_sequences_tensor, val_targets_tensor = create_sequences(val_data, val_sequence_length)\n",
    "test_sequences_tensor, test_targets_tensor = create_sequences(test_data, test_sequence_length)\n",
    "\n",
    "# Log the shapes of the created tensors\n",
    "logging.info(f\"Train sequences tensor shape: {train_sequences_tensor.shape}\")\n",
    "logging.info(f\"Validation sequences tensor shape: {val_sequences_tensor.shape}\")\n",
    "logging.info(f\"Test sequences tensor shape: {test_sequences_tensor.shape}\")\n",
    "\n",
    "logging.info(f\"Train targets tensor shape: {train_targets_tensor.shape}\")\n",
    "logging.info(f\"Validation targets tensor shape: {val_targets_tensor.shape}\")\n",
    "logging.info(f\"Test targets tensor shape: {test_targets_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5bdea-12e5-4f8d-9367-a224e545c247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48753e1f-7acd-4e83-a37a-365c4442c97d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b73ab139-092e-49d4-b485-49d7d94ab84d",
   "metadata": {},
   "source": [
    "## LSTM-GAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8175a62-5fb6-4d1e-8243-13c3970439ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efc633f0-49fe-4c0b-9f09-466285ec99e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 1/100, Train Loss: 1.2501428127288818, Val Loss: 0.21273615956306458\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.1875948905944824, Val Loss: 0.21265943348407745\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.182298183441162, Val Loss: 0.21212483942508698\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.1902509927749634, Val Loss: 0.21054977178573608\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.2005867958068848, Val Loss: 0.21048378944396973\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.186819076538086, Val Loss: 0.21073009073734283\n",
      "INFO:root:Epoch 7/100, Train Loss: 1.167364239692688, Val Loss: 0.2097870409488678\n",
      "INFO:root:Epoch 8/100, Train Loss: 1.1452869176864624, Val Loss: 0.20914912223815918\n",
      "INFO:root:Epoch 9/100, Train Loss: 1.0524779558181763, Val Loss: 0.2064506858587265\n",
      "INFO:root:Epoch 10/100, Train Loss: 1.0970128774642944, Val Loss: 0.20518778264522552\n",
      "INFO:root:Epoch 11/100, Train Loss: 1.0787626504898071, Val Loss: 0.20441295206546783\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.9714926481246948, Val Loss: 0.20251844823360443\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.9326176047325134, Val Loss: 0.20034314692020416\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.8961759805679321, Val Loss: 0.19878435134887695\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.8026695251464844, Val Loss: 0.19522954523563385\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.817661464214325, Val Loss: 0.19240006804466248\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.7765264511108398, Val Loss: 0.1881839781999588\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.6577982306480408, Val Loss: 0.18197186291217804\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.5727893114089966, Val Loss: 0.17714890837669373\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.5708097815513611, Val Loss: 0.17281979322433472\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.5398666262626648, Val Loss: 0.16627237200737\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.49589797854423523, Val Loss: 0.1604587733745575\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.40308353304862976, Val Loss: 0.15452775359153748\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.39365601539611816, Val Loss: 0.1499624252319336\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.3476214110851288, Val Loss: 0.14535725116729736\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.2858569920063019, Val Loss: 0.14113762974739075\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.2742707133293152, Val Loss: 0.13598819077014923\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.2509174346923828, Val Loss: 0.131586953997612\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.21994969248771667, Val Loss: 0.1282135546207428\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.2107909917831421, Val Loss: 0.12452401220798492\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.19666463136672974, Val Loss: 0.1213519498705864\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.20621474087238312, Val Loss: 0.11933746188879013\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.18388833105564117, Val Loss: 0.11634301394224167\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.18383687734603882, Val Loss: 0.11418966948986053\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.17326444387435913, Val Loss: 0.1115739643573761\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.15712977945804596, Val Loss: 0.10896230489015579\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.1544654667377472, Val Loss: 0.10700695961713791\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.1635889708995819, Val Loss: 0.1040615662932396\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.14467011392116547, Val Loss: 0.10117863118648529\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.14130820333957672, Val Loss: 0.09813272953033447\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.13242162764072418, Val Loss: 0.09543771296739578\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.14713673293590546, Val Loss: 0.09316718578338623\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.1365477740764618, Val Loss: 0.09057002514600754\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.13099154829978943, Val Loss: 0.08785069733858109\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.135655477643013, Val Loss: 0.08560892939567566\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.12573827803134918, Val Loss: 0.08365114778280258\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.12545549869537354, Val Loss: 0.08124703913927078\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.11584115773439407, Val Loss: 0.07879728823900223\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.11233431100845337, Val Loss: 0.07700606435537338\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.11112213134765625, Val Loss: 0.07536513358354568\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.09442076832056046, Val Loss: 0.07359655201435089\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.11425080895423889, Val Loss: 0.07159050554037094\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.10234343260526657, Val Loss: 0.06973183900117874\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.11315006762742996, Val Loss: 0.06876526027917862\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.09383343160152435, Val Loss: 0.06777285784482956\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.09938619285821915, Val Loss: 0.06674815714359283\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.10236441344022751, Val Loss: 0.06600473821163177\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.10446184128522873, Val Loss: 0.06542818248271942\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.09843955934047699, Val Loss: 0.06495700776576996\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.11085574328899384, Val Loss: 0.06405799835920334\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.09762229770421982, Val Loss: 0.06340580433607101\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.09357098489999771, Val Loss: 0.06276705116033554\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.08461862802505493, Val Loss: 0.061495933681726456\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.08304087072610855, Val Loss: 0.059917304664850235\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.09029804915189743, Val Loss: 0.05917711183428764\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.08915551751852036, Val Loss: 0.05822751671075821\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.088871069252491, Val Loss: 0.05742033198475838\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.09718605130910873, Val Loss: 0.05614984408020973\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.0807737410068512, Val Loss: 0.055626291781663895\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.0810299813747406, Val Loss: 0.05481681227684021\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.08817655593156815, Val Loss: 0.05414354056119919\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.09193246066570282, Val Loss: 0.053678665310144424\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.09229211509227753, Val Loss: 0.05326806753873825\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.08971422910690308, Val Loss: 0.052987392991781235\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.09001226723194122, Val Loss: 0.05298697575926781\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.09538727253675461, Val Loss: 0.052402839064598083\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.09953822940587997, Val Loss: 0.053262170404195786\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.07812218368053436, Val Loss: 0.053681716322898865\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.0934220626950264, Val Loss: 0.05299372598528862\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.09106908738613129, Val Loss: 0.053667422384023666\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.07775061577558517, Val Loss: 0.05375802144408226\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.08973174542188644, Val Loss: 0.05394044890999794\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.08762717992067337, Val Loss: 0.05403351038694382\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.09104584157466888, Val Loss: 0.05506889894604683\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.07564078271389008, Val Loss: 0.055330730974674225\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.08188266307115555, Val Loss: 0.055269259959459305\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.08020179718732834, Val Loss: 0.05575048178434372\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.09246429055929184, Val Loss: 0.05597164109349251\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.0919715017080307, Val Loss: 0.055303409695625305\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.09360568970441818, Val Loss: 0.0551605187356472\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.09040839970111847, Val Loss: 0.05562376230955124\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.08741878718137741, Val Loss: 0.05470484867691994\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.10085208714008331, Val Loss: 0.055369071662425995\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.08430574089288712, Val Loss: 0.05483285337686539\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.09486262500286102, Val Loss: 0.05518186837434769\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.07939159870147705, Val Loss: 0.05517435073852539\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.1404695212841034, Val Loss: 0.016312096267938614\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.13390032947063446, Val Loss: 0.016180727630853653\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.12366200983524323, Val Loss: 0.01620623841881752\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.12807106971740723, Val Loss: 0.016359826549887657\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.11173464357852936, Val Loss: 0.016489015892148018\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.12036846578121185, Val Loss: 0.016685033217072487\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.12279180437326431, Val Loss: 0.01690477691590786\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.14217886328697205, Val Loss: 0.01714814081788063\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.12649303674697876, Val Loss: 0.017441704869270325\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.11022166907787323, Val Loss: 0.017905905842781067\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.10696955025196075, Val Loss: 0.01838092692196369\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.11626436561346054, Val Loss: 0.018998688086867332\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.11835098266601562, Val Loss: 0.0198966171592474\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.12022095173597336, Val Loss: 0.021249491721391678\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.1038476973772049, Val Loss: 0.022429972887039185\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.11127914488315582, Val Loss: 0.024308660998940468\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.09380625933408737, Val Loss: 0.026125051081180573\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.10217469930648804, Val Loss: 0.0280135627835989\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.09026014804840088, Val Loss: 0.03001602552831173\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.09393218904733658, Val Loss: 0.030638977885246277\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.11743773519992828, Val Loss: 0.030631953850388527\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.08714231848716736, Val Loss: 0.030397968366742134\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.13461460173130035, Val Loss: 0.00858316384255886\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.13379240036010742, Val Loss: 0.008915613405406475\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.14054423570632935, Val Loss: 0.009177258238196373\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.1270798295736313, Val Loss: 0.009374171495437622\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.12668642401695251, Val Loss: 0.009459121152758598\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.13645750284194946, Val Loss: 0.009595992974936962\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.1338275671005249, Val Loss: 0.009551659226417542\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.14107279479503632, Val Loss: 0.009608177468180656\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.12235064804553986, Val Loss: 0.00968530960381031\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.11375809460878372, Val Loss: 0.009912880137562752\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.12735679745674133, Val Loss: 0.01001935638487339\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.11660930514335632, Val Loss: 0.010067461058497429\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.1168624758720398, Val Loss: 0.010238456539809704\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.09958063066005707, Val Loss: 0.010590031743049622\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.1117323786020279, Val Loss: 0.01124618947505951\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.08928211033344269, Val Loss: 0.01198403537273407\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.1019926443696022, Val Loss: 0.012693054974079132\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.0932735875248909, Val Loss: 0.013773255050182343\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.10176970064640045, Val Loss: 0.0147365378215909\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.09792042523622513, Val Loss: 0.015833405777812004\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.08968960493803024, Val Loss: 0.017014961689710617\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.1687682718038559, Val Loss: 0.04894094541668892\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.11838924139738083, Val Loss: 0.021307341754436493\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.032042796909809115, 'rmse': 0.1674833756622471, 'mae': 0.13976475298404695, 'mape': 47.43305683135986, 'r2': 0.8082156078389788}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.0437848567962646, Val Loss: 0.19314180314540863\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.7843017578125, Val Loss: 0.19262057542800903\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.5390803217887878, Val Loss: 0.1918768435716629\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.6205492615699768, Val Loss: 0.19208985567092896\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.5357415080070496, Val Loss: 0.19164030253887177\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.320607990026474, Val Loss: 0.19085144996643066\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.24482427537441254, Val Loss: 0.19053775072097778\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.2926187813282013, Val Loss: 0.18952496349811554\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.27373236417770386, Val Loss: 0.18841028213500977\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.32400795817375183, Val Loss: 0.18691958487033844\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.30616044998168945, Val Loss: 0.1860506534576416\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.3191022276878357, Val Loss: 0.1852322220802307\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.24179211258888245, Val Loss: 0.18520358204841614\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.1901557594537735, Val Loss: 0.18506434559822083\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.16004283726215363, Val Loss: 0.18447205424308777\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.18442559242248535, Val Loss: 0.18409007787704468\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.235049769282341, Val Loss: 0.18219143152236938\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.13840757310390472, Val Loss: 0.17971010506153107\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.20570330321788788, Val Loss: 0.17891156673431396\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.13193824887275696, Val Loss: 0.17857038974761963\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.09217026084661484, Val Loss: 0.1786479651927948\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.10065944492816925, Val Loss: 0.1786584109067917\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.14426937699317932, Val Loss: 0.17693254351615906\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.0887606292963028, Val Loss: 0.1749035269021988\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.10706676542758942, Val Loss: 0.17031653225421906\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.07751797139644623, Val Loss: 0.16397716104984283\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.07183098793029785, Val Loss: 0.1586996167898178\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.07707886397838593, Val Loss: 0.1542014628648758\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.08129569888114929, Val Loss: 0.15009568631649017\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.04139196500182152, Val Loss: 0.14678335189819336\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.04846149682998657, Val Loss: 0.1447487771511078\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.05207252502441406, Val Loss: 0.14218156039714813\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.0382566973567009, Val Loss: 0.1407497525215149\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.04746679961681366, Val Loss: 0.14007799327373505\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.06667158007621765, Val Loss: 0.13909201323986053\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.039815206080675125, Val Loss: 0.13665664196014404\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.03614988550543785, Val Loss: 0.13454203307628632\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.0332205556333065, Val Loss: 0.13158918917179108\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.033644046634435654, Val Loss: 0.12908269464969635\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.03573903441429138, Val Loss: 0.12607449293136597\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.03465370461344719, Val Loss: 0.12354199588298798\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.034354064613580704, Val Loss: 0.12188880890607834\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.024530671536922455, Val Loss: 0.11956766992807388\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.03629680350422859, Val Loss: 0.11796306073665619\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.023339292034506798, Val Loss: 0.11726172268390656\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.029025698080658913, Val Loss: 0.11576240509748459\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.032184235751628876, Val Loss: 0.11211986094713211\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.023861970752477646, Val Loss: 0.10707852989435196\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.02272244170308113, Val Loss: 0.10181184858083725\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.018194230273365974, Val Loss: 0.09801387041807175\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.016499806195497513, Val Loss: 0.09408219158649445\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.0277586467564106, Val Loss: 0.09033803641796112\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.018849674612283707, Val Loss: 0.08701908588409424\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.024508493021130562, Val Loss: 0.08429750055074692\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.01877821423113346, Val Loss: 0.08200157433748245\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.018429208546876907, Val Loss: 0.07895538210868835\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.02155640721321106, Val Loss: 0.07559110969305038\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.014575958251953125, Val Loss: 0.07191716134548187\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.02241206355392933, Val Loss: 0.0678851306438446\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.01723766326904297, Val Loss: 0.0637417659163475\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.025939147919416428, Val Loss: 0.058806877583265305\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.02053380198776722, Val Loss: 0.053818266838788986\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.01723799668252468, Val Loss: 0.04942488297820091\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.01929466612637043, Val Loss: 0.04605989530682564\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.015825221315026283, Val Loss: 0.043432630598545074\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.015669256448745728, Val Loss: 0.040774066001176834\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.011867746710777283, Val Loss: 0.03838837519288063\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.01581081561744213, Val Loss: 0.03633583337068558\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.024206040427088737, Val Loss: 0.034487828612327576\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.01408414077013731, Val Loss: 0.03318256512284279\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.02030819281935692, Val Loss: 0.03189435973763466\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.01699046790599823, Val Loss: 0.03027956373989582\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.014018664136528969, Val Loss: 0.028364961966872215\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.020550338551402092, Val Loss: 0.02679639682173729\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.017213625833392143, Val Loss: 0.02508397400379181\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.016258327290415764, Val Loss: 0.023464487865567207\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.012639016844332218, Val Loss: 0.02239358052611351\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.02033415250480175, Val Loss: 0.021526621654629707\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.014092917554080486, Val Loss: 0.021028093993663788\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.016460303217172623, Val Loss: 0.020694568753242493\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.018412863835692406, Val Loss: 0.020594628527760506\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.014374925754964352, Val Loss: 0.02086677961051464\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.015524109825491905, Val Loss: 0.021209487691521645\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.018112152814865112, Val Loss: 0.02179887890815735\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.017687963321805, Val Loss: 0.022188276052474976\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.014787569642066956, Val Loss: 0.022731931880116463\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.012921767309308052, Val Loss: 0.023318711668252945\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.015995057299733162, Val Loss: 0.02408645674586296\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.01566271111369133, Val Loss: 0.02387591451406479\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.014780652709305286, Val Loss: 0.024419227614998817\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.01601656898856163, Val Loss: 0.025004958733916283\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.015252894721925259, Val Loss: 0.025257881730794907\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.011652020737528801, Val Loss: 0.02585674449801445\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.01372344046831131, Val Loss: 0.02645118162035942\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.01369644794613123, Val Loss: 0.02736806869506836\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.015769386664032936, Val Loss: 0.026845108717679977\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.019578717648983, Val Loss: 0.02804531902074814\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.01731204055249691, Val Loss: 0.028501950204372406\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.016719099134206772, Val Loss: 0.029128246009349823\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.013241282664239407, Val Loss: 0.028934741392731667\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.02214311808347702, Val Loss: 0.017717745155096054\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.019308950752019882, Val Loss: 0.017162783071398735\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.018962513655424118, Val Loss: 0.016497492790222168\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.019396718591451645, Val Loss: 0.01629197970032692\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.032643500715494156, Val Loss: 0.015571505762636662\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.020187485963106155, Val Loss: 0.015486884862184525\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.024284886196255684, Val Loss: 0.015344822779297829\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.029020974412560463, Val Loss: 0.01548656914383173\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.016198715195059776, Val Loss: 0.015348033048212528\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.01865927316248417, Val Loss: 0.015560571104288101\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.018076878041028976, Val Loss: 0.014981761574745178\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.024875039234757423, Val Loss: 0.013751164078712463\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.0180080384016037, Val Loss: 0.013006996363401413\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.020794136449694633, Val Loss: 0.011231775395572186\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.022427497431635857, Val Loss: 0.009537704288959503\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.021779675036668777, Val Loss: 0.008202019147574902\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.020089030265808105, Val Loss: 0.00724816182628274\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.02214832417666912, Val Loss: 0.006787738762795925\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.02097390778362751, Val Loss: 0.005989935714751482\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.01967984437942505, Val Loss: 0.008831252343952656\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.024862803518772125, Val Loss: 0.009762517176568508\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.02485302835702896, Val Loss: 0.007145553361624479\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.020591765642166138, Val Loss: 0.011601230129599571\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.022908339276909828, Val Loss: 0.011550799943506718\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.017515067011117935, Val Loss: 0.010768654756247997\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.014666368253529072, Val Loss: 0.013073522597551346\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.019964946433901787, Val Loss: 0.011637881398200989\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.016119666397571564, Val Loss: 0.00874805636703968\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.015596836805343628, Val Loss: 0.006284911651164293\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.017052890732884407, Val Loss: 0.007837743498384953\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.016403375193476677, Val Loss: 0.012546851299703121\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.011433475650846958, Val Loss: 0.016308946534991264\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.014406545087695122, Val Loss: 0.02160847932100296\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.01577884703874588, Val Loss: 0.021168116480112076\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.02147585339844227, Val Loss: 0.01712370477616787\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.01864205114543438, Val Loss: 0.012665879912674427\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.012803931720554829, Val Loss: 0.009416974149644375\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.016794174909591675, Val Loss: 0.008371362462639809\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.01784648932516575, Val Loss: 0.009565934538841248\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.01507321372628212, Val Loss: 0.005836079828441143\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.015568156726658344, Val Loss: 0.005182381719350815\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.016939470544457436, Val Loss: 0.004937261343002319\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.02310991659760475, Val Loss: 0.004953584633767605\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.020927315577864647, Val Loss: 0.00459751533344388\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.02394581027328968, Val Loss: 0.004309827461838722\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.019262762740254402, Val Loss: 0.003989937715232372\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.018445584923028946, Val Loss: 0.003937298897653818\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.021084733307361603, Val Loss: 0.003991220146417618\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.016862129792571068, Val Loss: 0.004322583321481943\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.02434467524290085, Val Loss: 0.0047105420380830765\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.018412897363305092, Val Loss: 0.005983351264148951\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.023658091202378273, Val Loss: 0.0069725471548736095\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.019582439213991165, Val Loss: 0.008487970568239689\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.023946315050125122, Val Loss: 0.008728168904781342\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.018423041328787804, Val Loss: 0.007259864825755358\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.021375242620706558, Val Loss: 0.005339379888027906\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.01490769162774086, Val Loss: 0.0028259705286473036\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.018059909343719482, Val Loss: 0.0028108200058341026\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.023078305646777153, Val Loss: 0.004232695791870356\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.017601240426301956, Val Loss: 0.007450671400874853\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.016295934095978737, Val Loss: 0.011793261393904686\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.01853187009692192, Val Loss: 0.011048185639083385\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.017761142924427986, Val Loss: 0.008309575729072094\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.017186516895890236, Val Loss: 0.00449829688295722\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.018846560269594193, Val Loss: 0.0031127973925322294\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.017893031239509583, Val Loss: 0.003841159865260124\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.024792708456516266, Val Loss: 0.005857347976416349\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.014126920141279697, Val Loss: 0.007702528033405542\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.017065009102225304, Val Loss: 0.012068979442119598\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.024764716625213623, Val Loss: 0.004958994220942259\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.01773230917751789, Val Loss: 0.0075058299116790295\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.019706271588802338, Val Loss: 0.011689535342156887\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.019695911556482315, Val Loss: 0.007822543382644653\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.016935234889388084, Val Loss: 0.012219231575727463\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.01714904233813286, Val Loss: 0.014153238385915756\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.016261426731944084, Val Loss: 0.006547883618623018\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.017754245549440384, Val Loss: 0.003384507028385997\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.01796824112534523, Val Loss: 0.004878295585513115\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.23938249051570892, Val Loss: 0.03217429667711258\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.020301776006817818, Val Loss: 0.0029595778323709965\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.007779050478711724, 'rmse': 0.08180401687486913, 'mae': 0.0627930998802185, 'mape': 36.35398983955383, 'r2': 0.9307164696083576}\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.6243485808372498, Val Loss: 0.2184174805879593\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.6127982139587402, Val Loss: 0.21723806858062744\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.7143784761428833, Val Loss: 0.21630555391311646\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.5063400268554688, Val Loss: 0.21588969230651855\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.426948606967926, Val Loss: 0.21517127752304077\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.3478175103664398, Val Loss: 0.21503493189811707\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.1996341049671173, Val Loss: 0.2148686945438385\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.21696145832538605, Val Loss: 0.21433573961257935\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.24162757396697998, Val Loss: 0.21255238354206085\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.22386501729488373, Val Loss: 0.21092040836811066\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.2573546767234802, Val Loss: 0.2076389193534851\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.30281832814216614, Val Loss: 0.20499053597450256\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.2513231635093689, Val Loss: 0.20262491703033447\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.20303001999855042, Val Loss: 0.20266662538051605\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.16158567368984222, Val Loss: 0.20274803042411804\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.09768025577068329, Val Loss: 0.20471589267253876\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.1435641497373581, Val Loss: 0.20560228824615479\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.14368148148059845, Val Loss: 0.2063649743795395\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.147511824965477, Val Loss: 0.2057085931301117\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.14559306204319, Val Loss: 0.20114290714263916\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.07518625259399414, Val Loss: 0.19613924622535706\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.13186489045619965, Val Loss: 0.18939174711704254\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.07959461957216263, Val Loss: 0.1839735209941864\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.06560888886451721, Val Loss: 0.17892436683177948\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.05627899244427681, Val Loss: 0.17513369023799896\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.08480635285377502, Val Loss: 0.17071466147899628\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.056173380464315414, Val Loss: 0.16616728901863098\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.04567483812570572, Val Loss: 0.16203035414218903\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.05777615308761597, Val Loss: 0.16123446822166443\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.04611288756132126, Val Loss: 0.1611984223127365\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.04235958307981491, Val Loss: 0.1600840985774994\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.04993027448654175, Val Loss: 0.15612797439098358\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.04281073063611984, Val Loss: 0.14847519993782043\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.04531297832727432, Val Loss: 0.13973362743854523\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.046881403774023056, Val Loss: 0.1336400806903839\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.03863196074962616, Val Loss: 0.13194862008094788\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.03243725746870041, Val Loss: 0.13140711188316345\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.03896591439843178, Val Loss: 0.1290988177061081\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.03107891045510769, Val Loss: 0.12459178268909454\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.02742377296090126, Val Loss: 0.12024100124835968\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.03240096941590309, Val Loss: 0.11371546983718872\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.031462110579013824, Val Loss: 0.10883518308401108\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.035865459591150284, Val Loss: 0.10615839809179306\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.029787937179207802, Val Loss: 0.10404610633850098\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.023062946274876595, Val Loss: 0.1014171689748764\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.022779589518904686, Val Loss: 0.09850537776947021\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.027428600937128067, Val Loss: 0.09444122016429901\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.03160561993718147, Val Loss: 0.09109265357255936\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.02728731743991375, Val Loss: 0.08661923557519913\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.020471841096878052, Val Loss: 0.08267974108457565\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.02325509488582611, Val Loss: 0.07989590615034103\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.01869003102183342, Val Loss: 0.07813698798418045\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.021854957565665245, Val Loss: 0.07555489242076874\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.017937274649739265, Val Loss: 0.0733678936958313\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.02154475636780262, Val Loss: 0.07045842707157135\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.024918917566537857, Val Loss: 0.06676340103149414\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.025006823241710663, Val Loss: 0.06250852346420288\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.020871976390480995, Val Loss: 0.05835532024502754\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.019872570410370827, Val Loss: 0.05482105538249016\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.0162051972001791, Val Loss: 0.051696036010980606\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.020933473482728004, Val Loss: 0.0484592542052269\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.024284036830067635, Val Loss: 0.04569492116570473\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.017160343006253242, Val Loss: 0.043473049998283386\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.02388845756649971, Val Loss: 0.04195648059248924\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.02369869500398636, Val Loss: 0.04105658456683159\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.02064666524529457, Val Loss: 0.03955882787704468\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.020577579736709595, Val Loss: 0.03839768469333649\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.020087197422981262, Val Loss: 0.03636322543025017\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.022227440029382706, Val Loss: 0.03520486503839493\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.020420359447598457, Val Loss: 0.0329686738550663\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.01685241423547268, Val Loss: 0.030454376712441444\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.02037302777171135, Val Loss: 0.028931068256497383\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.01960035227239132, Val Loss: 0.027547482401132584\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.020364319905638695, Val Loss: 0.02655753493309021\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.02268279902637005, Val Loss: 0.025933563709259033\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.017092986032366753, Val Loss: 0.02519046887755394\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.016699962317943573, Val Loss: 0.024312354624271393\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.01858760602772236, Val Loss: 0.02351532131433487\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.01671578176319599, Val Loss: 0.022568849846720695\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.021694598719477654, Val Loss: 0.0221022330224514\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.017613952979445457, Val Loss: 0.021723106503486633\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.023208530619740486, Val Loss: 0.02101699262857437\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.023482654243707657, Val Loss: 0.020778529345989227\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.020567636936903, Val Loss: 0.02018689177930355\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.018762346357107162, Val Loss: 0.01995563693344593\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.014448312111198902, Val Loss: 0.01929275132715702\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.014034236781299114, Val Loss: 0.019291695207357407\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.018245859071612358, Val Loss: 0.01820976287126541\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.019993308931589127, Val Loss: 0.01805383525788784\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.016981355845928192, Val Loss: 0.01786746457219124\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.018041934818029404, Val Loss: 0.017735037952661514\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.019489221274852753, Val Loss: 0.017559675499796867\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.0155660854652524, Val Loss: 0.01705036871135235\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.016583152115345, Val Loss: 0.01662992127239704\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.01887385919690132, Val Loss: 0.016533855348825455\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.014947989955544472, Val Loss: 0.016250871121883392\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.015806861221790314, Val Loss: 0.016265831887722015\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.020307909697294235, Val Loss: 0.016393067315220833\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.02382354438304901, Val Loss: 0.016303671523928642\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.015021809376776218, Val Loss: 0.01613369956612587\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.01794189028441906, Val Loss: 0.0031133554875850677\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.01995369978249073, Val Loss: 0.003047152189537883\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.020358001813292503, Val Loss: 0.0029795377049595118\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.0209719967097044, Val Loss: 0.0030315713956952095\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.02109314315021038, Val Loss: 0.002921775449067354\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.021405117586255074, Val Loss: 0.0028572496958076954\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.020943330600857735, Val Loss: 0.0027267823461443186\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.023130331188440323, Val Loss: 0.002508060773834586\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.017815876752138138, Val Loss: 0.002595358295366168\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.025385523214936256, Val Loss: 0.0026264465413987637\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.02313757874071598, Val Loss: 0.0026070165913552046\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.017527753487229347, Val Loss: 0.002747997408732772\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.01691875420510769, Val Loss: 0.00329021830111742\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.023638969287276268, Val Loss: 0.003540954552590847\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.02356589026749134, Val Loss: 0.003751816228032112\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.016827059909701347, Val Loss: 0.0033557815477252007\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.017352838069200516, Val Loss: 0.003282207064330578\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.02012527547776699, Val Loss: 0.003016655333340168\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.020505815744400024, Val Loss: 0.0028510713018476963\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.017713304609060287, Val Loss: 0.003080356866121292\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.021334731951355934, Val Loss: 0.00358643289655447\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.01261088065803051, Val Loss: 0.0047342004254460335\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.015397635288536549, Val Loss: 0.004459702875465155\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.015848815441131592, Val Loss: 0.003707435680553317\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.017371652647852898, Val Loss: 0.003248210996389389\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.016212239861488342, Val Loss: 0.0033559829462319613\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.021792544052004814, Val Loss: 0.0036176105495542288\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.017454341053962708, Val Loss: 0.003975850064307451\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.017645003274083138, Val Loss: 0.001075252308510244\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.020144138485193253, Val Loss: 0.0009967390215024352\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.019921813160181046, Val Loss: 0.0009668687707744539\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.017832020297646523, Val Loss: 0.0010261749848723412\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.0230033528059721, Val Loss: 0.0010372729739174247\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.020177319645881653, Val Loss: 0.0010453384602442384\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.021647723391652107, Val Loss: 0.0011085097212344408\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.019890613853931427, Val Loss: 0.001139165717177093\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.022945398464798927, Val Loss: 0.0011370530119165778\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.020982693880796432, Val Loss: 0.0011705758515745401\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.018308551982045174, Val Loss: 0.0012785880826413631\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.016404349356889725, Val Loss: 0.0016495798481628299\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.0181872695684433, Val Loss: 0.001997671090066433\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.016267303377389908, Val Loss: 0.00274664000608027\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.02018711343407631, Val Loss: 0.0033240788616240025\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.02058977261185646, Val Loss: 0.0035831124987453222\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.01883201114833355, Val Loss: 0.0034594477619975805\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.01793632097542286, Val Loss: 0.0030464932788163424\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.01664978265762329, Val Loss: 0.003309488296508789\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.01737428642809391, Val Loss: 0.003784595988690853\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.013940252363681793, Val Loss: 0.003820076584815979\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.015091309323906898, Val Loss: 0.003921213559806347\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.018662279471755028, Val Loss: 0.004668659996241331\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.1837681084871292, Val Loss: 0.004271022509783506\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.028536247089505196, Val Loss: 0.0025577216874808073\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.005018480063881725, 'rmse': 0.06256193856251183, 'mae': 0.05098659060895443, 'mape': 16.569924354553223, 'r2': 0.9535238961668385}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.227638602256775, Val Loss: 0.1956970989704132\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.179488182067871, Val Loss: 0.1958930939435959\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.0653873682022095, Val Loss: 0.1937716007232666\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.8460184931755066, Val Loss: 0.19053487479686737\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.6525709629058838, Val Loss: 0.18707901239395142\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.4625282883644104, Val Loss: 0.18256783485412598\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.33441609144210815, Val Loss: 0.17487238347530365\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.22206728160381317, Val Loss: 0.16754697263240814\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.2200964242219925, Val Loss: 0.15967053174972534\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.2563988268375397, Val Loss: 0.1486792415380478\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.3672083914279938, Val Loss: 0.14032356441020966\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.4439404606819153, Val Loss: 0.13152626156806946\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.4711533486843109, Val Loss: 0.12467817962169647\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.3605075180530548, Val Loss: 0.11967149376869202\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.2825016975402832, Val Loss: 0.1154947429895401\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.1829860806465149, Val Loss: 0.11526456475257874\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.13735274970531464, Val Loss: 0.11562556028366089\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.12888137996196747, Val Loss: 0.11609124392271042\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.15649272501468658, Val Loss: 0.11682193726301193\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.19066911935806274, Val Loss: 0.11640036851167679\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.1701916605234146, Val Loss: 0.11055270582437515\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.1572445183992386, Val Loss: 0.10385072976350784\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.1037139818072319, Val Loss: 0.09781072288751602\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.08903522044420242, Val Loss: 0.09434667974710464\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.06791075319051743, Val Loss: 0.09500196576118469\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.07432008534669876, Val Loss: 0.09739412367343903\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.07245706021785736, Val Loss: 0.09973229467868805\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.06914790719747543, Val Loss: 0.09952280670404434\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.07257957011461258, Val Loss: 0.09535086899995804\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.06492682546377182, Val Loss: 0.08706054091453552\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.05147562548518181, Val Loss: 0.0763460248708725\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.04186609387397766, Val Loss: 0.06761299073696136\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.04005087539553642, Val Loss: 0.060736119747161865\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.05037359893321991, Val Loss: 0.0572764091193676\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.042794760316610336, Val Loss: 0.05586801841855049\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.03698812425136566, Val Loss: 0.05427434667944908\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.03378366306424141, Val Loss: 0.052506860345602036\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.031091202050447464, Val Loss: 0.04986405000090599\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.02712494321167469, Val Loss: 0.046409972012043\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.029069429263472557, Val Loss: 0.04204294830560684\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.029884010553359985, Val Loss: 0.03766288980841637\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.029525374993681908, Val Loss: 0.03351708501577377\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.029809314757585526, Val Loss: 0.030108455568552017\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.02532535046339035, Val Loss: 0.028293177485466003\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.025262001901865005, Val Loss: 0.027683308348059654\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.02371281385421753, Val Loss: 0.0274271909147501\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.022283125668764114, Val Loss: 0.02716718427836895\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.025644449517130852, Val Loss: 0.02592054381966591\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.02095806784927845, Val Loss: 0.024690905585885048\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.024497872218489647, Val Loss: 0.0226629376411438\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.021275928243994713, Val Loss: 0.021309752017259598\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.017626648768782616, Val Loss: 0.019838297739624977\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.022037360817193985, Val Loss: 0.018673153594136238\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.018331166356801987, Val Loss: 0.017725806683301926\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.022275708615779877, Val Loss: 0.01708550564944744\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.01685507968068123, Val Loss: 0.016785183921456337\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.01975322887301445, Val Loss: 0.01678449660539627\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.018283486366271973, Val Loss: 0.016730541363358498\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.01605459675192833, Val Loss: 0.01693405769765377\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.019714808091521263, Val Loss: 0.017312489449977875\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.018829146400094032, Val Loss: 0.017649205401539803\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.01910581812262535, Val Loss: 0.017924165353178978\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.020083073526620865, Val Loss: 0.01777656376361847\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.017886783927679062, Val Loss: 0.01768426224589348\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.018697410821914673, Val Loss: 0.017757177352905273\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.014934847131371498, Val Loss: 0.01782194897532463\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.017286770045757294, Val Loss: 0.017736855894327164\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.015285246074199677, Val Loss: 0.01743873953819275\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.017251094803214073, Val Loss: 0.016992485150694847\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.017524411901831627, Val Loss: 0.01664154604077339\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.018085652962327003, Val Loss: 0.016314690932631493\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.017255917191505432, Val Loss: 0.015902848914265633\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.016602898016572, Val Loss: 0.01573331281542778\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.016242126002907753, Val Loss: 0.015437338501214981\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.015131855383515358, Val Loss: 0.015408703126013279\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.01635901629924774, Val Loss: 0.015329918824136257\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.014797144569456577, Val Loss: 0.015460168942809105\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.015604902990162373, Val Loss: 0.015835117548704147\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.013937419280409813, Val Loss: 0.015850139781832695\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.014217304065823555, Val Loss: 0.016027802601456642\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.01634589210152626, Val Loss: 0.016421783715486526\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.014725719578564167, Val Loss: 0.016570117324590683\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.015448051504790783, Val Loss: 0.01674775406718254\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.016906440258026123, Val Loss: 0.016725046560168266\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.017756076529622078, Val Loss: 0.016571596264839172\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.013812009245157242, Val Loss: 0.01661841757595539\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.016015665605664253, Val Loss: 0.016576657071709633\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.014724627137184143, Val Loss: 0.01644887961447239\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.01605781726539135, Val Loss: 0.016095571219921112\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.014289453625679016, Val Loss: 0.016032889485359192\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.013890395872294903, Val Loss: 0.01647092215716839\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.015829432755708694, Val Loss: 0.01620195433497429\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.014286000281572342, Val Loss: 0.016141435131430626\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.014996351674199104, Val Loss: 0.016031954437494278\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.01429810095578432, Val Loss: 0.015888724476099014\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.014813321642577648, Val Loss: 0.015942536294460297\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.02759231999516487, Val Loss: 0.0013827934162691236\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.0268943440169096, Val Loss: 0.0014085454167798162\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.022571396082639694, Val Loss: 0.0014068352757021785\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.025625543668866158, Val Loss: 0.0013983261305838823\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.022707996889948845, Val Loss: 0.001360091962851584\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.021923892199993134, Val Loss: 0.0013021600898355246\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.02294807881116867, Val Loss: 0.0011928644962608814\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.02266027219593525, Val Loss: 0.0011285672662779689\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.020092660561203957, Val Loss: 0.001098704757168889\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.0198663417249918, Val Loss: 0.0011434780899435282\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.02007133886218071, Val Loss: 0.0013034878065809608\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.0191957950592041, Val Loss: 0.001572659588418901\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.021525586023926735, Val Loss: 0.001907665398903191\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.019618120044469833, Val Loss: 0.0019874039571732283\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.02129223756492138, Val Loss: 0.0019653772469609976\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.02040211111307144, Val Loss: 0.0017304506618529558\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.018329758197069168, Val Loss: 0.0015184469521045685\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.01749628596007824, Val Loss: 0.0015579208265990019\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.017182817682623863, Val Loss: 0.0017139761475846171\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.01877043955028057, Val Loss: 0.0019335385877639055\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.014780065976083279, Val Loss: 0.0019491686252877116\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.01521843858063221, Val Loss: 0.0017838471103459597\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.017181556671857834, Val Loss: 0.0012634153245016932\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.016582222655415535, Val Loss: 0.0008463943377137184\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.01584998331964016, Val Loss: 0.0016913842409849167\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.01403846126049757, Val Loss: 0.0012326709693297744\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.012913516722619534, Val Loss: 0.0011185581097379327\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.014164535328745842, Val Loss: 0.0014750913251191378\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.012553904205560684, Val Loss: 0.0012816657545045018\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.012552798725664616, Val Loss: 0.0015051835216581821\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.014233886264264584, Val Loss: 0.0014432716416195035\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.012209960259497166, Val Loss: 0.0013598025543615222\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.012049591168761253, Val Loss: 0.0013061220524832606\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.012958541512489319, Val Loss: 0.0019780753646045923\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.011676645837724209, Val Loss: 0.00261833518743515\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.010889372788369656, Val Loss: 0.0023040163796395063\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.012120401486754417, Val Loss: 0.0022216455545276403\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.010442474856972694, Val Loss: 0.0017829198623076081\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.01190878450870514, Val Loss: 0.0015537249855697155\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.012706594541668892, Val Loss: 0.0018743573455139995\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.010783417150378227, Val Loss: 0.0025983606465160847\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.012053102254867554, Val Loss: 0.0030683521181344986\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.010061304084956646, Val Loss: 0.0030306472908705473\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.010395471937954426, Val Loss: 0.0030180076137185097\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.014620767906308174, Val Loss: 0.0006166124367155135\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.01400495134294033, Val Loss: 0.0006114335847087204\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.015856467187404633, Val Loss: 0.0005681305774487555\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.013983267359435558, Val Loss: 0.0005540302372537553\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.013878406025469303, Val Loss: 0.0005827287677675486\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.013250529766082764, Val Loss: 0.0006793843931518495\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.013767990283668041, Val Loss: 0.0007950221188366413\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.013556189835071564, Val Loss: 0.0010357529390603304\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.012503456324338913, Val Loss: 0.0013702475698664784\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.014279534108936787, Val Loss: 0.0018839053809642792\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.012478876858949661, Val Loss: 0.002522774739190936\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.013712622225284576, Val Loss: 0.0031598974019289017\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.012544967234134674, Val Loss: 0.003144326386973262\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.014000322669744492, Val Loss: 0.00303678959608078\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.01603364758193493, Val Loss: 0.0027162188198417425\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.012352066114544868, Val Loss: 0.002570111770182848\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.01414327509701252, Val Loss: 0.0028131206054240465\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.014669179916381836, Val Loss: 0.002343966392800212\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.0148557648062706, Val Loss: 0.002099785255268216\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.01292884536087513, Val Loss: 0.0026661374140530825\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.010958404280245304, Val Loss: 0.0022277720272541046\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.01227696891874075, Val Loss: 0.0004709468921646476\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.012227209284901619, Val Loss: 0.0004294025129638612\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.012283970601856709, Val Loss: 0.00033192336559295654\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.010820714756846428, Val Loss: 0.0020996227394789457\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.010800925083458424, Val Loss: 0.003524660598486662\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.01171968225389719, Val Loss: 0.001576585229486227\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.01075815875083208, Val Loss: 0.002163836732506752\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.012643489055335522, Val Loss: 0.0012294661719352007\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.011424302123486996, Val Loss: 0.0018750797025859356\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.01139612402766943, Val Loss: 0.005467204377055168\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.012451904825866222, Val Loss: 0.0017488461453467607\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.009932167828083038, Val Loss: 0.0011069346219301224\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.010929325595498085, Val Loss: 0.0013405353529378772\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.011674717999994755, Val Loss: 0.0011934172362089157\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.010479471646249294, Val Loss: 0.004002253990620375\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.010267980396747589, Val Loss: 0.0042019993998110294\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.010103020817041397, Val Loss: 0.0025252988561987877\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.010433235205709934, Val Loss: 0.0018392513738945127\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.009360120631754398, Val Loss: 0.0018308054422959685\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.00947574619203806, Val Loss: 0.0016778656281530857\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.008617830462753773, Val Loss: 0.0035165706649422646\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.009796801023185253, Val Loss: 0.004830952733755112\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.010056992061436176, Val Loss: 0.0010058722691610456\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.13615471124649048, Val Loss: 0.004825426731258631\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.015734992921352386, Val Loss: 0.0005813572206534445\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.00349922000314109, 'rmse': 0.043053800031650914, 'mae': 0.035846096090972425, 'mape': 15.485897287726402, 'r2': 0.9614187964812075}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.417136549949646, Val Loss: 0.15189015865325928\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.160642385482788, Val Loss: 0.15229447185993195\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.3009973764419556, Val Loss: 0.15281759202480316\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.2211880683898926, Val Loss: 0.15259449183940887\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.0002294778823853, Val Loss: 0.1532852053642273\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.2911620140075684, Val Loss: 0.1532803773880005\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.6666488647460938, Val Loss: 0.1528206467628479\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.8786091804504395, Val Loss: 0.1537209302186966\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.6491826176643372, Val Loss: 0.154110848903656\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.6704526543617249, Val Loss: 0.15468116104602814\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.5407958030700684, Val Loss: 0.15478849411010742\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.5792041420936584, Val Loss: 0.15449580550193787\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.6509921550750732, Val Loss: 0.1551782637834549\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.4975200891494751, Val Loss: 0.15659038722515106\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.37280136346817017, Val Loss: 0.15769268572330475\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.40480223298072815, Val Loss: 0.15867096185684204\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.37290504574775696, Val Loss: 0.15939494967460632\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.3382239043712616, Val Loss: 0.1594368815422058\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.30908945202827454, Val Loss: 0.158810093998909\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.6676058769226074, Val Loss: 0.1564723551273346\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.4424334764480591, Val Loss: 0.15513324737548828\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.0170650482177734, Val Loss: 0.1476769894361496\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.2756606340408325, Val Loss: 0.14825177192687988\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.3691033124923706, Val Loss: 0.14886564016342163\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.3725504875183105, Val Loss: 0.14992235600948334\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.0527952909469604, Val Loss: 0.15028657019138336\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.3768813610076904, Val Loss: 0.1500893235206604\n",
      "INFO:root:Epoch 7/100, Train Loss: 1.1673414707183838, Val Loss: 0.1498960554599762\n",
      "INFO:root:Epoch 8/100, Train Loss: 1.5145108699798584, Val Loss: 0.14889176189899445\n",
      "INFO:root:Epoch 9/100, Train Loss: 1.0482484102249146, Val Loss: 0.14906732738018036\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.7843378186225891, Val Loss: 0.149392232298851\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.6961555480957031, Val Loss: 0.149944469332695\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.5334790945053101, Val Loss: 0.14958228170871735\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.5766965746879578, Val Loss: 0.14910295605659485\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.3995361328125, Val Loss: 0.1486770510673523\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.49088895320892334, Val Loss: 0.1490871161222458\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.49507835507392883, Val Loss: 0.14964017271995544\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.4470796585083008, Val Loss: 0.1507800817489624\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.3220788538455963, Val Loss: 0.1513577401638031\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.42274007201194763, Val Loss: 0.15216875076293945\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.37905195355415344, Val Loss: 0.15348191559314728\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.30220869183540344, Val Loss: 0.1524025797843933\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.350415587425232, Val Loss: 0.09080936014652252\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.5541706085205078, Val Loss: 0.09119798988103867\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.349021315574646, Val Loss: 0.09250857681035995\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.308653473854065, Val Loss: 0.09277953952550888\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.382449746131897, Val Loss: 0.09295163303613663\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.226897120475769, Val Loss: 0.093561552464962\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.7655806541442871, Val Loss: 0.09309348464012146\n",
      "INFO:root:Epoch 8/100, Train Loss: 1.048668384552002, Val Loss: 0.09230849891901016\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.8526753187179565, Val Loss: 0.09158529341220856\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.899298369884491, Val Loss: 0.09184187650680542\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.963388204574585, Val Loss: 0.09148090332746506\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.6668281555175781, Val Loss: 0.0920136496424675\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.5407204031944275, Val Loss: 0.09217116981744766\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.44275033473968506, Val Loss: 0.09196323156356812\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.4573565423488617, Val Loss: 0.09034109115600586\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.4063541889190674, Val Loss: 0.09046279639005661\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.3100859522819519, Val Loss: 0.09140873700380325\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.3146781027317047, Val Loss: 0.09205067902803421\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.4719875156879425, Val Loss: 0.09218785911798477\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.34975019097328186, Val Loss: 0.09291190654039383\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.40618211030960083, Val Loss: 0.09179460257291794\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.293783038854599, Val Loss: 0.09044133871793747\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.31616348028182983, Val Loss: 0.0899641290307045\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.28890010714530945, Val Loss: 0.09057237207889557\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.32434383034706116, Val Loss: 0.08956385403871536\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.35853540897369385, Val Loss: 0.08999311923980713\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.268729567527771, Val Loss: 0.08949413150548935\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.30049648880958557, Val Loss: 0.08969713002443314\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.2565065920352936, Val Loss: 0.08905932307243347\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.21249926090240479, Val Loss: 0.08823606371879578\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.21691729128360748, Val Loss: 0.08673731237649918\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.21410438418388367, Val Loss: 0.08609689772129059\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.21427367627620697, Val Loss: 0.08604872971773148\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.1511908918619156, Val Loss: 0.08556611090898514\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.15242360532283783, Val Loss: 0.08548154681921005\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.14018453657627106, Val Loss: 0.08514054119586945\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.14427369832992554, Val Loss: 0.08372331410646439\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.13415786623954773, Val Loss: 0.08038458973169327\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.16868281364440918, Val Loss: 0.07718909531831741\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.10348331928253174, Val Loss: 0.07361182570457458\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.10575199127197266, Val Loss: 0.06933306902647018\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.13862352073192596, Val Loss: 0.06575831025838852\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.10613293200731277, Val Loss: 0.06239404156804085\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.09433506429195404, Val Loss: 0.05993048846721649\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.09210719913244247, Val Loss: 0.05800555646419525\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.09968441724777222, Val Loss: 0.05694317817687988\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.11486821621656418, Val Loss: 0.05653218552470207\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.09448891133069992, Val Loss: 0.055477485060691833\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.1115889847278595, Val Loss: 0.05497949197888374\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.10282910615205765, Val Loss: 0.05422339215874672\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.08942662924528122, Val Loss: 0.05292979255318642\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.08110066503286362, Val Loss: 0.051761459559202194\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.07332664728164673, Val Loss: 0.04975634813308716\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.08296144008636475, Val Loss: 0.04843295365571976\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.07502976059913635, Val Loss: 0.046468351036310196\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.15288569033145905, Val Loss: 0.04298079386353493\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.08789237588644028, Val Loss: 0.04078688099980354\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.08315631002187729, Val Loss: 0.03852873668074608\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.08698943257331848, Val Loss: 0.03586443513631821\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.07609781622886658, Val Loss: 0.03398190438747406\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.08124881237745285, Val Loss: 0.03164764493703842\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.0729428380727768, Val Loss: 0.030644243583083153\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.08204790204763412, Val Loss: 0.029066015034914017\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.06041572242975235, Val Loss: 0.027365880087018013\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.07506504654884338, Val Loss: 0.025658125057816505\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.07313060015439987, Val Loss: 0.02365756593644619\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.06135173514485359, Val Loss: 0.02121559903025627\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.06534130871295929, Val Loss: 0.018903817981481552\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.09316989034414291, Val Loss: 0.016664333641529083\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.06264957040548325, Val Loss: 0.014704518020153046\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.06435493379831314, Val Loss: 0.012569315731525421\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.06950565427541733, Val Loss: 0.010077618062496185\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.06285901367664337, Val Loss: 0.008648421615362167\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.07102587819099426, Val Loss: 0.0074660899117589\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.06825040280818939, Val Loss: 0.0060387565754354\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.09069573879241943, Val Loss: 0.005253379233181477\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.0570930577814579, Val Loss: 0.005114155355840921\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.06082881987094879, Val Loss: 0.00454868096858263\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.060082804411649704, Val Loss: 0.004201881121844053\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.07401110976934433, Val Loss: 0.004355167504400015\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.06391852349042892, Val Loss: 0.00425532553344965\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.07269390672445297, Val Loss: 0.00409468961879611\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.07979607582092285, Val Loss: 0.0036528927739709616\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.06379670649766922, Val Loss: 0.003542069112882018\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.06905120611190796, Val Loss: 0.0033524225000292063\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.07397318631410599, Val Loss: 0.0036850410979241133\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.05247858166694641, Val Loss: 0.0035928369034081697\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.057987313717603683, Val Loss: 0.0038305502384901047\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.04514843225479126, Val Loss: 0.0037205584812909365\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.08673558384180069, Val Loss: 0.003999251872301102\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.06339222937822342, Val Loss: 0.004164010286331177\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.06563257426023483, Val Loss: 0.004479842260479927\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.09155311435461044, Val Loss: 0.0046602399088442326\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.06437450647354126, Val Loss: 0.0047087641432881355\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.053977854549884796, Val Loss: 0.004545401781797409\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.08486554026603699, Val Loss: 0.00475201616063714\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.05351351201534271, Val Loss: 0.004672233015298843\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.0604681596159935, Val Loss: 0.005171287339180708\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.05807981640100479, Val Loss: 0.005121996160596609\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.06825359910726547, Val Loss: 0.0051839472725987434\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.18332764506340027, Val Loss: 0.05156278610229492\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.23266835510730743, Val Loss: 0.026008902117609978\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.1979602426290512, Val Loss: 0.015316352248191833\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.19343674182891846, Val Loss: 0.020309386774897575\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.21908949315547943, Val Loss: 0.035109780728816986\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.06283561140298843, Val Loss: 0.028382975608110428\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.08572164815850555, 'rmse': 0.2626342677081274, 'mae': 0.22344190627336502, 'mape': 57.57993668317795, 'r2': 0.36620892524885273}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.7533421516418457, Val Loss: 0.20199128985404968\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.541016697883606, Val Loss: 0.20402197539806366\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.5501633882522583, Val Loss: 0.20560257136821747\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.4441241025924683, Val Loss: 0.2065930813550949\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.223410725593567, Val Loss: 0.20721350610256195\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.0922287702560425, Val Loss: 0.20655405521392822\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.9499384164810181, Val Loss: 0.20369496941566467\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.8852192759513855, Val Loss: 0.19850073754787445\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.6395297646522522, Val Loss: 0.1928025782108307\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.5369058847427368, Val Loss: 0.18399286270141602\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.4184926152229309, Val Loss: 0.17414818704128265\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.3365941643714905, Val Loss: 0.1638450026512146\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.30626919865608215, Val Loss: 0.15227746963500977\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.23174719512462616, Val Loss: 0.14073120057582855\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.2342446893453598, Val Loss: 0.13216492533683777\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.25970882177352905, Val Loss: 0.12526768445968628\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.28561314940452576, Val Loss: 0.12168589979410172\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.2739691436290741, Val Loss: 0.12162772566080093\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.28040486574172974, Val Loss: 0.12198848277330399\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.23266573250293732, Val Loss: 0.12426016479730606\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.18789467215538025, Val Loss: 0.1257799118757248\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.1463959664106369, Val Loss: 0.127629816532135\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.11975143104791641, Val Loss: 0.12905175983905792\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.1129336878657341, Val Loss: 0.12924517691135406\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.11544527858495712, Val Loss: 0.1292797327041626\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.12353721261024475, Val Loss: 0.12746217846870422\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.12209241837263107, Val Loss: 0.12331164628267288\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.09554439038038254, Val Loss: 0.1168137788772583\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.10394942760467529, Val Loss: 0.10985463857650757\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.0872424989938736, Val Loss: 0.1019158810377121\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.07652761787176132, Val Loss: 0.09455558657646179\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.07093562930822372, Val Loss: 0.08554375916719437\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.06992854923009872, Val Loss: 0.0795847550034523\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.07298842817544937, Val Loss: 0.07405349612236023\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.06727562844753265, Val Loss: 0.07008134573698044\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.06717967987060547, Val Loss: 0.06863173842430115\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.06596000492572784, Val Loss: 0.06777215003967285\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.05733640491962433, Val Loss: 0.06701084971427917\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.05693467706441879, Val Loss: 0.06584488600492477\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.04367140308022499, Val Loss: 0.0634773001074791\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.04521287605166435, Val Loss: 0.06100265681743622\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.046803027391433716, Val Loss: 0.057392142713069916\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.04877663031220436, Val Loss: 0.052968863397836685\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.049401089549064636, Val Loss: 0.0480039119720459\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.045670490711927414, Val Loss: 0.04311741143465042\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.0427200123667717, Val Loss: 0.03938954696059227\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.04774690791964531, Val Loss: 0.03647509217262268\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.042962316423654556, Val Loss: 0.034722842276096344\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.04196237400174141, Val Loss: 0.033875588327646255\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.04360061138868332, Val Loss: 0.034416768699884415\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.042572230100631714, Val Loss: 0.03556082025170326\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.04531678557395935, Val Loss: 0.03732031211256981\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.04155018925666809, Val Loss: 0.03947713226079941\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.039853185415267944, Val Loss: 0.041884321719408035\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.04159137234091759, Val Loss: 0.043753765523433685\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.03762473165988922, Val Loss: 0.04524872079491615\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.03863709792494774, Val Loss: 0.044931408017873764\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.03440162539482117, Val Loss: 0.044425103813409805\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.03497504070401192, Val Loss: 0.04304010421037674\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.0370154082775116, Val Loss: 0.042064227163791656\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.0391080342233181, Val Loss: 0.04021483287215233\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.03616586700081825, Val Loss: 0.03872121870517731\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.03940558061003685, Val Loss: 0.0366431325674057\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.03306611627340317, Val Loss: 0.03541736304759979\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.02902337722480297, Val Loss: 0.03410648554563522\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.031304121017456055, Val Loss: 0.03368116915225983\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.03706508129835129, Val Loss: 0.033007390797138214\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.035508714616298676, Val Loss: 0.03309943899512291\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.03342509642243385, Val Loss: 0.03257221728563309\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.028380276635289192, Val Loss: 0.03296086564660072\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.03100604936480522, Val Loss: 0.03273233026266098\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.03427668288350105, Val Loss: 0.03320346400141716\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.03733661398291588, Val Loss: 0.03306310996413231\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.02923622913658619, Val Loss: 0.03303102031350136\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.03234869986772537, Val Loss: 0.032651763409376144\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.03298619017004967, Val Loss: 0.032727956771850586\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.03350432589650154, Val Loss: 0.03239203244447708\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.03033122606575489, Val Loss: 0.032277144491672516\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.03262533247470856, Val Loss: 0.03207552060484886\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.038413017988204956, Val Loss: 0.03216388076543808\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.033384811133146286, Val Loss: 0.031468383967876434\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.032008178532123566, Val Loss: 0.0313013419508934\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.03733401745557785, Val Loss: 0.03105033189058304\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.027826698496937752, Val Loss: 0.0305117629468441\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.030291743576526642, Val Loss: 0.030242985114455223\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.0368766151368618, Val Loss: 0.030456673353910446\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.03151383623480797, Val Loss: 0.030122214928269386\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.034688714891672134, Val Loss: 0.030157171189785004\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.03181875869631767, Val Loss: 0.02970712259411812\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.027124907821416855, Val Loss: 0.029419492930173874\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.03255731984972954, Val Loss: 0.02949441224336624\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.03340592235326767, Val Loss: 0.028872480615973473\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.03233334794640541, Val Loss: 0.02924656681716442\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.02936222217977047, Val Loss: 0.029487304389476776\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.03438341245055199, Val Loss: 0.02895490638911724\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.03242603689432144, Val Loss: 0.028778141364455223\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.02718264050781727, Val Loss: 0.028776487335562706\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.03280951827764511, Val Loss: 0.0288059301674366\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.03481822833418846, Val Loss: 0.02869231067597866\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.035402413457632065, Val Loss: 0.02851177752017975\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.045891761779785156, Val Loss: 0.0015301635721698403\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.042478010058403015, Val Loss: 0.0016776154516264796\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.04195248708128929, Val Loss: 0.0018173217540606856\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.045179735869169235, Val Loss: 0.001961879199370742\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.040078844875097275, Val Loss: 0.0020915328059345484\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.04645220562815666, Val Loss: 0.002139909425750375\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.040465347468853, Val Loss: 0.0022452042903751135\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.036297380924224854, Val Loss: 0.0024250997230410576\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.03867495805025101, Val Loss: 0.002756665227934718\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.04353199526667595, Val Loss: 0.003174170618876815\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.0384848453104496, Val Loss: 0.0037258253432810307\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.03371020406484604, Val Loss: 0.004364373628050089\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.03855397179722786, Val Loss: 0.00506608048453927\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.03417874127626419, Val Loss: 0.005944947246462107\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.03645163029432297, Val Loss: 0.006715049967169762\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.04285264015197754, Val Loss: 0.007018037606030703\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.03584311902523041, Val Loss: 0.006683276034891605\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.03799184784293175, Val Loss: 0.005666798446327448\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.03587698936462402, Val Loss: 0.004715733230113983\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.031485479325056076, Val Loss: 0.003736770013347268\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.03249603137373924, Val Loss: 0.0029028570279479027\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.036501120775938034, Val Loss: 0.001039458205923438\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.03943081572651863, Val Loss: 0.0011437182547524571\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.04007762670516968, Val Loss: 0.0012512389803305268\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.047813743352890015, Val Loss: 0.0013460726477205753\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.04216529801487923, Val Loss: 0.0014584973687306046\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.0435359813272953, Val Loss: 0.0014712770935148\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.03648229315876961, Val Loss: 0.0015128663508221507\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.03841685503721237, Val Loss: 0.0014639789005741477\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.037893231958150864, Val Loss: 0.0013857525773346424\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.0376288928091526, Val Loss: 0.0013130481820553541\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.035824406892061234, Val Loss: 0.001250678556971252\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.03539498150348663, Val Loss: 0.0013553714379668236\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.03795931860804558, Val Loss: 0.001682902337051928\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.032882288098335266, Val Loss: 0.002136981813237071\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.03417100012302399, Val Loss: 0.0026645332109183073\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.03272566571831703, Val Loss: 0.0032395278103649616\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.03411775082349777, Val Loss: 0.003752812510356307\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.03435761108994484, Val Loss: 0.0038110038731247187\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.03269093483686447, Val Loss: 0.003309834050014615\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.030425969511270523, Val Loss: 0.002618917729705572\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.030985603109002113, Val Loss: 0.0020171746145933867\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.16193780303001404, Val Loss: 0.002861177548766136\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.04397895559668541, Val Loss: 0.0023268742952495813\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.008568019000813365, 'rmse': 0.07721472354900957, 'mae': 0.05836733505129814, 'mape': 19.220509976148605, 'r2': 0.9255532888489768}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.4287054538726807, Val Loss: 0.22979427874088287\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.1864327192306519, Val Loss: 0.22876513004302979\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.0623968839645386, Val Loss: 0.22812026739120483\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.9425869584083557, Val Loss: 0.22553078830242157\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.6961570382118225, Val Loss: 0.22139224410057068\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.49783727526664734, Val Loss: 0.2143295854330063\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.3399530351161957, Val Loss: 0.20760220289230347\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.25202199816703796, Val Loss: 0.19708706438541412\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.29456233978271484, Val Loss: 0.19091081619262695\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.3362785577774048, Val Loss: 0.18564362823963165\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.4303494393825531, Val Loss: 0.18391844630241394\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.5360685586929321, Val Loss: 0.1866213083267212\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.4727325439453125, Val Loss: 0.1920202523469925\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.3542383015155792, Val Loss: 0.2013353407382965\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.3001992702484131, Val Loss: 0.20340509712696075\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.2734307646751404, Val Loss: 0.19385667145252228\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.26640787720680237, Val Loss: 0.17004430294036865\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.24026967585086823, Val Loss: 0.1426486074924469\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.19344250857830048, Val Loss: 0.12066703289747238\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.142753005027771, Val Loss: 0.11131531745195389\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.15257088840007782, Val Loss: 0.10533594340085983\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.16955813765525818, Val Loss: 0.10165490955114365\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.15656130015850067, Val Loss: 0.10137779265642166\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.13647246360778809, Val Loss: 0.10795221477746964\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.11070670187473297, Val Loss: 0.11055278033018112\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.11165161430835724, Val Loss: 0.1045168861746788\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.10667671263217926, Val Loss: 0.09098660200834274\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.09435709565877914, Val Loss: 0.08160051703453064\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.06827116757631302, Val Loss: 0.08011128008365631\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.0692174881696701, Val Loss: 0.0711175799369812\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.07046382129192352, Val Loss: 0.061078768223524094\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.06539510190486908, Val Loss: 0.05817919597029686\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.04611565172672272, Val Loss: 0.060584597289562225\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.048262547701597214, Val Loss: 0.06420338153839111\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.04800819233059883, Val Loss: 0.06774593889713287\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.04735337570309639, Val Loss: 0.07064978033304214\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.046999845653772354, Val Loss: 0.07438661903142929\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.03899291157722473, Val Loss: 0.07438348233699799\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.03548780828714371, Val Loss: 0.07054046541452408\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.04033247008919716, Val Loss: 0.06284044682979584\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.04031224921345711, Val Loss: 0.057918425649404526\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.036895908415317535, Val Loss: 0.0575440376996994\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.03388169780373573, Val Loss: 0.05272115394473076\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.03209102153778076, Val Loss: 0.04636053368449211\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.03713351488113403, Val Loss: 0.04012393206357956\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.033611688762903214, Val Loss: 0.03777759522199631\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.02995823696255684, Val Loss: 0.039372991770505905\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.026414360851049423, Val Loss: 0.04159019887447357\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.028963729739189148, Val Loss: 0.043002817779779434\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.02420332096517086, Val Loss: 0.04279686510562897\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.030070409178733826, Val Loss: 0.04140675440430641\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.024385645985603333, Val Loss: 0.041041046380996704\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.02689189650118351, Val Loss: 0.03931061550974846\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.025533294305205345, Val Loss: 0.038441527634859085\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.02686411328613758, Val Loss: 0.039559513330459595\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.025445161387324333, Val Loss: 0.04225870594382286\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.02842129021883011, Val Loss: 0.04367957264184952\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.02355864830315113, Val Loss: 0.043585631996393204\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.026892436668276787, Val Loss: 0.04561876878142357\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.028203513473272324, Val Loss: 0.050255440175533295\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.024156615138053894, Val Loss: 0.05593065172433853\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.022266481071710587, Val Loss: 0.06251920014619827\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.017636969685554504, Val Loss: 0.0684819221496582\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.028245801106095314, Val Loss: 0.07289344817399979\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.025802334770560265, Val Loss: 0.07749851047992706\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.02107103168964386, Val Loss: 0.08172684907913208\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.04576444253325462, Val Loss: 0.025019405409693718\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.043024830520153046, Val Loss: 0.02410920336842537\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.050124455243349075, Val Loss: 0.023162342607975006\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.05129842460155487, Val Loss: 0.022393658757209778\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.056479573249816895, Val Loss: 0.020996728911995888\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.03978176414966583, Val Loss: 0.019514769315719604\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.04619918391108513, Val Loss: 0.017917318269610405\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.043525733053684235, Val Loss: 0.016401231288909912\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.041654642671346664, Val Loss: 0.014812029898166656\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.04108095169067383, Val Loss: 0.01349847111850977\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.03967255353927612, Val Loss: 0.012299025431275368\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.04306953400373459, Val Loss: 0.010961745865643024\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.0382845513522625, Val Loss: 0.009715712629258633\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.038582317531108856, Val Loss: 0.008017260581254959\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.040257539600133896, Val Loss: 0.007728588301688433\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.03947930410504341, Val Loss: 0.007758018560707569\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.03707859292626381, Val Loss: 0.008077984675765038\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.04110352694988251, Val Loss: 0.008026063442230225\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.03219643235206604, Val Loss: 0.00760630052536726\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.031670525670051575, Val Loss: 0.007596753537654877\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.03805467486381531, Val Loss: 0.008491282351315022\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.03128206357359886, Val Loss: 0.00809774361550808\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.02770734205842018, Val Loss: 0.007650739047676325\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.03012095019221306, Val Loss: 0.00822546798735857\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.028263438493013382, Val Loss: 0.009147677570581436\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.025616303086280823, Val Loss: 0.009288419969379902\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.026583680883049965, Val Loss: 0.009344985708594322\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.0298335961997509, Val Loss: 0.009103568270802498\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.027132919058203697, Val Loss: 0.008131270296871662\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.022510385140776634, Val Loss: 0.008994310162961483\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.022905142977833748, Val Loss: 0.008656034246087074\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.02303997613489628, Val Loss: 0.008473682217299938\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.021349843591451645, Val Loss: 0.0092167342081666\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.022149210795760155, Val Loss: 0.010797739028930664\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.02724466472864151, Val Loss: 0.009275700896978378\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.021920310333371162, Val Loss: 0.008938916027545929\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.01824970543384552, Val Loss: 0.008344277739524841\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.02420288883149624, Val Loss: 0.010505730286240578\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.02487785369157791, Val Loss: 0.012252316810190678\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.018854370340704918, Val Loss: 0.009618889540433884\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.03579656034708023, Val Loss: 0.005415305495262146\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.036889854818582535, Val Loss: 0.005690127145498991\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.04047004505991936, Val Loss: 0.00572156859561801\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.036571402102708817, Val Loss: 0.005823642015457153\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.03439420461654663, Val Loss: 0.00591896940022707\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.029527908191084862, Val Loss: 0.005982923787087202\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.03831804171204567, Val Loss: 0.006014187820255756\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.03098898194730282, Val Loss: 0.006097655743360519\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.03170381486415863, Val Loss: 0.006134245079010725\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.02656320109963417, Val Loss: 0.0062025729566812515\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.03247823938727379, Val Loss: 0.006524103228002787\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.03252791613340378, Val Loss: 0.007759625557810068\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.03484490141272545, Val Loss: 0.00917154923081398\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.0303548201918602, Val Loss: 0.010348258540034294\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.03204859420657158, Val Loss: 0.01294359564781189\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.02844041772186756, Val Loss: 0.01632378250360489\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.025855934247374535, Val Loss: 0.019378136843442917\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.02948988974094391, Val Loss: 0.0171912033110857\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.02428804524242878, Val Loss: 0.015456294640898705\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.0258925948292017, Val Loss: 0.017417313531041145\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.024695292115211487, Val Loss: 0.017242545261979103\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.13300879299640656, Val Loss: 0.018781954422593117\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.03797154873609543, Val Loss: 0.002440074924379587\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.040337130427360535, Val Loss: 0.002186562167480588\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.0346059575676918, Val Loss: 0.0020204687025398016\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.03327372297644615, Val Loss: 0.0018699420616030693\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.034167565405368805, Val Loss: 0.0019153497414663434\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.0306252371519804, Val Loss: 0.002392934402450919\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.033251162618398666, Val Loss: 0.003960465081036091\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.03159814327955246, Val Loss: 0.007640419062227011\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.030710546299815178, Val Loss: 0.014339689165353775\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.030145753175020218, Val Loss: 0.024417543783783913\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.03843209147453308, Val Loss: 0.034370698034763336\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.036615774035453796, Val Loss: 0.040842022746801376\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.03413035348057747, Val Loss: 0.04163088649511337\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.0330619215965271, Val Loss: 0.0339190848171711\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.024231409654021263, Val Loss: 0.022418593987822533\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.02920287847518921, Val Loss: 0.01163207646459341\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.026528945192694664, Val Loss: 0.006163505371659994\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.02749372273683548, Val Loss: 0.00631928164511919\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.02866026945412159, Val Loss: 0.010742221027612686\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.02511286549270153, Val Loss: 0.02198806032538414\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.023347986862063408, Val Loss: 0.03849198296666145\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.02257518842816353, Val Loss: 0.051393069326877594\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.022084781900048256, Val Loss: 0.05410394445061684\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.02159733511507511, Val Loss: 0.03522906079888344\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.018814325192943217, 'rmse': 0.12037099948089483, 'mae': 0.0955329068005085, 'mape': 42.219001948833466, 'r2': 0.8769440843640355}\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.963023841381073, Val Loss: 0.24604074656963348\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.9642530679702759, Val Loss: 0.2431274652481079\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.9784212708473206, Val Loss: 0.24071107804775238\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.6652987003326416, Val Loss: 0.23638916015625\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.4514888823032379, Val Loss: 0.23207640647888184\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.3937317132949829, Val Loss: 0.2292201668024063\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.2827494144439697, Val Loss: 0.22556978464126587\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.3078833222389221, Val Loss: 0.22383339703083038\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.28575628995895386, Val Loss: 0.22068701684474945\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.2714419960975647, Val Loss: 0.21515317261219025\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.3310968279838562, Val Loss: 0.21238379180431366\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.2977219521999359, Val Loss: 0.20815715193748474\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.24251355230808258, Val Loss: 0.20628543198108673\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.1861095279455185, Val Loss: 0.20560337603092194\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.1929132491350174, Val Loss: 0.20293036103248596\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.240558922290802, Val Loss: 0.20065166056156158\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.2726747691631317, Val Loss: 0.19589170813560486\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.1697743982076645, Val Loss: 0.18854188919067383\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.11178118735551834, Val Loss: 0.18122977018356323\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.09839563816785812, Val Loss: 0.1746799349784851\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.1144646480679512, Val Loss: 0.16907061636447906\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.11751660704612732, Val Loss: 0.1645273119211197\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.07923460006713867, Val Loss: 0.16143536567687988\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.07560037076473236, Val Loss: 0.15976540744304657\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.07920318841934204, Val Loss: 0.15796619653701782\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.08160965889692307, Val Loss: 0.1546083688735962\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.055052969604730606, Val Loss: 0.15108686685562134\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.07018075883388519, Val Loss: 0.14632050693035126\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.05742098018527031, Val Loss: 0.14260220527648926\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.051829464733600616, Val Loss: 0.14163462817668915\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.05481691285967827, Val Loss: 0.14315660297870636\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.03125142306089401, Val Loss: 0.14412392675876617\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.038312364369630814, Val Loss: 0.14320388436317444\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.059849612414836884, Val Loss: 0.1398289054632187\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.03902174159884453, Val Loss: 0.13613329827785492\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.03437843173742294, Val Loss: 0.13383738696575165\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.03842382878065109, Val Loss: 0.1315723955631256\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.033602502197027206, Val Loss: 0.12926717102527618\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.02809964120388031, Val Loss: 0.1263698786497116\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.02645847387611866, Val Loss: 0.12369854003190994\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.030037423595786095, Val Loss: 0.12202315032482147\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.025383226573467255, Val Loss: 0.12195064127445221\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.021855536848306656, Val Loss: 0.12247219681739807\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.02293582260608673, Val Loss: 0.12235172837972641\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.0265997052192688, Val Loss: 0.12187468260526657\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.028832564130425453, Val Loss: 0.11862434446811676\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.02085173688828945, Val Loss: 0.11428341269493103\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.01745527610182762, Val Loss: 0.10963083058595657\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.019680840894579887, Val Loss: 0.10668153315782547\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.021544689312577248, Val Loss: 0.10376942902803421\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.020127899944782257, Val Loss: 0.1022544652223587\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.021877624094486237, Val Loss: 0.1010153740644455\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.02258148603141308, Val Loss: 0.10014716535806656\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.01839996688067913, Val Loss: 0.09863552451133728\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.02329118363559246, Val Loss: 0.09630617499351501\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.021673329174518585, Val Loss: 0.09170075505971909\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.019655711948871613, Val Loss: 0.08614641427993774\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.016488710418343544, Val Loss: 0.07999967783689499\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.016979726031422615, Val Loss: 0.07498118281364441\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.01348869688808918, Val Loss: 0.07092751562595367\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.0159536674618721, Val Loss: 0.06725583225488663\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.01659073866903782, Val Loss: 0.06453313678503036\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.028804242610931396, Val Loss: 0.062424853444099426\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.015672320500016212, Val Loss: 0.06075523421168327\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.01505257934331894, Val Loss: 0.05901091918349266\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.01275259256362915, Val Loss: 0.056022126227617264\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.02510424703359604, Val Loss: 0.053324565291404724\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.01716194860637188, Val Loss: 0.0504915788769722\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.014191736467182636, Val Loss: 0.04759588837623596\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.014199797995388508, Val Loss: 0.045367561280727386\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.014314842410385609, Val Loss: 0.043339528143405914\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.01443182211369276, Val Loss: 0.041879575699567795\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.017145857214927673, Val Loss: 0.04074207320809364\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.01832978054881096, Val Loss: 0.03871950879693031\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.017868978902697563, Val Loss: 0.03601842746138573\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.012909303419291973, Val Loss: 0.03323302045464516\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.015214132145047188, Val Loss: 0.030464043840765953\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.016155628487467766, Val Loss: 0.027960004284977913\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.014198781922459602, Val Loss: 0.02583935298025608\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.013446209952235222, Val Loss: 0.02348124235868454\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.01523587852716446, Val Loss: 0.021780211478471756\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.012489400804042816, Val Loss: 0.020436108112335205\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.014571692794561386, Val Loss: 0.019654516130685806\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.014446313492953777, Val Loss: 0.019094936549663544\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.016218319535255432, Val Loss: 0.018807295709848404\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.016413453966379166, Val Loss: 0.018719376996159554\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.011270243674516678, Val Loss: 0.018696479499340057\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.013301239348948002, Val Loss: 0.019322583451867104\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.014357514679431915, Val Loss: 0.01946076937019825\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.01715466007590294, Val Loss: 0.020040348172187805\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.012872252613306046, Val Loss: 0.020809268578886986\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.01172110065817833, Val Loss: 0.021685006096959114\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.010912560857832432, Val Loss: 0.022054225206375122\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.01144610159099102, Val Loss: 0.02223956771194935\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.010342799127101898, Val Loss: 0.023286081850528717\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.013722090981900692, Val Loss: 0.024186817929148674\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.016505097970366478, Val Loss: 0.024123847484588623\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.01196196861565113, Val Loss: 0.024683108553290367\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.01158824935555458, Val Loss: 0.02515072375535965\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.014678764156997204, Val Loss: 0.025166025385260582\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.017766324803233147, Val Loss: 0.012471622787415981\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.02486332878470421, Val Loss: 0.01176181435585022\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.016499757766723633, Val Loss: 0.010600287467241287\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.01864665001630783, Val Loss: 0.009455371648073196\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.01873837411403656, Val Loss: 0.0086571229621768\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.0158685352653265, Val Loss: 0.007935883477330208\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.02261866256594658, Val Loss: 0.007687136065214872\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.019523903727531433, Val Loss: 0.00757034495472908\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.02269294671714306, Val Loss: 0.007890901528298855\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.02386111207306385, Val Loss: 0.008083022199571133\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.021723221987485886, Val Loss: 0.007604011334478855\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.020688729360699654, Val Loss: 0.0070026349276304245\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.017632795497775078, Val Loss: 0.007160019129514694\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.015974801033735275, Val Loss: 0.009074566885828972\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.01625383272767067, Val Loss: 0.012049865908920765\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.016142001375555992, Val Loss: 0.012842362746596336\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.014023279771208763, Val Loss: 0.011887160129845142\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.017715496942400932, Val Loss: 0.008703445084393024\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.01305496133863926, Val Loss: 0.00743425777181983\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.01346426922827959, Val Loss: 0.009178235195577145\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.014355125837028027, Val Loss: 0.008422127924859524\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.015605882741510868, Val Loss: 0.006791471038013697\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.014609131030738354, Val Loss: 0.00940127857029438\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.013128278777003288, Val Loss: 0.010434006340801716\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.014819953590631485, Val Loss: 0.010488529689610004\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.011174744926393032, Val Loss: 0.01230048667639494\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.013927171006798744, Val Loss: 0.010114745236933231\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.012437439523637295, Val Loss: 0.00949457660317421\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.012159056030213833, Val Loss: 0.006836724933236837\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.01232061441987753, Val Loss: 0.007822616957128048\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.015836795791983604, Val Loss: 0.006768179591745138\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.01391561608761549, Val Loss: 0.011518414132297039\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.014461932703852654, Val Loss: 0.018452633172273636\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.015215457417070866, Val Loss: 0.012560773640871048\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.010287086479365826, Val Loss: 0.008859163150191307\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.010628373362123966, Val Loss: 0.011659516021609306\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.013139418326318264, Val Loss: 0.011793086305260658\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.011731401085853577, Val Loss: 0.01231947261840105\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.011043302714824677, Val Loss: 0.012823773548007011\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.01205015741288662, Val Loss: 0.00838764850050211\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.014482075348496437, Val Loss: 0.012880624271929264\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.011577745899558067, Val Loss: 0.0206154752522707\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.012933916412293911, Val Loss: 0.013749675825238228\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.01572669856250286, Val Loss: 0.007527310401201248\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.010981453582644463, Val Loss: 0.012719323858618736\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.01504061371088028, Val Loss: 0.009903897531330585\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.009794799610972404, Val Loss: 0.009578824043273926\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.012335577979683876, Val Loss: 0.01285599172115326\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.012229434214532375, Val Loss: 0.011278729885816574\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.012109487317502499, Val Loss: 0.005927381571382284\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.008992576040327549, Val Loss: 0.004874500446021557\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.011144695803523064, Val Loss: 0.004472884349524975\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.009922496974468231, Val Loss: 0.00502644432708621\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.006915768142789602, Val Loss: 0.007573962211608887\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.01101232971996069, Val Loss: 0.010140161961317062\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.011176756583154202, Val Loss: 0.009013943374156952\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.00947042927145958, Val Loss: 0.007525967434048653\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.009088573046028614, Val Loss: 0.006365176290273666\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.008195947855710983, Val Loss: 0.006192551925778389\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.009151233360171318, Val Loss: 0.006119797471910715\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.006608244497328997, Val Loss: 0.006086706183850765\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.006843545474112034, Val Loss: 0.006449104752391577\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.009101481176912785, Val Loss: 0.006655360572040081\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.007196498569101095, Val Loss: 0.0073466007597744465\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.006461204495280981, Val Loss: 0.008016934618353844\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.006637276615947485, Val Loss: 0.008998069912195206\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.007889026775956154, Val Loss: 0.009935261681675911\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.010755778290331364, Val Loss: 0.009176558814942837\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.007943502627313137, Val Loss: 0.00807470828294754\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.006821444723755121, Val Loss: 0.007173894438892603\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.006068485323339701, Val Loss: 0.006552461534738541\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.0084465853869915, Val Loss: 0.006344558205455542\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.010797722265124321, Val Loss: 0.0032789241522550583\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.010996720753610134, Val Loss: 0.0030727891717106104\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.01008166279643774, Val Loss: 0.00289910682477057\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.00988199096173048, Val Loss: 0.002543465234339237\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.012610356323421001, Val Loss: 0.002389633795246482\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.01029650866985321, Val Loss: 0.0019041674677282572\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.009687838144600391, Val Loss: 0.0017454877961426973\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.00833035446703434, Val Loss: 0.0014963909052312374\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.009848780930042267, Val Loss: 0.0014371839351952076\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.010052106343209743, Val Loss: 0.0016202852129936218\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.010770170018076897, Val Loss: 0.0016448949463665485\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.011876408010721207, Val Loss: 0.001768106478266418\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.011995135806500912, Val Loss: 0.0018587021622806787\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.010864900425076485, Val Loss: 0.0017251978861168027\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.00971354078501463, Val Loss: 0.001381702721118927\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.007968462072312832, Val Loss: 0.0014720596373081207\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.008307098411023617, Val Loss: 0.0022772513329982758\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.0068441457115113735, Val Loss: 0.003724797395989299\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.010501915588974953, Val Loss: 0.003982877358794212\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.00904533825814724, Val Loss: 0.003095336491242051\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.009772076271474361, Val Loss: 0.002278505591675639\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.00816584937274456, Val Loss: 0.003294652095064521\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.008992576040327549, Val Loss: 0.0034909560345113277\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.009334630332887173, Val Loss: 0.0030830027535557747\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.0106721892952919, Val Loss: 0.0034814870450645685\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.012146783992648125, Val Loss: 0.002814074046909809\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.011777767911553383, Val Loss: 0.0074228146113455296\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.010390207171440125, Val Loss: 0.009891167283058167\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.00956160668283701, Val Loss: 0.004138029180467129\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.010036759078502655, Val Loss: 0.0029440918006002903\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.009077339433133602, Val Loss: 0.0024573986884206533\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.009856858290731907, Val Loss: 0.0031388059724122286\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.007358233910053968, Val Loss: 0.00610033143311739\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.0087423799559474, Val Loss: 0.005492248572409153\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.0074033127166330814, Val Loss: 0.005163875408470631\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.2176561951637268, Val Loss: 0.004105210304260254\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.009056905284523964, Val Loss: 0.0018594205612316728\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.0055077883647754785, 'rmse': 0.0635040587770487, 'mae': 0.05202890038490295, 'mape': 25.51583208143711, 'r2': 0.9433757877325458}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.502448558807373, Val Loss: 0.2465660274028778\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.505738377571106, Val Loss: 0.24815262854099274\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.4765344858169556, Val Loss: 0.24984171986579895\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.51911199092865, Val Loss: 0.2519559860229492\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.3858765363693237, Val Loss: 0.2533940374851227\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.384000301361084, Val Loss: 0.255656898021698\n",
      "INFO:root:Epoch 7/100, Train Loss: 1.2361633777618408, Val Loss: 0.2575714588165283\n",
      "INFO:root:Epoch 8/100, Train Loss: 1.2405415773391724, Val Loss: 0.25807562470436096\n",
      "INFO:root:Epoch 9/100, Train Loss: 1.2113678455352783, Val Loss: 0.258343905210495\n",
      "INFO:root:Epoch 10/100, Train Loss: 1.0522631406784058, Val Loss: 0.2573149502277374\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.9322336316108704, Val Loss: 0.2564997375011444\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.886588454246521, Val Loss: 0.2542984187602997\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.7685519456863403, Val Loss: 0.24946792423725128\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.6769397258758545, Val Loss: 0.24423111975193024\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.5517520904541016, Val Loss: 0.2372794896364212\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.4909687638282776, Val Loss: 0.22793778777122498\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.4119662940502167, Val Loss: 0.2180173248052597\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.34462496638298035, Val Loss: 0.2079807072877884\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.29110103845596313, Val Loss: 0.19858108460903168\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.23055724799633026, Val Loss: 0.18849149346351624\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.23640069365501404, Val Loss: 0.1790066510438919\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.21138955652713776, Val Loss: 0.1712634414434433\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.23385705053806305, Val Loss: 0.16382083296775818\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.2158869504928589, Val Loss: 0.1574643850326538\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.2306113988161087, Val Loss: 0.15257945656776428\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.2509922683238983, Val Loss: 0.1494416892528534\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.20168323814868927, Val Loss: 0.14639581739902496\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.19594934582710266, Val Loss: 0.14523233473300934\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.16053415834903717, Val Loss: 0.14561881124973297\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.17088119685649872, Val Loss: 0.14526784420013428\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.15118612349033356, Val Loss: 0.1457960158586502\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.12874570488929749, Val Loss: 0.14619354903697968\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.12761202454566956, Val Loss: 0.1456245481967926\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.121601402759552, Val Loss: 0.1442858874797821\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.12134203314781189, Val Loss: 0.14441992342472076\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.10792480409145355, Val Loss: 0.14321336150169373\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.09570705890655518, Val Loss: 0.14228925108909607\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.1058809906244278, Val Loss: 0.14037469029426575\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.09577301144599915, Val Loss: 0.13761189579963684\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.09677714109420776, Val Loss: 0.13559693098068237\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.09570018947124481, Val Loss: 0.13279573619365692\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.0899941697716713, Val Loss: 0.1307705044746399\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.08972255140542984, Val Loss: 0.13046401739120483\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.08928883075714111, Val Loss: 0.1304549127817154\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.08418266475200653, Val Loss: 0.13237512111663818\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.08334372192621231, Val Loss: 0.13460175693035126\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.07805996388196945, Val Loss: 0.13643097877502441\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.08899183571338654, Val Loss: 0.13980300724506378\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.07538023591041565, Val Loss: 0.14342164993286133\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.0816054567694664, Val Loss: 0.14819739758968353\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.08097786456346512, Val Loss: 0.1528928130865097\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.07257046550512314, Val Loss: 0.15853427350521088\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.07588857412338257, Val Loss: 0.16298894584178925\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.0808592364192009, Val Loss: 0.16873814165592194\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.07252182811498642, Val Loss: 0.17286305129528046\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.07682033628225327, Val Loss: 0.17690803110599518\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.0719902291893959, Val Loss: 0.18094362318515778\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.07120643556118011, Val Loss: 0.18576662242412567\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.07189782708883286, Val Loss: 0.18851448595523834\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.06795220822095871, Val Loss: 0.19288329780101776\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.07189283519983292, Val Loss: 0.1984041929244995\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.07450968027114868, Val Loss: 0.20251047611236572\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.07885047048330307, Val Loss: 0.20627637207508087\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.062049224972724915, Val Loss: 0.20869562029838562\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.12385759502649307, Val Loss: 0.025876330211758614\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.1254729926586151, Val Loss: 0.02495771087706089\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.1311059296131134, Val Loss: 0.02422056533396244\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.1292184591293335, Val Loss: 0.023735543712973595\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.1219511553645134, Val Loss: 0.02354482002556324\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.12382727861404419, Val Loss: 0.02270600013434887\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.1380782127380371, Val Loss: 0.022321749478578568\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.11285631358623505, Val Loss: 0.02197955548763275\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.12402265518903732, Val Loss: 0.021972814574837685\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.13005907833576202, Val Loss: 0.021804139018058777\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.1227559819817543, Val Loss: 0.021747229620814323\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.11943234503269196, Val Loss: 0.0228602085262537\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.10164760053157806, Val Loss: 0.023726586252450943\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.11181183159351349, Val Loss: 0.024237001314759254\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.1042172834277153, Val Loss: 0.025133255869150162\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.10044422745704651, Val Loss: 0.025798756629228592\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.11035756021738052, Val Loss: 0.026224272325634956\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.10154536366462708, Val Loss: 0.026342477649450302\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.10567279160022736, Val Loss: 0.025538494810461998\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.0970798209309578, Val Loss: 0.023740043863654137\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.09772341698408127, Val Loss: 0.021900292485952377\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.08419237285852432, Val Loss: 0.019877757877111435\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.08747512847185135, Val Loss: 0.01787896268069744\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.0875396877527237, Val Loss: 0.015907464548945427\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.1016325056552887, Val Loss: 0.014313682913780212\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.08788370341062546, Val Loss: 0.013710728846490383\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.08561991900205612, Val Loss: 0.014224514365196228\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.07990730553865433, Val Loss: 0.01523787621408701\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.08116438239812851, Val Loss: 0.01570172607898712\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.08109485357999802, Val Loss: 0.015142696909606457\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.07791267335414886, Val Loss: 0.013445677235722542\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.08032305538654327, Val Loss: 0.0119068818166852\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.07675638794898987, Val Loss: 0.010435289703309536\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.0786312073469162, Val Loss: 0.010003971867263317\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.07054007053375244, Val Loss: 0.010038976557552814\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.07342768460512161, Val Loss: 0.01056110579520464\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.07659769803285599, Val Loss: 0.011572944931685925\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.07386062294244766, Val Loss: 0.01159796305000782\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.06886891275644302, Val Loss: 0.01135214976966381\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.07180041819810867, Val Loss: 0.011062554083764553\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.0751805379986763, Val Loss: 0.010555625893175602\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.06038431450724602, Val Loss: 0.010568507015705109\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.06565845012664795, Val Loss: 0.010356214828789234\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.07210101932287216, Val Loss: 0.010203276760876179\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.07207964360713959, Val Loss: 0.010189974680542946\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.07194115966558456, Val Loss: 0.009620065800845623\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.06728730350732803, Val Loss: 0.009593113325536251\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.06783882528543472, Val Loss: 0.009495370090007782\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.059595607221126556, Val Loss: 0.009297958575189114\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.06553621590137482, Val Loss: 0.009092908352613449\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.07137487083673477, Val Loss: 0.009110900573432446\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.07226819545030594, Val Loss: 0.008785039186477661\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.062231019139289856, Val Loss: 0.008819805458188057\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.060551341623067856, Val Loss: 0.008977847173810005\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.05638518184423447, Val Loss: 0.009021337144076824\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.06378170847892761, Val Loss: 0.008972099050879478\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.06277842074632645, Val Loss: 0.00889861211180687\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.0604717917740345, Val Loss: 0.00866966973990202\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.06016762927174568, Val Loss: 0.008709798566997051\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.0593387708067894, Val Loss: 0.008642023429274559\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.06451798975467682, Val Loss: 0.00858546607196331\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.051910046488046646, Val Loss: 0.008405379019677639\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.057174451649188995, Val Loss: 0.008044716902077198\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.05999429523944855, Val Loss: 0.00793623086065054\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.06167091056704521, Val Loss: 0.007960310205817223\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.050055038183927536, Val Loss: 0.00797533243894577\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.050718072801828384, Val Loss: 0.007804322987794876\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.05724668130278587, Val Loss: 0.007872140035033226\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.06586910039186478, Val Loss: 0.007729986682534218\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.05893394351005554, Val Loss: 0.007761506363749504\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.06343331187963486, Val Loss: 0.008005626499652863\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.055135998874902725, Val Loss: 0.00848100520670414\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.06032072380185127, Val Loss: 0.008400877006351948\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.0566251240670681, Val Loss: 0.008771360851824284\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.056322261691093445, Val Loss: 0.00897651445120573\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.06370238959789276, Val Loss: 0.009236724115908146\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.05526510626077652, Val Loss: 0.009110480546951294\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.05503473058342934, Val Loss: 0.009085984900593758\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.05442214384675026, Val Loss: 0.00938284769654274\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.0570359043776989, Val Loss: 0.009433703497052193\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.04930165037512779, Val Loss: 0.009496212005615234\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.05835782736539841, Val Loss: 0.009263531304895878\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.05351521074771881, Val Loss: 0.009122648276388645\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.06167988479137421, Val Loss: 0.009126110933721066\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.05667916685342789, Val Loss: 0.008945327252149582\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.05986209213733673, Val Loss: 0.008983741514384747\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.051568396389484406, Val Loss: 0.009086048230528831\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.0537554956972599, Val Loss: 0.009202523157000542\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.055466026067733765, Val Loss: 0.009397445246577263\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.05699513852596283, Val Loss: 0.005876924842596054\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.06357737630605698, Val Loss: 0.005678028799593449\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.06052830070257187, Val Loss: 0.00560076953843236\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.06112600862979889, Val Loss: 0.005520279984921217\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.05524870380759239, Val Loss: 0.005463762674480677\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.06617068499326706, Val Loss: 0.005457498133182526\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.053411815315485, Val Loss: 0.005499809514731169\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.05400808900594711, Val Loss: 0.005445747636258602\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.060917310416698456, Val Loss: 0.005432465113699436\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.058505915105342865, Val Loss: 0.005458394531160593\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.05507291108369827, Val Loss: 0.0054917000234127045\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.052407946437597275, Val Loss: 0.005684271454811096\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.050411395728588104, Val Loss: 0.006154521368443966\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.052461378276348114, Val Loss: 0.006726526655256748\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.049718428403139114, Val Loss: 0.007206264417618513\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.062283165752887726, Val Loss: 0.008046530187129974\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.05488518998026848, Val Loss: 0.008757890202105045\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.04904281347990036, Val Loss: 0.009304492734372616\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.05719243362545967, Val Loss: 0.009749318473041058\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.052490539848804474, Val Loss: 0.010065611451864243\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.04580426216125488, Val Loss: 0.010445202700793743\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.05503236874938011, Val Loss: 0.010981268249452114\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.04935307428240776, Val Loss: 0.011335528455674648\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.0634576678276062, Val Loss: 0.011407943442463875\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.047088976949453354, Val Loss: 0.011757973581552505\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.05085944011807442, Val Loss: 0.012669946067035198\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.055376578122377396, Val Loss: 0.013753327541053295\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.048566482961177826, Val Loss: 0.015293640084564686\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.04796651750802994, Val Loss: 0.016577862203121185\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.16360735893249512, Val Loss: 0.007077991962432861\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.0665474459528923, Val Loss: 0.008907733485102654\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.032273242622613905, 'rmse': 0.14224291270306183, 'mae': 0.11832129806280137, 'mape': 52.55296587944031, 'r2': 0.6598209656545981}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.114409327507019, Val Loss: 0.24901129305362701\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.2063474655151367, Val Loss: 0.24776457250118256\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.9804095029830933, Val Loss: 0.24822452664375305\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.9580923914909363, Val Loss: 0.2469721883535385\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.8297428488731384, Val Loss: 0.24606643617153168\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.166979432106018, Val Loss: 0.24695225059986115\n",
      "INFO:root:Epoch 7/100, Train Loss: 1.202215552330017, Val Loss: 0.24779300391674042\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.8347111344337463, Val Loss: 0.24618056416511536\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.6433969736099243, Val Loss: 0.24812538921833038\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.7019402384757996, Val Loss: 0.24916377663612366\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.8622403740882874, Val Loss: 0.249809131026268\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.8646953105926514, Val Loss: 0.2504543662071228\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.6258569359779358, Val Loss: 0.24967673420906067\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.5205638408660889, Val Loss: 0.2486199289560318\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.4478377401828766, Val Loss: 0.24747240543365479\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.44012451171875, Val Loss: 0.24385853111743927\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.5167776346206665, Val Loss: 0.2404211312532425\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.39425593614578247, Val Loss: 0.2384372353553772\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.4401926100254059, Val Loss: 0.23661763966083527\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.3851467967033386, Val Loss: 0.23071876168251038\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.35679367184638977, Val Loss: 0.2270658016204834\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.38395532965660095, Val Loss: 0.2198459953069687\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.25912898778915405, Val Loss: 0.21473272144794464\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.2695210874080658, Val Loss: 0.21185019612312317\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.27040112018585205, Val Loss: 0.2078779935836792\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.23256215453147888, Val Loss: 0.20568998157978058\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.2403411865234375, Val Loss: 0.20222875475883484\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.22773776948451996, Val Loss: 0.2013508826494217\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.1513472944498062, Val Loss: 0.19685040414333344\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.212645024061203, Val Loss: 0.19389605522155762\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.20666156709194183, Val Loss: 0.19015327095985413\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.20792551338672638, Val Loss: 0.18724896013736725\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.15507453680038452, Val Loss: 0.18345966935157776\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.1299903243780136, Val Loss: 0.18042239546775818\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.13354918360710144, Val Loss: 0.1770269125699997\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.15921762585639954, Val Loss: 0.17339934408664703\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.127281054854393, Val Loss: 0.16995558142662048\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.15400664508342743, Val Loss: 0.16642607748508453\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.12575602531433105, Val Loss: 0.16224616765975952\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.09630606323480606, Val Loss: 0.16031858325004578\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.11091981828212738, Val Loss: 0.1551511138677597\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.10469531267881393, Val Loss: 0.15010683238506317\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.11550585180521011, Val Loss: 0.1448763906955719\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.1061495691537857, Val Loss: 0.13878607749938965\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.09350595623254776, Val Loss: 0.1336906999349594\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.07193917036056519, Val Loss: 0.12883447110652924\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.09263353794813156, Val Loss: 0.12452681362628937\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.0820271447300911, Val Loss: 0.12160032987594604\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.11782199889421463, Val Loss: 0.11796793341636658\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.0976652130484581, Val Loss: 0.11594826728105545\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.09393991529941559, Val Loss: 0.11298122256994247\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.06675893813371658, Val Loss: 0.1102464497089386\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.08140780031681061, Val Loss: 0.10776263475418091\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.07419956475496292, Val Loss: 0.10493117570877075\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.07279231399297714, Val Loss: 0.10145258903503418\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.07627392560243607, Val Loss: 0.09799114614725113\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.060386933386325836, Val Loss: 0.09498102217912674\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.08441627770662308, Val Loss: 0.09325244277715683\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.0795036107301712, Val Loss: 0.09184511005878448\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.08727408200502396, Val Loss: 0.08926043659448624\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.062123868614435196, Val Loss: 0.08677641302347183\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.05738849192857742, Val Loss: 0.08473645150661469\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.056593600660562515, Val Loss: 0.08201085031032562\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.060926470905542374, Val Loss: 0.07997222244739532\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.06395165622234344, Val Loss: 0.07759540528059006\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.05595367029309273, Val Loss: 0.07593636959791183\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.07044646143913269, Val Loss: 0.07526789605617523\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.07546943426132202, Val Loss: 0.07628168910741806\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.06480952352285385, Val Loss: 0.0759449452161789\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.07743475586175919, Val Loss: 0.07636243849992752\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.056174054741859436, Val Loss: 0.07601013034582138\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.04980219155550003, Val Loss: 0.07654060423374176\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.06221643090248108, Val Loss: 0.07714919745922089\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.046753715723752975, Val Loss: 0.07938922941684723\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.055156126618385315, Val Loss: 0.08179140090942383\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.042107850313186646, Val Loss: 0.08412665128707886\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.057860735803842545, Val Loss: 0.08614275604486465\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.055691368877887726, Val Loss: 0.08756769448518753\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.06436319649219513, Val Loss: 0.08948121219873428\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.05492834001779556, Val Loss: 0.092003233730793\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.05494557321071625, Val Loss: 0.09261570870876312\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.0499127134680748, Val Loss: 0.09342697262763977\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.06439816206693649, Val Loss: 0.09606759250164032\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.06472142040729523, Val Loss: 0.09800109267234802\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.04882927983999252, Val Loss: 0.09690165519714355\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.046840060502290726, Val Loss: 0.0992024764418602\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.05734967812895775, Val Loss: 0.10047793388366699\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.08397101610898972, Val Loss: 0.05184489116072655\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.09345779567956924, Val Loss: 0.05010436102747917\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.08640088886022568, Val Loss: 0.048197176307439804\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.10839246213436127, Val Loss: 0.04636796563863754\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.06806450337171555, Val Loss: 0.044802624732255936\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.07427790760993958, Val Loss: 0.0433143749833107\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.09908238053321838, Val Loss: 0.042261771857738495\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.08764908462762833, Val Loss: 0.04097282886505127\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.09812743961811066, Val Loss: 0.03884762153029442\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.07626877725124359, Val Loss: 0.03552575781941414\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.09456940740346909, Val Loss: 0.03343217447400093\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.07299855351448059, Val Loss: 0.031433094292879105\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.09132131934165955, Val Loss: 0.028525052592158318\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.07862421870231628, Val Loss: 0.026643747463822365\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.07408060133457184, Val Loss: 0.024813272058963776\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.056396376341581345, Val Loss: 0.023832155391573906\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.07523702830076218, Val Loss: 0.02376372553408146\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.0647689700126648, Val Loss: 0.023433076217770576\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.05958538129925728, Val Loss: 0.02327512763440609\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.09184996783733368, Val Loss: 0.02349979430437088\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.06367041170597076, Val Loss: 0.024571172893047333\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.062313180416822433, Val Loss: 0.024471404030919075\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.07903086394071579, Val Loss: 0.025970883667469025\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.06259571760892868, Val Loss: 0.02497890591621399\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.06634660065174103, Val Loss: 0.023145105689764023\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.054564669728279114, Val Loss: 0.02321009710431099\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.05254361405968666, Val Loss: 0.024433618411421776\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.057646289467811584, Val Loss: 0.024767760187387466\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.049931056797504425, Val Loss: 0.02456495352089405\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.04903086647391319, Val Loss: 0.025397412478923798\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.04745933786034584, Val Loss: 0.02733520232141018\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.05087190493941307, Val Loss: 0.0262786615639925\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.04587586969137192, Val Loss: 0.021917622536420822\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.04994437098503113, Val Loss: 0.019547712057828903\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.053096167743206024, Val Loss: 0.019227901473641396\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.04968486726284027, Val Loss: 0.020761316642165184\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.050209496170282364, Val Loss: 0.02171720564365387\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.04755570739507675, Val Loss: 0.02098371461033821\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.04705328121781349, Val Loss: 0.020184198394417763\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.04299904778599739, Val Loss: 0.01941279135644436\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.04011562466621399, Val Loss: 0.01862042397260666\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.036367785185575485, Val Loss: 0.018363820388913155\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.03727914020419121, Val Loss: 0.018503950908780098\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.03792307525873184, Val Loss: 0.01894470490515232\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.04117894917726517, Val Loss: 0.02030167728662491\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.03984340280294418, Val Loss: 0.022092023864388466\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.052059903740882874, Val Loss: 0.02458418905735016\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.043554503470659256, Val Loss: 0.025965867564082146\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.04261498525738716, Val Loss: 0.02681703120470047\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.038610346615314484, Val Loss: 0.02813688851892948\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.04274022579193115, Val Loss: 0.02765209972858429\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.03702038526535034, Val Loss: 0.026696955785155296\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.03718341886997223, Val Loss: 0.026837648823857307\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.03165339678525925, Val Loss: 0.02745920419692993\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.03880428522825241, Val Loss: 0.028124956414103508\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.05275578051805496, Val Loss: 0.02676345780491829\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.028861843049526215, Val Loss: 0.0252061914652586\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.04020167887210846, Val Loss: 0.025555327534675598\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.04275388643145561, Val Loss: 0.026796283200383186\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.03729771077632904, Val Loss: 0.02762214094400406\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.03471587970852852, Val Loss: 0.027616435661911964\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.03871992975473404, Val Loss: 0.027307122945785522\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.053729455918073654, Val Loss: 0.004069935530424118\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.036106884479522705, Val Loss: 0.003756930585950613\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.05473950505256653, Val Loss: 0.003716095583513379\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.045797672122716904, Val Loss: 0.003504035761579871\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.045699235051870346, Val Loss: 0.0033645406365394592\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.03232894837856293, Val Loss: 0.0034454138949513435\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.05599411576986313, Val Loss: 0.003404186572879553\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.04306484013795853, Val Loss: 0.003249366767704487\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.04622294753789902, Val Loss: 0.0032345070503652096\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.030279865488409996, Val Loss: 0.003192555857822299\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.04401303082704544, Val Loss: 0.003287301631644368\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.04364987835288048, Val Loss: 0.0036757278721779585\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.05681633576750755, Val Loss: 0.00395567761734128\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.044339485466480255, Val Loss: 0.0043704453855752945\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.05672617256641388, Val Loss: 0.005187072325497866\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.043778467923402786, Val Loss: 0.00596278440207243\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.05590221658349037, Val Loss: 0.006148745771497488\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.04779306426644325, Val Loss: 0.006210912484675646\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.033091478049755096, Val Loss: 0.00569413136690855\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.036225710064172745, Val Loss: 0.005902027245610952\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.038413114845752716, Val Loss: 0.005647621117532253\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.046633124351501465, Val Loss: 0.005830305628478527\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.03720088675618172, Val Loss: 0.007124521769583225\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.053983911871910095, Val Loss: 0.007804874796420336\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.03712829202413559, Val Loss: 0.006826494354754686\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.04714949056506157, Val Loss: 0.004434702452272177\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.03263343125581741, Val Loss: 0.00481801014393568\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.03694423288106918, Val Loss: 0.004906316287815571\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.042967528104782104, Val Loss: 0.0043635498732328415\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.04373715817928314, Val Loss: 0.006670399568974972\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.22931122779846191, Val Loss: 0.019119082018733025\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.047771912068128586, Val Loss: 0.006788345053792\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.021806843718513845, 'rmse': 0.12449743108368191, 'mae': 0.10301006734371185, 'mape': 33.08679759502411, 'r2': 0.7796093291735696}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.051257848739624, Val Loss: 0.23422066867351532\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.4794224500656128, Val Loss: 0.23233871161937714\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.9085217118263245, Val Loss: 0.23217371106147766\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.8604235649108887, Val Loss: 0.23201540112495422\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.6766758561134338, Val Loss: 0.23062855005264282\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.9689751863479614, Val Loss: 0.2281649112701416\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.9910125136375427, Val Loss: 0.22617578506469727\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.8399750590324402, Val Loss: 0.22345474362373352\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.8293827772140503, Val Loss: 0.22127005457878113\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.7407426834106445, Val Loss: 0.2195509970188141\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.6126828193664551, Val Loss: 0.21429406106472015\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.6521733999252319, Val Loss: 0.21260181069374084\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.614128589630127, Val Loss: 0.20942436158657074\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.4201285243034363, Val Loss: 0.20415467023849487\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.45107853412628174, Val Loss: 0.20037201046943665\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.31797516345977783, Val Loss: 0.19545871019363403\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.29415205121040344, Val Loss: 0.18996161222457886\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.2534426152706146, Val Loss: 0.18554183840751648\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.279376745223999, Val Loss: 0.18029457330703735\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.2453056424856186, Val Loss: 0.17801208794116974\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.2336674928665161, Val Loss: 0.17341454327106476\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.21915441751480103, Val Loss: 0.1702803373336792\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.23193994164466858, Val Loss: 0.16601531207561493\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.20304390788078308, Val Loss: 0.16215501725673676\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.22765563428401947, Val Loss: 0.15969839692115784\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.2496049553155899, Val Loss: 0.15647099912166595\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.20606014132499695, Val Loss: 0.15372170507907867\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.21066683530807495, Val Loss: 0.1500643789768219\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.2168433517217636, Val Loss: 0.147594153881073\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.18848909437656403, Val Loss: 0.14560388028621674\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.15462695062160492, Val Loss: 0.14258521795272827\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.15132494270801544, Val Loss: 0.13997478783130646\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.14279265701770782, Val Loss: 0.13933922350406647\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.1459004431962967, Val Loss: 0.13566699624061584\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.12939341366291046, Val Loss: 0.13230662047863007\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.13994699716567993, Val Loss: 0.1290627270936966\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.1289091557264328, Val Loss: 0.12733550369739532\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.19226011633872986, Val Loss: 0.12375917285680771\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.1291663646697998, Val Loss: 0.12171779572963715\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.13540124893188477, Val Loss: 0.1178794652223587\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.1345619559288025, Val Loss: 0.11599284410476685\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.1446399837732315, Val Loss: 0.11231057345867157\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.11225564032793045, Val Loss: 0.10932830721139908\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.10698201507329941, Val Loss: 0.10548940300941467\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.11792927980422974, Val Loss: 0.10129966586828232\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.12346494197845459, Val Loss: 0.09675820916891098\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.1131044402718544, Val Loss: 0.09273216873407364\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.12900111079216003, Val Loss: 0.08894891291856766\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.09693797677755356, Val Loss: 0.08470669388771057\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.09543661773204803, Val Loss: 0.08122266829013824\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.10439092665910721, Val Loss: 0.07803000509738922\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.09711223095655441, Val Loss: 0.07454784214496613\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.09779605269432068, Val Loss: 0.07148714363574982\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.08381114900112152, Val Loss: 0.06809782236814499\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.08519246429204941, Val Loss: 0.0651732012629509\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.08253695070743561, Val Loss: 0.0630795955657959\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.1149904727935791, Val Loss: 0.06075754389166832\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.08701124787330627, Val Loss: 0.058224309235811234\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.09233125299215317, Val Loss: 0.055530793964862823\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.10113120824098587, Val Loss: 0.052945200353860855\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.08220930397510529, Val Loss: 0.050517965108156204\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.09547894448041916, Val Loss: 0.049370016902685165\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.0798964574933052, Val Loss: 0.04855060577392578\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.09921423345804214, Val Loss: 0.04698420688509941\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.08205542713403702, Val Loss: 0.04526973143219948\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.09069766849279404, Val Loss: 0.043272148817777634\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.08850236237049103, Val Loss: 0.04153725132346153\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.08014778047800064, Val Loss: 0.04028194770216942\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.08106549829244614, Val Loss: 0.03833213448524475\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.0726514458656311, Val Loss: 0.03743218630552292\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.08146239072084427, Val Loss: 0.036678291857242584\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.08694033324718475, Val Loss: 0.036648474633693695\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.0859207734465599, Val Loss: 0.03608813136816025\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.08365614712238312, Val Loss: 0.03468148410320282\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.08781146258115768, Val Loss: 0.03325376287102699\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.08709167689085007, Val Loss: 0.032302021980285645\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.08265938609838486, Val Loss: 0.032458581030368805\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.08879221975803375, Val Loss: 0.031787268817424774\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.08072434365749359, Val Loss: 0.030925923958420753\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.06358040124177933, Val Loss: 0.029709134250879288\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.08985353261232376, Val Loss: 0.029846200719475746\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.10521101951599121, Val Loss: 0.029386088252067566\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.0795646533370018, Val Loss: 0.028398431837558746\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.09140404313802719, Val Loss: 0.028291620314121246\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.07211025804281235, Val Loss: 0.028417810797691345\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.08419763296842575, Val Loss: 0.027364477515220642\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.09370560944080353, Val Loss: 0.027739934623241425\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.07747367769479752, Val Loss: 0.025933319702744484\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.06707141548395157, Val Loss: 0.026462119072675705\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.07990891486406326, Val Loss: 0.025964656844735146\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.09897253662347794, Val Loss: 0.026715725660324097\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.07356920838356018, Val Loss: 0.026245826855301857\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.08259465545415878, Val Loss: 0.027200348675251007\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.08066210150718689, Val Loss: 0.02753674052655697\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.07413175702095032, Val Loss: 0.027500005438923836\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.06274811923503876, Val Loss: 0.02726796269416809\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.08089086413383484, Val Loss: 0.028905238956212997\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.07252753525972366, Val Loss: 0.02959411032497883\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.08349516987800598, Val Loss: 0.028329255059361458\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.08061067014932632, Val Loss: 0.02891395427286625\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.09806559979915619, Val Loss: 0.01039912085980177\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.0822027251124382, Val Loss: 0.010558866895735264\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.09949326515197754, Val Loss: 0.009917755611240864\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.08468066900968552, Val Loss: 0.009561091661453247\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.09483275562524796, Val Loss: 0.009745522402226925\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.10206013172864914, Val Loss: 0.009137670509517193\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.07912413775920868, Val Loss: 0.009189470671117306\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.09271032363176346, Val Loss: 0.008940618485212326\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.09953156113624573, Val Loss: 0.008254310116171837\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.08106241375207901, Val Loss: 0.007699530106037855\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.07497686892747879, Val Loss: 0.007431523874402046\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.08276823908090591, Val Loss: 0.007556174416095018\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.09719468653202057, Val Loss: 0.007700115907937288\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.07892689108848572, Val Loss: 0.007853730581700802\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.09627992659807205, Val Loss: 0.00801461935043335\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.09332229197025299, Val Loss: 0.007597603835165501\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.08222776651382446, Val Loss: 0.007130584679543972\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.07750814408063889, Val Loss: 0.00711415009573102\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.07340297102928162, Val Loss: 0.006894445978105068\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.05217302218079567, Val Loss: 0.006714025977998972\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.08294419944286346, Val Loss: 0.006451200693845749\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.08975948393344879, Val Loss: 0.006468483712524176\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.0794212743639946, Val Loss: 0.005813955795019865\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.07340638339519501, Val Loss: 0.005978643428534269\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.06389316916465759, Val Loss: 0.00701891491189599\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.05843013897538185, Val Loss: 0.009232615120708942\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.06612661480903625, Val Loss: 0.01251829881221056\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.07137859612703323, Val Loss: 0.011760890483856201\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.06406538188457489, Val Loss: 0.00958971492946148\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.07359695434570312, Val Loss: 0.008456207811832428\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.07387150079011917, Val Loss: 0.00768359424546361\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.054823458194732666, Val Loss: 0.007556661497801542\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.06862159818410873, Val Loss: 0.007302879821509123\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.07506261765956879, Val Loss: 0.0076617030426859856\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.0693485289812088, Val Loss: 0.008570118807256222\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.05761142820119858, Val Loss: 0.009767835959792137\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.049642086029052734, Val Loss: 0.011232891120016575\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.06425666809082031, Val Loss: 0.013103071600198746\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.05894829332828522, Val Loss: 0.013438074849545956\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.050663869827985764, Val Loss: 0.012210945598781109\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.057390861213207245, Val Loss: 0.011515784077346325\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.05754246562719345, Val Loss: 0.01035152655094862\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.06831326335668564, Val Loss: 0.009258020669221878\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.07949855923652649, Val Loss: 0.0035423242952674627\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.0842740386724472, Val Loss: 0.0033991015516221523\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.07289475202560425, Val Loss: 0.00347716617397964\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.0736832395195961, Val Loss: 0.0037573196459561586\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.06590530276298523, Val Loss: 0.0038644331507384777\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.07735597342252731, Val Loss: 0.003844871185719967\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.08305490016937256, Val Loss: 0.0040798974223434925\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.06134352087974548, Val Loss: 0.004139034543186426\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.06400145590305328, Val Loss: 0.004788162186741829\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.07099612802267075, Val Loss: 0.005320793483406305\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.06943129003047943, Val Loss: 0.0064061847515404224\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.05351872369647026, Val Loss: 0.006838169880211353\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.05591572821140289, Val Loss: 0.006699818652123213\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.07193367928266525, Val Loss: 0.006945499684661627\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.06738433241844177, Val Loss: 0.006927066948264837\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.05535702407360077, Val Loss: 0.0064533245749771595\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.059606846421957016, Val Loss: 0.006133286748081446\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.062012068927288055, Val Loss: 0.004790965002030134\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.06329047679901123, Val Loss: 0.0036541633307933807\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.06464221328496933, Val Loss: 0.003192146774381399\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.06655001640319824, Val Loss: 0.0035419475752860308\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.0701008141040802, Val Loss: 0.003613158827647567\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.05241752415895462, Val Loss: 0.0035846431273967028\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.05599299818277359, Val Loss: 0.0035277872812002897\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.06399476528167725, Val Loss: 0.003386989701539278\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.06393734365701675, Val Loss: 0.003217724384739995\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.051157355308532715, Val Loss: 0.003830007277429104\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.06036292016506195, Val Loss: 0.003891596570611\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.06226624920964241, Val Loss: 0.0040026092901825905\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.047560445964336395, Val Loss: 0.0041536130011081696\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.04981324076652527, Val Loss: 0.0040364693850278854\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.057835184037685394, Val Loss: 0.004311965312808752\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.0543142631649971, Val Loss: 0.004761618096381426\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.05777360126376152, Val Loss: 0.005198336206376553\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.04973708838224411, Val Loss: 0.005569447763264179\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.057737138122320175, Val Loss: 0.005036017391830683\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.06349499523639679, Val Loss: 0.004901838023215532\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.055095162242650986, Val Loss: 0.0054849074222147465\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.05130268260836601, Val Loss: 0.006216876208782196\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.05378315597772598, Val Loss: 0.006720154546201229\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.14672401547431946, Val Loss: 0.009628847241401672\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.06476153433322906, Val Loss: 0.005274593830108643\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.009062258992344141, 'rmse': 0.08756192724734986, 'mae': 0.0749424010515213, 'mape': 38.93280953168869, 'r2': 0.9162590643136864}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.0602295398712158, Val Loss: 0.26376497745513916\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.7403256297111511, Val Loss: 0.2633747458457947\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.44843539595603943, Val Loss: 0.2617385685443878\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.2646251916885376, Val Loss: 0.2592088282108307\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.184500053524971, Val Loss: 0.2562742233276367\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.18327094614505768, Val Loss: 0.25362280011177063\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.3040195405483246, Val Loss: 0.25003883242607117\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.4105384945869446, Val Loss: 0.2478506863117218\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.4250768721103668, Val Loss: 0.24645432829856873\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.3425629138946533, Val Loss: 0.24598661065101624\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.21698662638664246, Val Loss: 0.24716846644878387\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.1330040991306305, Val Loss: 0.249659463763237\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.12876124680042267, Val Loss: 0.25133016705513\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.17550188302993774, Val Loss: 0.24827149510383606\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.18187671899795532, Val Loss: 0.23957252502441406\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.154245063662529, Val Loss: 0.2244253307580948\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.09820046275854111, Val Loss: 0.20449227094650269\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.07471925765275955, Val Loss: 0.18400037288665771\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.07967822253704071, Val Loss: 0.1675768494606018\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.07922513037919998, Val Loss: 0.15858478844165802\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.0719524696469307, Val Loss: 0.15445123612880707\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.05510000139474869, Val Loss: 0.15273484587669373\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.049046825617551804, Val Loss: 0.1486586183309555\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.04439525306224823, Val Loss: 0.1406429409980774\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.03561585023999214, Val Loss: 0.13521018624305725\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.0369514562189579, Val Loss: 0.1380452960729599\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.036335576325654984, Val Loss: 0.1400085687637329\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.034103721380233765, Val Loss: 0.13268372416496277\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.025223789736628532, Val Loss: 0.1186923012137413\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.02015543356537819, Val Loss: 0.10662168264389038\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.02343040518462658, Val Loss: 0.10292267799377441\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.022274676710367203, Val Loss: 0.10283359885215759\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.021160589531064034, Val Loss: 0.10215073823928833\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.019357163459062576, Val Loss: 0.09389705210924149\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.016027135774493217, Val Loss: 0.08138541132211685\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.013033595867455006, Val Loss: 0.07252947986125946\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.0129368482157588, Val Loss: 0.06939981877803802\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.014719417318701744, Val Loss: 0.06945119053125381\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.012833589687943459, Val Loss: 0.06730563938617706\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.012320014648139477, Val Loss: 0.061365723609924316\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.01135158073157072, Val Loss: 0.0541844442486763\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.01119998935610056, Val Loss: 0.04892139881849289\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.011144980788230896, Val Loss: 0.045510806143283844\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.010494115762412548, Val Loss: 0.045209962874650955\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.01104698609560728, Val Loss: 0.044999171048402786\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.0101397093385458, Val Loss: 0.044574908912181854\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.008780593983829021, Val Loss: 0.043573569506406784\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.011193063110113144, Val Loss: 0.04110947623848915\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.008224769495427608, Val Loss: 0.03863488882780075\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.00943052675575018, Val Loss: 0.037664107978343964\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.00940875243395567, Val Loss: 0.03672957420349121\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.00865575484931469, Val Loss: 0.03566592186689377\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.008530212566256523, Val Loss: 0.033852946013212204\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.00784849189221859, Val Loss: 0.03162185847759247\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.008952751755714417, Val Loss: 0.02907761186361313\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.00792623683810234, Val Loss: 0.025594588369131088\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.007385168690234423, Val Loss: 0.022664248943328857\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.007347560953348875, Val Loss: 0.020384712144732475\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.007176653947681189, Val Loss: 0.01921199820935726\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.007884686812758446, Val Loss: 0.01897544041275978\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.007385995239019394, Val Loss: 0.019351128488779068\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.007153952959924936, Val Loss: 0.019847098737955093\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.006673081777989864, Val Loss: 0.01964246854186058\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.006387269590049982, Val Loss: 0.018496042117476463\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.00646570697426796, Val Loss: 0.016956092789769173\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.006331507582217455, Val Loss: 0.015169387683272362\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.007175487466156483, Val Loss: 0.013589040376245975\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.0073825884610414505, Val Loss: 0.012410316616296768\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.0071660908870399, Val Loss: 0.011778739280998707\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.006681648548692465, Val Loss: 0.011474376544356346\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.006896629463881254, Val Loss: 0.011278385296463966\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.007339439354836941, Val Loss: 0.0111235985532403\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.00709450663998723, Val Loss: 0.011048618704080582\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.007413311395794153, Val Loss: 0.010918250307440758\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.006403373554348946, Val Loss: 0.01052359864115715\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.0064072818495333195, Val Loss: 0.010021964088082314\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.006584037560969591, Val Loss: 0.009635704569518566\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.005966378841549158, Val Loss: 0.009227831847965717\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.007481214124709368, Val Loss: 0.008778804913163185\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.006256957538425922, Val Loss: 0.008298709988594055\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.006769237108528614, Val Loss: 0.007945413701236248\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.005947326775640249, Val Loss: 0.007667722646147013\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.007212239783257246, Val Loss: 0.007473289500921965\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.007801995147019625, Val Loss: 0.0073137120343744755\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.006583850365132093, Val Loss: 0.007177057676017284\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.006239582784473896, Val Loss: 0.007101760245859623\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.006377037148922682, Val Loss: 0.0070485640317201614\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.007519284263253212, Val Loss: 0.0069900150410830975\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.006062018685042858, Val Loss: 0.006991162896156311\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.006649211514741182, Val Loss: 0.006970981135964394\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.006228577345609665, Val Loss: 0.006920375861227512\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.005953127518296242, Val Loss: 0.006867974530905485\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.005892045330256224, Val Loss: 0.006804023403674364\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.006470967084169388, Val Loss: 0.0068004438653588295\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.006563872564584017, Val Loss: 0.006712221074849367\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.006685358937829733, Val Loss: 0.006669540423899889\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.006414154078811407, Val Loss: 0.00661397585645318\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.005856451578438282, Val Loss: 0.006563547067344189\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.006438591051846743, Val Loss: 0.006546562071889639\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.006364951375871897, Val Loss: 0.006562910042703152\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.015117015689611435, Val Loss: 0.0008769495179876685\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.015355918556451797, Val Loss: 0.0011945869773626328\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.014753593131899834, Val Loss: 0.001488448935560882\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.014294958673417568, Val Loss: 0.001709128264337778\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.014188063330948353, Val Loss: 0.0018162061460316181\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.011697610840201378, Val Loss: 0.0018960738088935614\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.011998436413705349, Val Loss: 0.001963944174349308\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.011869956739246845, Val Loss: 0.002248006174340844\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.011167972348630428, Val Loss: 0.0028956965543329716\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.010851766914129257, Val Loss: 0.0038489357102662325\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.01175682619214058, Val Loss: 0.004676503594964743\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.012915553525090218, Val Loss: 0.004980570171028376\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.01252789981663227, Val Loss: 0.00448048859834671\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.011659384705126286, Val Loss: 0.003737181890755892\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.010404566302895546, Val Loss: 0.003279177937656641\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.01139624509960413, Val Loss: 0.004100291058421135\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.013423844240605831, Val Loss: 0.005991628859192133\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.009866070933640003, Val Loss: 0.008029079996049404\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.00996953435242176, Val Loss: 0.009414729662239552\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.01134744193404913, Val Loss: 0.008243611082434654\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.009073477238416672, Val Loss: 0.005705985240638256\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.01635042205452919, Val Loss: 0.001064262818545103\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.15115144848823547, Val Loss: 0.0022583005484193563\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.02570841833949089, Val Loss: 0.0019345148466527462\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.0025796075933612883, 'rmse': 0.04684158922872127, 'mae': 0.0419115774333477, 'mape': 19.339941442012787, 'r2': 0.9793407112063651}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.6058413982391357, Val Loss: 0.2659578323364258\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.2356117963790894, Val Loss: 0.2643788754940033\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.9917277097702026, Val Loss: 0.2634771764278412\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.7050489783287048, Val Loss: 0.2619328796863556\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.4835585057735443, Val Loss: 0.2583557069301605\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.4115862548351288, Val Loss: 0.25558745861053467\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.2379101812839508, Val Loss: 0.24931132793426514\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.36357367038726807, Val Loss: 0.2414957731962204\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.3763327896595001, Val Loss: 0.23411832749843597\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.38836178183555603, Val Loss: 0.23010054230690002\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.4029525816440582, Val Loss: 0.22548329830169678\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.31312400102615356, Val Loss: 0.22338753938674927\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.2223685383796692, Val Loss: 0.22127622365951538\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.22131091356277466, Val Loss: 0.21996575593948364\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.1650398075580597, Val Loss: 0.22000019252300262\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.14249752461910248, Val Loss: 0.2175445854663849\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.1658644676208496, Val Loss: 0.21440263092517853\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.17759142816066742, Val Loss: 0.21017931401729584\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.14920398592948914, Val Loss: 0.20497675240039825\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.12283878028392792, Val Loss: 0.19799451529979706\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.10361005365848541, Val Loss: 0.18922848999500275\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.06100242957472801, Val Loss: 0.179588183760643\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.08931972831487656, Val Loss: 0.17137065529823303\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.07288875430822372, Val Loss: 0.16505460441112518\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.06753070652484894, Val Loss: 0.16247326135635376\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.05795745924115181, Val Loss: 0.16236978769302368\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.06268950551748276, Val Loss: 0.16113385558128357\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.05564825236797333, Val Loss: 0.15922679007053375\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.047493819147348404, Val Loss: 0.15492181479930878\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.055991869419813156, Val Loss: 0.1464843451976776\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.03171199560165405, Val Loss: 0.13742142915725708\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.03642113879323006, Val Loss: 0.12779654562473297\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.032523129135370255, Val Loss: 0.12102293223142624\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.03247498348355293, Val Loss: 0.11550117284059525\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.027509190142154694, Val Loss: 0.11027324199676514\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.028063848614692688, Val Loss: 0.1066063866019249\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.027978267520666122, Val Loss: 0.10218778252601624\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.025395892560482025, Val Loss: 0.09739460051059723\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.024639572948217392, Val Loss: 0.09292192757129669\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.030260801315307617, Val Loss: 0.08967459201812744\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.023394383490085602, Val Loss: 0.0862322598695755\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.02817297726869583, Val Loss: 0.08181878924369812\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.023036494851112366, Val Loss: 0.0773644745349884\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.019575538113713264, Val Loss: 0.07455886900424957\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.023086944594979286, Val Loss: 0.072100430727005\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.025087770074605942, Val Loss: 0.06949824094772339\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.019757846370339394, Val Loss: 0.06734886020421982\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.019595617428421974, Val Loss: 0.06430771946907043\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.022361652925610542, Val Loss: 0.061269182711839676\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.01789071410894394, Val Loss: 0.058003079146146774\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.015073513612151146, Val Loss: 0.0547843761742115\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.020245419815182686, Val Loss: 0.0525888167321682\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.01767948642373085, Val Loss: 0.050857409834861755\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.01576542854309082, Val Loss: 0.04957633092999458\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.0180644653737545, Val Loss: 0.04777617007493973\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.01941571943461895, Val Loss: 0.04513542354106903\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.025854816660284996, Val Loss: 0.04188375920057297\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.01618886925280094, Val Loss: 0.039126861840486526\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.017012884840369225, Val Loss: 0.03642848879098892\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.020032282918691635, Val Loss: 0.03418233245611191\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.014601444825530052, Val Loss: 0.03202034533023834\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.015576861798763275, Val Loss: 0.03033318743109703\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.01591617986559868, Val Loss: 0.02922048419713974\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.014909844845533371, Val Loss: 0.029076818376779556\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.01564471796154976, Val Loss: 0.02980724908411503\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.018022682517766953, Val Loss: 0.03011276200413704\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.01651925779879093, Val Loss: 0.03030703403055668\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.01173917856067419, Val Loss: 0.02925335429608822\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.011609312146902084, Val Loss: 0.02791365049779415\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.01625952683389187, Val Loss: 0.025845292955636978\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.013473848812282085, Val Loss: 0.02413834258913994\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.013535180129110813, Val Loss: 0.02289523556828499\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.012500529177486897, Val Loss: 0.02197093516588211\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.012336726300418377, Val Loss: 0.021047869697213173\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.01600351743400097, Val Loss: 0.020320121198892593\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.011963547207415104, Val Loss: 0.019775036722421646\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.015184818767011166, Val Loss: 0.019451240077614784\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.01361844502389431, Val Loss: 0.019265059381723404\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.011842096224427223, Val Loss: 0.019319096580147743\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.009171029552817345, Val Loss: 0.01938149333000183\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.011808485724031925, Val Loss: 0.01948779635131359\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.010545940138399601, Val Loss: 0.019780203700065613\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.013148934580385685, Val Loss: 0.01993040181696415\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.01379698421806097, Val Loss: 0.02038860134780407\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.013799077831208706, Val Loss: 0.021283458918333054\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.010781127959489822, Val Loss: 0.02153017744421959\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.014914399944245815, Val Loss: 0.021957244724035263\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.011457935906946659, Val Loss: 0.02214096300303936\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.01409793458878994, Val Loss: 0.022297155112028122\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.012187635526061058, Val Loss: 0.022231800481677055\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.010844442062079906, Val Loss: 0.022244436666369438\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.010210038162767887, Val Loss: 0.022337812930345535\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.010382283478975296, Val Loss: 0.02204062044620514\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.015918223187327385, Val Loss: 0.021326588466763496\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.011724131181836128, Val Loss: 0.021865161135792732\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.016322823241353035, Val Loss: 0.021392060443758965\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.013188076205551624, Val Loss: 0.021364809945225716\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.009103037416934967, Val Loss: 0.0215311162173748\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.015840189531445503, Val Loss: 0.007493356708437204\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.020118258893489838, Val Loss: 0.007187434006482363\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.019952937960624695, Val Loss: 0.007153525948524475\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.022946013137698174, Val Loss: 0.00669971015304327\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.01887683756649494, Val Loss: 0.006480052135884762\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.02210060879588127, Val Loss: 0.006112242583185434\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.015821242704987526, Val Loss: 0.0058077601715922356\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.017505282536149025, Val Loss: 0.005440427456051111\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.014603840187191963, Val Loss: 0.005273669492453337\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.02460366301238537, Val Loss: 0.004807526711374521\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.01841266080737114, Val Loss: 0.004546561278402805\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.01772315427660942, Val Loss: 0.004357059486210346\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.019441382959485054, Val Loss: 0.004146134946495295\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.01537882350385189, Val Loss: 0.0043215565383434296\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.01938679628074169, Val Loss: 0.005544648971408606\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.016271667554974556, Val Loss: 0.007350284606218338\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.013932080939412117, Val Loss: 0.00876280851662159\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.016007199883461, Val Loss: 0.007544449996203184\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.01708569936454296, Val Loss: 0.004512886982411146\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.011294707655906677, Val Loss: 0.0038740646559745073\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.013397990725934505, Val Loss: 0.0048124343156814575\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.016123753041028976, Val Loss: 0.005526700522750616\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.013713164255023003, Val Loss: 0.005775743629783392\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.018373722210526466, Val Loss: 0.008109385147690773\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.013787214644253254, Val Loss: 0.011708677746355534\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.020069168880581856, Val Loss: 0.007807901594787836\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.013806239701807499, Val Loss: 0.004611218348145485\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.011589090339839458, Val Loss: 0.007118699140846729\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.012624762021005154, Val Loss: 0.007885023020207882\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.01619062013924122, Val Loss: 0.004624222870916128\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.012042573653161526, Val Loss: 0.009766477160155773\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.011347869411110878, Val Loss: 0.01784643344581127\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.021294187754392624, Val Loss: 0.012363563291728497\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.01843303069472313, Val Loss: 0.009868643246591091\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.013933911919593811, Val Loss: 0.009405243210494518\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.013606789521872997, Val Loss: 0.0068197669461369514\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.01424203347414732, Val Loss: 0.004151196219027042\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.020005660131573677, Val Loss: 0.005182956345379353\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.014484317973256111, Val Loss: 0.006662224419414997\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.01245720125734806, Val Loss: 0.007639046758413315\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.014598294161260128, Val Loss: 0.0005539538688026369\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.014948287047445774, Val Loss: 0.0005184239707887173\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.01656755991280079, Val Loss: 0.0006165688391774893\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.012540587224066257, Val Loss: 0.0006992458365857601\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.01982317678630352, Val Loss: 0.000763458083383739\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.015499565750360489, Val Loss: 0.0008602301240898669\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.015322900377213955, Val Loss: 0.001110631157644093\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.019373880699276924, Val Loss: 0.0014155741082504392\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.019337434321641922, Val Loss: 0.0020986045710742474\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.011679846793413162, Val Loss: 0.002864072797819972\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.014814591966569424, Val Loss: 0.0036876013036817312\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.015900010243058205, Val Loss: 0.0046218507923185825\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.016236677765846252, Val Loss: 0.005318407900631428\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.01665416918694973, Val Loss: 0.005058733746409416\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.016527947038412094, Val Loss: 0.004050967749208212\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.012930200435221195, Val Loss: 0.0030688175465911627\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.015950461849570274, Val Loss: 0.002697597723454237\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.017331648617982864, Val Loss: 0.0027574270498007536\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.013745603151619434, Val Loss: 0.0030678610783070326\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.015470126643776894, Val Loss: 0.003936295863240957\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.014787914231419563, Val Loss: 0.007707691751420498\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.012217981740832329, Val Loss: 0.010131401009857655\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.2269333302974701, Val Loss: 0.006592943798750639\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.019669368863105774, Val Loss: 0.0034026107750833035\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.006970277440268546, 'rmse': 0.07392303149477587, 'mae': 0.060555824637413026, 'mape': 26.768431216478348, 'r2': 0.9446790599675541}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.503300428390503, Val Loss: 0.29967594146728516\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.3024332523345947, Val Loss: 0.2997796833515167\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.1108436584472656, Val Loss: 0.29878664016723633\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.7457672357559204, Val Loss: 0.2976182699203491\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.5828490257263184, Val Loss: 0.2964920401573181\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.4168747663497925, Val Loss: 0.29514652490615845\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.29856833815574646, Val Loss: 0.2908521890640259\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.2472381740808487, Val Loss: 0.28576627373695374\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.2495996505022049, Val Loss: 0.2815176844596863\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.2586156725883484, Val Loss: 0.2773405611515045\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.2798904478549957, Val Loss: 0.272514283657074\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.29946544766426086, Val Loss: 0.2671986222267151\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.2376832664012909, Val Loss: 0.26278984546661377\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.21655140817165375, Val Loss: 0.2569018602371216\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.14532719552516937, Val Loss: 0.25223660469055176\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.10192647576332092, Val Loss: 0.24816296994686127\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.09063823521137238, Val Loss: 0.2436622828245163\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.15687145292758942, Val Loss: 0.23917026817798615\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.17792919278144836, Val Loss: 0.23520152270793915\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.14336641132831573, Val Loss: 0.23056021332740784\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.06859032809734344, Val Loss: 0.22441506385803223\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.069706492125988, Val Loss: 0.2153574675321579\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.09003466367721558, Val Loss: 0.2008505016565323\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.08078325539827347, Val Loss: 0.1876530796289444\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.10947665572166443, Val Loss: 0.18090596795082092\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.05713117867708206, Val Loss: 0.17880025506019592\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.051160186529159546, Val Loss: 0.1797044277191162\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.0422213040292263, Val Loss: 0.17888441681861877\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.05731203034520149, Val Loss: 0.17495228350162506\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.0477830208837986, Val Loss: 0.16974660754203796\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.04290897026658058, Val Loss: 0.1635831892490387\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.03737835958600044, Val Loss: 0.1567712277173996\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.03168221935629845, Val Loss: 0.14939044415950775\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.024993546307086945, Val Loss: 0.14243268966674805\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.02833285555243492, Val Loss: 0.13556766510009766\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.02883690968155861, Val Loss: 0.12916693091392517\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.03211869299411774, Val Loss: 0.12252393364906311\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.023012831807136536, Val Loss: 0.11776373535394669\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.027356218546628952, Val Loss: 0.11376005411148071\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.02592034637928009, Val Loss: 0.11152224242687225\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.027348080649971962, Val Loss: 0.10939571261405945\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.027132302522659302, Val Loss: 0.10688839852809906\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.0271933451294899, Val Loss: 0.10225929319858551\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.020148372277617455, Val Loss: 0.09801434725522995\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.020870940759778023, Val Loss: 0.09306839853525162\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.025266366079449654, Val Loss: 0.08651647716760635\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.02411254495382309, Val Loss: 0.08074291050434113\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.01769658550620079, Val Loss: 0.07522401958703995\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.02012820541858673, Val Loss: 0.0713253766298294\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.017081089317798615, Val Loss: 0.06818187981843948\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.023107141256332397, Val Loss: 0.064471036195755\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.021053999662399292, Val Loss: 0.06367402523756027\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.01878882572054863, Val Loss: 0.06266660243272781\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.011688267812132835, Val Loss: 0.061491671949625015\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.02099469304084778, Val Loss: 0.05895083770155907\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.017312556505203247, Val Loss: 0.055358026176691055\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.013691173866391182, Val Loss: 0.051538292318582535\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.02248719148337841, Val Loss: 0.04822636395692825\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.013724526390433311, Val Loss: 0.04643198475241661\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.012583548203110695, Val Loss: 0.0444830097258091\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.015520885586738586, Val Loss: 0.042852092534303665\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.015807239338755608, Val Loss: 0.04093712195754051\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.017208347097039223, Val Loss: 0.03923221305012703\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.01407864224165678, Val Loss: 0.03652579337358475\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.01356491632759571, Val Loss: 0.034061215817928314\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.012730296701192856, Val Loss: 0.0316024087369442\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.014538473449647427, Val Loss: 0.02938242256641388\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.018949680030345917, Val Loss: 0.026757335290312767\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.01313245389610529, Val Loss: 0.024454627186059952\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.015381863340735435, Val Loss: 0.022178104147315025\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.014744510874152184, Val Loss: 0.020512042567133904\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.012216547504067421, Val Loss: 0.01926460489630699\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.011545967310667038, Val Loss: 0.018420714884996414\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.015411500819027424, Val Loss: 0.017786704003810883\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.01287772599607706, Val Loss: 0.01724119856953621\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.011522059328854084, Val Loss: 0.016536695882678032\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.013230279088020325, Val Loss: 0.015803571790456772\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.014730054885149002, Val Loss: 0.015110351145267487\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.011216205544769764, Val Loss: 0.014621172100305557\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.012562505900859833, Val Loss: 0.014181693084537983\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.013090802356600761, Val Loss: 0.013775236904621124\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.015280169434845448, Val Loss: 0.013202623464167118\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.0171798188239336, Val Loss: 0.013027764856815338\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.017977530136704445, Val Loss: 0.012493479065597057\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.013416789472103119, Val Loss: 0.012069215066730976\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.013543513603508472, Val Loss: 0.011768193915486336\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.015520953573286533, Val Loss: 0.01166137307882309\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.012219255790114403, Val Loss: 0.011556308716535568\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.018194150179624557, Val Loss: 0.011243593879044056\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.014707634225487709, Val Loss: 0.010712984018027782\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.011023393832147121, Val Loss: 0.01044540200382471\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.010806540958583355, Val Loss: 0.010279583744704723\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.011284505017101765, Val Loss: 0.010360739193856716\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.014006651937961578, Val Loss: 0.010416381992399693\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.015267733484506607, Val Loss: 0.010227344930171967\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.012616177089512348, Val Loss: 0.010071384720504284\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.01334091741591692, Val Loss: 0.010213221423327923\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.010855112224817276, Val Loss: 0.010000457055866718\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.012724568136036396, Val Loss: 0.010126558132469654\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.013097040355205536, Val Loss: 0.009993261657655239\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.017544694244861603, Val Loss: 0.002253721235319972\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.01773260533809662, Val Loss: 0.0023286996874958277\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.016402965411543846, Val Loss: 0.0023214013781398535\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.01563883014023304, Val Loss: 0.0023155317176133394\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.01815183088183403, Val Loss: 0.0021833081264048815\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.01612657867372036, Val Loss: 0.002062863204628229\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.017767954617738724, Val Loss: 0.0020141059067100286\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.016894297674298286, Val Loss: 0.0018622704083099961\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.016846483573317528, Val Loss: 0.0018658654298633337\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.011991034261882305, Val Loss: 0.0020183934830129147\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.01897571049630642, Val Loss: 0.0022491784766316414\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.014829544350504875, Val Loss: 0.0025719411205500364\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.013887086883187294, Val Loss: 0.0029601948335766792\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.016277074813842773, Val Loss: 0.0035584745928645134\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.014853899367153645, Val Loss: 0.004113300703465939\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.014481493271887302, Val Loss: 0.004573505837470293\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.015652839094400406, Val Loss: 0.005048335995525122\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.017742276191711426, Val Loss: 0.0057596731930971146\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.01842571422457695, Val Loss: 0.006300543434917927\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.016274847090244293, Val Loss: 0.006466826424002647\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.016442973166704178, Val Loss: 0.005473981145769358\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.01635352149605751, Val Loss: 0.0035445792600512505\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.015382224693894386, Val Loss: 0.002747627906501293\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.016115469858050346, Val Loss: 0.0025625377893447876\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.02013544552028179, Val Loss: 0.00323560182005167\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.014256073161959648, Val Loss: 0.007150939200073481\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.013421433046460152, Val Loss: 0.01347480621188879\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.015464124269783497, Val Loss: 0.013289256021380424\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.013131408020853996, Val Loss: 0.0005194108234718442\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.01877361536026001, Val Loss: 0.0005226286593824625\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.01806720532476902, Val Loss: 0.0005678368615917861\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.016270186752080917, Val Loss: 0.0005914292996749282\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.020902790129184723, Val Loss: 0.0006866084295324981\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.01994864083826542, Val Loss: 0.0007502997177653015\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.01643439196050167, Val Loss: 0.0008684431668370962\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.016847115010023117, Val Loss: 0.0011476052459329367\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.014919498935341835, Val Loss: 0.0014880934031680226\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.015367706306278706, Val Loss: 0.0020464411936700344\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.019713176414370537, Val Loss: 0.0025144063401967287\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.017595501616597176, Val Loss: 0.0028605833649635315\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.015793384984135628, Val Loss: 0.0031829706858843565\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.017581691965460777, Val Loss: 0.002377949422225356\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.014525072649121284, Val Loss: 0.001992672448977828\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.01281227171421051, Val Loss: 0.0013007443631067872\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.014210700988769531, Val Loss: 0.0012268220307305455\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.014955569989979267, Val Loss: 0.001523687969893217\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.009800680913031101, Val Loss: 0.0021737662609666586\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.020004041492938995, Val Loss: 0.0031272743362933397\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.010847649537026882, Val Loss: 0.007080336567014456\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.26527878642082214, Val Loss: 0.006044055335223675\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.023778805509209633, Val Loss: 0.002049687784165144\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.0035298299510031937, 'rmse': 0.05371174645692114, 'mae': 0.04514377936720848, 'mape': 16.71630561351776, 'r2': 0.9704255170812901}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.264999270439148, Val Loss: 0.262530118227005\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.2883368730545044, Val Loss: 0.26352953910827637\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.1177581548690796, Val Loss: 0.26299920678138733\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.1234687566757202, Val Loss: 0.26211199164390564\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.17234468460083, Val Loss: 0.26082348823547363\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.0258536338806152, Val Loss: 0.2588185966014862\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.9601061344146729, Val Loss: 0.2550315260887146\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.8946589231491089, Val Loss: 0.25048643350601196\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.7287406921386719, Val Loss: 0.244659423828125\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.671931803226471, Val Loss: 0.23639658093452454\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.5180720686912537, Val Loss: 0.22902844846248627\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.41355881094932556, Val Loss: 0.22033044695854187\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.3691432774066925, Val Loss: 0.21138212084770203\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.30057117342948914, Val Loss: 0.20297688245773315\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.26176145672798157, Val Loss: 0.19601191580295563\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.2195519059896469, Val Loss: 0.19299563765525818\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.2119046002626419, Val Loss: 0.19332516193389893\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.20438316464424133, Val Loss: 0.20121313631534576\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.19716070592403412, Val Loss: 0.21839173138141632\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.19895458221435547, Val Loss: 0.24031366407871246\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.1919933557510376, Val Loss: 0.26872068643569946\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.17597860097885132, Val Loss: 0.2948373556137085\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.1541961133480072, Val Loss: 0.3196432292461395\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.1441512554883957, Val Loss: 0.33817344903945923\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.1264570653438568, Val Loss: 0.3485592305660248\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.1320866197347641, Val Loss: 0.35276511311531067\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.11936651915311813, Val Loss: 0.3536844849586487\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.11900163441896439, Val Loss: 0.3489084839820862\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.1077512577176094, Val Loss: 0.3417210578918457\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.10261810570955276, Val Loss: 0.3299854099750519\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.07791857421398163, Val Loss: 0.31398382782936096\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.08718313276767731, Val Loss: 0.2929410934448242\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.07296172529459, Val Loss: 0.27054163813591003\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.0780097097158432, Val Loss: 0.24828724563121796\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.0628705695271492, Val Loss: 0.2281920313835144\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.06886652112007141, Val Loss: 0.21276384592056274\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.25902336835861206, Val Loss: 0.13344331085681915\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.2461671531200409, Val Loss: 0.12790167331695557\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.23702213168144226, Val Loss: 0.12275133281946182\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.2576826810836792, Val Loss: 0.11875468492507935\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.24550341069698334, Val Loss: 0.114637091755867\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.26100024580955505, Val Loss: 0.11044161766767502\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.21428896486759186, Val Loss: 0.10645738989114761\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.22183923423290253, Val Loss: 0.10348832607269287\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.21611244976520538, Val Loss: 0.10266033560037613\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.22626081109046936, Val Loss: 0.10326588153839111\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.18832649290561676, Val Loss: 0.10447660088539124\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.1928810328245163, Val Loss: 0.10669910907745361\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.14481335878372192, Val Loss: 0.11096999049186707\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.1567320078611374, Val Loss: 0.11499680578708649\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.1659451574087143, Val Loss: 0.12050143629312515\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.14594344794750214, Val Loss: 0.12329793721437454\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.16625747084617615, Val Loss: 0.12291963398456573\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.14768564701080322, Val Loss: 0.12263206392526627\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.13329897820949554, Val Loss: 0.11986590921878815\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.1362852305173874, Val Loss: 0.11559700965881348\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.13406512141227722, Val Loss: 0.10925203561782837\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.11519033461809158, Val Loss: 0.10124543309211731\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.10153128951787949, Val Loss: 0.09186544269323349\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.09929600358009338, Val Loss: 0.08097252249717712\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.10100210458040237, Val Loss: 0.07320833951234818\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.09537266194820404, Val Loss: 0.06881945580244064\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.0872597023844719, Val Loss: 0.06976369023323059\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.08007162064313889, Val Loss: 0.07566510140895844\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.0655154138803482, Val Loss: 0.08145924657583237\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.08082085102796555, Val Loss: 0.08289419859647751\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.07992544025182724, Val Loss: 0.08185148984193802\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.07140866667032242, Val Loss: 0.07903804630041122\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.06645560264587402, Val Loss: 0.07587026804685593\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.06439699977636337, Val Loss: 0.07281766086816788\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.061887022107839584, Val Loss: 0.06899964064359665\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.056891605257987976, Val Loss: 0.0668112263083458\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.05892229825258255, Val Loss: 0.0628647580742836\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.054207053035497665, Val Loss: 0.06065107882022858\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.05634761229157448, Val Loss: 0.061008520424366\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.056898973882198334, Val Loss: 0.06647476553916931\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.05202237889170647, Val Loss: 0.07112631946802139\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.05257118120789528, Val Loss: 0.0761050209403038\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.047102782875299454, Val Loss: 0.07863342761993408\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.04673657566308975, Val Loss: 0.07729174196720123\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.04765211418271065, Val Loss: 0.07328559458255768\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.04632839187979698, Val Loss: 0.06829375773668289\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.042011361569166183, Val Loss: 0.06704216450452805\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.04029818996787071, Val Loss: 0.06629083305597305\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.04012686759233475, Val Loss: 0.06727325171232224\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.04776231199502945, Val Loss: 0.07029885798692703\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.04387504234910011, Val Loss: 0.07237483561038971\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.04081415757536888, Val Loss: 0.07436968386173248\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.036311786621809006, Val Loss: 0.07345075160264969\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.03918186202645302, Val Loss: 0.07078955322504044\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.03914700448513031, Val Loss: 0.06840779632329941\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.038909152150154114, Val Loss: 0.06515766680240631\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.033365845680236816, Val Loss: 0.06142530217766762\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.03606368601322174, Val Loss: 0.059537582099437714\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.03617231920361519, Val Loss: 0.05798709765076637\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.030011393129825592, Val Loss: 0.05756697431206703\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.03642622008919716, Val Loss: 0.0580114908516407\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.033569589257240295, Val Loss: 0.058822132647037506\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.032663263380527496, Val Loss: 0.05905672535300255\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.030828000977635384, Val Loss: 0.06058163195848465\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.035285450518131256, Val Loss: 0.06064818799495697\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.03590812534093857, Val Loss: 0.060614798218011856\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.032411932945251465, Val Loss: 0.06005704030394554\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.03179313242435455, Val Loss: 0.05966071039438248\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.03652873635292053, Val Loss: 0.059975866228342056\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.033701300621032715, Val Loss: 0.05977516993880272\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.03250276669859886, Val Loss: 0.05907135829329491\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.032401204109191895, Val Loss: 0.05903930589556694\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.030309094116091728, Val Loss: 0.058758266270160675\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.034387994557619095, Val Loss: 0.058750636875629425\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.027551930397748947, Val Loss: 0.05821318179368973\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.03589879721403122, Val Loss: 0.05780152976512909\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.02748834155499935, Val Loss: 0.05800078809261322\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.030065761879086494, Val Loss: 0.05837294086813927\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.032592274248600006, Val Loss: 0.05754771828651428\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.03211662545800209, Val Loss: 0.05705529823899269\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.03233441710472107, Val Loss: 0.05686952546238899\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.029444042593240738, Val Loss: 0.05619657784700394\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.031698282808065414, Val Loss: 0.05610443651676178\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.03113728016614914, Val Loss: 0.05555729195475578\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.028451139107346535, Val Loss: 0.055331695824861526\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.028786491602659225, Val Loss: 0.05489728972315788\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.03085833042860031, Val Loss: 0.05451840162277222\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.032404202967882156, Val Loss: 0.05404617637395859\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.032869286835193634, Val Loss: 0.053839173167943954\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.03039928711950779, Val Loss: 0.05347949638962746\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.0320347361266613, Val Loss: 0.053969606757164\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.03054693713784218, Val Loss: 0.05348897725343704\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.030514750629663467, Val Loss: 0.05405731126666069\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.03194965422153473, Val Loss: 0.05441781505942345\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.028502952307462692, Val Loss: 0.05442820116877556\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.02723337896168232, Val Loss: 0.053758405148983\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.029144683852791786, Val Loss: 0.05335266888141632\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.02604002133011818, Val Loss: 0.053340110927820206\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.027387987822294235, Val Loss: 0.053584735840559006\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.03098248317837715, Val Loss: 0.053670771420001984\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.04965022951364517, Val Loss: 0.0012592591810971498\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.03997230529785156, Val Loss: 0.001151286531239748\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.03718585893511772, Val Loss: 0.0012517531868070364\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.04216416925191879, Val Loss: 0.0013797159772366285\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.03720824420452118, Val Loss: 0.0016009850660338998\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.04344932734966278, Val Loss: 0.0018921107985079288\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.03412593528628349, Val Loss: 0.0023005336988717318\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.03706377372145653, Val Loss: 0.0028739331755787134\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.03852288797497749, Val Loss: 0.0035975074861198664\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.04091844707727432, Val Loss: 0.004500245209783316\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.03765944018959999, Val Loss: 0.005550042260438204\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.03422175720334053, Val Loss: 0.006675320211797953\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.03514990583062172, Val Loss: 0.007587424013763666\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.03655822575092316, Val Loss: 0.008605845272541046\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.035988613963127136, Val Loss: 0.00948560331016779\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.03383048623800278, Val Loss: 0.010063806548714638\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.03590836748480797, Val Loss: 0.00991027057170868\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.030916457995772362, Val Loss: 0.009432423859834671\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.028726335614919662, Val Loss: 0.00892363116145134\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.03036019578576088, Val Loss: 0.00847707875072956\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.0263062696903944, Val Loss: 0.007869924418628216\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.027287879958748817, Val Loss: 0.0070722708478569984\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.1684887409210205, Val Loss: 0.0026620454154908657\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.044092483818531036, Val Loss: 0.0006864287424832582\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.04281932860612869, Val Loss: 0.00054327049292624\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.05262060835957527, Val Loss: 0.00045572471572086215\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.04547496140003204, Val Loss: 0.0004951826413162053\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.043501999229192734, Val Loss: 0.000562164350412786\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.03826829418540001, Val Loss: 0.0007409756653942168\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.03543489798903465, Val Loss: 0.000915859651286155\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.04042654111981392, Val Loss: 0.0010898918844759464\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.04351353645324707, Val Loss: 0.001352449064143002\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.03801552951335907, Val Loss: 0.0016628863522782922\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.03835116699337959, Val Loss: 0.0021405748557299376\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.03401680290699005, Val Loss: 0.002638439182192087\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.03724917024374008, Val Loss: 0.003076695604249835\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.03598841279745102, Val Loss: 0.0037753337528556585\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.03861275687813759, Val Loss: 0.004053561482578516\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.02945031225681305, Val Loss: 0.004216835368424654\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.031979333609342575, Val Loss: 0.004111235961318016\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.03518439084291458, Val Loss: 0.004504007752984762\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.031199682503938675, Val Loss: 0.005806967616081238\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.03411925956606865, Val Loss: 0.00797019712626934\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.03251923248171806, Val Loss: 0.010136116296052933\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.03208211809396744, Val Loss: 0.010260901413857937\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.026986420154571533, Val Loss: 0.009226718917489052\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.05055927014327608, 'rmse': 0.15904270208064425, 'mae': 0.12912164516747, 'mape': 42.921781092882156, 'r2': 0.4567311956832666}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.6244361400604248, Val Loss: 0.13745027780532837\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.2737151384353638, Val Loss: 0.1380174607038498\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.2357138395309448, Val Loss: 0.1385444849729538\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.1481908559799194, Val Loss: 0.13771216571331024\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.1838066577911377, Val Loss: 0.13768519461154938\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.8909035325050354, Val Loss: 0.13726697862148285\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.9117196798324585, Val Loss: 0.1374111920595169\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.7052352428436279, Val Loss: 0.13780321180820465\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.4020957052707672, Val Loss: 0.13721005618572235\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.35861870646476746, Val Loss: 0.1361674815416336\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.2831573784351349, Val Loss: 0.13625049591064453\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.33894434571266174, Val Loss: 0.13535289466381073\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.34194427728652954, Val Loss: 0.13549232482910156\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.2821917235851288, Val Loss: 0.13500776886940002\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.3634283244609833, Val Loss: 0.13455399870872498\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.3130054175853729, Val Loss: 0.13468730449676514\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.30332836508750916, Val Loss: 0.13638468086719513\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.24006707966327667, Val Loss: 0.13745014369487762\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.17307862639427185, Val Loss: 0.13922925293445587\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.18929730355739594, Val Loss: 0.14009542763233185\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.24901579320430756, Val Loss: 0.1399965137243271\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.1849864423274994, Val Loss: 0.13915203511714935\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.17288938164710999, Val Loss: 0.13771766424179077\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.15805144608020782, Val Loss: 0.13504692912101746\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.11986958235502243, Val Loss: 0.1328296661376953\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.16233178973197937, Val Loss: 0.1317647397518158\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.14266027510166168, Val Loss: 0.12952469289302826\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.11148053407669067, Val Loss: 0.1286540925502777\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.08557913452386856, Val Loss: 0.12858466804027557\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.10001018643379211, Val Loss: 0.12984544038772583\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.07109358161687851, Val Loss: 0.13194364309310913\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.10465565323829651, Val Loss: 0.13165611028671265\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.06850022077560425, Val Loss: 0.12942883372306824\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.0778169110417366, Val Loss: 0.12756364047527313\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.09242380410432816, Val Loss: 0.1257128268480301\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.058746617287397385, Val Loss: 0.12459734827280045\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.053951941430568695, Val Loss: 0.12261417508125305\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.05942131578922272, Val Loss: 0.12042100727558136\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.056430887430906296, Val Loss: 0.11777470260858536\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.04789290949702263, Val Loss: 0.11456454545259476\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.06070244684815407, Val Loss: 0.11142206937074661\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.04482915624976158, Val Loss: 0.10919002443552017\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.048319507390260696, Val Loss: 0.10734153538942337\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.03668583557009697, Val Loss: 0.10486196726560593\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.04470382630825043, Val Loss: 0.10289053618907928\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.042608074843883514, Val Loss: 0.09923640638589859\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.03835465386509895, Val Loss: 0.09491996467113495\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.03324396163225174, Val Loss: 0.09155921638011932\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.04518081620335579, Val Loss: 0.08945275098085403\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.04344687610864639, Val Loss: 0.0867210328578949\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.04659542813897133, Val Loss: 0.08387874066829681\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.039853535592556, Val Loss: 0.0812084972858429\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.028806110844016075, Val Loss: 0.077871173620224\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.043277475982904434, Val Loss: 0.07347135245800018\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.04377136006951332, Val Loss: 0.0696733295917511\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.027882197871804237, Val Loss: 0.06597437709569931\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.027888143435120583, Val Loss: 0.06263505667448044\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.03220684826374054, Val Loss: 0.05950687453150749\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.040796685963869095, Val Loss: 0.05693107098340988\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.03054232895374298, Val Loss: 0.05491596832871437\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.034119073301553726, Val Loss: 0.05274268612265587\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.037715911865234375, Val Loss: 0.049768853932619095\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.03773946315050125, Val Loss: 0.04678795859217644\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.026705311611294746, Val Loss: 0.04403381049633026\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.029188988730311394, Val Loss: 0.041040051728487015\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.025963107123970985, Val Loss: 0.038124360144138336\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.02991810441017151, Val Loss: 0.035545285791158676\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.02591782622039318, Val Loss: 0.03288347274065018\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.024313930422067642, Val Loss: 0.03133183345198631\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.03310752287507057, Val Loss: 0.03055926412343979\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.028204454109072685, Val Loss: 0.03004053793847561\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.038883693516254425, Val Loss: 0.029495811089873314\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.026348132640123367, Val Loss: 0.029473014175891876\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.026348114013671875, Val Loss: 0.029177092015743256\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.02126559428870678, Val Loss: 0.028947312384843826\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.025876088067889214, Val Loss: 0.028765825554728508\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.020527608692646027, Val Loss: 0.028648458421230316\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.02743801288306713, Val Loss: 0.02876460738480091\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.02526877447962761, Val Loss: 0.028843767940998077\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.023301737383008003, Val Loss: 0.029653048142790794\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.02813577651977539, Val Loss: 0.030204331502318382\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.023897606879472733, Val Loss: 0.030546924099326134\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.023975489661097527, Val Loss: 0.0307695921510458\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.018638206645846367, Val Loss: 0.030894111841917038\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.02225099317729473, Val Loss: 0.03108443133533001\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.028898924589157104, Val Loss: 0.03161810711026192\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.019490201026201248, Val Loss: 0.03148439899086952\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.02001209557056427, Val Loss: 0.03188616409897804\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.02609286457300186, Val Loss: 0.03218881040811539\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.02646861970424652, Val Loss: 0.0328403040766716\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.023516830056905746, Val Loss: 0.032634228467941284\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.02186877653002739, Val Loss: 0.033036138862371445\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.027322623878717422, Val Loss: 0.03352278098464012\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.028667153790593147, Val Loss: 0.03343593329191208\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.020886776968836784, Val Loss: 0.033635180443525314\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.027522433549165726, Val Loss: 0.034022293984889984\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.02401304431259632, Val Loss: 0.034639548510313034\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.036993734538555145, Val Loss: 0.01581539213657379\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.0312868133187294, Val Loss: 0.01518179476261139\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.043117884546518326, Val Loss: 0.014325589872896671\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.04164152964949608, Val Loss: 0.013441765680909157\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.02835424616932869, Val Loss: 0.0130901038646698\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.03545777127146721, Val Loss: 0.012564057484269142\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.028938140720129013, Val Loss: 0.012521792203187943\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.03374464064836502, Val Loss: 0.012159336358308792\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.03313182294368744, Val Loss: 0.01236734725534916\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.023648936301469803, Val Loss: 0.012380719184875488\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.030563635751605034, Val Loss: 0.012676901184022427\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.034278739243745804, Val Loss: 0.012752329930663109\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.0347495973110199, Val Loss: 0.011873925104737282\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.03316622972488403, Val Loss: 0.01109448354691267\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.025878623127937317, Val Loss: 0.010568682104349136\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.027118274942040443, Val Loss: 0.010595142841339111\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.026730278506875038, Val Loss: 0.010814131237566471\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.028152083978056908, Val Loss: 0.010561352595686913\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.02933438867330551, Val Loss: 0.010023855604231358\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.025479333475232124, Val Loss: 0.009196309372782707\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.022153420373797417, Val Loss: 0.009060232900083065\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.03091573156416416, Val Loss: 0.010697917081415653\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.019605396315455437, Val Loss: 0.01354942936450243\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.0246121883392334, Val Loss: 0.01574321836233139\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.019580120220780373, Val Loss: 0.017920561134815216\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.027192575857043266, Val Loss: 0.018808891996741295\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.026153411716222763, Val Loss: 0.015726251527667046\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.021718807518482208, Val Loss: 0.015396954491734505\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.023541638627648354, Val Loss: 0.013313394039869308\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.02277020551264286, Val Loss: 0.009868193417787552\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.01746787503361702, Val Loss: 0.008505805395543575\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.018294382840394974, Val Loss: 0.007412298116832972\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.0238120649009943, Val Loss: 0.0067835464142262936\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.02295110560953617, Val Loss: 0.006569716613739729\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.02315625175833702, Val Loss: 0.010066800750792027\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.020424455404281616, Val Loss: 0.009896458126604557\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.022185655310750008, Val Loss: 0.007785532157868147\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.023214586079120636, Val Loss: 0.007762751542031765\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.02054212987422943, Val Loss: 0.006148234475404024\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.01944408379495144, Val Loss: 0.005141932517290115\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.020062651485204697, Val Loss: 0.004281367175281048\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.018780572339892387, Val Loss: 0.005603508558124304\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.02121429517865181, Val Loss: 0.006396748591214418\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.019233541563153267, Val Loss: 0.007346463855355978\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.018973475322127342, Val Loss: 0.010276720859110355\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.01594540663063526, Val Loss: 0.014756937511265278\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.029998095706105232, Val Loss: 0.012682093307375908\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.01467321440577507, Val Loss: 0.011654635891318321\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.018910342827439308, Val Loss: 0.011232517659664154\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.014817082323133945, Val Loss: 0.012813707813620567\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.020837925374507904, Val Loss: 0.011660096235573292\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.025662075728178024, Val Loss: 0.009114709682762623\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.02007398009300232, Val Loss: 0.007545266766101122\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.015239065513014793, Val Loss: 0.007617127615958452\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.013795847073197365, Val Loss: 0.008323967456817627\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.014976887963712215, Val Loss: 0.009074368514120579\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.015716461464762688, Val Loss: 0.010577586479485035\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.017064295709133148, Val Loss: 0.011605841107666492\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.015683144330978394, Val Loss: 0.01129082404077053\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.019550548866391182, Val Loss: 0.009840104728937149\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.01894862949848175, Val Loss: 0.008210878819227219\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.019649244844913483, Val Loss: 0.00295075005851686\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.026579517871141434, Val Loss: 0.0030709083657711744\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.02345915511250496, Val Loss: 0.0030573748517781496\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.02080455981194973, Val Loss: 0.003005219390615821\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.019022632390260696, Val Loss: 0.002958995057269931\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.01781092956662178, Val Loss: 0.0030609802342951298\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.03034151718020439, Val Loss: 0.002883285516873002\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.01696079783141613, Val Loss: 0.0028434714768081903\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.020732257515192032, Val Loss: 0.00278443843126297\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.021257011219859123, Val Loss: 0.002812035381793976\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.015948841348290443, Val Loss: 0.002703237347304821\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.01790044456720352, Val Loss: 0.0026717635337263346\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.020211704075336456, Val Loss: 0.0025332882069051266\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.017570823431015015, Val Loss: 0.0026213605888187885\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.013871526345610619, Val Loss: 0.002742878859862685\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.016057088971138, Val Loss: 0.00286717526614666\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.017670832574367523, Val Loss: 0.003232272109016776\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.017218848690390587, Val Loss: 0.0038459061179310083\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.020906712859869003, Val Loss: 0.00381046743132174\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.02274193800985813, Val Loss: 0.00402079289779067\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.020423484966158867, Val Loss: 0.004572091158479452\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.021598290652036667, Val Loss: 0.004733398091048002\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.015616461634635925, Val Loss: 0.00399835966527462\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.017297519370913506, Val Loss: 0.0035988285671919584\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.016203537583351135, Val Loss: 0.004069522488862276\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.01771692745387554, Val Loss: 0.004705730825662613\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.012533311732113361, Val Loss: 0.005049580708146095\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.01736680045723915, Val Loss: 0.005461646243929863\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.022674623876810074, Val Loss: 0.0038061724044382572\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.01591658964753151, Val Loss: 0.00404414301738143\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.016692833974957466, Val Loss: 0.0043702214024960995\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.02284351736307144, Val Loss: 0.007075579836964607\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.012002102099359035, Val Loss: 0.013367160223424435\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.2286699265241623, Val Loss: 0.016224047169089317\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.018666693940758705, Val Loss: 0.003087949473410845\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.00860800282098353, 'rmse': 0.08156178517504162, 'mae': 0.07158331722021102, 'mape': 37.82346159219742, 'r2': 0.9157246833778275}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.990028977394104, Val Loss: 0.17069600522518158\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.8934193849563599, Val Loss: 0.17583554983139038\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.8592188358306885, Val Loss: 0.18040132522583008\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.9184776544570923, Val Loss: 0.18427275121212006\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.8643684387207031, Val Loss: 0.1892201453447342\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.803834319114685, Val Loss: 0.19347478449344635\n",
      "INFO:root:Epoch 7/100, Train Loss: 1.8654550313949585, Val Loss: 0.19902415573596954\n",
      "INFO:root:Epoch 8/100, Train Loss: 1.8322010040283203, Val Loss: 0.2038315236568451\n",
      "INFO:root:Epoch 9/100, Train Loss: 1.819520115852356, Val Loss: 0.2083846479654312\n",
      "INFO:root:Epoch 10/100, Train Loss: 1.706495761871338, Val Loss: 0.21151894330978394\n",
      "INFO:root:Epoch 11/100, Train Loss: 1.706116795539856, Val Loss: 0.2146254926919937\n",
      "INFO:root:Epoch 12/100, Train Loss: 1.5889959335327148, Val Loss: 0.21783950924873352\n",
      "INFO:root:Epoch 13/100, Train Loss: 1.5943766832351685, Val Loss: 0.21920455992221832\n",
      "INFO:root:Epoch 14/100, Train Loss: 1.6110060214996338, Val Loss: 0.2220144122838974\n",
      "INFO:root:Epoch 15/100, Train Loss: 1.4455748796463013, Val Loss: 0.22443842887878418\n",
      "INFO:root:Epoch 16/100, Train Loss: 1.309666395187378, Val Loss: 0.22482182085514069\n",
      "INFO:root:Epoch 17/100, Train Loss: 1.3124877214431763, Val Loss: 0.2244396060705185\n",
      "INFO:root:Epoch 18/100, Train Loss: 1.1311460733413696, Val Loss: 0.22128526866436005\n",
      "INFO:root:Epoch 19/100, Train Loss: 1.1101661920547485, Val Loss: 0.2156130075454712\n",
      "INFO:root:Epoch 20/100, Train Loss: 1.016918659210205, Val Loss: 0.20977091789245605\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.8509427905082703, Val Loss: 0.20285528898239136\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.8984498977661133, Val Loss: 0.16179105639457703\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.8473873138427734, Val Loss: 0.1645830124616623\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.9275095462799072, Val Loss: 0.1673499196767807\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.9558602571487427, Val Loss: 0.17064782977104187\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.9717293977737427, Val Loss: 0.1735924929380417\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.9148246049880981, Val Loss: 0.17620369791984558\n",
      "INFO:root:Epoch 7/100, Train Loss: 1.868436574935913, Val Loss: 0.17916978895664215\n",
      "INFO:root:Epoch 8/100, Train Loss: 1.8438655138015747, Val Loss: 0.18142451345920563\n",
      "INFO:root:Epoch 9/100, Train Loss: 1.8191615343093872, Val Loss: 0.1834086924791336\n",
      "INFO:root:Epoch 10/100, Train Loss: 1.7354772090911865, Val Loss: 0.1844140589237213\n",
      "INFO:root:Epoch 11/100, Train Loss: 1.7190412282943726, Val Loss: 0.18582037091255188\n",
      "INFO:root:Epoch 12/100, Train Loss: 1.6477406024932861, Val Loss: 0.18751876056194305\n",
      "INFO:root:Epoch 13/100, Train Loss: 1.6138041019439697, Val Loss: 0.18853293359279633\n",
      "INFO:root:Epoch 14/100, Train Loss: 1.544660210609436, Val Loss: 0.18975114822387695\n",
      "INFO:root:Epoch 15/100, Train Loss: 1.4453692436218262, Val Loss: 0.1887756586074829\n",
      "INFO:root:Epoch 16/100, Train Loss: 1.3781671524047852, Val Loss: 0.18549209833145142\n",
      "INFO:root:Epoch 17/100, Train Loss: 1.2589550018310547, Val Loss: 0.1818513572216034\n",
      "INFO:root:Epoch 18/100, Train Loss: 1.0670418739318848, Val Loss: 0.17772094905376434\n",
      "INFO:root:Epoch 19/100, Train Loss: 1.1397980451583862, Val Loss: 0.17185863852500916\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.8586763739585876, Val Loss: 0.16660816967487335\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.9111738801002502, Val Loss: 0.15948587656021118\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.8040794134140015, Val Loss: 0.15180812776088715\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.7558010220527649, Val Loss: 0.14398345351219177\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.6654958128929138, Val Loss: 0.13824191689491272\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.5839768648147583, Val Loss: 0.13150547444820404\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.49655961990356445, Val Loss: 0.12448977679014206\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.5250983834266663, Val Loss: 0.1176028773188591\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.4501788914203644, Val Loss: 0.11150423437356949\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.38344109058380127, Val Loss: 0.10412242263555527\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.39334413409233093, Val Loss: 0.09800604730844498\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.35894775390625, Val Loss: 0.09260816127061844\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.349243700504303, Val Loss: 0.08647177368402481\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.32525211572647095, Val Loss: 0.0810750424861908\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.3075398802757263, Val Loss: 0.07589490711688995\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.28986456990242004, Val Loss: 0.07137034088373184\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.27640706300735474, Val Loss: 0.06686124205589294\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.28871968388557434, Val Loss: 0.06252733618021011\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.26089203357696533, Val Loss: 0.058343321084976196\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.2608163356781006, Val Loss: 0.054316285997629166\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.2508578896522522, Val Loss: 0.05137066915631294\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.24090784788131714, Val Loss: 0.048086974769830704\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.2186422497034073, Val Loss: 0.04555288329720497\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.20559310913085938, Val Loss: 0.043072476983070374\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.19324085116386414, Val Loss: 0.04076065868139267\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.2176889032125473, Val Loss: 0.038497764617204666\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.22086940705776215, Val Loss: 0.03653598576784134\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.21413497626781464, Val Loss: 0.03488503769040108\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.18015633523464203, Val Loss: 0.03347872197628021\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.19223542511463165, Val Loss: 0.032922569662332535\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.19179317355155945, Val Loss: 0.03234981372952461\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.19160622358322144, Val Loss: 0.031719308346509933\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.1802399754524231, Val Loss: 0.031098557636141777\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.1841476410627365, Val Loss: 0.030681684613227844\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.1604071706533432, Val Loss: 0.030467437580227852\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.19418902695178986, Val Loss: 0.03020433709025383\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.17274896800518036, Val Loss: 0.029749194160103798\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.1812344491481781, Val Loss: 0.029404735192656517\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.17416764795780182, Val Loss: 0.029087604954838753\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.1444406658411026, Val Loss: 0.029150312766432762\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.15352581441402435, Val Loss: 0.029240349307656288\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.17429223656654358, Val Loss: 0.02932528592646122\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.15225166082382202, Val Loss: 0.029446475207805634\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.17220449447631836, Val Loss: 0.029125751927495003\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.1748056262731552, Val Loss: 0.029088599607348442\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.15606051683425903, Val Loss: 0.02867930941283703\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.1651056706905365, Val Loss: 0.028388021513819695\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.16080185770988464, Val Loss: 0.02889164350926876\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.14718452095985413, Val Loss: 0.02882082387804985\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.16714143753051758, Val Loss: 0.028864029794931412\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.15576663613319397, Val Loss: 0.029232513159513474\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.151536226272583, Val Loss: 0.029012972488999367\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.14126580953598022, Val Loss: 0.028844676911830902\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.1597377508878708, Val Loss: 0.028880728408694267\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.16465777158737183, Val Loss: 0.029194673523306847\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.16575415432453156, Val Loss: 0.029307913035154343\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.15371190011501312, Val Loss: 0.02890055812895298\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.15787304937839508, Val Loss: 0.0285890344530344\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.1373859941959381, Val Loss: 0.028877055272459984\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.15783213078975677, Val Loss: 0.029160046949982643\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.144799143075943, Val Loss: 0.028666753321886063\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.1641467809677124, Val Loss: 0.028227318078279495\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.16048873960971832, Val Loss: 0.0285212229937315\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.1317138671875, Val Loss: 0.028293851763010025\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.14389261603355408, Val Loss: 0.02798675373196602\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.14895787835121155, Val Loss: 0.02779899351298809\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.16318953037261963, Val Loss: 0.027829336002469063\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.14789244532585144, Val Loss: 0.028481705114245415\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.15503941476345062, Val Loss: 0.02871702052652836\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.1456051766872406, Val Loss: 0.02851061150431633\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.14752458035945892, Val Loss: 0.028633691370487213\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.14505836367607117, Val Loss: 0.028560243546962738\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.14411242306232452, Val Loss: 0.02840980887413025\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.15600158274173737, Val Loss: 0.028391346335411072\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.12551820278167725, Val Loss: 0.028084171935915947\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.1533731371164322, Val Loss: 0.02837372198700905\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.17091743648052216, Val Loss: 0.028269674628973007\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.13442976772785187, Val Loss: 0.028260866180062294\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.14991557598114014, Val Loss: 0.028228623792529106\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.14789627492427826, Val Loss: 0.028181780129671097\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.15778768062591553, Val Loss: 0.02868250198662281\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.1405872404575348, Val Loss: 0.037276580929756165\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.15208660066127777, Val Loss: 0.037735726684331894\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.1631775200366974, Val Loss: 0.03841958940029144\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.1577553153038025, Val Loss: 0.03894561529159546\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.15550290048122406, Val Loss: 0.0392337404191494\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.24069491028785706, Val Loss: 0.013034489937126637\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.24353113770484924, Val Loss: 0.01880972646176815\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.2659654915332794, Val Loss: 0.0346805639564991\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.24866653978824615, Val Loss: 0.058782245963811874\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.2506619691848755, Val Loss: 0.09064948558807373\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.252225399017334, Val Loss: 0.1282341182231903\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.23829126358032227, Val Loss: 0.17051474750041962\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.24317407608032227, Val Loss: 0.21437911689281464\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.2669629454612732, Val Loss: 0.2570825517177582\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.2463681697845459, Val Loss: 0.3077678978443146\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.2368040382862091, Val Loss: 0.34794139862060547\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.23651209473609924, Val Loss: 0.3799830377101898\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.24135005474090576, Val Loss: 0.4144928455352783\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.2040071338415146, Val Loss: 0.4384904205799103\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.21221379935741425, Val Loss: 0.45595628023147583\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.2109743356704712, Val Loss: 0.47427311539649963\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.20387646555900574, Val Loss: 0.4885358512401581\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.22580471634864807, Val Loss: 0.4915206730365753\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.2059396654367447, Val Loss: 0.4929865896701813\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.18849126994609833, Val Loss: 0.4941423237323761\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.2041400969028473, Val Loss: 0.4907389283180237\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.15084481239318848, Val Loss: 0.02522759884595871\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.05481469761580229, 'rmse': 0.20926341291300496, 'mae': 0.17995292991399764, 'mape': 66.4184433221817, 'r2': 0.4200803160158042}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.1082308292388916, Val Loss: 0.14440089464187622\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.2048907279968262, Val Loss: 0.14447900652885437\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.323429822921753, Val Loss: 0.14467297494411469\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.2474439144134521, Val Loss: 0.14447836577892303\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.09958815574646, Val Loss: 0.1445888727903366\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.0054634809494019, Val Loss: 0.14436909556388855\n",
      "INFO:root:Epoch 7/100, Train Loss: 1.0561723709106445, Val Loss: 0.14364947378635406\n",
      "INFO:root:Epoch 8/100, Train Loss: 1.062491536140442, Val Loss: 0.14387844502925873\n",
      "INFO:root:Epoch 9/100, Train Loss: 1.039426326751709, Val Loss: 0.14362776279449463\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.8348278999328613, Val Loss: 0.14328652620315552\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.8085730075836182, Val Loss: 0.14308500289916992\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.547184944152832, Val Loss: 0.14248019456863403\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.7927114367485046, Val Loss: 0.142660453915596\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.610945999622345, Val Loss: 0.14148758351802826\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.6482461094856262, Val Loss: 0.14060087502002716\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.5105696320533752, Val Loss: 0.13987992703914642\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.4323509931564331, Val Loss: 0.13844308257102966\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.47257107496261597, Val Loss: 0.13705864548683167\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.3949969410896301, Val Loss: 0.13649794459342957\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.41008850932121277, Val Loss: 0.13525475561618805\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.47396019101142883, Val Loss: 0.1343098282814026\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.39505040645599365, Val Loss: 0.13277536630630493\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.3207719922065735, Val Loss: 0.13280649483203888\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.42805084586143494, Val Loss: 0.13224342465400696\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.2936241626739502, Val Loss: 0.1303572654724121\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.2696552276611328, Val Loss: 0.13027435541152954\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.3313366174697876, Val Loss: 0.127717062830925\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.2490873783826828, Val Loss: 0.1267021745443344\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.343960165977478, Val Loss: 0.12602119147777557\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.29874134063720703, Val Loss: 0.12450098246335983\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.24970746040344238, Val Loss: 0.12352864444255829\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.2077682614326477, Val Loss: 0.12330856919288635\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.21788690984249115, Val Loss: 0.1219203770160675\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.294304758310318, Val Loss: 0.12015540897846222\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.22128798067569733, Val Loss: 0.11850658804178238\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.1963643580675125, Val Loss: 0.1173299178481102\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.18169094622135162, Val Loss: 0.11652059853076935\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.22598043084144592, Val Loss: 0.11474237591028214\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.23048274219036102, Val Loss: 0.1142028272151947\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.20070399343967438, Val Loss: 0.11441316455602646\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.2186005860567093, Val Loss: 0.1131298840045929\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.16438308358192444, Val Loss: 0.1104404553771019\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.1906280666589737, Val Loss: 0.10804527252912521\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.2006193846464157, Val Loss: 0.10573841631412506\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.15220412611961365, Val Loss: 0.10231918841600418\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.19683942198753357, Val Loss: 0.09992102533578873\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.18975773453712463, Val Loss: 0.09739547967910767\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.19797064363956451, Val Loss: 0.09542638063430786\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.1605878472328186, Val Loss: 0.09360247850418091\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.17436526715755463, Val Loss: 0.09219833463430405\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.1764022558927536, Val Loss: 0.09017057716846466\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.15528540313243866, Val Loss: 0.08771505206823349\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.16938701272010803, Val Loss: 0.08612830191850662\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.16425156593322754, Val Loss: 0.08461560308933258\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.1696586161851883, Val Loss: 0.08277600258588791\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.14318004250526428, Val Loss: 0.08142075687646866\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.24298617243766785, Val Loss: 0.08005724847316742\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.1807696521282196, Val Loss: 0.07721023261547089\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.16413603723049164, Val Loss: 0.0746266171336174\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.1481235772371292, Val Loss: 0.07251062244176865\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.11901295185089111, Val Loss: 0.07013346999883652\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.203536257147789, Val Loss: 0.06672148406505585\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.16254521906375885, Val Loss: 0.06416336447000504\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.14464695751667023, Val Loss: 0.06188968941569328\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.23166309297084808, Val Loss: 0.0598674938082695\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.12578758597373962, Val Loss: 0.05838385969400406\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.15409447252750397, Val Loss: 0.057015471160411835\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.18049490451812744, Val Loss: 0.05638532340526581\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.14983510971069336, Val Loss: 0.056006450206041336\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.13231568038463593, Val Loss: 0.05522614344954491\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.1482500582933426, Val Loss: 0.05521354451775551\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.13968627154827118, Val Loss: 0.05636928603053093\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.1438063532114029, Val Loss: 0.05673368647694588\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.13021370768547058, Val Loss: 0.05754176527261734\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.12432272732257843, Val Loss: 0.05793764442205429\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.15066808462142944, Val Loss: 0.05767381563782692\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.11464635282754898, Val Loss: 0.05957253277301788\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.12398114055395126, Val Loss: 0.06152107194066048\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.1692570447921753, Val Loss: 0.0635012537240982\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.12451424449682236, Val Loss: 0.06624922156333923\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.1303647756576538, Val Loss: 0.0694122239947319\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.16403692960739136, Val Loss: 0.07305319607257843\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.1451277881860733, Val Loss: 0.07443553954362869\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.14145760238170624, Val Loss: 0.0764891654253006\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.11651955544948578, Val Loss: 0.07940253615379333\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.1372263878583908, Val Loss: 0.08246754854917526\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.13301868736743927, Val Loss: 0.08474094420671463\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.12674188613891602, Val Loss: 0.08297394216060638\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.13437004387378693, Val Loss: 0.08373250812292099\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.14968682825565338, Val Loss: 0.08869094401597977\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.1396535187959671, Val Loss: 0.09094523638486862\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.17709030210971832, Val Loss: 0.059327512979507446\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.17832380533218384, Val Loss: 0.024252910166978836\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.1876021772623062, Val Loss: 0.023289604112505913\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.1925569623708725, Val Loss: 0.021861013025045395\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.17653724551200867, Val Loss: 0.020589563995599747\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.17203518748283386, Val Loss: 0.01944025233387947\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.1453009694814682, Val Loss: 0.018757522106170654\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.1797219067811966, Val Loss: 0.017397990450263023\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.15370477735996246, Val Loss: 0.01616339012980461\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.19689419865608215, Val Loss: 0.015566055662930012\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.16197222471237183, Val Loss: 0.015279858373105526\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.1668461412191391, Val Loss: 0.014608747325837612\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.14369237422943115, Val Loss: 0.015083344653248787\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.1677880585193634, Val Loss: 0.014579487033188343\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.11079054325819016, Val Loss: 0.014972145669162273\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.17636115849018097, Val Loss: 0.015530704520642757\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.1597532033920288, Val Loss: 0.016524378210306168\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.1634688675403595, Val Loss: 0.01751730777323246\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.14066962897777557, Val Loss: 0.01819043979048729\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.1791638433933258, Val Loss: 0.01941477693617344\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.14541099965572357, Val Loss: 0.020309550687670708\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.1448489874601364, Val Loss: 0.02128148451447487\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.12982642650604248, Val Loss: 0.024095535278320312\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.1306983381509781, Val Loss: 0.026111476123332977\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.170426145195961, Val Loss: 0.028064409270882607\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.13620413839817047, Val Loss: 0.031551461666822433\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.14974276721477509, Val Loss: 0.03758272901177406\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.1058012917637825, Val Loss: 0.04086676612496376\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.11773698031902313, Val Loss: 0.044482145458459854\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.15620535612106323, Val Loss: 0.04490922763943672\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.1714489758014679, Val Loss: 0.04475998878479004\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.10781478881835938, Val Loss: 0.04379282146692276\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.1605745106935501, Val Loss: 0.04465373232960701\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.14174066483974457, Val Loss: 0.046287305653095245\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.22820022702217102, Val Loss: 0.3254488408565521\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.20481762290000916, Val Loss: 0.07708108425140381\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.12343805003911257, 'rmse': 0.3049897563062527, 'mae': 0.2292731687426567, 'mape': 60.47710657119751, 'r2': 0.646415705915749}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.3876307010650635, Val Loss: 0.24255800247192383\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.9638486504554749, Val Loss: 0.24193644523620605\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.6878368854522705, Val Loss: 0.24059222638607025\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.4861047863960266, Val Loss: 0.23942099511623383\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.32006537914276123, Val Loss: 0.23668541014194489\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.2499159276485443, Val Loss: 0.23631209135055542\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.2695062756538391, Val Loss: 0.23524782061576843\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.28939083218574524, Val Loss: 0.23290576040744781\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.31470343470573425, Val Loss: 0.23057004809379578\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.2456204742193222, Val Loss: 0.22713978588581085\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.2554977238178253, Val Loss: 0.22597484290599823\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.19290302693843842, Val Loss: 0.2219032198190689\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.14745277166366577, Val Loss: 0.22167067229747772\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.15649811923503876, Val Loss: 0.2199886441230774\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.1655598282814026, Val Loss: 0.2174372524023056\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.15282733738422394, Val Loss: 0.21308790147304535\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.10640218108892441, Val Loss: 0.20910003781318665\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.10246556997299194, Val Loss: 0.20368754863739014\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.08990733325481415, Val Loss: 0.19876724481582642\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.09485551714897156, Val Loss: 0.19400137662887573\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.07849259674549103, Val Loss: 0.18952663242816925\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.06938401609659195, Val Loss: 0.18530890345573425\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.04894186556339264, Val Loss: 0.1814243495464325\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.058330781757831573, Val Loss: 0.17783598601818085\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.050317827612161636, Val Loss: 0.1740405261516571\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.044012658298015594, Val Loss: 0.16868863999843597\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.03821055218577385, Val Loss: 0.16296720504760742\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.037773001939058304, Val Loss: 0.1586698442697525\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.038895998150110245, Val Loss: 0.1550375372171402\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.0357980951666832, Val Loss: 0.1533910632133484\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.029681257903575897, Val Loss: 0.15172159671783447\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.0267635490745306, Val Loss: 0.14884144067764282\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.018357543274760246, Val Loss: 0.1453782021999359\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.02836555987596512, Val Loss: 0.1427125781774521\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.025033416226506233, Val Loss: 0.1405291110277176\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.020683210343122482, Val Loss: 0.1384413242340088\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.02641422115266323, Val Loss: 0.1344241350889206\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.01960192434489727, Val Loss: 0.13086043298244476\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.014500987716019154, Val Loss: 0.1287560611963272\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.014137552119791508, Val Loss: 0.1273123025894165\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.01945033296942711, Val Loss: 0.12594974040985107\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.018289202824234962, Val Loss: 0.12497617304325104\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.02150445058941841, Val Loss: 0.12216059118509293\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.016284693032503128, Val Loss: 0.11703652888536453\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.013900716789066792, Val Loss: 0.11174628138542175\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.01571693643927574, Val Loss: 0.10896709561347961\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.020894989371299744, Val Loss: 0.11014726758003235\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.01454605907201767, Val Loss: 0.1121697947382927\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.018063046038150787, Val Loss: 0.1102195456624031\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.012904697097837925, Val Loss: 0.10602056235074997\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.015190886333584785, Val Loss: 0.09899140894412994\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.011183482594788074, Val Loss: 0.09190162271261215\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.013335412368178368, Val Loss: 0.08717429637908936\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.015757927671074867, Val Loss: 0.08498191833496094\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.013327139429748058, Val Loss: 0.08339681476354599\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.013420052826404572, Val Loss: 0.0819406732916832\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.012628673575818539, Val Loss: 0.0796772837638855\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.012547516264021397, Val Loss: 0.07644699513912201\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.012416633777320385, Val Loss: 0.07184842973947525\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.015043207444250584, Val Loss: 0.06739804893732071\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.012174872681498528, Val Loss: 0.06294114887714386\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.013138091191649437, Val Loss: 0.059241414070129395\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.014136189594864845, Val Loss: 0.05678567662835121\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.01301715150475502, Val Loss: 0.053504861891269684\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.012366331182420254, Val Loss: 0.049493372440338135\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.011534741148352623, Val Loss: 0.04481155797839165\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.010238828137516975, Val Loss: 0.040025435388088226\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.011353407055139542, Val Loss: 0.036284059286117554\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.010166092775762081, Val Loss: 0.03329493850469589\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.012350787408649921, Val Loss: 0.030899634584784508\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.012268275022506714, Val Loss: 0.028941301628947258\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.010435415431857109, Val Loss: 0.027210647240281105\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.010937032289803028, Val Loss: 0.026117660105228424\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.009946545585989952, Val Loss: 0.024918455630540848\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.010007020086050034, Val Loss: 0.023816576227545738\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.013330060988664627, Val Loss: 0.02273569628596306\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.013409917242825031, Val Loss: 0.02170923538506031\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.01033068634569645, Val Loss: 0.020792314782738686\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.00935441441833973, Val Loss: 0.020058296620845795\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.00978843867778778, Val Loss: 0.01976642571389675\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.007776238489896059, Val Loss: 0.019897514954209328\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.012154671363532543, Val Loss: 0.020192738622426987\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.01036815159022808, Val Loss: 0.02061579003930092\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.011835035867989063, Val Loss: 0.02106739766895771\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.007809660397469997, Val Loss: 0.021539991721510887\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.01029107253998518, Val Loss: 0.022114021703600883\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.009214082732796669, Val Loss: 0.022685224190354347\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.014800287783145905, Val Loss: 0.023329496383666992\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.010464816354215145, Val Loss: 0.02373403310775757\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.009995679371058941, Val Loss: 0.02363932505249977\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.009935836307704449, Val Loss: 0.024270229041576385\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.011551124043762684, Val Loss: 0.02468833141028881\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.010442318394780159, Val Loss: 0.025154033675789833\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.010111497715115547, Val Loss: 0.026096967980265617\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.00763585465028882, Val Loss: 0.026582153514027596\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.01013738289475441, Val Loss: 0.02656039595603943\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.009984632954001427, Val Loss: 0.027142271399497986\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.008524589240550995, Val Loss: 0.028187083080410957\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.009276286698877811, Val Loss: 0.028555812314152718\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.01076758187264204, Val Loss: 0.029165850952267647\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.01944892108440399, Val Loss: 0.021847622469067574\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.01853436417877674, Val Loss: 0.009721282869577408\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.022216062992811203, Val Loss: 0.009464270435273647\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.020288575440645218, Val Loss: 0.009126892313361168\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.019867215305566788, Val Loss: 0.008937892504036427\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.01773226074874401, Val Loss: 0.008719142526388168\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.018024083226919174, Val Loss: 0.008409304544329643\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.02036275342106819, Val Loss: 0.008181944489479065\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.018361570313572884, Val Loss: 0.008026557974517345\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.01623147912323475, Val Loss: 0.0076331570744514465\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.01499849371612072, Val Loss: 0.007035736460238695\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.014808177947998047, Val Loss: 0.006471800152212381\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.015166908502578735, Val Loss: 0.006740978453308344\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.017451060935854912, Val Loss: 0.007458054460585117\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.013673525303602219, Val Loss: 0.008408572524785995\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.013628101907670498, Val Loss: 0.009795687161386013\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.011037154123187065, Val Loss: 0.011308682151138783\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.015036082826554775, Val Loss: 0.012797309085726738\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.017905807122588158, Val Loss: 0.012053136713802814\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.012379191815853119, Val Loss: 0.009732634760439396\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.014475135132670403, Val Loss: 0.0041670831851661205\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.01500367745757103, Val Loss: 0.002208883175626397\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.013444151729345322, Val Loss: 0.002729415660724044\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.013162681832909584, Val Loss: 0.0029438601341098547\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.01082130242139101, Val Loss: 0.004422186873853207\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.012110734358429909, Val Loss: 0.003698702435940504\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.012369831092655659, Val Loss: 0.004114239010959864\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.010272401385009289, Val Loss: 0.003975106403231621\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.01010473258793354, Val Loss: 0.0028427760116755962\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.012463248334825039, Val Loss: 0.0051032681949436665\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.012851194478571415, Val Loss: 0.008599608205258846\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.013578440062701702, Val Loss: 0.0037837177515029907\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.010622709058225155, Val Loss: 0.0037945539224892855\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.009931501932442188, Val Loss: 0.008244866505265236\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.009547999128699303, Val Loss: 0.015036563389003277\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.01148267649114132, Val Loss: 0.009138179011642933\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.011863439343869686, Val Loss: 0.005866142455488443\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.012565591372549534, Val Loss: 0.0054623340256512165\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.010726341977715492, Val Loss: 0.0030403693672269583\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.009019135497510433, Val Loss: 0.0031195729970932007\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.008013727143406868, Val Loss: 0.004041303414851427\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.009383080527186394, Val Loss: 0.004820185247808695\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.21030458807945251, Val Loss: 0.005241581704467535\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.011814003810286522, Val Loss: 0.008950428105890751\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.010982396267354488, 'rmse': 0.09419381156938417, 'mae': 0.08326858282089233, 'mape': 33.45345973968506, 'r2': 0.9042858532627275}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.2492481470108032, Val Loss: 0.24805717170238495\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.221413254737854, Val Loss: 0.24581032991409302\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.0696132183074951, Val Loss: 0.24443796277046204\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.0421744585037231, Val Loss: 0.2439635992050171\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.0482442378997803, Val Loss: 0.24330775439739227\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.8405799865722656, Val Loss: 0.243809312582016\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.8259310126304626, Val Loss: 0.24305124580860138\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.7385393381118774, Val Loss: 0.2426888793706894\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.7395325899124146, Val Loss: 0.24263928830623627\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.487921804189682, Val Loss: 0.24041470885276794\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.35498249530792236, Val Loss: 0.24063748121261597\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.3121000826358795, Val Loss: 0.23809786140918732\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.2940693199634552, Val Loss: 0.2376926988363266\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.3522998094558716, Val Loss: 0.23818165063858032\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.25492796301841736, Val Loss: 0.23941181600093842\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.3020806908607483, Val Loss: 0.23630116879940033\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.33373168110847473, Val Loss: 0.23533698916435242\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.31363460421562195, Val Loss: 0.23513108491897583\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.2685750722885132, Val Loss: 0.2350849062204361\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.30486592650413513, Val Loss: 0.23489022254943848\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.18212464451789856, Val Loss: 0.23218880593776703\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.18851211667060852, Val Loss: 0.2295447289943695\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.16711817681789398, Val Loss: 0.22855497896671295\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.1791510432958603, Val Loss: 0.22952261567115784\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.1663389354944229, Val Loss: 0.22884969413280487\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.1659628450870514, Val Loss: 0.2296861708164215\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.16891923546791077, Val Loss: 0.2307765632867813\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.17138312757015228, Val Loss: 0.22913016378879547\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.15642715990543365, Val Loss: 0.2281116247177124\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.150522843003273, Val Loss: 0.2264930158853531\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.11080839484930038, Val Loss: 0.22444218397140503\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.10358598083257675, Val Loss: 0.22246035933494568\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.0945596918463707, Val Loss: 0.2200593203306198\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.09648420661687851, Val Loss: 0.2190694957971573\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.09979820996522903, Val Loss: 0.21817556023597717\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.07364485412836075, Val Loss: 0.2181079387664795\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.10191943496465683, Val Loss: 0.21666675806045532\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.1035560816526413, Val Loss: 0.2153209149837494\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.08880382031202316, Val Loss: 0.21170100569725037\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.09649044275283813, Val Loss: 0.20921054482460022\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.07801106572151184, Val Loss: 0.20622383058071136\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.09587766975164413, Val Loss: 0.20325952768325806\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.06635141372680664, Val Loss: 0.20120713114738464\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.07584508508443832, Val Loss: 0.19943180680274963\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.09073422104120255, Val Loss: 0.19781559705734253\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.06801187992095947, Val Loss: 0.19608977437019348\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.06738503277301788, Val Loss: 0.19434455037117004\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.07307832688093185, Val Loss: 0.19140376150608063\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.058964796364307404, Val Loss: 0.18901297450065613\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.05664888396859169, Val Loss: 0.18575112521648407\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.06033855304121971, Val Loss: 0.18224817514419556\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.0745394378900528, Val Loss: 0.1780470609664917\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.061384331434965134, Val Loss: 0.1724609136581421\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.060301367193460464, Val Loss: 0.1682969629764557\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.058784160763025284, Val Loss: 0.16474619507789612\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.054451994597911835, Val Loss: 0.161220520734787\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.06487617641687393, Val Loss: 0.1580566167831421\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.06346943229436874, Val Loss: 0.15482647716999054\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.06023497134447098, Val Loss: 0.15149863064289093\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.04991511255502701, Val Loss: 0.1492708921432495\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.05561564117670059, Val Loss: 0.14612683653831482\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.0659518614411354, Val Loss: 0.14399565756320953\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.05000559985637665, Val Loss: 0.14006640017032623\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.07010405510663986, Val Loss: 0.1363120824098587\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.055081095546483994, Val Loss: 0.13220131397247314\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.05524939298629761, Val Loss: 0.12757037580013275\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.0652778372168541, Val Loss: 0.12287402898073196\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.050554946064949036, Val Loss: 0.11927137523889542\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.051214851438999176, Val Loss: 0.11453291773796082\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.04447898641228676, Val Loss: 0.10963321477174759\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.048733603209257126, Val Loss: 0.1044466570019722\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.04633128643035889, Val Loss: 0.09937097877264023\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.053925950080156326, Val Loss: 0.094693623483181\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.04608044773340225, Val Loss: 0.08948201686143875\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.04666261374950409, Val Loss: 0.08468994498252869\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.04920047149062157, Val Loss: 0.07940684258937836\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.05643574148416519, Val Loss: 0.0732714831829071\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.048837918788194656, Val Loss: 0.06783167272806168\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.05833311751484871, Val Loss: 0.06277117878198624\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.045468807220458984, Val Loss: 0.059049028903245926\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.053389161825180054, Val Loss: 0.05529695749282837\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.05411951243877411, Val Loss: 0.05100579932332039\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.05300332233309746, Val Loss: 0.04755258187651634\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.05353913828730583, Val Loss: 0.04418843612074852\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.052184101194143295, Val Loss: 0.041316937655210495\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.052245475351810455, Val Loss: 0.038209352642297745\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.044163599610328674, Val Loss: 0.0358651727437973\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.055168308317661285, Val Loss: 0.03266119211912155\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.05230819061398506, Val Loss: 0.030272923409938812\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.03857440501451492, Val Loss: 0.02773945964872837\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.05640300363302231, Val Loss: 0.025602011010050774\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.05053606629371643, Val Loss: 0.02414895035326481\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.044098637998104095, Val Loss: 0.023197410628199577\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.04612647369503975, Val Loss: 0.022203316912055016\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.05286911129951477, Val Loss: 0.020788807421922684\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.05163359269499779, Val Loss: 0.019471822306513786\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.0500091053545475, Val Loss: 0.018410103395581245\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.04000210016965866, Val Loss: 0.01762164756655693\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.04789439216256142, Val Loss: 0.01699741929769516\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.05220266431570053, Val Loss: 0.016015205532312393\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.05175400897860527, Val Loss: 0.020439280197024345\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.05001119524240494, Val Loss: 0.019728362560272217\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.056709542870521545, Val Loss: 0.019679749384522438\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.049718424677848816, Val Loss: 0.019462062045931816\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.06212146207690239, Val Loss: 0.019690509885549545\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.06362516433000565, Val Loss: 0.01842178963124752\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.062440354377031326, Val Loss: 0.018419010564684868\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.0584900788962841, Val Loss: 0.018158026039600372\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.06380240619182587, Val Loss: 0.017226340249180794\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.06792692095041275, Val Loss: 0.01741706021130085\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.05552715063095093, Val Loss: 0.016625499352812767\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.05591677874326706, Val Loss: 0.01559273712337017\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.059044379740953445, Val Loss: 0.014299836941063404\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.06130943074822426, Val Loss: 0.013524770736694336\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.05527494102716446, Val Loss: 0.011905156075954437\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.0557006411254406, Val Loss: 0.01064437534660101\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.06198109686374664, Val Loss: 0.00996775459498167\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.048712290823459625, Val Loss: 0.010072456672787666\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.05441003292798996, Val Loss: 0.011865643784403801\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.05210127681493759, Val Loss: 0.013853134587407112\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.05101423338055611, Val Loss: 0.01579882577061653\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.05827813223004341, Val Loss: 0.018198879435658455\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.049503784626722336, Val Loss: 0.019456133246421814\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.05474558845162392, Val Loss: 0.021014709025621414\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.05098692327737808, Val Loss: 0.021507225930690765\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.05102754384279251, Val Loss: 0.022385776042938232\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.051046643406152725, Val Loss: 0.021686701104044914\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.05329873412847519, Val Loss: 0.019084997475147247\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.053660932928323746, Val Loss: 0.017285415902733803\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.04431384429335594, Val Loss: 0.016240796074271202\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.039960525929927826, Val Loss: 0.014866985380649567\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.0457819364964962, Val Loss: 0.013724624179303646\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.04727600887417793, Val Loss: 0.014200516976416111\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.046541567891836166, Val Loss: 0.01632821187376976\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.046641379594802856, Val Loss: 0.01859358139336109\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.04402386024594307, Val Loss: 0.022713784128427505\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.03603687882423401, Val Loss: 0.02469201758503914\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.06613127142190933, Val Loss: 0.006655591074377298\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.05333786830306053, Val Loss: 0.00653041061013937\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.06322819739580154, Val Loss: 0.005955398548394442\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.05433441326022148, Val Loss: 0.005820033606141806\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.05808631703257561, Val Loss: 0.00624482799321413\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.057130664587020874, Val Loss: 0.005511431023478508\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.04883114621043205, Val Loss: 0.005797156132757664\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.06487005203962326, Val Loss: 0.005582403391599655\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.055234722793102264, Val Loss: 0.005901827476918697\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.0522531233727932, Val Loss: 0.005650781560689211\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.05727367103099823, Val Loss: 0.0055084205232560635\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.0545664057135582, Val Loss: 0.005564328283071518\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.053327493369579315, Val Loss: 0.0063714743591845036\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.056107617914676666, Val Loss: 0.007197597995400429\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.05159187316894531, Val Loss: 0.0076884133741259575\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.052024807780981064, Val Loss: 0.007840202189981937\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.05251195281744003, Val Loss: 0.008948973380029202\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.053419485688209534, Val Loss: 0.00974613893777132\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.04528585821390152, Val Loss: 0.010903149843215942\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.05018310248851776, Val Loss: 0.010998301208019257\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.05486584082245827, Val Loss: 0.011319427751004696\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.056022804230451584, Val Loss: 0.009833104908466339\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.0479569286108017, Val Loss: 0.007189310621470213\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.05049949139356613, Val Loss: 0.005608050152659416\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.04500982537865639, Val Loss: 0.005919931456446648\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.055089324712753296, Val Loss: 0.005938143003731966\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.052174411714076996, Val Loss: 0.005518786143511534\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.04739506542682648, Val Loss: 0.0051160636357963085\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.04795892536640167, Val Loss: 0.0069907186552882195\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.04205755144357681, Val Loss: 0.009493939578533173\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.05299282446503639, Val Loss: 0.010266759432852268\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.03989347070455551, Val Loss: 0.009465180337429047\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.03490316867828369, Val Loss: 0.008662428706884384\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.04318279027938843, Val Loss: 0.007811729796230793\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.04276714473962784, Val Loss: 0.007875223644077778\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.03828306868672371, Val Loss: 0.007987048476934433\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.04222133010625839, Val Loss: 0.008681468665599823\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.043575987219810486, Val Loss: 0.009133449755609035\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.04411258175969124, Val Loss: 0.009730366058647633\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.04765770211815834, Val Loss: 0.010389521718025208\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.03781504929065704, Val Loss: 0.009919235482811928\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.04378264397382736, Val Loss: 0.009219201281666756\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.04403981938958168, Val Loss: 0.007994054816663265\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.03202822431921959, Val Loss: 0.007431524805724621\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.04257325828075409, Val Loss: 0.007894948124885559\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.038469571620225906, Val Loss: 0.008312145248055458\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.03732890635728836, Val Loss: 0.01007433608174324\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.036284852772951126, Val Loss: 0.01157626137137413\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.16794148087501526, Val Loss: 0.06254620850086212\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.05692533776164055, Val Loss: 0.015599889680743217\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.015627714339643717, 'rmse': 0.11940191174753974, 'mae': 0.1017513744533062, 'mape': 32.76222765445709, 'r2': 0.9196832159764661}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.0025796075933612883\n",
      "Best Parameters: {'weight_decay': 0.0001, 'num_heads': 16, 'lstm_num_layers': 1, 'lstm_hidden_dim': 256, 'lstm_dropout': 0.1, 'learning_rate': 0.0005, 'gat_hidden_dim': 128, 'gat_dropout': 0.1, 'combined_dim': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 1/100, Train Loss: 0.764237105846405, Val Loss: 1.3015921115875244\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.47665053606033325, Val Loss: 1.2948862314224243\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.27276065945625305, Val Loss: 1.285361409187317\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.15158914029598236, Val Loss: 1.2725001573562622\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.1413181871175766, Val Loss: 1.2571420669555664\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.21228311955928802, Val Loss: 1.2423819303512573\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.3023011088371277, Val Loss: 1.229813575744629\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.33643659949302673, Val Loss: 1.2208800315856934\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.278263121843338, Val Loss: 1.217869758605957\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.1689596027135849, Val Loss: 1.2201802730560303\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.09201625734567642, Val Loss: 1.2239415645599365\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.11089079827070236, Val Loss: 1.2202236652374268\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.17180083692073822, Val Loss: 1.202036738395691\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.1768922507762909, Val Loss: 1.1705071926116943\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.12040151655673981, Val Loss: 1.1299530267715454\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.07558907568454742, Val Loss: 1.087957501411438\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.07194482535123825, Val Loss: 1.050742268562317\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.07131825387477875, Val Loss: 1.031280279159546\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.05904384329915047, Val Loss: 1.0316853523254395\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.04559637978672981, Val Loss: 1.03446626663208\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.045915983617305756, Val Loss: 1.0255603790283203\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.04748924449086189, Val Loss: 1.001453161239624\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.03599008172750473, Val Loss: 0.9663857221603394\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.025866514071822166, Val Loss: 0.9246939420700073\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.02256055921316147, Val Loss: 0.8807681202888489\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.028118759393692017, Val Loss: 0.8425999879837036\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.026504574343562126, Val Loss: 0.8163605332374573\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.021671604365110397, Val Loss: 0.7927173972129822\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.013684350997209549, Val Loss: 0.7668384313583374\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.014432409778237343, Val Loss: 0.7451490163803101\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.018570756539702415, Val Loss: 0.7229529619216919\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.01810205914080143, Val Loss: 0.6953180432319641\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.015805136412382126, Val Loss: 0.6548207402229309\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.012540772557258606, Val Loss: 0.6110306978225708\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.012921316549181938, Val Loss: 0.5844288468360901\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.012912734411656857, Val Loss: 0.5709507465362549\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.01283787190914154, Val Loss: 0.5529388189315796\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.01156681776046753, Val Loss: 0.5304142832756042\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.010035336017608643, Val Loss: 0.5095353722572327\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.00991938915103674, Val Loss: 0.49157455563545227\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.009313922375440598, Val Loss: 0.46913108229637146\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.009771333076059818, Val Loss: 0.43845847249031067\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.009720217436552048, Val Loss: 0.40319904685020447\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.009739379398524761, Val Loss: 0.37788933515548706\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.008947915397584438, Val Loss: 0.3605310618877411\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.010177926160395145, Val Loss: 0.34662336111068726\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.009534018114209175, Val Loss: 0.3304155170917511\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.008274450898170471, Val Loss: 0.31386762857437134\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.008262268267571926, Val Loss: 0.29152336716651917\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.008154968731105328, Val Loss: 0.2697424590587616\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.009414315223693848, Val Loss: 0.2533385455608368\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.00863589160144329, Val Loss: 0.24257715046405792\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.008374898694455624, Val Loss: 0.2310558706521988\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.008026531897485256, Val Loss: 0.20956338942050934\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.00761408032849431, Val Loss: 0.18746621906757355\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.008183619007468224, Val Loss: 0.1707575023174286\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.007168228272348642, Val Loss: 0.1604839563369751\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.007120588794350624, Val Loss: 0.1506466120481491\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.007975983433425426, Val Loss: 0.14060276746749878\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.0068786777555942535, Val Loss: 0.13270854949951172\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.007019325625151396, Val Loss: 0.1259523183107376\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.0072329081594944, Val Loss: 0.120635487139225\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.007127373479306698, Val Loss: 0.11514496058225632\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.00731791602447629, Val Loss: 0.10919942706823349\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.007335033733397722, Val Loss: 0.10331104695796967\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.007297055330127478, Val Loss: 0.09612280130386353\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.006673859898000956, Val Loss: 0.08838174492120743\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.007904333993792534, Val Loss: 0.08125824481248856\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.007088187150657177, Val Loss: 0.0759807825088501\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.006833079736679792, Val Loss: 0.07246994227170944\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.0065775527618825436, Val Loss: 0.07046069949865341\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.006736758165061474, Val Loss: 0.06859496980905533\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.007831589318811893, Val Loss: 0.06652144342660904\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.006198875140398741, Val Loss: 0.0641874223947525\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.006682234816253185, Val Loss: 0.061326779425144196\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.006523041985929012, Val Loss: 0.05898279696702957\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.007010431028902531, Val Loss: 0.056661706417798996\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.005604146979749203, Val Loss: 0.05472998321056366\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.0069133383221924305, Val Loss: 0.05275359004735947\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.006130372639745474, Val Loss: 0.051779743283987045\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.006126106716692448, Val Loss: 0.0511220283806324\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.0059466054663062096, Val Loss: 0.05083661898970604\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.005703609436750412, Val Loss: 0.0506969653069973\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.006592279765754938, Val Loss: 0.05028066784143448\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.00696648471057415, Val Loss: 0.05030076578259468\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.006399908103048801, Val Loss: 0.05007506534457207\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.005755119491368532, Val Loss: 0.04985528439283371\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.006904694717377424, Val Loss: 0.04943899065256119\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.006689222063869238, Val Loss: 0.04938095808029175\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.006173541769385338, Val Loss: 0.04918808117508888\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.006024913862347603, Val Loss: 0.049177322536706924\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.006489286199212074, Val Loss: 0.0488353967666626\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.006869958247989416, Val Loss: 0.04853847622871399\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.00701808650046587, Val Loss: 0.04831375181674957\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.00643550418317318, Val Loss: 0.048206668347120285\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.006936881225556135, Val Loss: 0.04818959906697273\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.006597654428333044, Val Loss: 0.04797327518463135\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.006064863875508308, Val Loss: 0.04806624725461006\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.006369818467646837, Val Loss: 0.04823426529765129\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.007013247814029455, Val Loss: 0.048094071447849274\n",
      "INFO:root:Test MSE: 0.027540989220142365, Test RMSE: 0.1659547806486525, Test MAE: 0.12347143888473511, Test MAPE: 40.471863746643066, Test R2: 0.9693317985256257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics: (0.027540989220142365, 0.1659547806486525, 0.12347143888473511, 40.471863746643066, 0.9693317985256257)\n",
      "Shape of test_predictions: (27, 27, 1)\n",
      "Shape of test_targets: (27, 27, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, ParameterSampler\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model\n",
    "class LSTM_GAT_Model(nn.Module):\n",
    "    def __init__(self, static_input_dim, lstm_input_dim, lstm_hidden_dim, lstm_num_layers, gat_input_dim, gat_hidden_dim, num_heads, combined_dim, output_dim, lstm_dropout=0.3, gat_dropout=0.3):\n",
    "        super(LSTM_GAT_Model, self).__init__()\n",
    "\n",
    "        # LSTM for time series features\n",
    "        self.lstm = nn.LSTM(lstm_input_dim, lstm_hidden_dim, lstm_num_layers, batch_first=True, dropout=lstm_dropout if lstm_num_layers > 1 else 0.0)\n",
    "        self.lstm_bn = nn.BatchNorm1d(lstm_hidden_dim)\n",
    "\n",
    "        # Fully connected layer to combine LSTM output with static features\n",
    "        self.fc1 = nn.Linear(lstm_hidden_dim + static_input_dim, gat_input_dim)\n",
    "        self.fc1_bn = nn.BatchNorm1d(gat_input_dim)\n",
    "        self.dropout1 = nn.Dropout(lstm_dropout)\n",
    "\n",
    "        # GAT for combined features\n",
    "        self.gat = pyg_nn.GATConv(gat_input_dim, gat_hidden_dim, heads=num_heads)\n",
    "        self.gat_bn = nn.BatchNorm1d(gat_hidden_dim * num_heads)\n",
    "        self.dropout2 = nn.Dropout(gat_dropout)\n",
    "\n",
    "        # Fully connected layer for final output\n",
    "        self.fc2 = nn.Linear(gat_hidden_dim * num_heads, combined_dim)\n",
    "        self.fc2_bn = nn.BatchNorm1d(combined_dim)\n",
    "        self.fc3 = nn.Linear(combined_dim, output_dim)\n",
    "\n",
    "    def forward(self, data, sequences):\n",
    "        sequences = sequences.to(device)\n",
    "        data = data.to(device)\n",
    "\n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(sequences)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Use the last hidden state from LSTM\n",
    "        lstm_out = self.lstm_bn(lstm_out)\n",
    "\n",
    "        # Ensure data.x has the correct shape and expand it to match the batch size\n",
    "        static_features = data.x.unsqueeze(0).expand(sequences.size(0), -1, -1)  # (batch_size, num_nodes, static_input_dim)\n",
    "\n",
    "        # Combine LSTM output with static features\n",
    "        combined_features = torch.cat([lstm_out.unsqueeze(1).expand(-1, static_features.size(1), -1), static_features], dim=2)  # Concatenate along the feature dimension\n",
    "\n",
    "        # Fully connected layer to reduce dimension\n",
    "        combined_features = combined_features.view(-1, combined_features.size(2))  # Flatten batch and num_nodes dimensions\n",
    "        combined_features = self.fc1(combined_features)\n",
    "        combined_features = self.fc1_bn(combined_features)\n",
    "        combined_features = self.dropout1(combined_features)\n",
    "\n",
    "        # GAT forward pass\n",
    "        gat_out = self.gat(combined_features, data.edge_index, data.edge_attr)\n",
    "        gat_out = self.gat_bn(gat_out)\n",
    "        gat_out = self.dropout2(gat_out)\n",
    "\n",
    "        # Fully connected layers for final output\n",
    "        combined_gat = self.fc2(gat_out)\n",
    "        combined_gat = self.fc2_bn(combined_gat)\n",
    "        output = self.fc3(combined_gat)\n",
    "\n",
    "        output = output.view(sequences.size(0), -1, self.fc3.out_features)  # Reshape to (batch_size, num_nodes, output_dim)\n",
    "        return output  # Return node-specific outputs\n",
    "\n",
    "# Compute metrics\n",
    "def compute_metrics(output, target, criterion):\n",
    "    mse = criterion(output, target).item()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = torch.mean(torch.abs(output - target)).item()\n",
    "    mape = torch.mean(torch.abs((output - target) / (target + 1e-5))).item() * 100\n",
    "    return mse, rmse, mae, mape\n",
    "\n",
    "# Hyperparameter space for random search\n",
    "param_distributions = {\n",
    "    'lstm_hidden_dim': [64, 128, 256],\n",
    "    'lstm_num_layers': [1, 2, 3],\n",
    "    'gat_hidden_dim': [32, 64, 128],\n",
    "    'num_heads': [4, 8, 16],\n",
    "    'combined_dim': [64, 128, 256],\n",
    "    'lstm_dropout': [0.1, 0.2, 0.3],\n",
    "    'gat_dropout': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "    'weight_decay': [1e-4, 5e-4, 1e-3]\n",
    "}\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define test_loader outside the function\n",
    "test_loader = DataLoader(TensorDataset(test_sequences_tensor, test_targets_tensor), batch_size=48, shuffle=False)\n",
    "\n",
    "# Training and evaluation function with cross-validation\n",
    "def cross_val_evaluate(param_sample, graph_data):\n",
    "    lstm_hidden_dim = param_sample['lstm_hidden_dim']\n",
    "    lstm_num_layers = param_sample['lstm_num_layers']\n",
    "    gat_hidden_dim = param_sample['gat_hidden_dim']\n",
    "    num_heads = param_sample['num_heads']\n",
    "    combined_dim = param_sample['combined_dim']\n",
    "    lstm_dropout = param_sample['lstm_dropout']\n",
    "    gat_dropout = param_sample['gat_dropout']\n",
    "    learning_rate = param_sample['learning_rate']\n",
    "    weight_decay = param_sample['weight_decay']\n",
    "\n",
    "    model = LSTM_GAT_Model(\n",
    "        static_input_dim=8,\n",
    "        lstm_input_dim=27,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        gat_input_dim=lstm_hidden_dim + 8,  # Corrected static_input_dim here\n",
    "        gat_hidden_dim=gat_hidden_dim,\n",
    "        num_heads=num_heads,\n",
    "        combined_dim=combined_dim,\n",
    "        output_dim=1,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "        gat_dropout=gat_dropout\n",
    "    ).to(device)  # Move model to device\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    num_epochs = 100\n",
    "    batch_size = 48\n",
    "    early_stopping_patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    aggregated_metrics = {'mse': [], 'rmse': [], 'mae': [], 'mape': [], 'r2': []}\n",
    "\n",
    "    for train_index, val_index in kf.split(train_sequences_tensor):\n",
    "        train_sequences, val_sequences = train_sequences_tensor[train_index].to(device), train_sequences_tensor[val_index].to(device)\n",
    "        train_targets, val_targets = train_targets_tensor[train_index].to(device), train_targets_tensor[val_index].to(device)\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(train_sequences, train_targets), batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(TensorDataset(val_sequences, val_targets), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize the scheduler here, after train_loader is defined\n",
    "        scheduler = OneCycleLR(optimizer, max_lr=learning_rate, epochs=num_epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "        # Lists to store losses\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for sequences, targets in train_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                loss = criterion(output, targets_expanded)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for sequences, targets in val_loader:\n",
    "                    sequences, targets = sequences.to(device), targets.to(device)\n",
    "                    output = model(graph_data, sequences)\n",
    "\n",
    "                    # Ensure the target shape matches the output shape\n",
    "                    targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                    loss = criterion(output, targets_expanded)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            logging.info(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "            # Learning rate scheduling\n",
    "            scheduler.step()\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= early_stopping_patience:\n",
    "                    logging.info('Early stopping triggered')\n",
    "                    break\n",
    "\n",
    "        # Load the best model\n",
    "        model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "        # Validation evaluation\n",
    "        model.eval()\n",
    "        val_mse, val_rmse, val_mae, val_mape = 0, 0, 0, 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                mse, rmse, mae, mape = compute_metrics(output, targets_expanded, criterion)\n",
    "                val_mse += mse\n",
    "                val_rmse += rmse\n",
    "                val_mae += mae\n",
    "                val_mape += mape\n",
    "\n",
    "                all_predictions.append(output.cpu().numpy())\n",
    "                all_targets.append(targets_expanded.cpu().numpy())\n",
    "\n",
    "        # Compute overall R-squared\n",
    "        all_predictions = np.vstack(all_predictions)\n",
    "        all_targets = np.vstack(all_targets)\n",
    "\n",
    "        # Flatten the arrays to 2D for r2_score computation\n",
    "        all_predictions_flat = all_predictions.reshape(-1, 1)\n",
    "        all_targets_flat = all_targets.reshape(-1, 1)\n",
    "\n",
    "        val_r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "\n",
    "        val_mse /= len(val_loader)\n",
    "        val_rmse /= len(val_loader)\n",
    "        val_mae /= len(val_loader)\n",
    "        val_mape /= len(val_loader)\n",
    "\n",
    "        aggregated_metrics['mse'].append(val_mse)\n",
    "        aggregated_metrics['rmse'].append(val_rmse)\n",
    "        aggregated_metrics['mae'].append(val_mae)\n",
    "        aggregated_metrics['mape'].append(val_mape)\n",
    "        aggregated_metrics['r2'].append(val_r2)\n",
    "\n",
    "    avg_metrics = {metric: np.mean(aggregated_metrics[metric]) for metric in aggregated_metrics}\n",
    "    logging.info(f'Avg Validation Metrics: {avg_metrics}')\n",
    "\n",
    "    return avg_metrics\n",
    "\n",
    "# Random search for hyperparameter tuning\n",
    "param_samples = list(ParameterSampler(param_distributions, n_iter=20, random_state=42))\n",
    "best_score = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for param_sample in param_samples:\n",
    "    avg_metrics = cross_val_evaluate(param_sample, graph_data)\n",
    "    if avg_metrics['mse'] < best_score:\n",
    "        best_score = avg_metrics['mse']\n",
    "        best_params = param_sample\n",
    "\n",
    "print(f'Best Score: {best_score}')\n",
    "print(f'Best Parameters: {best_params}')\n",
    "\n",
    "# Train on the full training set with the best hyperparameters\n",
    "def train_on_full_train_set(best_params, graph_data):\n",
    "    lstm_hidden_dim = best_params['lstm_hidden_dim']\n",
    "    lstm_num_layers = best_params['lstm_num_layers']\n",
    "    gat_hidden_dim = best_params['gat_hidden_dim']\n",
    "    num_heads = best_params['num_heads']\n",
    "    combined_dim = best_params['combined_dim']\n",
    "    lstm_dropout = best_params['lstm_dropout']\n",
    "    gat_dropout = best_params['gat_dropout']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "    weight_decay = best_params['weight_decay']\n",
    "    num_epochs = 100  # Define num_epochs\n",
    "    batch_size = 48  # Define batch_size\n",
    "\n",
    "    model = LSTM_GAT_Model(\n",
    "        static_input_dim=8,\n",
    "        lstm_input_dim=27,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        gat_input_dim=lstm_hidden_dim + 8,  # Corrected static_input_dim here\n",
    "        gat_hidden_dim=gat_hidden_dim,\n",
    "        num_heads=num_heads,\n",
    "        combined_dim=combined_dim,\n",
    "        output_dim=1,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "        gat_dropout=gat_dropout\n",
    "    ).to(device)  # Move model to device\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    train_loader = DataLoader(TensorDataset(train_sequences_tensor, train_targets_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize the scheduler here, after train_loader is defined\n",
    "    scheduler = OneCycleLR(optimizer, max_lr=learning_rate, epochs=num_epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "    early_stopping_patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    val_loader = DataLoader(TensorDataset(val_sequences_tensor, val_targets_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Lists to store losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, targets in train_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(graph_data, sequences)\n",
    "\n",
    "            # Ensure the target shape matches the output shape\n",
    "            targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "            loss = criterion(output, targets_expanded)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                loss = criterion(output, targets_expanded)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        logging.info(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        scheduler.step()\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), 'best_model_full_train.pth')\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= early_stopping_patience:\n",
    "                logging.info('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load('best_model_full_train.pth'))\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "best_model, best_train_losses, best_val_losses = train_on_full_train_set(best_params, graph_data)\n",
    "\n",
    "# Test evaluation\n",
    "def evaluate_on_test_set(model, graph_data, criterion):\n",
    "    model.eval()\n",
    "    test_mse, test_rmse, test_mae, test_mape = 0, 0, 0, 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in test_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            output = model(graph_data, sequences)\n",
    "\n",
    "            # Ensure the target shape matches the output shape\n",
    "            targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "            mse, rmse, mae, mape = compute_metrics(output, targets_expanded, criterion)\n",
    "            test_mse += mse\n",
    "            test_rmse += rmse\n",
    "            test_mae += mae\n",
    "            test_mape += mape\n",
    "\n",
    "            all_predictions.append(output.cpu().numpy())\n",
    "            all_targets.append(targets_expanded.cpu().numpy())\n",
    "\n",
    "    # Compute overall R-squared\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "\n",
    "    # Flatten the arrays to 2D for r2_score computation\n",
    "    all_predictions_flat = all_predictions.reshape(-1, 1)\n",
    "    all_targets_flat = all_targets.reshape(-1, 1)\n",
    "\n",
    "    test_r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "\n",
    "    test_mse /= len(test_loader)\n",
    "    test_rmse /= len(test_loader)\n",
    "    test_mae /= len(test_loader)\n",
    "    test_mape /= len(test_loader)\n",
    "\n",
    "    logging.info(f'Test MSE: {test_mse}, Test RMSE: {test_rmse}, Test MAE: {test_mae}, Test MAPE: {test_mape}, Test R2: {test_r2}')\n",
    "\n",
    "    return (test_mse, test_rmse, test_mae, test_mape, test_r2), all_predictions, all_targets\n",
    "\n",
    "# Pass criterion as an argument\n",
    "test_metrics, test_predictions, test_targets = evaluate_on_test_set(best_model, graph_data, nn.MSELoss())\n",
    "\n",
    "# Debugging prints\n",
    "print(f'Test Metrics: {test_metrics}')\n",
    "print(\"Shape of test_predictions:\", test_predictions.shape)\n",
    "print(\"Shape of test_targets:\", test_targets.shape)\n",
    "\n",
    "# Plotting the predictions vs. actual values for the last 24 hours\n",
    "last_hours = 24\n",
    "\n",
    "if test_predictions.shape[0] >= last_hours and test_targets.shape[0] >= last_hours:\n",
    "    last_predictions = test_predictions[-last_hours:, :]\n",
    "    last_targets = test_targets[-last_hours:, :]\n",
    "    node_index = 24\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(last_targets[:, node_index], label=f'Actual Node {node_index}')\n",
    "    plt.plot(last_predictions[:, node_index], label=f'Predicted Node {node_index}', linestyle='dashed')\n",
    "\n",
    "    plt.xlabel('Time-Step')\n",
    "    plt.ylabel('Consumption')\n",
    "    plt.title(f'LSTM-GAT Model Predicted vs Actual Consumption for Node {node_index} (Last {last_hours} Hours)')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Not enough samples to plot the last {last_hours} hours.\")\n",
    "\n",
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_train_losses, label='Train Loss')\n",
    "plt.plot(best_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for LSTM-GAT Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a4c0d2-953f-41e9-a428-1ac660546d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611f563-6e56-4d3d-8bb0-f2daca57639b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "573a92ba-6d17-4c76-95e3-531ce60674c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_predictions: (27, 27, 1)\n",
      "Shape of test_targets: (27, 27, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABA8AAAJOCAYAAADYlC4oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd1gU59oG8HvpHQQBERGwIzY09hMbGntiiy12Y0yMmlhOjL3HaDQxaiwngu0zJibW2BPFEhsaxYodxYKKIqD0Mt8f6+7ssgvswu4O5f5dFxfvzLwz82zffeYtMkEQBBARERERERER5cJM6gCIiIiIiIiIqGhj8oCIiIiIiIiI8sTkARERERERERHlickDIiIiIiIiIsoTkwdERERERERElCcmD4iIiIiIiIgoT0weEBEREREREVGemDwgIiIiIiIiojwxeUBEREREREREeWLyoBhYv349ZDIZzp8/n2e9hw8fYtSoUahWrRpsbW3h6uqK2rVrY8SIEXj48CHu378PmUym09/9+/dx9OhR5fL69eu1nrNNmzaQyWTw8/PT6zY9e/YMU6ZMQb169eDk5AQrKytUqFABPXr0wO7du5GVlaV1v927d0Mmk8HNzQ1paWnK9a1atdLpds2aNSvXmIYMGQKZTAZHR0e8efNGY/uDBw9gZmaW73H0pbifjx49qve+iufG/fv3dd5n2bJlkMlkqFWrlt7nU3jy5AlmzZqFiIiIAh9DH61atUKrVq1Mcq68+Pn5qT2fHBwc0LhxY2zcuNEk59f2eBf0vvnmm2+wc+dOg8WmoHifye09I6d79+5h9OjRyvctOzs7BAYGYtq0aXj8+LHB4ysJcnvsCvNeYgjTpk1DxYoVYWFhARcXF5Odd/z48ZDJZOjSpYvW7dqek7q+dyrq2djY4MGDBxrbW7VqVaj3Um38/PwwZMgQgx5TF3fv3oW1tTVOnz6tXLd27Vp069YNfn5+sLW1RZUqVfDZZ58hJiYmz2M9e/YMbm5ukMlk+OOPP3Q6v+L5m1v90aNHQyaT6X6DTCTn9wwnJyc0a9YMW7ZskTq0Ajl8+DAcHBz4/ktEWllIHQAZxqNHj1C/fn24uLhgwoQJqF69OhISEnD9+nVs3boV9+7dQ5MmTdS+FADAqFGjkJCQgM2bN6ut9/LyUn6pcnR0REhIiMaXmaioKBw9ehROTk56xXrmzBm8//77EAQBn332GZo0aQIHBwdER0fjzz//RI8ePbBmzRoMHz5cY9+QkBAAQFxcHHbu3Ik+ffoAAFauXInExERlvb1792LevHlYt24datSooVxfoUKFPGOztLREZmYmfvvtN43zr1u3Do6OjmrnKY5CQ0MBANeuXcPZs2fRuHFjvY/x5MkTzJ49G35+fqhXr56BIyzamjdvjsWLFwOQv+4WL16MwYMHIykpCZ999pnJ41m5cmWB9vvmm2/Qq1cvdOvWzbAB6WHPnj3o27cvypYti9GjRyMoKAgymQxXrlxBaGgo9u7di4sXL0oWX1GV22NXv359nD59GjVr1jR5TLt27cL8+fMxdepUdOzYEdbW1iY5b0ZGBv7v//4PAHDgwAE8fvwY3t7eBj9PWloapk2bhk2bNhn82EXFxIkT0a5dOzRt2lS5bubMmWjdujW++eYbeHt74+bNm5g7dy527dqFixcvwtPTU+uxPv/8c9jY2JgqdMn16tULEyZMgCAIiIqKwjfffIP+/ftDEAT0799f6vD0EhwcjEaNGmHKlCnYsGGD1OEQURHD5EEJ8fPPP+PFixcIDw+Hv7+/cn23bt0wZcoUZGdnw8zMDE2aNFHbz8nJCenp6RrrVfXp0wdr167F7du3UbVqVeX60NBQeHt7o3bt2rh+/bpOccbHx6Nbt25wcHDAyZMn4eXlpbZ9wIABuHz5Ml6+fKmx79OnT7Fv3z60adMGp06dQkhIiDJ5kPPL8o0bNwAAtWrVwjvvvKNTbABgZWWFrl27IjQ0VC15IAgC1q9fjz59+uDnn3/W+XhFzfnz53Hp0iV07twZe/fuRUhISIGSB6WZi4uL2uulbdu28PX1xffff59r8iArKwuZmZlG+UElxQ9FQ4iKikLfvn1RrVo1hIWFwdnZWbmtTZs2GDt2LHbs2CFhhMWPk5NTnu/lxnT16lUAwNixY+Hh4WGQYyYnJ8POzi7POrt27UJsbKzyPW3Dhg2YMmWKQc6vqkOHDvjll18wceJE1K1b1+DHl1pkZCR27tyJAwcOqK2/ePGi2uPZsmVL1K9fHw0bNsTPP/+MadOmaRxr27ZtOHjwIH766ScMHjzY6LEbW0ZGBmQyGSwscv/K7OnpqXztNW3aFM2bN4efnx/WrFlT7JIHgDz506dPH8ybNw8+Pj5Sh0NERQi7LZQQL1++hJmZWa5f2szMCv5Qt2vXDj4+Psor1gCQnZ2NDRs2YPDgwXod++eff8azZ8+waNEijcSBQp06ddC6dWuN9Rs2bEBmZibGjRuHHj164PDhw1qbkRbWsGHDcOrUKdy8eVO57u+//8aDBw8wdOhQrftcvXoVH3zwAcqUKQMbGxvUq1dPa8b+xo0b6NChA+zs7FC2bFl8+umneP36tdZj/v333wgODoaTkxPs7OzQvHlzHD58uFC3TdFy49tvv0WzZs3w66+/Ijk5WaPe48eP8cknn8DHxwdWVlYoX748evXqhWfPnuHo0aNo2LAhAGDo0KEaXUJya0Y/ZMgQje4ts2fPRuPGjeHq6gonJyfUr18fISEhEARB79vWrVs3+Pr6Ijs7W2Nb48aNUb9+feXy77//jsaNG8PZ2Rl2dnaoVKkShg0bpvc5AXkyoXr16srnoqKJ9KJFizBv3jz4+/vD2toaYWFhAOQJnPfffx+urq6wsbFBUFAQtm7dqnHcM2fOoHnz5rCxsUH58uUxefJkZGRkaNTTdn+npaVhzpw5CAgIgI2NDdzc3NC6dWucOnUKgLyZbVJSEjZs2KB8/FSP8fTpU4wcORIVKlSAlZUV/P39MXv2bGRmZqqd58mTJ+jduzccHR3h7OyMPn364OnTpzrdb99//z2SkpKwcuVKtcSBgkwmQ48ePdTWhYaGom7durCxsYGrqyu6d++OyMhItTpDhgyBg4MD7ty5g06dOsHBwQE+Pj6YMGGCWlcnAFi1ahXq1q0LBwcHODo6okaNGmo/PGfNmqW1mbS2Ju9+fn7o0qUL9uzZg6CgINja2iIgIAB79uxR7hMQEAB7e3s0atRIoxuaIu5r164hODgY9vb2cHd3x+jRo9Veo3k9drl1W9i9ezeaNm0KOzs7ODo6ol27dhqt0BS39dq1a+jXrx+cnZ3h6emJYcOGISEhQeM+UOXn56f8Eenp6an2fpCdnY1FixahRo0asLa2hoeHBwYNGoRHjx6pHUPR/P/48eNo1qwZ7OzsdHpNhoSEwMrKCuvWrYOPjw/WrVtXoPeP/Hz11Vdwc3PDpEmT8q2bmpqKyZMnw9/fH1ZWVvD29sbnn3+O+Ph4tXoZGRn46quvUK5cOdjZ2eE///kPwsPDtR5T19dkfs/p3KxatQrlypVDu3bt1NZr+07RoEEDmJub4+HDhxrb4uLi8Pnnn2P+/PmoWLFivuctLF2fX7l1Bcn5/ql4DW3atAkTJkyAt7c3rK2tcefOHb3i8vX1hbu7O549e6a2/rfffsN7770HLy8v5XvE119/jaSkJLV6+ryPPXr0CL169YKjoyNcXFzw0Ucf4dy5c1q7j+n6+dO1a1c4ODgU64slRGQcTB6UEE2bNkV2djZ69OiBgwcPGrRpvZmZGYYMGYKNGzcqxyI4dOgQHj16lOuP6dz89ddfMDc3R6dOnfSOIzQ0FF5eXujYsSOGDRuG7OxsnftV60NxJVk1WRISEoIWLVqotbxQuHnzJpo1a4Zr165h2bJl2L59O2rWrIkhQ4Zg0aJFynrPnj1Dy5YtcfXqVaxcuRKbNm3CmzdvMHr0aI1j/t///R/ee+89ODk5YcOGDdi6dStcXV3Rvn37AicQUlJSsGXLFjRs2BC1atXCsGHD8Pr1a/z+++9q9R4/foyGDRtix44dGD9+PPbv34+lS5fC2dkZr169Qv369bFu3ToA8j7Op0+fxunTp/Hxxx/rHdP9+/cxcuRIbN26Fdu3b0ePHj0wZswYzJ07V+9jDRs2DNHR0Thy5Ija+hs3biA8PFz5XD19+jT69OmDSpUq4ddff8XevXsxY8YMjS/husrIyMCDBw/g7u6utn7ZsmU4cuQIFi9ejP3796NGjRoICwtD8+bNER8fj9WrV2PXrl2oV68e+vTpo/Zcvn79OoKDgxEfH4/169dj9erVuHjxIubNm5dvPJmZmejYsSPmzp2LLl26YMeOHVi/fj2aNWuG6Oho5X1ga2uLTp06KR8/RfeHp0+folGjRjh48CBmzJiB/fv3Y/jw4ViwYAFGjBihPE9KSgratm2LQ4cOYcGCBfj9999Rrlw5ZWug/Bw6dEjtal1+FixYgOHDhyMwMBDbt2/Hjz/+iMuXL6Np06a4ffu2Wt2MjAy8//77CA4Oxq5duzBs2DD88MMPWLhwobLOr7/+ilGjRqFly5bYsWMHdu7ciXHjxml8idfHpUuXMHnyZEyaNAnbt2+Hs7MzevTogZkzZ2Lt2rX45ptvsHnzZiQkJKBLly5ISUnRiLtTp04IDg7Gzp07MXr0aKxZs0btPs3rsdPml19+wQcffAAnJyds2bIFISEhePXqFVq1aoV//vlHo37Pnj1RrVo1bNu2DV9//TV++eUXjBs3Ls/bvWPHDmVLrQMHDqi9H3z22WeYNGkS2rVrh927d2Pu3Lk4cOAAmjVrhhcvXqgdJyYmBgMGDED//v2xb98+jBo1Ks/zPnr0CIcOHcIHH3wAd3d3DB48GHfu3MHx48fz3K8gHB0dMW3aNBw8eFDjPUaVIAjo1q0bFi9ejIEDB2Lv3r0YP348NmzYgDZt2qj98BsxYgQWL16MQYMGYdeuXejZsyd69OiBV69eqR1T19dkYZ7Te/fuRYsWLXS6GHDs2DFkZWUhMDBQY9vYsWPh7++v9XNNV9nZ2cjMzNT405YU0uf5pY/JkycjOjoaq1evxp9//ql3a5qEhATExcWhWrVqautv376NTp06ISQkBAcOHMCXX36JrVu3omvXrhrH0OV9LCkpCa1bt0ZYWBgWLlyIrVu3wtPTU+v7sK6fP4C8FWazZs2wd+9evW43EZUCAhV569atEwAI586dy7VOdna2MHLkSMHMzEwAIMhkMiEgIEAYN26cEBUVlet+LVu2FAIDA7VuCwsLEwAIv//+u3Dv3j1BJpMJe/bsEQRBED788EOhVatWgiAIQufOnQVfX1+dbkuNGjWEcuXKaazPysoSMjIylH9ZWVlq248fPy4AEL7++mvl7fX39xd8fX2F7OxsjePpcp/lNHjwYMHe3l4QBEGYOXOmUK5cOSEjI0N4+fKlYG1tLaxfv16IjY0VAAgzZ85U7te3b1/B2tpaiI6OVjtex44dBTs7OyE+Pl4QBEGYNGmSIJPJhIiICLV67dq1EwAIYWFhgiAIQlJSkuDq6ip07dpV4z6qW7eu0KhRI43bmddjrLBx40YBgLB69WpBEATh9evXgoODg/Duu++q1Rs2bJhgaWkpXL9+PddjnTt3TgAgrFu3TmNby5YthZYtW2qsHzx4cJ7PE8VzYM6cOYKbm5va45rbMVVlZGQInp6eQv/+/dXWf/XVV4KVlZXw4sULQRAEYfHixQIA5eOiD19fX6FTp07K52lUVJQwePBgAYDw3//+VxAEQYiKihIACJUrVxbS09PV9q9Ro4YQFBQkZGRkqK3v0qWL4OXlpXze9+nTR7C1tRWePn2qrJOZmSnUqFFD4/HOed8oHueff/45z9tib28vDB48WGP9yJEjBQcHB+HBgwdq6xX327Vr1wRBEIRVq1YJAIRdu3ap1RsxYkSuzw1VNjY2QpMmTfKso/Dq1SvB1tZW6NSpk9r66OhowdraWu0xVzweW7duVavbqVMnoXr16srl0aNHCy4uLnmed+bMmYK2j0ltrztfX1/B1tZWePTokXJdRESEAEDw8vISkpKSlOt37twpABB2796tEfePP/6odq758+cLAIR//vlHuS63x07xnq14L8nKyhLKly8v1K5dW+099fXr14KHh4fQrFkzjdu6aNEitWOOGjVKsLGx0fo+q0qxf2xsrHJdZGSkAEAYNWqUWt2zZ88KAIQpU6Yo17Vs2VIAIBw+fDjP86iaM2eOAEA4cOCAIAiC8nNq4MCBavUUr0nV56Su752qnyVpaWlCpUqVhHfeeUd5f+T8DD1w4IDW+/G3334TAAj/+9//BEEQ75tx48ap1du8ebMAQO3x1fU1qctzWptnz54JAIRvv/0237qJiYlCQECA4OPjI7x+/Vpt2549ewRLS0vhypUrgiCof4fQhaJ+fn8K+jy/fH19tb5mcr5/KmJo0aKFTjELgqCMISMjQ0hPTxdu3bolvP/++4Kjo6Nw/vz5XPfLzs4WMjIyhGPHjgkAhEuXLim36fo+9tNPPwkAhP3796vVGzlypMZzXtfPH4WpU6cKZmZmwps3b3S+L4io5GPLgxJCJpNh9erVuHfvHlauXImhQ4ciIyMDP/zwAwIDA3Hs2LFCHd/f3x+tWrVCaGgoXr58qcyCa5PzqkFuMyeoGj9+PCwtLZV/77//vtp2RXN7xTllMhmGDBmCBw8eFLopvzZDhw7Fs2fPsH//fmzevBlWVlb48MMPtdY9cuQIgoODNfoFDhkyBMnJycrmwWFhYQgMDNToL5uzP+SpU6cQFxeHwYMHq92P2dnZ6NChA86dO1egq6MhISGwtbVF3759AQAODg748MMPceLECbUrt/v370fr1q0REBCg9zn0deTIEbRt2xbOzs4wNzeHpaUlZsyYgZcvX+L58+d6HcvCwgIDBgzA9u3blc2ss7KysGnTJnzwwQdwc3MDAGWXi969e2Pr1q16jyi9b98+5fPU398fW7duxZgxYzRaBbz//vuwtLRULt+5cwc3btzARx99BABqj22nTp0QExOj7CoTFhaG4OBgtcHIzM3Ndbqqv3//ftjY2BS4G8aePXvQunVrlC9fXi3Gjh07AoDyvSQsLAyOjo4ar1Vj9O89ffo0UlJSNJod+/j4oE2bNhrvATKZTONKXp06ddS6OTVq1Ajx8fHo168fdu3aVairlAr16tVTG6xP8Rpq1aqVWt99xXpt3a4Uzw8Fxf2p6Paij5s3b+LJkycYOHCg2hVlBwcH9OzZE2fOnNHotpTz8axTpw5SU1P1fj2qxpzzcWvUqBECAgI0HrcyZcqgTZs2Oh1bEARlVwVFU3vF59S2bduMMrCtlZUV5s2bh/Pnz2tt6g1A2Soh523+8MMPYW9vr7zNivsm5+Pdu3dvjb71ur4mC/qcfvLkCQDtXRRUpaamokePHnjw4AF+//13ODg4KLclJCRg5MiRmDRpUr6zT+TXomDhwoU4d+6cxl/v3r3V6un7/NJHz5499aq/cuVKWFpawsrKCtWqVcP+/fuxZcsWNGjQQK3evXv30L9/f5QrV075mdeyZUsA0OiCpcv72LFjx+Do6IgOHTqo1evXr5/asj6fPwoeHh7Izs7WuSsaEZUOTB6UML6+vvjss88QEhKC27dv47fffkNqair++9//FvrYw4cPx59//onvv/8etra26NWrl9Z6w4YNU0sEBAcHK7dVrFgRsbGxGl9YJ0yYoPyCkHMsBEXT+kaNGsHd3R3x8fGIj49H9+7dIZPJlIkFQ/L19UVwcDBCQ0MRGhqKvn375jpw18uXL7WO31C+fHnldsX/cuXKadTLuU7RR7JXr15q96OlpSUWLlwIQRAQFxen1+1RNOXt3LkzBEFQ3oeKx1C1i0ZsbGy+s1IYQnh4ON577z0A8rEwTp48iXPnzmHq1KkAoNGkWxfDhg1Damoqfv31VwDAwYMHERMTo9a9pkWLFti5cycyMzMxaNAgVKhQAbVq1dJ5Wq3//Oc/OHfuHM6fP4/r168jPj4ey5Ytg5WVlVq9nM8JxeM6ceJEjcdV0Txb8WVf1+eKNrGxsShfvnyBxzl59uwZ/vzzT40YFU2UVWPUNtK6LjEC8veCqKgoneoqXkO5vc5yDrBqZ2enMdK7tbU1UlNTlcsDBw5EaGgoHjx4gJ49e8LDwwONGzfGX3/9pVNM2ri6uqotK54Tua1XjQeQJ8AUSS4Fxf2pbRDZ/OR3v2VnZ2s0kc95fsUgnwV5Per7uOU2Do42R44cQVRUFD788EMkJiYq39N69+6N5ORko02T17dvX9SvXx9Tp07VOgbJy5cvYWFhodGNSSaToVy5cmqfB4Dm60Xbc0DX12RBn9OKxzav2RHS0tLQvXt3/PPPP9i9e7fGQLtTp06FpaUlRo8erXwsFFMeJycnIz4+HoIg4P79+xq3I+fFjUqVKuGdd97R+Mt5n+r7/NKHPs9FQJ70OXfuHE6dOoU1a9bA0dERffv2VUvMv3nzBu+++y7Onj2LefPm4ejRozh37hy2b98OQPM1psv7WG7vwznX6fP5o6A4d0Fe+0RUcnG2hRKud+/eWLBggXIk7MLo0aMHPv/8c3z77bcYMWIEbG1ttdabNWuWWn9HR0dHZbldu3Y4dOgQ9u3bp5Z88PHxUV65z/kjbMuWLUhOTkZ4eDjKlCmjcb4dO3bg1atXWrcVxrBhwzBgwABkZ2dj1apVudZzc3PTOue14mpO2bJllfW0ZfBzrlPUX758ea79wXObHis3oaGhEAQBf/zxh9Y5tDds2IB58+bB3Nwc7u7uGoNN6cPGxkbrAGs5v5j8+uuvsLS0xJ49e9S+IGmbv15XNWvWRKNGjbBu3TqMHDkS69atQ/ny5ZVJCoUPPvgAH3zwAdLS0nDmzBksWLAA/fv3h5+fn9o0Zdo4OzvrNINHzoH2FI/r5MmTNQYCVKhevToA3Z8r2ri7u+Off/5RzrCir7Jly6JOnTqYP3++1u2KpJibm5vWwd10vUrVvn17LF++HGfOnMl33APFj6ncXmeK+1ZfQ4cOxdChQ5GUlITjx49j5syZ6NKlC27dugVfX1/l8zItLU1tpgxDtFLQJjMzEy9fvlT78ai4P3P+oNRFfvebmZmZwd83czt/zoSktsdN2+CUuVEkjb///nt8//33WrePHDlS35DzJZPJsHDhQrRr1w7/+9//NLa7ubkhMzMTsbGxaj92BUHA06dPlS2fFPfN06dP1VqrKJ4DqnR9TQL5P6e1UTwOuSWl09LS0K1bN4SFhWHXrl1qFwQUrl69ivv372tNHipmXHj16hXKly+Pc+fOqW1XvO/pS5/nl42NjcZAg4D8tazt/UOf5yIgf99VfC40bdoUAQEBaNmyJcaNG6ccNPXIkSN48uQJjh49qmxtAEBjIE196Po+rM/nj4Li+VDQ91ciKpnY8qCE0PblEJBnuh8+fKj25aKgbG1tMWPGDHTt2jXP+ez9/PzUrhaofiB9/PHH8PT0xFdffZVrzDmFhITA0dERhw8fRlhYmNrfd999h7S0NGzevLnQty+n7t27o3v37hg2bFieP26Cg4OVXwpUbdy4EXZ2dsp9W7dujWvXruHSpUtq9X755Re15ebNm8PFxQXXr1/XevXlnXfe0Uiw5CUrKwsbNmxA5cqVNe6/sLAwTJgwATExMdi/fz8AoGPHjggLC9Nowqgqr6uRfn5+uHXrltoXtZcvXypH+ldQTH1lbm6uXJeSklLoedSHDh2Ks2fP4p9//sGff/6JwYMHq50j5+1o2bKlcgCqixcvFurcealevTqqVq2KS5cu5fq4KhJtrVu3xuHDh9VG6s7KysJvv/2W73k6duyI1NTUfAcTtba21vr4denSBVevXkXlypW1xqh4L2ndujVev36N3bt3q+2f8/mcm3HjxsHe3h6jRo3SmmwSBEE5VWPTpk1ha2uL//u//1Or8+jRI2W3ocKwt7dHx44dMXXqVKSnp+PatWsAoJwd5PLly2r1//zzz0KdLy8538sU96fqiPC5PXY5Va9eHd7e3vjll1/UmoYnJSVh27ZtyhkYjEXRBSHn43bu3DlERkYW+HF79eoVduzYgebNm2t9T1OMNm+IpLk2bdu2Rbt27TBnzhzl1XUFxW3KeZu3bduGpKQk5XbF45nz8d66davG4K26viZV5fac1sbX1xe2tra4e/euxjZFi4MjR45g27ZtaN++vdZjLF26VONx+OGHHwDILyiEhYXBwcEBVlZWub7v6Uuf55efn5/G6/jWrVt5fs4VxrvvvotBgwZh7969yq6LioREzil716xZU+DztGzZEq9fv1Z+fisoWt8p6PP5o3Dv3j24ubnpfbGCiEo2tjwoRo4cOaI2NZhCp06dMH/+fJw8eRJ9+vRBvXr1YGtri6ioKKxYsQIvX77Ed999Z5AYxo8fj/Hjxxd4fxcXF+zcuRNdu3ZF3bp18dlnn6FJkyZwcHDAy5cvcfz4cTx9+hTNmjUDIL+aER4ejs8++0xrX9jmzZtjyZIlCAkJKdToztrY2NhovUqf08yZM5V9UmfMmAFXV1ds3rwZe/fuxaJFi5TT0H355ZcIDQ1F586dMW/ePHh6emLz5s24ceOG2vEcHBywfPlyDB48GHFxcejVqxc8PDwQGxuLS5cuITY2Ns+WEDnt378fT548wcKFC7VOoVirVi2sWLECISEh6NKlC+bMmYP9+/ejRYsWmDJlCmrXro34+HgcOHAA48ePR40aNVC5cmXY2tpi8+bNCAgIgIODA8qXL4/y5ctj4MCBWLNmDQYMGIARI0bg5cuXWLRoEZycnNTO27lzZ3z//ffo378/PvnkE7x8+RKLFy/W+GKlr379+mH8+PHo168f0tLSNPrDzpgxA48ePUJwcDAqVKiA+Ph4/Pjjj2p9T41lzZo16NixI9q3b48hQ4bA29sbcXFxiIyMxIULF5QzX0ybNg27d+9GmzZtMGPGDNjZ2eGnn37SaayLfv36Yd26dfj0009x8+ZNtG7dGtnZ2Th79iwCAgKUY17Url0bR48exZ9//gkvLy84OjqievXqmDNnDv766y80a9YMY8eORfXq1ZGamor79+9j3759WL16NSpUqIBBgwbhhx9+wKBBgzB//nxUrVoV+/btw8GDB3W6L/z9/fHrr78q37NGjx6NoKAgAPLZJhStZbp37w4XFxdMnz4dU6ZMwaBBg9CvXz+8fPkSs2fPho2NDWbOnKn3Y6FoPdW8eXN4eXnh6dOnWLBgAZydnZVXhzt16gRXV1cMHz4cc+bMgYWFBdavX691ijpDsLKywpIlS/DmzRs0bNgQp06dwrx589CxY0f85z//UdbL7bHLyczMDIsWLcJHH32ELl26YOTIkUhLS8N3332H+Ph4fPvtt0a5HQrVq1fHJ598guXLl8PMzAwdO3bE/fv3MX36dPj4+OQ7i0NuNm/ejNTUVIwdO1bre5qbmxs2b96MkJAQ5Q9YQ1u4cCEaNGiA58+fq8060K5dO7Rv3x6TJk1CYmIimjdvjsuXL2PmzJkICgrCwIEDAcjHvRgwYACWLl0KS0tLtG3bFlevXsXixYs13it1fU3q8pzWxsrKCk2bNsWZM2c0tvXq1Qv79+/H1KlT4ebmplbHyckJNWvWBCAf7yM3gYGBWh+nwtLn+TVw4EAMGDAAo0aNQs+ePfHgwQMsWrRIoyuEIc2dOxe//fYbpk+fjr///hvNmjVDmTJl8Omnn2LmzJmwtLTE5s2bNS4o6GPw4MH44YcfMGDAAMybNw9VqlTB/v37le/Dqq3PdP38UThz5gxatmypdysMIirhpBqpkXSnGO05t7+oqCjhzJkzwueffy7UrVtXcHV1FczNzQV3d3ehQ4cOwr59+3I9tq6zLeRFn9kWFJ4+fSpMnjxZqFOnjmBvby9YWloK5cuXF7p27Sps3LhRORrwl19+KQDQmKFA1ddffy0AEP7991/lusLOtpAbbbMtCIIgXLlyRejatavg7OwsWFlZCXXr1tU62vz169eFdu3aCTY2NoKrq6swfPhwYdeuXWojpCscO3ZM6Ny5s+Dq6ipYWloK3t7eQufOndUeD11GDO/WrZtgZWUlPH/+PNc6ffv2FSwsLJSj+z98+FAYNmyYUK5cOeVj07t3b+HZs2fKfbZs2SLUqFFDsLS01LhPNmzYIAQEBAg2NjZCzZo1hd9++03rbAuhoaFC9erVBWtra6FSpUrCggULhJCQkHxnFMhP//79BQBC8+bNNbbt2bNH6Nixo+Dt7S1YWVkJHh4eQqdOnYQTJ07ke1xfX1+hc+fOedZRjOz+3Xffad1+6dIloXfv3oKHh4dgaWkplCtXTmjTpo1yFgyFkydPCk2aNBGsra2FcuXKCf/973+F//3vfzrdNykpKcKMGTOEqlWrClZWVoKbm5vQpk0b4dSpU8o6ERERQvPmzQU7OzsBgNoxYmNjhbFjxwr+/v6CpaWl4OrqKjRo0ECYOnWq2sjbjx49Enr27Ck4ODgIjo6OQs+ePYVTp07pNNuCwt27d4VRo0YJVapUEaytrQVbW1uhZs2awvjx4zWe12vXrhXq1KkjWFlZCc7OzsIHH3ygHGleIbfXcc6ZEzZs2CC0bt1a8PT0FKysrJTP8cuXL6vtFx4eLjRr1kywt7cXvL29hZkzZwpr167VOtuCtucGAOHzzz9XW6ftOaKI+/Lly0KrVq0EW1tbwdXVVfjss880RjvP7bHLOduCws6dO4XGjRsLNjY2gr29vRAcHCycPHlS6/2jOluCIOg+K0Fu+2dlZQkLFy4UqlWrJlhaWgply5YVBgwYIDx8+FCtXl6fRTnVq1dP8PDwENLS0nKt06RJE6Fs2bJCWlqawWZbyEnxPpMz7pSUFGHSpEmCr6+vYGlpKXh5eQmfffaZ8OrVK7V6aWlpwoQJEwQPDw/l7COnT5/WOjOALq9JXZ/T2oSEhAjm5ubCkydP1Nbn9d0jv/fkgs62kFv9zz//XGP2E12fX9nZ2cKiRYuESpUqCTY2NsI777wjHDlyJNfZFnSNWRC0v8YV/vvf/woAhGPHjgmCIAinTp0SmjZtKtjZ2Qnu7u7Cxx9/LFy4cEHj+anr+5ggyGed6dGjh9r78L59+7TOhqPr58+dO3cEAMK2bdt0vh+IqHSQCYKWiXOJiIjIZIYMGYI//vhDoxk8kSmkpqaiYsWKmDBhAiZNmiR1OFRI33zzDaZNm4bo6OgCDYA8ffp0bNy4EXfv3tWY/YOISje+IxARERGVYjY2Npg9e7ZywGN7e3upQyIdrVixAgBQo0YNZGRk4MiRI1i2bBkGDBhQoMRBfHw8fvrpJyxfvpyJAyLSwHcFIiIiolLuk08+QXx8PO7du4fatWtLHQ7pyM7ODj/88APu37+PtLQ0VKxYEZMmTcK0adMKdLyoqChMnjwZ/fv3N3CkRFQSsNsCEREREREREeWJUzUSERERERERUZ6KVfLg+PHj6Nq1K8qXLw+ZTIadO3fmWf/o0aOQyWQafzmnxiMiIiIiIiKi3BWrMQ+SkpJQt25dDB06FD179tR5v5s3b6rNm2zMeX2JiIiIiIiISppilTzo2LEjOnbsqPd+Hh4ecHFxKdA5s7Oz8eTJEzg6OkImkxXoGEREREREpB9BEPD69WuUL18eZmbFqsE0UYlUrJIHBRUUFITU1FTUrFkT06ZNQ+vWrXOtm5aWhrS0NOXy48ePUbNmTVOESUREREREOTx8+LBAU08SkWGV6OSBl5cX/ve//6FBgwZIS0vDpk2bEBwcjKNHj6JFixZa91mwYAFmz56tsf7hw4dqXR+IiIiIiMh4EhMT4ePjA0dHR6lDISIU46kaZTIZduzYgW7duum1X9euXSGTybB7926t23O2PFC8aSUkJDB5QERERERkIomJiXB2dub3cKIiotR1HmrSpAlu376d63Zra2s4OTmp/RERERERERGVZqUueXDx4kV4eXlJHQYRERERERFRsVGsxjx48+YN7ty5o1yOiopCREQEXF1dUbFiRUyePBmPHz/Gxo0bAQBLly6Fn58fAgMDkZ6ejv/7v//Dtm3bsG3bNqluAhEREREREVGxU6ySB+fPn1ebKWH8+PEAgMGDB2P9+vWIiYlBdHS0cnt6ejomTpyIx48fw9bWFoGBgdi7dy86depk8tiJiIiIiMjwsrKykJGRIXUYRMWSpaUlzM3NdapbbAdMNBUO1EJEREREZHr5fQ8XBAFPnz5FfHy86YMjKkFcXFxQrlw5yGSyPOsVq5YHREREREREAJSJAw8PD9jZ2eX7w4eI1AmCgOTkZDx//hwA8h0bkMkDIiIiIiIqVrKyspSJAzc3N6nDISq2bG1tAQDPnz+Hh4dHnl0YSt1sC0REREREVLwpxjiws7OTOBKi4k/xOspv7BAmD4iIiIiIqFhiVwWiwtP1dcTkARERERERERHlickDIiIiIiIiAiC/Cr1z506pwyiWSvp9x+QBERERERGRiZ06dQrm5ubo0KGD3vv6+flh6dKlhg9KR0+fPsWYMWNQqVIlWFtbw8fHB127dsXhw4cli8mUZs2ahXr16mmsj4mJQceOHU0fkIkweUBERERERGRioaGhGDNmDP755x9ER0dLHY7O7t+/jwYNGuDIkSNYtGgRrly5ggMHDqB169b4/PPPpQ5PUuXKlYO1tbXUYRgNkwdEREREREQmlJSUhK1bt+Kzzz5Dly5dsH79eo06u3fvxjvvvAMbGxuULVsWPXr0AAC0atUKDx48wLhx4yCTyZSD3Wm7Gr506VL4+fkpl8+dO4d27dqhbNmycHZ2RsuWLXHhwgW9Yh81ahRkMhnCw8PRq1cvVKtWDYGBgRg/fjzOnDmjrBcdHY0PPvgADg4OcHJyQu/evfHs2TPldkW8mzZtgp+fH5ydndG3b1+8fv1aWeePP/5A7dq1YWtrCzc3N7Rt2xZJSUnK++HLL79Ui61bt24YMmSIctnPzw/z5s3DoEGD4ODgAF9fX+zatQuxsbHK2GrXro3z588r91m/fj1cXFywc+dOVKtWDTY2NmjXrh0ePnyo3D579mxcunRJef8rHr+c3RauXLmCNm3aKOP/5JNP8ObNG+X2IUOGoFu3bli8eDG8vLzg5uaGzz//PN9ZD6TC5AERERERERV7ggCkp0vzJwj6xfrbb7+hevXqqF69OgYMGIB169ZBUDnI3r170aNHD3Tu3BkXL17E4cOH8c477wAAtm/fjgoVKmDOnDmIiYlBTEyMzud9/fo1Bg8ejBMnTuDMmTOoWrUqOnXqpPaDPS9xcXE4cOAAPv/8c9jb22tsd3FxAQAIgoBu3bohLi4Ox44dw19//YW7d++iT58+avXv3r2LnTt3Ys+ePdizZw+OHTuGb7/9FoC8C0C/fv0wbNgwREZG4ujRo+jRo4fa/aSLH374Ac2bN8fFixfRuXNnDBw4EIMGDcKAAQNw4cIFVKlSBYMGDVI7bnJyMubPn48NGzbg5MmTSExMRN++fQEAffr0wYQJExAYGKi8/3PeLsUxOnTogDJlyuDcuXP4/fff8ffff2P06NFq9cLCwnD37l2EhYVhw4YNWL9+vdZkUlFgIXUAREREREREhZWRAXzzjTTnnjIFsLLSvX5ISAgGDBgAAOjQoQPevHmDw4cPo23btgCA+fPno2/fvpg9e7Zyn7p16wIAXF1dYW5uDkdHR5QrV06vONu0aaO2vGbNGpQpUwbHjh1Dly5d8t3/zp07EAQBNWrUyLPe33//jcuXLyMqKgo+Pj4AgE2bNiEwMBDnzp1Dw4YNAQDZ2dlYv349HB0dAQADBw7E4cOHMX/+fMTExCAzMxM9evSAr68vAKB27dp63V4A6NSpE0aOHAkAmDFjBlatWoWGDRviww8/BABMmjQJTZs2xbNnz5T3Z0ZGBlasWIHGjRsDADZs2ICAgACEh4ejUaNGcHBwgIWFRZ73/+bNm5GSkoKNGzcqEy0rVqxA165dsXDhQnh6egIAypQpgxUrVsDc3Bw1atRA586dcfjwYYwYMULv22psbHlARERERERkIjdv3kR4eLjySraFhQX69OmD0NBQZZ2IiAgEBwcb/NzPnz/Hp59+imrVqsHZ2RnOzs548+aNzmMuKK7OK7pK5CYyMhI+Pj7KxAEA1KxZEy4uLoiMjFSu8/PzUyYOAMDLywvPnz8HIE+WBAcHo3bt2vjwww/x888/49WrVzrfVoU6deooy4of7KpJCMU6xXkB+WOiaOkBADVq1NCIPT+RkZGoW7euWguN5s2bIzs7Gzdv3lSuCwwMhLm5uXJZ9T4oatjygIiIiIiIij1LS3kLAKnOrauQkBBkZmbC29tbuU4QBFhaWuLVq1coU6YMbG1t9Y7BzMxMo0l/zr7zQ4YMQWxsLJYuXQpfX19YW1ujadOmSE9P1+kcVatWhUwmQ2RkJLp165ZrPUEQtCYYcq63zHHHyWQyZGdnAwDMzc3x119/4dSpUzh06BCWL1+OqVOn4uzZs/D399fp9uY8h+Lc2tYpzptzfX7rcpPbfZDzOHndB0UNWx4QEREREVGxJ5PJuw5I8afrb8rMzExs3LgRS5YsQUREhPLv0qVL8PX1xebNmwHIr5bnNe2hlZUVsrKy1Na5u7vj6dOnaj+oIyIi1OqcOHECY8eORadOnRAYGAhra2u8ePFCt+Ah7zLRvn17/PTTT8qBC1XFx8cDkLcyiI6OVg4yCADXr19HQkICAgICdD6fTCZD8+bNMXv2bFy8eBFWVlbYsWOH8vaqjveQlZWFq1ev6nzsvGRmZqoNonjz5k3Ex8cru2tou/9zqlmzJiIiItTup5MnT8LMzAzVqlUzSJymxuQBERHpzMFB/gWpfXupIyEiIip+9uzZg1evXmH48OGoVauW2l+vXr0QEhICAJg5cya2bNmCmTNnIjIyEleuXMGiRYuUx/Hz88Px48fx+PFj5Y//Vq1aITY2FosWLcLdu3fx008/Yf/+/Wrnr1KlCjZt2oTIyEicPXsWH330kd6tHFauXImsrCw0atQI27Ztw+3btxEZGYlly5ahadOmAIC2bduiTp06+Oijj3DhwgWEh4dj0KBBaNmypVp3gLycPXsW33zzDc6fP4/o6Ghs374dsbGxyuRDmzZtsHfvXuzduxc3btzAqFGjlMmLwrK0tMSYMWNw9uxZXLhwAUOHDkWTJk3QqFEjAPL7PyoqChEREXjx4gXS0tI0jvHRRx/BxsYGgwcPxtWrVxEWFoYxY8Zg4MCByq4SxQ2TB0REpDNF8vzQIWnjICIiKo5CQkLQtm1bODs7a2zr2bMnIiIicOHCBbRq1Qq///47du/ejXr16qFNmzY4e/assu6cOXNw//59VK5cGe7u7gCAgIAArFy5Ej/99BPq1q2L8PBwTJw4Ue0coaGhePXqFYKCgjBw4ECMHTsWHh4eet0Gf39/XLhwAa1bt8aECRNQq1YttGvXDocPH8aqVasAiFMWlilTBi1atEDbtm1RqVIl/Pbbbzqfx8nJCcePH0enTp1QrVo1TJs2DUuWLEHHjh0BAMOGDcPgwYOVSQl/f3+0bt1ar9uSGzs7O0yaNAn9+/dH06ZNYWtri19//VW5vWfPnujQoQNat24Nd3d3bNmyResxDh48iLi4ODRs2BC9evVCcHAwVqxYYZAYpSAT9J3ropRJTEyEs7MzEhIS4OTkJHU4RESSUm2WyU8PIiIypry+h6empiIqKgr+/v6wsbGRKEIqidavX48vv/zSYK0YigNdX09seUBEREREREREeWLygIiIiIiIiIjyxOQBEREREREREeTTWZamLgv6YPKAiIh0smSJ1BEQERERkVSYPCAiIp2sWyd1BEREREQkFSYPiIhIJ9HRUkdARERERFJh8oCIiHSSlKS+vGOHNHEQERERkekxeUBERDrJzlZfXr1amjiIiIiIyPSYPCAiogKJiJA6AiIiIiIyFSYPiIioQDiLERERUdE2a9Ys1KtXT7k8ZMgQdOvWzeRx3L9/HzKZDBG88qC3onTfMXlAREQFkp4udQRERETFz5AhQyCTySCTyWBpaYlKlSph4sSJSMo5uJAR/Pjjj1i/fr1OdaX40Xrnzh0MHToUFSpUgLW1Nfz9/dGvXz+cP3/eZDFISVtyx8fHBzExMahVq5Y0Qalg8oCIiIiIiMiEOnTogJiYGNy7dw/z5s3DypUrMXHiRK11MzIyDHZeZ2dnuLi4GOx4hnT+/Hk0aNAAt27dwpo1a3D9+nXs2LEDNWrUwIQJE6QOTzLm5uYoV64cLCwspA6FyQMiIiIiIiJTsra2Rrly5eDj44P+/fvjo48+ws6dOwGIXQ1CQ0NRqVIlWFtbQxAEJCQk4JNPPoGHhwecnJzQpk0bXLp0Se243377LTw9PeHo6Ijhw4cjNTVVbXvOK9vZ2dlYuHAhqlSpAmtra1SsWBHz588HAPj7+wMAgoKCIJPJ0KpVK+V+69atQ0BAAGxsbFCjRg2sXLlS7Tzh4eEICgqCjY0N3nnnHVy8eDHP+0MQBAwZMgRVq1bFiRMn0LlzZ1SuXBn16tXDzJkzsWvXLmXdK1euoE2bNrC1tYWbmxs++eQTvHnzRuM2Ll68GF5eXnBzc8Pnn3+uloRZuXIlqlatChsbG3h6eqJXr17KbX5+fli6dKlafPXq1cOsWbOUyzKZDGvWrEGXLl1gZ2eHgIAAnD59Gnfu3EGrVq1gb2+Ppk2b4u7du8p9FI/rmjVr4OPjAzs7O3z44YeIf9sPdNasWdiwYQN27dqlbJly9OhRrS1Ajh07hkaNGsHa2hpeXl74+uuvkZmZqdzeqlUrjB07Fl999RVcXV1Rrlw5tfgLiskDIiIiIiIqObLSc//LztSjboZudQ3A1tZW7cftnTt3sHXrVmzbtk35o7Fz5854+vQp9u3bh3///Rf169dHcHAw4uLiAABbt27FzJkzMX/+fJw/fx5eXl4aP+pzmjx5MhYuXIjp06fj+vXr+OWXX+Dp6QlAngAAgL///hsxMTHYvn07AODnn3/G1KlTMX/+fERGRuKbb77B9OnTsWHDBgBAUlISunTpgurVq+Pff//FrFmzcm1VoRAREYFr165hwoQJMDPT/ImqaC2RnJyMDh06oEyZMjh37hx+//13/P333xg9erRa/bCwMNy9exdhYWHYsGED1q9fr+yucf78eYwdOxZz5szBzZs3ceDAAbRo0SLP+LSZO3cuBg0ahIiICNSoUQP9+/fHyJEjMXnyZGU3i5xxKR7XP//8EwcOHEBERAQ+//xzAMDEiRPRu3dvZauUmJgYNGvWTOO8jx8/RqdOndCwYUNcunQJq1atQkhICObNm6dWb8OGDbC3t8fZs2exaNEizJkzB3/99Zfet1OV9G0fiIiIiIiIDOXaN7lvc6wK+H8kLkd+p5kkUHDwAyoNEZdvLgUykzXr1Zmlf4wqwsPD8csvvyA4OFi5Lj09HZs2bYK7uzsA4MiRI7hy5QqeP38Oa2trAMDixYuxc+dO/PHHH/jkk0+wdOlSDBs2DB9//DEAYN68efj77781Wh8ovH79Gj/++CNWrFiBwYMHAwAqV66M//znPwCgPLebmxvKlSun3G/u3LlYsmQJevToAUDeQuH69etYs2YNBg8ejM2bNyMrKwuhoaGws7NDYGAgHj16hM8++yzX++D27dsAgBo1auR5X23evBkpKSnYuHEj7O3tAQArVqxA165dsXDhQmXio0yZMlixYgXMzc1Ro0YNdO7cGYcPH8aIESMQHR0Ne3t7dOnSBY6OjvD19UVQUFCe59Vm6NCh6N27NwBg0qRJaNq0KaZPn4727dsDAL744gsMHTpUbZ/U1FRs2LABFSpUAAAsX74cnTt3xpIlS1CuXDnY2toiLS1N7f7OaeXKlfDx8cGKFSsgk8lQo0YNPHnyBJMmTcKMGTOUyZc6depg5syZAICqVatixYoVOHz4MNq1a6f3bVVgywMiIiIiIiIT2rNnDxwcHGBjY4OmTZuiRYsWWL58uXK7r6+v8sc7APz777948+YN3Nzc4ODgoPyLiopSNo2PjIxE06ZN1c6Tc1lVZGQk0tLS1JIW+YmNjcXDhw8xfPhwtTjmzZunFkfdunVhZ2enUxyAvNsCIO8OkBfFsRWJAwBo3rw5srOzcfPmTeW6wMBAmJubK5e9vLzw/PlzAEC7du3g6+uLSpUqYeDAgdi8eTOSk7UkhfJRp04dZVmRtKhdu7bautTUVCQmJirXVaxYUZk4AOT3S87Y86N4nFXvq+bNm+PNmzd49OiR1vgA9fugoNjygIiI8vW25SIREVHRFzgl922yHNdOA/6bR90cP2Srf1ngkHJq3bo1Vq1aBUtLS5QvXx6WlpZq21V/HAPysQm8vLxw9OhRjWMVdABEW1tbvffJzs4GIO+60LhxY7Vtih/rikSAPqpVqwZA/sNYdWrJnARByDXBoLo+5/0pk8mUsTs6OuLChQs4evQoDh06hBkzZmDWrFk4d+4cXFxcYGZmpnEbtA1aqXoOxbm1rVOcN6+Y80uaqNJ2H2hLvuR1HxQUWx4QEVG+pk+XOgIiIiIdmVvl/mdmoUddS93qFoC9vT2qVKkCX19fjR952tSvXx9Pnz6FhYUFqlSpovZXtmxZAEBAQADOnDmjtl/OZVVVq1aFra0tDh8+rHW7lZX8tmVlZSnXeXp6wtvbG/fu3dOIQzHAYs2aNXHp0iWkpKToFAcgH5CwZs2aWLJkidYfuIpBBWvWrImIiAi1aS1PnjwJMzMzZQJCFxYWFmjbti0WLVqEy5cv4/79+zhy5AgAeXeNmJgYZd3ExERERUXpfOy8REdH48mTJ8rl06dPq8VuZWWldn9rU7NmTZw6dUotwXHq1Ck4OjrC29vbIHHmhskDIiLK14ULYlmH7zhERERkQG3btkXTpk3RrVs3HDx4EPfv38epU6cwbdo05eB8X3zxBUJDQxEaGopbt25h5syZuHbtWq7HtLGxwaRJk/DVV19h48aNuHv3Ls6cOYOQkBAAgIeHB2xtbXHgwAE8e/YMCQkJAOSzAixYsAA//vgjbt26hStXrmDdunX4/vvvAQD9+/eHmZkZhg8fjuvXr2Pfvn1YvHhxnrdPJpNh3bp1uHXrFlq0aIF9+/bh3r17uHz5MubPn48PPvgAAPDRRx/BxsYGgwcPxtWrVxEWFoYxY8Zg4MCByq4D+dmzZw+WLVuGiIgIPHjwABs3bkR2djaqV68OAGjTpg02bdqEEydO4OrVqxg8eLBaF4jCUMR+6dIlnDhxAmPHjkXv3r2VYxz4+fnh8uXLuHnzJl68eKG1xcOoUaPw8OFDjBkzBjdu3MCuXbswc+ZMjB8/Xutgk4bE5AEREeXr7fcFAICzs3RxEBERlUYymQz79u1DixYtMGzYMFSrVg19+/bF/fv3lT+a+/TpgxkzZmDSpElo0KABHjx4kOcghQAwffp0TJgwATNmzEBAQAD69Omj7BdvYWGBZcuWYc2aNShfvrzyB/zHH3+MtWvXYv369ahduzZatmyJ9evXK1seODg44M8//8T169cRFBSEqVOnYuHChfnexkaNGuH8+fOoXLkyRowYgYCAALz//vu4du2acupEOzs7HDx4EHFxcWjYsCF69eqF4OBgrFixQuf70sXFBdu3b0ebNm0QEBCA1atXY8uWLQgMDAQgn4GiRYsW6NKlCzp16oRu3bqhcuXKOh8/L1WqVEGPHj3QqVMnvPfee6hVq5bajBgjRoxA9erV8c4778Dd3R0nT57UOIa3tzf27duH8PBw1K1bF59++imGDx+OadOmGSTGvMiEgnRKKUUSExPh7OyMhIQEODk5SR0OEZEkVLvWvfsucOKEvPzoEWDkFnJERFRK5fU9PDU1FVFRUfD394eNjY1EERLpbtasWdi5c6dy6s2iRNfXE1seEBGRXlRnHcpn2mYiIiIiKiGYPCAiIr2oJg+0tKYjIiIiohKIyQMiIiqw2FipIyAiIiIq+mbNmlUkuyzog8kDIiIqsLQ0qSMgIiIiIlNg8oCIiAqMQ+4SERERlQ5MHhARERERUbGUnZ0tdQhExZ6uryMLI8dBREQliBlTzkREVARYWVnBzMwMT548gbu7O6ysrCBTnVeYiPIlCALS09MRGxsLMzMzWFlZ5VmfyQMiItKZvb3UERAREQFmZmbw9/dHTEwMnjx5InU4RMWanZ0dKlasCLN8rhIxeUBERHl6/FgsV6woXRxERESqrKysULFiRWRmZiIrK0vqcIiKJXNzc1hYWOjUcofJAyIiytOiRWJ56FDp4iAiIspJJpPB0tISlpaWUodCVOKx9yoREeVp716xPGGCdHEQERERkXSYPCAiojxp60pqbm76OIiIiIhIOkweEBFRnlJTNdc5OJg+DiIiIiKSDpMHRESUJ0HQXOfvL5ZVB1QkIiIiopKJyQMiItLbgAFiWXVARSIiIiIqmZg8ICIivfXtK5YPHJAuDiIiIiIyDSYPiIhIb97eYpndFoiIiIhKPiYPiIioUFJSpI6AiIiIiIyNyQMiIiqU7GypIyAiIiIiY2PygIiIiIiIiIjyxOQBERHpxNpa6giIiIiISCpMHhARkU48PKSOgIiIiIikwuQBERHlat06sdy8uXRxEBEREZG0mDwgIqJcrVkjlhcvli4OIiIiIpIWkwdERJSrGzfEsre3dHEQERERkbSYPCAioly9eZP7NjN+ghARERGVGvzqR0REucrKyn2bra3p4iAiIiIiaTF5QEREBcJuDERERESlB5MHRERUIB06iOUlS6SLg4iIiIiMj8kDIiIqkK++Esv/93/SxUFERERExsfkARERFYhqt4WoKOniICIiIiLjY/KAiIgKLa9ZGYiIiIio+GPygIiICi2vWRmIiIiIqPhj8oCIiPJlbi51BEREREQkJSYPiIgoX87OUkdARERERFJi8oCIiLR6/FgsBwZKFwcRERERSY/JAyIi0mriRLE8bpx0cRARERGR9Jg8ICIirY4dE8vdu6tsELJNHgsRERERSYvJAyIi0urlSy0rX4QDl2cCSdEmj4eIiIiIpGMhdQBERFQ0padrWXn0fSD9GfDsFPDeYchkgCCYPDQiIiIiMjG2PCAiIt2lP5P/f3EEAGBtLWEsRERERGQyTB4QEVGBubtLHQERERERmQKTB0REpBst/ROaNxfL69aZMBYiIiIiMikmD4iISDeZKRqrFi8Wy0weEBEREZVcTB4QEZFuoo+KZauKAABvb3FVZKRpwyEiIiIi02HygIiIdPNsr1jOzNToxpCQYOJ4iIiIiMhkmDwgIqI8yWRvCxXfF1dmPwEy09TqZWSYLiYiIiIiMi0mD4iIKE82Nm8L3u8BTs3EDU/OSBIPEREREZkekwdERKTh8WOx7OPztnB5JpD6XNxw50eTxkRERERE0rGQOgAiIip6Vq8Wyx06vC1cm6teKe60yeIhIiIiImmx5QEREWnYsUMsf/VVLpUy4kwSCxERERFJj8kDIiLScP++WFadjlEdR0gkIiIiKi2YPCAiIg0pKVJHQERERERFCZMHRESkITs7xwpBkCQOIiIiIioamDwgIqL8ZeZsimABuDYFAFhZmT4cIiIiIjItzrZARET5e3hcLNvWAKr0BWwrAABcXIDnz7XvRkREREQlA1seEBFR/p4dFMtenYDH+4B76wEA9eqJm8LDTRoVEREREZkIkwdERJS/il2hbKx2fxMQFw68+AcAMHeuWG3+fNOHRkRERETGx+QBERHlr3xroF860CcVyE4W12dnoVEjcfHcOdOHRkRERETGxzEPiIgof5dnAc//Aby7AFYeQHqUfH38Q8DVT1ktLk6K4IiIiIjI2NjygIiIcmVp+bZwbQ4QewSIGA+U6yBWuLVKrX5amuliIyIiIiLTYfKAiIhyVaaMlpXVxojlZztMFgsRERERSYfJAyIiUrNDJR/QpImWCmWri+WkR0aPh4iIiIikV6ySB8ePH0fXrl1Rvnx5yGQy7Ny5M999jh07hgYNGsDGxgaVKlXC6tWrjR8oEVEx9sMPYnnqVC0VzFQ/OlKNHQ4RERERFQHFKnmQlJSEunXrYsWKFTrVj4qKQqdOnfDuu+/i4sWLmDJlCsaOHYtt27YZOVIiouIrMlIsN2oEQBDyqF2sPkaIiIiIqICK1WwLHTt2RMeOHXWuv3r1alSsWBFLly4FAAQEBOD8+fNYvHgxevbsaaQoiYiKt/j4HCsyVVsX2Mn/WTgBmSlA+S4mioqIiIiIpFSskgf6On36NN577z21de3bt0dISAgyMjJgqRxGXJSWloY0leHCExMTjR4nEVFRkpmZY8XT82LZsZr8/3/+AF6eApwDTRYXEREREUmnRLc3ffr0KTw9PdXWeXp6IjMzEy9evNC6z4IFC+Ds7Kz88/HxMUWoRERFV8x+sVzpU/n/5KfAo73AvfWShEREREREplWikwcAIJPJ1JaFt313c65XmDx5MhISEpR/Dx8+NHqMRERFmnd7AG9balUdKP8fPgJ4dQ54shcAYFGi27ERERERUYn+uleuXDk8ffpUbd3z589hYWEBNzc3rftYW1vD2traFOERERUP5VsA/dKA7HTAXPH+mKZWxckJiIszfWhEREREZBoluuVB06ZN8ddff6mtO3ToEN555x2t4x0QEZEWV2YDfwcDN1RnulHJPQsCqlYVFx8/NllkRERERGQixSp58ObNG0RERCAiIgKAfCrGiIgIREdHA5B3ORg0aJCy/qeffooHDx5g/PjxiIyMRGhoKEJCQjBx4kQpwiciKp6uzgZiw4BLKu+dFi5iOe0NRo4UF2fONFlkRERERGQixSp5cP78eQQFBSEoKAgAMH78eAQFBWHGjBkAgJiYGGUiAQD8/f2xb98+HD16FPXq1cPcuXOxbNkyTtNIRFRYzkFi+f5ODB0qLh49avJoiIiIiMjIZIJiBEHSKjExEc7OzkhISICTk5PU4RARGZ1iPFlz87fTNv6iMsBs/7cfGXd2AeHd5OUyrYCOYcr9bG2B5GTTxEpERCUXv4cTFS3FquUBERGZjp1dHht9O4rl11fVNqWmGiceIiIiIpIOkwdERKSkOthh5cp5VLS0EsvZ2Wqb2J6NiIiIqOQp0VM1EhGRflQHOxwwAECGajMCW/XKZtbyxEGVoSAiIiKiko3JAyIiUlId7HDCBACPLoorHHM0RWi6CUi8BpRtZorQiIiIiEhC7LZARERKqt0WAAAx+8Sy3wj1bW8eAY/2AlH/Z/S4iIiIiEhaTB4QEZGSxmCH5dsDsJSXc3ZPuDQeeHUeuL/JFKERERERkYTYbYGIiHJXvjnQPx3ISgfMrfKvT0REREQlElseEBFR7q7MBv5qDUQulToSIiIiIpIQkwdERJS7q7OB2KPA5UlaNsrUlszNTRIREREREUmAyQMiIioYmb1YzkqHg4N0oRARERGRcTF5QEREBWPnJ5ZjI+HvLy5qzNpARERERMUakwdERFQwFfqL5durMWCAuLh6tenDISIiIiLjYfKAiIgKptrHYvn1TfTtKy7u2GH6cIiIiIjIeDhVIxERabCxgXx6RnGNZiVHdwDmAMyAakPh7S1uio42bnxEREREZFpMHhARkQZ3dwDPr4sr7Py1V2y8Fkh+ALhUU1udnGy82IiIiIjI9Jg8ICIiAMC6dWL5vfcAxOwVV1QcqH2nxNvA00NAWiJQtrFydVaWcWIkIiIiImlwzAMiIgIALFsmlmfPBuDVDoClfEX1T7XvFPkN8Oo8cOt7Y4dHRERERBJiywMiIgIAREWJZW9vAEJDoH+6fOwDcyvJ4iIiIiIi6bHlARERAQDevMmx4soc4FBLIJKtCoiIiIhKO7Y8ICIiAFrGKbg6S/7/xXGg1temDoeIiIiIihC2PCAiIiIiIiKiPDF5QEREhaAyFoIgSBcGERERERkVkwdERFRwVh5iOSUJZvxUISIiIiqR+DWPiIgKzr2lWI67AFtb6UIhIiIiIuNh8oCIiDRlZ6gsWOdeL2Ay5B8lloB9BfkUj0RERERU4jB5QEREmmJviWVbv9zrlQ0AGiwFak8FZGno0EHctGSJsYIjIiIiIlNj8oCIiNRYWAB4dlBcUbF/7pXNzICESODhn8DjPfjqK3HT//2f0UIkIiIiIhNj8oCIiNQ4OQHweBeApXxFtVF573BnFRD/L3Dpa7VuC1FRxoqQiIiIiEzNQuoAiIhIeuHhYjkwEIDnO0D/dCArHTC3ynU/ddlqS2/eGCw8IiIiIpIYWx4QERHmzxfL48YBuDIXONQCuL64wMfMyip8XERERERUNDB5QEREOHNGLHfvDuDqTODFCeDKVMliIiIiIqKig8kDIiJCfLzUERARERFRUcbkARERIT1d6giIiIiIqChj8oCIiArJXOoAiIiIiMjImDwgIqLCMXeVOgIiIiIiMjImD4iISF12psqCDtM01pwIwAwwszZWREREREQkMQupAyAioiLm5R2xbO2Tf/0aYwEzGZCVDKTEQCbzgiAYLzwiIiIiMj22PCAiInXPDotln97517e0AV5dBB79CTw9Bms2QCAiIiIqcZg8ICIidZ7NAFjKyzXG6rZP9BYg/l/g7Ei4uxstMiIiIiKSCJMHRESkJJMBKFsP6J8O9E0HnMrpd4DsRDRvLi7u2GHI6IiIiIhIKkweEBGRkp0dgCvzgIPvAtcWFegY48aJ5R9+MExcRERERCQtDphIRFTKPX4slr29AVydIV94+Q9Qe6rex2vUSCxHRhYuNiIiIiIqGtjygIiolFu9Wiz31mF8RH0kJBj2eEREREQkDSYPiIhKua1bxfKnnxr22BkZhj0eEREREUmDyQMiolJOo9sCEREREVEOTB4QEZVyycmGOAqH0CEiIiIqyZg8ICIq5QRBZSE7U2XBUveDePcAYAaYOxgoKiIiIiIqSnipiIiIRHEPxbJlBd33a7IGuFVLXs54DcDRoGERERERkbTY8oCIiETPDovlit1138/aBXgRDjzcBby6YfCwiIiIiEhabHlAREQiz0aQd1fIAGpM0G/fmD3y/2dGArhg4MCIiIiISEpseUBERCK32kD/dKBvOuBcvmDHeHPdsDERkc7WrQNkMvkfERGRITF5QEREoqvzgYPvAle/LcRB0mBlZbCIiEgPw4ZJHQEREZVUTB4QEZHoynTg5T/A1RmFOoyLi2HCIaKCW7dO6giIiKgkYfKAiIgAwKCtBerVE8vh4YY7LhHlbvp09eWZM6WJg4iISiYmD4iICADg5ma4Y336qVieP99wxyWi3M2bp7785Ik0cRARUcnE5AERUSm2Y4dYbtjQcMftrjLL47lzhjsuEekuK0vqCIiIqCRh8oCIqBT74QexPHWqcc4RF2ec4xKRaMkSqSMgIqKSjskDIqJS7No1sdzoHdXLlJb6H6xMIwBmgFVZtdVpaQUKjYj0MHGi1BEQEVFJZyF1AEREJJ3ERNWFp2LZ0kv/g727Fbi3HjC3AoRsMD9NREREVHLwmx0RUSmWmamyEHNULHt31f9gFm7A83+AB38AqQmFDY2IdKQ6JaMhZ00hIiJSxeQBERHJeQQBsAIgA2p+pf/+0YeA538D8ReAu78ZOjoiysWwYWL53j3A3l66WIiIqORi8oCIiORcA4D+aUDfdMClov772/qI5fvrcq9HREbj7Q00by4uq86oQkREVBhMHhARkdzV+cCB5sCV+QXb3ytILL++YZiYiChPqskBi7cjWYWGiuu+/tq08RARUcnF5AEREcldmQ7EnQKuzSrY/hYqY/AKrw0SEhHlrUcPsXzypPy/t7e4LirKtPEQEVHJxeQBEREZgSB1AESlTqNGmusyMkwfBxERlUxMHhARkVFYcDJgIqNS7bJgbi5dHEREVDoweUBEREb54eHkZPhjEpGoZ0+xfOqUdHEQEVHpwOQBERHBwcHwx6xaVSw/fmz44xOVdoJK7yBtXRaIiIgMickDIqJSSvUHfSX/LJUtlgU/qK0fADPAzg8jR4qrZ84s+CGJSFN4uFg247c5IiIyAb16pAqCgGPHjuHEiRO4f/8+kpOT4e7ujqCgILRt2xY+Pj75H4SIiIoE1R/0Y0bEigsWngU/aMudwKMdgJUrhtYAhg2Trz56tOCHJCJNzZqJ5T/+0NxuawukpJguHiIiKvl0ylWnpKTgm2++gY+PDzp27Ii9e/ciPj4e5ubmuHPnDmbOnAl/f3906tQJZ86cMXbMRERkAIcOieWhbY+LC14dCn5Qc1vg+Qng/q9qq588KfghiUhTlkpjoe7dNbe/845YVh1YkYiIqKB0anlQrVo1NG7cGKtXr0b79u1haanZpPXBgwf45Zdf0KdPH0ybNg0jRowweLBERGQ4sSqNDVC2HgArABlAwKSCH/TMF8DLI/JyRioAGwBAamrBD0lE6lS7LMhk2uts2QJUqCAvT5+uPcFARESkD5kgCPlOxn316lXUqlVLpwOmp6fjwYMHqKo6UlYxlpiYCGdnZyQkJMCJQ4cTUQmi+qNDyBbkK7IzAZl57r9I8rPnXSDxH3n5P8cg820hniPfTxsi0oWlJZCZKS9v3557YkDxMrayAtLSTBMbkSHxezhR0aJTtwVdEwcAYGVlVWISB0REpca1+cCB5sDlOQVPHABAxd5i+faywsdFRBoUiQNAtxYF6enGi4WIiEoPncfn9fb2xsCBAxEaGoqoqChjxkRERKZ2eToQdwq4Prdwx6kySCzH/VO4YxGRBk57SkREUtE5efDpp58iJiYGY8aMQZUqVeDn54dhw4Zh06ZNePTokTFjJCKi4sLOWSxnxEkXB1EJ5e8vlkNDpYuDiIhKH53GPFCVkZGB06dP4+jRozh27BhOnz6NtLQ0VKpUCW3atMGaNWuMFask2NeKiEoqtTEPNqss9C/k4AS/iMeSfSQei2MeEBWe2us2n9eUPnWJiiJ+DycqWvROHuT06tUrLFmyBMuXL8ebN2+QpTp3UAnANy0iKqmYPCAqXh4/FmdQAJg8oJKP38OJihadpmpUlZqaipMnT+Lo0aM4evQozp07Bz8/P/Tp0wctW7Y0RoxEREREpV7lymJ58eL861tbc5YFIiIyHJ2TBzNnzkRYWBjOnTuHSpUqoWXLlhg9ejRatmyJcuXKGTNGIiIyIplMtcWYZeEPaOkGZLwCnOvA3BwoYQ3SiCSjmgiYMCH/+gEBQESEvBweDjRqZJSwiIiolNA5eTB37lxUrFgRP/zwAz788EO4ubkZMy4iIjIRa2uVXyQWBnhvb7EDeHYEsPeFnR3w+nXhD0lU2hVkloU1a4DGjeXlsWOBM2cMGxMREZUuOs+2sG/fPvTt2xfr169H+fLlUbt2bYwZMwZ//PEHYmNjjRkjEREZUU3fh+KCZ9vCH1AA8Pw4cP83VKworuYUc0QFV7WqWNalywKg3tLg0iXDxkNERKWPzsmDDh064Ntvv8WZM2fw4sULLFy4EHZ2dli0aBEqVKiAwMBAjB492pixEhGRgSxZIpYbN7UGYAVABgRMKfzBj/cDnh8Bnh1A9+7i6tWrC39ootIqJUUs69JlIafUVMPFQkREpVOhZlvIyspCeHg4du/ejZUrV3K2BSKiYiIoSOwL/eihAO8KMiA7E5CZqw/RXhC/2ANIBgA8bpGJCj7mAIDAQODq1cIdmqg00neWBVWccYGKM34PJypa9JptITs7G+fPn0dYWBiOHj2KkydPIikpCRUqVED37t3RunVrY8VJREQGdPeuWPaO/wa4uhco1waoN6/wB7fyBNKj5Md2fALABwAQHV34QxOVRgEBYnnaNOniICKi0k3nlgedOnXCyZMn8fr1a5QvXx6tWrVC69at0bp1a1SqVMnYcUqGGU8iKoksLMRZEITNZpAPVACgvwEuTZ74FHi4Rl6uMh2yxnMAAObmQGZm4Q9PVNoUpvUAWx5Qccbv4URFi84tD5ydnfHdd9+hdevWqKo6ag8RERU76j3MDPyLovoXYvIg5jcAc7Sck4h0wYFGiYioqNA5ebBlyxZjxkFERCWFWzWxnPRIujiISoA6dcTy2LH6729lBaSnGy4eIiIqvXROHmzcuFGneoMGDSpwMEREVAKYm6sspORajYjyFxcnln/8Uf/9q1YFrl2Tlx8/Bry9DRMXERGVPjonD4YMGQIHBwdYWFggt2ESZDIZkwdERKSikDM3EFGhzJ0L9OghL/frBxw/Lm08RERUfOmcPAgICMCzZ88wYMAADBs2DHVU29EREVExla1SNs+1lt7M7IDsNKBcO8Mdk6iUcXcXy337FuwY3buL5fPnCxcPERGVbma6Vrx27Rr27t2LlJQUtGjRAu+88w5WrVqFxMREY8ZHRERGpTL9gYWb4Q7bfCtQawZQ5WPDHZOolHnxQiwbYuipFPYiIiKiQtA5eQAAjRs3xpo1axATE4OxY8di69at8PLywkcffYS0tDRjxUhEREZiZ6WSAHZvZbgDC+nAs2PAgz8Md0wiIiIikoxeyQMFW1tbDBo0CLNnz0ajRo3w66+/Ijk52dCxERGRkWXLrAFYAZABNacb7sD/9AdijwAPf1WbZ56IdFO+vFguaJcFIiIiQ9I7efD48WN88803qFq1Kvr27YuGDRvi2rVrKFOmjDHiIyIiI3JwtAf6pQJ9MwCPQAMeOVVZsrEx4GGJSomYGLHM2bKJiKgo0Dl5sHXrVnTs2BFVq1bFuXPnsGTJEjx8+BCLFi1CjRo1jBkjEREZUHi4WG5f7zBwsClweSYM20RAHHyxfHntM/QQERERUfEhE3KbdzEHMzMzVKxYER999BE8PT1zrTd27FiDBVcUJCYmwtnZGQkJCXBycpI6HCKiQvvgA2D3bnn56UpneDq/HfegvwF/5G91BzLlo72NOJyItaGOAIDFi4EJEwx3GqKSqEoV4O5defm994CDBwt3PEtLIPPt2Ki6fesjKhr4PZyoaNE5eeDn5wdZPlelZDIZ7t27Z5DAigq+aRFRSePpCTx/Li8Lm1Xe1w2ZPDgYDLw8AgB4XGELKrSUd9pu3Bg4c8ZwpyEqiVS/bhnix75qMuLRI8Dbu/DHJDIFfg8nKlosdK14//59I4ZBRESm8uqVCU5SaYwyeeCdtAaAPHlw+7YJzk1EaqZOBYYNk5dHjQJ27ZI2HiIiKp4KNNsCEREVXxkZJjiJbwex/OaaspiYqKUuESlVry6W333XMMccOlQsh4UZ5phERFT66JQ8+PXXX3U+4MOHD3Hy5MkCB5SflStXwt/fHzY2NmjQoAFOnDiRa92jR49CJpNp/N24ccNo8REREQArlSkWstKURUW/ayLS7tYtsXz8uOGP//q14Y9JRESlg07Jg1WrVqFGjRpYuHAhIiMjNbYnJCRg37596N+/Pxo0aIC4uDiDBwoAv/32G7788ktMnToVFy9exLvvvouOHTsiOjo6z/1u3ryJmJgY5V/VqlWNEh8RUfGSrVI2RkM0SwDmgP8AIxybiIiIiExJpzEPjh07hj179mD58uWYMmUK7O3t4enpCRsbG7x69QpPnz6Fu7s7hg4diqtXr8LDw8MowX7//fcYPnw4Pv74YwDA0qVLcfDgQaxatQoLFizIdT8PDw+4uLgYJSYiouJLJXlg7mr4wzddD7y+Dbg3N/yxiUqgoCCx3LixdHEQERFpo/OAiV26dEGXLl3w8uVL/PPPP7h//z5SUlJQtmxZBAUFISgoCGZmxhtCIT09Hf/++y++/vprtfXvvfceTp06lee+QUFBSE1NRc2aNTFt2jS0bt3aaHESERUXFmbp4kJZI/zAz3gDPD0GJD8D0NbwxycqYSIixDJnJSEioqJG5+SBgpubGz744ANjxJKnFy9eICsrC56enmrrPT098fTpU637eHl54X//+x8aNGiAtLQ0bNq0CcHBwTh69ChatGihdZ+0tDSkpYn9cxM5uhcRlVCZ2eYArABkADWnG/4E50fK/78IA7DS8McnIiIiIpPRO3kgNZnq5McABEHQWKdQvXp1VFcZtrhp06Z4+PAhFi9enGvyYMGCBZg9e7bhAiYiKrIsgX6pgJANyDj5DpGUmjQRy4GBhj++uTmQlWX44xIRUelRbL4tli1bFubm5hqtDJ4/f67RGiEvTZo0we08JhqfPHkyEhISlH8PHz4scMxEREWZu8NT4EBT4PJ0IJckLBGZxtmzYvnqVcMfX3U4qsePDX98IiIq+YpN8sDKygoNGjTAX3/9pbb+r7/+QrNmzXQ+zsWLF+Hl5ZXrdmtrazg5Oan9ERGVRLN7TQNenQWu5z7gbOEwIUFUVEyYIJZnzpQuDiIiKr6KTfIAAMaPH4+1a9ciNDQUkZGRGDduHKKjo/Hpp58CkLcaGDRokLL+0qVLsXPnTty+fRvXrl3D5MmTsW3bNowePVqqm0BEJCnVK47/qXHSyGezU5asrdPzqEdUurVvL5YrVzbOOVSTBzt2GOccRERUshWrMQ/69OmDly9fYs6cOYiJiUGtWrWwb98++Pr6AgBiYmIQHR2trJ+eno6JEyfi8ePHsLW1RWBgIPbu3YtOnTpJdROIiCS1aJFYrlDGyG2X7f2ApGsAgPLucYh6VM645yMqpg4dEst37hj/fK9eGf8cRERU8sgEQRD02SErKwvr16/H4cOH8fz5c2RnZ6ttP3LkiEEDlFpiYiKcnZ2RkJDALgxEVOxVrw7cuiUvZ26Uwdz87Yb+en0U6Ob8XODWDADAV7tW4but8lZi27cD3bsb/nRExZXqkCP6fSsrmuchMhR+DycqWvTutvDFF1/giy++QFZWFmrVqoW6deuq/RERUdGlOgasMnFgLNVGKoufBG9XllevNvJ5iYoR1dmvfXyki4OIiCg/endb+PXXX7F161Y2/SciKoZSUxUl1cuORhr+xsnj7bFlqNKyp3J1RIRxTkdUHO3eLZZVel4SEREVOXonD6ysrFClShVjxEJEREYmNlVWSR6YuxjvhA1XAilPAbcg5ar4eOOdjoiIiIiMQ+/LTRMmTMCPP/4IPYdKICKiIkQmyxQXXJsa70Rpr4CnR4FHe5Sr0jnxAhEAoF8/sezhYfzzmRWrObaIiKio0XvAxO7duyMsLAyurq4IDAyEpaWl2vbt27fnsmfxxIFaiKgkEQdMy4Sw2QFAOtDqDFC+kXFO+Is4QpvsI/HjhvlnItMPYOjpCTx/brrzERUWv4cTFS16d1twcXFBdw6TTURUzJkB/VIAIRuQ8XIkUWnQty+wbJm8/MUXwI8/ShsPEREVL3q3PChtmPEkopJEcaXT1jIRybveA8q1AoK+Nd4J2fKASKuPPwZCQuRlV1fg5UvTnFfxHlC2LBAba5pzEhUUv4cTFS16tzxQiI2Nxc2bNyGTyVCtWjW4u7sbMi4iIjKiT4NXAa/Oyv+MmTwgIq0UiQMAuHzZ9Oc3VbKCiIhKDr3bqiYlJWHYsGHw8vJCixYt8O6776J8+fIYPnw4kpOTjREjEREZWOMq56QOgYje8vY2/TnZ+oeIiPSld/Jg/PjxOHbsGP7880/Ex8cjPj4eu3btwrFjxzBhwgRjxEhERAZWocxjE51JdVBd/lohAuTjDSg4O0sXBxERkT707rawbds2/PHHH2jVqpVyXadOnWBra4vevXtj1apVhoyPiIiMwMPlqWlOZOEOZD55u5AOwNo05yUqwhSDFgLAtWvSxUFERKQPvVseJCcnw9PTU2O9h4cHuy0QERVhO3aIZXeHF6Y5qXtLZdHVMd405yQqRqToskBERFQQeicPmjZtipkzZyI1NVW5LiUlBbNnz0bTpk0NGhwRERnOwoWKkgAnuzdvy0aeprHmJAAyAOZwdso27rmIioHp08Wyvb3pzy+T5V+HiIhIG727Lfz444/o0KEDKlSogLp160ImkyEiIgI2NjY4ePCgMWIkIiIDuH1bURJgpsgZmBt56quytYCg74CMJFSpao6ot0MthIcDjRoZ99RERdG8eWL55k0jnCArFTCzzjVLUKYMEBdnhPMSEVGJp/clp1q1auH27dtYsGAB6tWrhzp16uDbb7/F7du3ERgYaIwYiYjIABIS5P9lsixxpUtj457U3BxIeQY8PYz/DjigXP3DD8Y9LVFxYJQuC+FfAH+1BGIOa93cvbtYVm0FQURElB+ZIHCynrwkJibC2dkZCQkJcHIy8hU6IiIjEi9EZkHYbA8gA2h1DCj/H+Oe+BfFic0h+ygTAODjA0RHG/e0REXNkiXAxInyso0NkJJi4BOkPge2K8alsgH6a57g8WOgQgV52csLePJEowpRkcHv4URFi07dFnbv3o2OHTvC0tISu3fvzrPu+++/b5DAiIjIWGRAvxTIp040ZQdoscVDbKwJT0tURCgSBwBw544RTnB+ispCKpD0ALD3Vaui2trh+XMjxEBERCWWTsmDbt264enTp/Dw8EC3bt1yrSeTyZCVlZXrdiIikp6NZTJwoA3g2Qqov0iSGNLSJDktUZFh8C4L6fFAdIjKClvg0X6g+qe57sKvbEREpA+dxjzIzs6Gh4eHspzbHxMHRERFX+9GvwGvzgE3vpMsBnaYo9Jm3TqxbGVlhBNcXZpjRQrw7xgjnIiIiEorvQdM3LhxI9K0XDJKT0/Hxo0bDRIUEREZT23fK1KHQFTqDBsmlu/dM/DBM5OBG7O1bTDwiYiIqDTTO3kwdOhQJCiG7Fbx+vVrDB061CBBERGR8XiX4QhpRFIyeJeF+zsMfEAiIiJNeicPBEGATMvcwY8ePYKzs7NBgiIiIuPxcDb1KGl6f9QQlSg7VH7bW+g02pSeLn2tsmCrvo19hIiIyEB0/ggLCgqCTCaDTCZDcHAwLFQ+/bKyshAVFYUOHToYJUgiIjIcd4cXpj2heRkg66Vpz0lUhPToIZZPnjTCCazLAWmP5OVWfwNHWwHIkC+nxgG2bmrVnZ0BLY1IiYiI8qRz8kAxy0JERATat28PBwcH5TYrKyv4+fmhZ8+eBg+QqCQKDwd++AHYskXqSKj0EeBsH/+2bKIWAdW+BCJnQI+PHKISq1EjAx4sOwsQsoB2R4AL44H4a0D5ZoBzXSDhvLzOjVAg6L9qu3XsCPz6q7y8bh3AXqdERKQLmSDo155tw4YN6NOnD2xsbIwVU5GSmJgIZ2dnJCQkwMnJSepwqIRQ9PyxsQFSUqSNhUqHx4+BChUAQMCr/znDxf41YOYC9H1l/JNnJAM3lgJCBmR1JwOQDzXP1tRUGuzYIbY8MDcHMg05hmHsGSB8NFB3JlChq7g+Ogz4p428bFUR6PVAbTfx/QDw8QGiow0YE5EB8Xs4UdGi92WgwYMHAwDOnz+PyMhIyGQyBAQEoEGDBgYPjqikS02VOgIqLSZOVJSyYWP5NmPlUt80J7e0A5KigcRIONmOQWKKq2nOS1QEqDbKPHXKgAcWBCCsB5AZAxx/H+j+BrC1l2/zbiHWy9TsMqQ6YOMTjp9KREQ60jt58PjxY/Tt2xcnT56Ei4sLACA+Ph7NmjXDli1b4OPjY+gYiUqUx4+ljoBKI7GftQw2VhYABKD2LNMFcG8NAODTNsuxaO9M052XSGKqLWwM2mUh4YY8caCQlQTgbfLA3BzKbkk+H+Z5mKwsA8ZEREQlWoGmaszIyEBkZCTi4uIQFxeHyMhICIKA4cOHGyNGohKlXz/15SVLpImDSpfnqhMs9EsG+qUD5f9j8ji61t2nLDORRiVdeLhYNjP0ECPHcnyY2LurL/9nG1BrJuDVysAnJiKi0krvj7ITJ05g1apVqF69unJd9erVsXz5cpw4ccKgwRGVRKpfJgFg0iRp4qDSJS1N/t/GMgU40Ai48F9x8A0TqlbhhrI8kw0QqIRr1kws//GHAQ/8JhpIuiQuVxym+Xp2rAbEngZurzXgiYmIqDTTu9tCxYoVkZGRobE+MzMT3qqd6IhIK8WPOAU2GSVT6lh3H/DqvPyvgembvXg4JyrLR4+a/PREJqX6/t69uwEPfGaU+nLT/2nWOTVYnHEhI1k+9ggREVEh6N3yYNGiRRgzZgzOnz8PxUQN58+fxxdffIHFixcbPEAiIjKc6l43pQ5BiQO1ERVAxmvg+V5x2bXl2zEOctZLEssP/jJ+XEREVOLpnTwYMmQIIiIi0LhxY9jY2MDa2hqNGzfGhQsXMGzYMLi6uir/iEg3O3ZIHQGVFuWcn0odghJnGyEqgMQX6stt9mmvV2WMWL4yXWOzvb0BYyIiolJB724LS5cuNUIYRKVbv378IUWm4e70Iv9KJqI6Cj1RSWZra8CDZam0KLCpAljl0h2h+lDg8tvuDSnXNTY3bw4cOiQv79hh4G4VRERUIumdPBg8eLAx4iAqdSwtAcXwITnHQSAylrKSJQ8sAGRKdG4i0/v4Y7E8YoSBDpqVBrgHAg1DgCtzgPancq9raaO6o8bm0FCgQgV5+euvmTwgIqL86Z08UHj+/DmeP3+O7OxstfV16tQpdFBEJZXqTAuBgUBEhGShUKkkoIxd/NuyiWda8OoKxOwEzGzyrUpUEmzeLJZ//NEAB8xMAQ63B8q1BQK/AqoOK9ThVMe4jooqZGxERFQq6J08+PfffzF48GBERkYqB0xUkMlkyOLQ8US56t9fLO/ZA1SpInZXePxY/csckTE4272SF8wcTHvipv8DbtYBzC0hvwqqZYA3ohLE4F3RHuwEXp6Q/yXFAM1WGezQWibRIiIi0qB38mDo0KGoVq0aQkJC4OnpCZkE84QTFVf374tlb2/gl1+AHj3ky4GBQHy8FFFR6ZENZYsDpyDTntqmLJB4C0h5BGCSac9NVNxlZwBnh4jLL05KFgoREZVeeicPoqKisH37dlSpUsUY8RCVaDkb5qj2MU1IMG0sVBqZ4fy9eqjmdR+oPcv0p3+4BQBQyzsCVx+/Y/rzExVXT48DSBeX39GxH4RXVyBmL2DhbJSwiIiodNF7qsbg4GBcunTJGLEQEZERLFkils9a/A70SwcqtJIsniZVzkp2bqJiR8gGjvZUWSEDyrfWbd9m64GgxUDAOOD1HWNER0REpYjeLQ/Wrl2LwYMH4+rVq6hVqxYsLS3Vtr///vsGC46oNDA3F1skcNwDMoZ16+T/bSyTMb1xS+Dfd4F3fpAsnhrlb0p2biJTePxYLHt4FPJgLy8CUGma1ihU932tXYE3D4BnR+QDG9SfU8hgiIioNNM7eXDq1Cn8888/2L9/v8Y2DphIpL+FC4GJE+Xlli2BO7w4RAYWHS3/3yrgKMriX+DWv5ImDyp73pbs3ESm0FOlocDq1YU82LEP1ZerDNFv/9tvuzgkXtVIHtjYGGFgRyIiKrH07rYwduxYDBw4EDExMcjOzlb7Y+KASDf29mJ5wgSxfPeu6WOhki8pSf7f36NozMfm73lfWVa9QktUUpw/L5ZVx7YpkDSV1221rwtxIEFjTd26Yll1KmEiIiJt9E4evHz5EuPGjYOnp6cx4iEqsaZPF8tdu0oXB5U+2dny/x6Oz6QN5C2fMo+U5UJflSUqggx7LUVlVqv68w15YCxbJpZHjjTooYmIqATSO3nQo0cPhIWFGSMWohJt5UqxvGWLdHFQ6eXmGCd1CAAAJ7s3yvKOHRIGQlSUZaUBggC0/xdwrg9UHguY6f21TZ2QrbbYqJFYjows3KGJiKjk03vMg2rVqmHy5Mn4559/ULt2bY0BE8eOHWuw4IhKkrg8frcNHw6EhMjLLVoAx4+bJiYqXco6vpA6BACAhblYVozHQEQ5XJgKpEQD9RYAnf8txIGsAaTJi2+eAY5eWmulpRXiFEREVCrIBEHQ7ASXB39//9wPJpPh3r17hQ6qKElMTISzszMSEhLg5OQkdThUjMlUWp5qe9Xlt52ooOTPLQEHvmqP9nX/AiAD+mfns5cR7AkCEi8BFs6Q9XkFQD7bSGam6UMhMibF+3mBn99pL4FtZd8epAzQpxCthg4GAy+PyMuVJwGNv9UaK8DPnqJq3Tpg2DD5hYa1a6WOxrT4PZyoaNG75UFUVNEYcIuIiPTjbPd2ujeZfd4VjaXF70DURsDCDvLB22QG7htOJD3Vrji1axfwIBHfiOWsV4WKB/UWA4fry8sPNmgkD6joGzZM/j8kBPjzT+BZ0Ri+hohKoUJ2niMiouIhGykZ1vKiU0F/0RSStRfw6jLweC+0jfxOVBJ8/rlY3rOnAAfIeAPc/V5ctqpYuIA8g8RyVkrhjkWSe/5c3qKFiEgKerc8GKZIf+YiNDS0wMEQlWaNGwNnz8rLH39c+pomkrGZ4fczPdG65img1pz8qxvDkzDgyS4AgJV5MtKzHKSJg8iIYmLEsrd3AQ5we736cofThQlHzsxW3iehyvDCH4skl50t727CbiZEZGp6tzx49eqV2t/z589x5MgRbN++HfHx8UYIkaj4U53L3sNDe50zZ8SyYvBEIkNae3ws0C8dqBgsTQCW4kBtFVwfShMDUVGWlQpEqAw8beYMOJQv/HFbHwQCvwacq2hssrYu/OHJNCxyXPKTyYDwcGliIaLSSe+WBzu0zKuVnZ2NUaNGoVKlSgYJiqikGTVKLH/L7qYkARvLFLQICAPOHwIa/ihNEJ51lMXKHlG4FxsgTRxERdXDQ1Dr0tP2qGGOK7MAonfIu0RU/VRtlMSAACAiQl4OD1efvpGkN326WO7VC1i8GKhQQVzXuHHpHEiRiKSh92wLubl58yZatWqFGNX2eiUAR3klQ7C1BVJT5eW8XnEc9ZoMLTxc/uWyXa2D+OXzvijrFA/0l/DJ9Yv8Sf7p2uVYEzYaAJ/rVLIU6n18ZwCQfOPtgiXQP90wQe2sDSRflZd7JQJWjspNivcIQP5ftRUcSc/JCXj9Wl5WfT6pPs8AwMenZE59y+/hREWLwQZMvHv3LjI53xaRVorEQX58fMTykiXGiYVKF8VVKy+XJyhjHy9pLKr83O9LHQKRURWoO4CVs1j+zy6DxaI2wt7trWqbVFsaXLpkuFOSYSgSBzkJAmCvMnHOw4eApaVpYiKi0kvvbgvjx49XWxYEATExMdi7dy8GDx5ssMCISqPTp8XmiJMmARMmSBsPFX8XLsj/uzm8LFIjdPu4lcBLZFTqqTYx795djx0FARAygTYHgX/HAnEXgYodDRdYla+Bi/3k5chvgEDtAyfqmuimouHNG6BJE3Gw5cxMDqRIRMald/Lg4sWLastmZmZwd3fHkiVL8p2JgYjypjoyd1aWdHFQyZGQIP/v5vRS2kByqOD6SOoQiAzuhx/E8pYteuz46jIQ/hlQexrQfIPB40K1D8XkQfp9wx+fJHPmjLyl4sSJ4jqZTJ5Q4PgVRGRoeicPwsLCjBEHEREZQUaG/L+rXZy0geTg6vBK6hCIDC4pqQA7CQJwtBeQegc41hl4Pw5wKGPYwNSaHWUb9tgkuQkTgL59NQdSnDYNmDtXuriIqOTRe8yDlJQUJCcnK5cfPHiApUuX4tChQwYNjKgk0qXZuLNKl1ctk5sQFYAAV0dF8kCWZ02js/YGIEN8qrty1bp10oVDJLnXUfLEgUIqE2ukydY27+3e3prdFebNA2rVMl5MRFT66J08+OCDD7Bx40YAQHx8PBo1aoQlS5bggw8+wKpVqwweIFFxpzoHc40a+de/dk0s9+9v+HiodHK2fdt/AfZ51jO6ljuBwGmoFtxbuWrNGunCIZLcyaHqy2V8pYmDipwvvhDLun4fEAT1wTqvXQNsbAwbFxGVXnonDy5cuIB3330XAPDHH3+gXLlyePDgATZu3Ihly5YZPECi4k51KJDQ0Pzrq457wMGryDAExCe/bdLiFCBtKNZlgVeX4JkujiR/+7aE8RBJKTkGeHVcXPbqqlsTtQLJ/bgcpb9oCgkRy2vX6r5faioQGCgup6VpTu1IRFQQeicPkpOT4egonx/40KFD6NGjB8zMzNCkSRM8ePDA4AESFXc3bohlDl5E0pAh9NhQAOZA4CxpQzk/HniyG3j2NxR9rxMTpQ2JyBAePxbLrq467nR+kvpyiz8MFo8G/6GAzBqw8QEE9XEP/P3FsurtIGkVaAyNt65elY95oEom4+NLRIWjd/KgSpUq2LlzJx4+fIiDBw/ivffeAwA8f/4cTk5OBg+QqLgryKwJqk0O+UFPhvDXlY5AvwzAz4DTvxVEcqyyaCbLBCCfXoyouFNtZbZ4sQ47ZCYBjzaJy451AXMrg8el1HAZ0GAJUHkQkHhTbdO334plTpxVcsydK07jqFChgnx2BiKigtA7eTBjxgxMnDgRfn5+aNy4MZo2bQpA3gohKCjI4AESlUaqU3zVqSNdHFQy2FimwMf1HnBurPRtVyv0UBZd7YvW9JFEhXHkiFgeOjT3ekpvcjS5aXfMoPFosLAFnvwF3FoLXP1ObVP37mL55EnjhkGm1aiR5kCKEycCTZpIEw8RFW96Jw969eqF6OhonD9/HgcOHFCuDw4Oxg+qExwTUe7irwL3NgAZb7RuVv0iF1e0ZtijYqh51X+we0J34M4KqUMBqgxRFn3cHkkXB5GB6d2CJkucuQqWXoCNc+51DeXJLiDjGfAg9ylOCtNUnoouQQAsVCZoP3sWcHCQLh4iKp70Th4AQLly5RAUFAQzM3H3Ro0aoYYuQ8kTEXCsF3DmY+AGZygh4ytf5gm8XJ5KHYacvTh/vbcrkwdUSmVnAGX8gQYr5ImDDqeljoiKsPymadRVRgbg4yMuJyVJ3xiNiIoXvZMHSUlJmD59Opo1a4YqVaqgUqVKan9EpJ1yqiRBAJJuAsgErnyVa33VAbc57gEVhOJ542yXCBurojd1R4UyTB5QKZSVDhzpClxfBFQeBnz4BHDk9IykTnWaxhEjDHfc6Ghg+HD1dRxIkYh0ZZF/FXUff/wxjh07hoEDB8LLywsypiyJcqU6KNHbsUWB1Bz9vLNSAXPNSZgXLpT3SwSANm2Amzc1qhDladEi+X8nuwTYWSXnXVkCPm4PpQ6hSNmxA+jxdkiInH2UqfjI92vRowPA84Pyv4QooPkak8SlITsLMDPWtJBUWKrTNP74o2GPvXYt8MknQOPG4roKFeTTSes0XgcRlVp6Jw/279+PvXv3onnz5saIh6hEUfx4A4CVK98Wrub4FvDyOuBRX2PfCRPE5MGtW8aJj0q2vXvl/13sEmBpUYBpP4zM2S5B6hCKlN69xXL79sDBg9LFQvoJDxfLVavmUTE7CzjZT1x+/pfRYtJKZgcIbxOJiQ8BFz/Tnp90ZuyxJxQDKaomu4YNA379le89RJQ7vbstlClTBq46T2BMVLo9fy6Wvb3fFh5sVK90sr/J4qHS5ckT+f8ydq+kDSQnC2cAMpy90zjfqqWJ6oB7hw5JFwfpr7/K27jqrAsaYs8CUGkFVO+7XKsahcd7Yvnqt2qbLPS+nEQlQc4EwqFDgIuLZOEQURGnd/Jg7ty5mDFjBpKTi14TWKJiwcFPfTnrtSRhUMmXmgoAApztFVf47SSMRsV/fgcCp+Gvax2ljoTIIO7dE8vKRHFOggAc66m+zr+n9rrGEqTSl+7RVrVNvirDLrD/e+mSnQ14eIjLCQkcSJGItNM7ebBkyRIcPHgQnp6eqF27NurXr6/2R0T5aPE7UH8ZILMCrDyAGl/mOmVj374qu7UwTXhUcsj7zQt4nvD2W6FTTSnDEVm6AK8uoVp59sdRUB0cjYofncaoiL8OZKrMehK40Gjx5MpVZWBrM/Vfh1OniuVRo0wUDxUZz54B77+vvo4DKRJRTjJB0G9YptmzZ+e5febMmYUKqKhJTEyEs7MzEhIS4OTkJHU4VMyoZu6Vr7Q76wB7b8CxGvAsDEi6D5RrD3g00/0YRDqQP3cE1Kl4EZcWNAKa7gD8u0odFrCjEpAShahn5VFpvPyb6fbtQPfuEsclIW1X+R49yuMqNhUpOr1P76wDJF8Rl/tL9Ib+hwcgZADVxgN1p6ttUtwOR0cgMVGC2EhJ8VjY2wNvtF9fMArVgVsVpHx/5vdwoqJF7x5uJS05QGRSGclA+DB5OWA2EBsGvDgG3FoN9HombWxUYl2ODgL6ZUgdhihF/lz3cXsCQAAgw+rVpTt5oA1nWSlhVBMHfiOli6P1fuDRDsDGJdcqr9mbTlIffyyWc06raGzdu8sTlxUqiOvi400bAxEVXQUeHufff/9FZGQkZDIZatasiaCgIEPGRVSiKMcYfaAyhPHD7cCbS/Jy+nMgOxMw44hVZFg2limwt04AwucBjX+SOhw5S08gI+rtAG3ZAMwRESFtSEURZ1kpfqys8tpqBvnzHdK+FpNjgFshQFYKUG00O7cXQb/8IpYNPU2jLry95S1ozMyAdu04fSMRifQe8+D58+do06YNGjZsiLFjx2L06NFo0KABgoODERsba4wYiYqlfiqzcU2Z8rYQ8ZW40m+I+g6xl7UeR3UeZtWrEUS6aFb1H/w2pj9wd2X+lU2lXBtl0dZKPh9Zab6y1b69WH7vvdzrUdG0RGUMwg4dtFTIzpD/Emt7EnCqA1QcBJibmyw+Df9+CWQ8BbITgLR46eKgXKWkSB2BXHY2p20kInV6Jw/GjBmDxMREXLt2DXFxcXj16hWuXr2KxMREjB071hgxEhVLf/4plidMeFtIvyOuDPgUsPUXl08P1nqcM2fEckiI4eKj0qF8mRiULxMjdRjqqo9TFss5yweQS0+XKhjpqU7LyC/qxc/cuWJ5pbYc3aW5wOmBgI070OUS8J8NJotNKyt3sXwzVLo4iIio2NE7eXDgwAGsWrUKAQEBynU1a9bETz/9hP379xs0OKLiLCkpnwqWNkDzneJy8lVjhkOllLNdAqwt06QOQ51bDWXRy5ljfeTk7CyWOdJ50ZeQIJY1BrhMTwAi5wL3NwP7G5k0rlzVmiOWb/0gXRxERFTs6J08yM7OhqWlpcZ6S0tLZGdnGyQoolLDo476cgZHqSLDcrJNhI1lqtRhqFNpsu3l8kTCQIom1ZYI9epJFgYZwm2VVgZZcdLFocpb7DaEDPXXn5S9KYiIqOjTO3nQpk0bfPHFF3jyRPzAefz4McaNG4fg4GCDBkdUomRn5rJB5WX45JTWGl5eYnndOsOFRCWfk+3ropc8UOFkm5B/pRKsShWxrOj510jlAvWLF6aNhwzs0pdi2cJNsjDUqGUI1KeL9PAQy2z1Ij1HR6kjICJSp3fyYMWKFXj9+jX8/PxQuXJlVKlSBf7+/nj9+jWWL19ujBiJSoZ01eSBrVj0GSKWz2mfvuvcObH8yScGjYpKKEWSyd46CbZWRWT0LVUyawAynI96R+pIJHX3rliWYlR1MiJBgNqP8/fO5Fq1qFCOzwOAM3NLQ3VgZM5yQERFjd7zwvn4+ODChQv466+/cOPGDQiCgJo1a6Jt27bGiI+o2FNe5ElX6XdeQWUqhsbLgYdvB61yEccSUaXajzYztwYMRCrWrAEAAY42r2FtkQa1hFVR0Pz/gFdXce1RLakjITIIjavEKTnG83CpgqJuwgRg4kR5eccOYO1aaeMpjTZvFstMKBJRUVPgSeXbtWuHdu3aGTIWohJDtbln5cpvCw6OQLuzwPOjQGWVFgZWdkCFnoCFI+DeVP6F09bTlOFSCXTjBgAIiI7zgZkZAMfqEkeUg7kDEPcvrC1SkZJpJXU0klB9n7DI8Wns4wM8fCgv79gBdO9uurhIdx98IJa/+CLHxgsql+7NXE0Sj+4sAWTkWePVK9NEQupSi24vMyIi3bstHDlyBDVr1kRiYqLGtoSEBAQGBuLEiRMGDY6ouOrSRSxv2vS2cH8z8OoCUPFDwMZZfYd3fwe82gGxZ4CHe7QeU/WqVni4YeOlkufNGwCQYW3YxwDMgcAZEkeUw/GeQMweLB8yWupIJBMYKJa3blXfdvq0WB440DTxkP4OHBDLqlM2AgCiVQaoabjaJPHoLOC/gIUz4FQLyNI+T6ogaF1NRESlmEwQdPt4eP/999G6dWuMGzdO6/Zly5YhLCwMO3bsMGiAUktMTISzszMSEhLg5OQkdThUTFhZARlvL+ooX2G/yOT/LcsDH2oZieoXawDpAGRAf82ZS8LDgcaN5WVbWyA52dBRU0kikwGK/tZCttrKouHt6+Hawxqo9XUkgNL3Y0X14dB22/PbTtLL8zH6xRzA2xdfn8yiNZVBVjpw92d5SzffPoCLmMni805avP/V8Xs4UdGic8uDS5cuoUOHDrluf++99/Dvv/8aJCii4i4jZ2tQQSUZkJHb1HSKqz8CkKXZblF1BPaUIjj+HRU9NpYpcHV4AYR/XrQSBwAA+Q8pF/t45BzxnahEqD4BkDkAFmWKVuIAAMytgNvrgWvfAedy9rcgIiLSTufkwbNnz2BpaZnrdgsLC8TGxhokKKISJ/m5yoIOQ408/NtooVDp0bTqSYSMGA7cXSV1KJrMXQAADjZvlKtKU3cc1UZ69vbSxUFGkhYHBP4X6JsI9HyWf30pJJwHkArEHpY6EtKC0zQSUVGkc/LA29sbV65cyXX75cuX4aU6GT0RiS59K5ad6muvU6alWD49TGsVK5Vx5TgHN+XH2yUGns5F9IeLU10A8qkkzc3kTXV++EHKgEyrb1+xfPOm9jqKbkoAMH26ceMhAzveG9gdAJwdCZjnfuGlKCpyjZRKkX4qEzFpDMBJRFQE6Jw86NSpE2bMmIFULcPApqSkYObMmeiiOkocEYnuh4rloKXa67RUGTFNiNXa2fHXX8VyvXoGiYxKMGe7BNhYpuVfUQqVRwEALMwFuNm/AACcPCllQKaVrjJGnepUrKrOnBHLCxcaNx7Sn2oC18cnx8bYw0DmS+DezyaNyRDc3KSOoPTauVMsawzASURUBOicPJg2bRri4uJQrVo1LFq0CLt27cLu3buxcOFCVK9eHXFxcZg6daoxYyUqdqytFaXX4sryTbRXtvNQX854o1FFdbq2Fy8KFRqVAk52CbCy0D6SuuT8OiuL7o7yJzN7vuVOYxwVklz79mL5jz9UNmQWw9FsszOVxf79xdW8+m1anKaRiIo6nZMHnp6eOHXqFGrVqoXJkyeje/fu6NatG6ZMmYJatWrh5MmT8PTk3PRE61Rm52rZUkuFPNuEWovFyDWGColKKUebN7Auqi0PrGyURSe7BABAWhEN1dCWLBHLGr39sjOB7CyTxkMFc/26WFYd0Bb3VafbLWIDJaqSqYxcH3dHWfzxR3G1ams3IiIinZMHAODr64t9+/bhxYsXOHv2LM6cOYMXL15g37598PPzM1KIRMWLagOc0NDc62lVZ4FYfrBZaxUzvV61VJo52LyBtUVR/kVuDkCGO8+qAig905L9979i+dw5lQ1Z6cD1hcCt5co7g/3Pi65cn6/nRotl749MEkuBVOghlq/M1lqFLdyIiEhVgX6GlClTBg0bNkSjRo1QpkwZQ8dEVKw9fSqWxb7MbwfMMnfOe+eAsW8L5oBvD/UpHt+aMkUsV69e0Cip5MuGvc0bWFumArDJt7YkGv0MBM5A7GuP/OuWIKo/OtXGO3j2D3B5GnBhHJCeCADo00fcrDqYGhVhgkr/m0YrpIsjP/W+EctP92mtkq35EURERKUYr2ESGZjWq1E9Y4Hgo0D703nvbG4OtNgFBH0vf3W+idKoojqI0q1bhQiUSizFQG53n1WBuVkW4FBZ2oByY2YJvDwPGfgLBQBwcoBYvrkBALBli7jqt99MHA/pLyvHGCO2RXi+PUeVPjPmnC+0KHHO5zoDEZFUmDwgMraHfwJX5gAZrwGXgPzrV3gfSHkC3PgJuMhBSEl/EycCgAyr/x4JQRCAWrMkjigXZwYDT/dibPsf869bQqi2HlCdihEAkBEjlrWM0l9aunUUNxYWKgupxWywRPsqgG1FoNaU/OuSUX3wgVjm1KxEVFQxeUBkbCf6ALe+B4531X2fGwuBjGfAI15qJP0dOyb/H5fkhrKfvAL8e0obUK7kLQ6aVzslcRymozoAnepUjEhPUK/o280U4VABqQ6M27SpyoYUlS4LLi1MFk+BtdwOVBpUpMd1LC0OHhTLEyZIFwcRUV6YPCAyupTC7Z6RqLHq/ffFsup0YUQA8PIlYGOZAjeHF0D4qCI/6l5ZJ47Khpvr1JetnZVN4C0tJYiH8vTVV2JZtWsJnCsAfoMBW3/g3V9MHpfenp0Bri0B/p2gNsZOEX/LKJHynG1GEID0eDY/IiLJMXlAZCSF67Oo8tK8sUFj665dYvnQocKch0qi9HSgSZVTWDZ4LHB3tdTh5EH+C8XFNl7aMIqCK1+LZatqwK21wPN/AQCTJombgoJMHBdppToLgXLQSyEbePo3EDgZ6HYHcPTWum+Rcv1byBPc6UCyeKM4FnYR8+oScGEScG89kFWUZ9AhopKOyQMiA/riC7E8Zgw0B8/SVcXhYvnKf3OvR5SL8mVi4O5Y1K/o2wEAnOwSAZT8K2qqP/yHD8+5VeUHQfotIPkmcEZeSXWQ1IgIY0VHhZZ4DzjxPrC3DvD8vNTR6MbWTyxfXaosdu8url6yxGTRUG6O9wfu/Q84+zEQuVQ+hhIRkQSYPCAyINV+sHPnQnnlEAAg02PU7UZLVRbStE7ZSJQXZ9sEWFkUMHllKvYVAQAO1kmQyUr+c1z1h//atTm3aumbkBJpxGjI4E6PeltIBx78LmkoOqszXyzf/5+yOHu2uJrJgyIgWfFekA1c/hqImA2kxua5CxGRMTB5QGRAr3NeDPh3olj2Haj7gazs1JfTkjSq1KsnllVbPBABgLNdIizNM6QOI2/lewMAbKxS4GAjH9tDMc1kqdPuH8B3AFAjx6j37ONcfMT9JZb9+koXhz7KNRLLWS+VRW+VHhfPn5swnlJK9X3P1VWHHW4vAS5O54UFIjI5Jg+IjCkxXCzXm6ffvmYqnU4vaE6jdfGiWF6+XM+4qMRzsHld9FseVJdfqbWxSIGTtTx5sGiRlAEZj+qPA7Ocn7x31gIpD4GGy4H689W3pcp/0Nnbaz8WScvW9m0hZ5LHo4HJYykQjSejpqwsE8RRyo0aJZan6DprZtQa4G4xGJSTiEoUJg+IjCpTLNrpOQJVs/8Ty6mP8qzKi5OUk6NtMUgeOHkAkMHaKhsvk9wBAAcOSBuSsdSvL5bVEiTZmUD4COCfXkDY2yk1zd3E7ZcWAAA2bRJXNWxovDgpfx9/LJZHjHhbSOXleSo41fc9rdM0BnwNOAcBFi7q6yN/kP/nTAxEZCLFLnmwcuVK+Pv7w8bGBg0aNMCJEyfyrH/s2DE0aNAANjY2qFSpElavLsojj1OJ46z4xVCASbQrdgKsygKONQDfPkBWqkFDo5IsGw7Wb2BtkQbAWupg8lZ/KRA4A6kZNgBK7lV11abfaj8OXlwTyy+Pyv/X/0lcd28lAPUB7GJiDB4e6WHzZrH8449vCxdmiSvNdGl3TiRKzyvPG3dR/h3gvaNAz1jASSUTWb4tkPIUuLEMeLyH3RiIyOiKVfLgt99+w5dffompU6fi4sWLePfdd9GxY0dER0drrR8VFYVOnTrh3XffxcWLFzFlyhSMHTsW27ZtM3HkVNoo58judB7oEQt0vlGwA3W98f/t3Xd4FNX6wPHvZtM7SQgJgdB7kV4FxAKiIs2CvcG1i1exXlEUu6LX3gF/NlCvIFZEkSa9SZUaIAkJPb1n9/fHJJmZ3fTs7uxu3s/z8HBm5uzMG0g2O++c8x7odDdk74JM+3PEx6vtuXPtDotG7MDx9hQW+0NIW6NDqYEPnFYr0+fnGxiKEdbdrLbLK9+3vULTQZKG7qagsv+SI5oKmP3fc1ksjhFUcxdhnF+Hwq99YdV1YPaFSzdBwpUQPQR6zoDcZNj5PKy6HpI+B4ub17oRQng0j0oevPbaa9x2221MmTKFLl268N///peWLVvy3nuV/6J+//33SUxM5L///S9dunRhypQp3Hrrrbz66qsujlw0Btonpi1aAFkp8Oel8M8bENamficNiIbtL8DuZ2HlFXaHN25U27ffXr9LCO/0wR93sHrvYOgx0+hQqrflXkj/iXF9FgFg8cIHZxs0pU8CbAeC5GxT20O+Vf4212OkkjCYZopa60nGhVEfvZ6HoJYQOwpK8oyORmhZLUA+YIH0H5V9JhOM+BouWg5+obDlIZRVmbJg3S3wz9tQYl9kWQghHMFjkgdFRUVs3ryZUaNG6faPGjWKNWvWVPqatWvX2vUfPXo0mzZtori48sxsYWEhWVlZuj9C1MY116jtN94Atj8D6b8oN/5njtT/xEXHlL/zDtrNadRWxK7iW1o0MuVJrDO50byx9kNoc6WxAdVS37abau7koUaMUNsrV2oOlNgMs2jWW22HdQdTAEQNgtJCAGJj1cPahIRwAyZNRUtPS/50vhe6z4DYwZBzsGJ3WB1WFxZOklPNPC6fsuVdCzI0Oy2w7QHY+SIUnnFmZEKIRspjkgenTp2itLSUZs2a6fY3a9aM9PT0Sl+Tnp5eaf+SkhJOnTpV6WteeOEFIiIiKv60bNnSMV+A8Hrr16vtCROAo5qChwHhjrlIvhTlEtV7/30I9CsgJuwk/zr/Hc0cGvfWNKzy92RvoB3mPkCzMh5Hl9r1rXDRnzDgA2h+EZxWMgVbtqiHL7zQsTGKBhq3D86ZDf0/rrmvu/Exw99Pw85nYPV1FbtHjlS7yLQ456l2mcbND6vtkHMqP8Gwz+337X4WNj8ChaftjwkhRAN4TPKgnMnmg7DVarXbV1P/yvaXe+yxx8jMzKz4k5yc3MCIRWNhX/BI81QxLKYBZ9aMc978pN1R7RJu8jRSLFwIg9qt5aXJj3DvwHuNDqfWokIb4VOyjf9S2zGj9ccCY+DsTtj9Nqy9DdCPNMrOdkF8wo72Rq9iJMi+T+DIfEgcBx1uMySuBitKBayQtaNi17vvqoefe87+JcIxbr1VbdvNqj2mqdE1eF7lJ2jSHS49CATq9x/+GI5864AIhRBC5THJg5iYGMxms90ogxMnTtiNLigXFxdXaX9fX1+io6MrfU1AQADh4eG6P0IYqudLajv5Q7vDy5ap7fPPd0E8wq0dPgxxkWk0CT2Lv7/R0dReZPBZo0NwCu0T2xjbHGLpcbU97Avs7HsVLGchd78sw+YmLrtMbVcs3rRpCmx9EH4ZaEhMzqJNVh1pwMw7Ub3ly9X2LbfYHtXMR4ztVfVJItrCpDTwa6rfv+ku5W95/xBCOIjHJA/8/f3p27cvS5fqh3kuXbqUIUOGVPqawYMH2/X/7bff6NevH35+fk6LVQiH/qLuco9+21Ki29QOg86VGkmNXn4+NAnJwN/sKUUwlPfiyOAswPs+4E6dqra3bbM5GDVMbQdVntCuUCDDj93BDvXBvDI9TVu3osR7/49KSmruI+qnymUa6/o5IiASJqRASFd1nylYqUJ77GdIWypJBCFEg3lM8gDggQce4OOPP2bOnDns2bOHf//73xw9epQ77rgDUKYc3HjjjRX977jjDo4cOcIDDzzAnj17mDNnDp988gnTp0836ksQjUWRAwtt2hbfys9w3LmF17FYIDwoC19PSR74Kk/KwoKy8cbkQWmp2tY+yaW0UFm3fdxRuHB15S82axIKfyvjxrt1U3fNnu2wMEUtaf8/ATj8o2bDwwolVkWW+vNcvv4wdgfEXgL4wMAPIT8VDn4Bq2+CIwvsHkAIIURdeFTy4Oqrr+a///0vzzzzDL169WLlypX8/PPPtGrVCoC0tDSOHj1a0b9Nmzb8/PPPLF++nF69ejFr1izefPNNJk3ysGWUhEfx9wcOauYZBrZu+EmDO6jtbfZ1D7QDaVKrKc4sGoewoGz8fT3kBqCp8vTdz1zsOQkPR1h3B/w5BjL/gdihlffp+47aPqRMQF+yRN31+ONOjE/Uzsa71Xbza42Lo6F8ItV2+pYquwkX0tbmCmpf+9f5+MCFP8Elu6DNZLAGQMpXUJwGa26E/R/ar/QihBC15Gt0AHV11113cdddd1V6bN68eXb7RowYwZYt8otQONfChWq7d28g+Ut1R7cXG36BoQthaXelHd7O7vAHH6hFl/r0gePH7bqIRiQ0MBc/c1VjYd1M54cgbQHbjvSg1OIlT27LTJmitrUjBrBa4cg8pX18GVxbRdKkzRVQUQRV+f/Ujl6ocrizcB3rSbU98J2q+7m71rfCodeU9q5Z0PzH6vsL1xj8BaT+DF0frrmvrcjOyt/Hlmt2FsPmu5VVGDrfC/6RDghSCNGYeNTIAyHc1UMPqe3//Q9ofzMVQ1jbX9HwCzTtBq1vg84PQkAoFOunRWiLLJ2Q1RwbOSuhgTllyQMPqJgY2wt6zOLT9fdhtSo/M94yeuaTT9T2zp2aAznaVXyqGUJsO2VJuA2zGfvh/UFhhsTiED1nqO2TK4yLo5HRvtfZFVQ98i34hcOAtyCqZ/0v0vIC+307n4StMyC/8qXOhRCiKpI8EMIBkpLUdkIC0OZauKYIJp503A3AkI8hqAWkfg8pS2ruLxopCwfS25GdHwbBiUYHUzOzGaxWLuylzvufP9/AeFxh/f1qWztcvFKa949c7y3I5wm0I8x69ADO7jcsFocLjlTbgVEVTe1SwMLxrrlGbb/8ss3Bv66ElWNh2fiGXSQoGsbspLw4bYWDb0PSl5W+RAghqiLJAyEcwGKx2fH7BbDyCihw8DCArf+GtF9grd16TrrpkaIxM/HhsttZsO4K6PGM0cHUzs4nuXvIU/Rvuw6Azz83OB5nO6G5C+3/UfV9Yy9R21mHAbj8cnWXdmqEcK67NeUNfvwROPSZuiPiXJfH43BRg6FJf+g5q2LXUE05Dm3yRDjGunVqW7dMY1G22j6zquEXatJNWYnBNlm57UEokflPQojak+SBEI5WWginVkDqQlg+0UkXyQWrPmNx771qu3t3J11WeIQzudF8vPxOaDvZ6FBqzdcXuibsAfQjeTzV8OFqW3uzb1fpvG0NBXyHfAx+URDZG/yUDOH336uH585tWJyi9tLS1HZCAtDsPKAsa3uuFzzBHfoZJFwCJWcrds2Zox5+9FEDYvJyxVXViN2vSUyZIh1zsaBYmHQMgtraBJEPRWfh5F+ylKMQokaSPBDC0VL/UttFZ5x3naxDus033lDbu3Y577LCvQX65RMTdpKWUYc8bjhKdOgpAHJyDA7EAVZpHhZqb/Y5uVXfsab/o+BYuGgVJIyF9CV2H+7tRj0J17BaoMX5cFU+jNoAES2NjqjhDnwGO5+BLfdXJKe1BTq9IannMXZoVlXqNqPqfnXlFwSX74PosuxmUFvwKYGkz2H7C3B0IVhs1yMVQgiVJA+EcLSt09V261sde26zOheVtXc49tzCKwzusIYXJz/KN/ddaXQodRYVqjzxLPXmz66b71fbIV1q95rMA7Dredj+OBScrLm/cL7sJPixF2x9BKL6GB2NYxz6FChLTmWl2B2u8im5cDyLpr5Jt3ur7lcfZjOMXgF93oULl0FANOyfA8d/gr+uh0PzlBGUQghRCUkeCOFAYWFA7t/qjh7/cewFhmqGxp75w7HnFh5v4UJoFn6CsMBsWsceMTqcOosK9Y6CgNoK6nYDC3KPqu1z/1e7Ex78jIpVGbY9D8hCDIZbew/k7Ib9b8DJg0ZH4xgRmor+O543Lg6hZ3bSquqd74SwVspopqxtZTvzYcNU2PNfKM6u5sVCiMZKkgdCNNAMzYjCq64C0IwjdvTSXS1G67dt6h5o51aPG+fYS4uqpaYqN4kmE2zYYFwcr78OkSEZADQJOlt9ZzfUpCx2Tzd4sNr+j23+sP/rEJgAPqEQXcuRB21uVNtJ7wH64n3a+grC+QIDgdO/qju0KxV4snNeUtvJC4yLo5HQJhljYzUHSl1cwNBkArQJCitsfxS2zZSRTkIIO5I8EKKB3npLbX/8sYsvfvof3aZ2bvXixS6OpRFr0UJtDxxoXBx79kB4YDa+5hL8/T2p8JXyqygyONPgOBwjOVltz5qlOZCXBtG9YXwSXF2HrzVRs+ICyo2FtsbJKgcUYxfVmzZNbY8fZ/OzFRaLV2jaWW1bMwwLo7HQLtP44ouaA7qiLwGuCWbUBnTLwgLsfw22v1hpdyFE4yXJAyEaKFN7D+CKSsXRF6ntw7J2ltG0T4+q2+cKGRkQHpyFn7mkxr5uxRwJgL/Zy+fZ/jkBfugKf04EUx1+/drOUXD1k0nBJ5+o7a/mOngJXtEorV2rtnXLNJo0799tXFTbKKY3jE1SRkRpHXgNUpa5JgYhhEeQ5IEQjqSb4OykJwbD5yt/m4OgaQ9ZWslg2lEH5Vq1cn0cACUlEBqYg5/ZwyqbtbkdgB+2XmZwIA2nTRz5+dkczFwPFMHxH+txZk0C4cTGerxeNERurmZjy9Nq2yfKrq+3CQw0OgLvVFJVjjesKVyyB3q/Bn1cWHsirCVMTIOABP3+ozKMUQihkuSBEI7m3xQwQ4d7nHP+oCg4/0/o8TRkbobCU7rD3bqp7RkOXOFJ2KuqvoFxqwVYCQ3IwddcDNjeubqxXo9B96eYs+JmKqq9e6gumjIGC7TTxvNP2fWtk1hNYmWDUn1de1Nn1GiXRunIR2q737vGxeEi55yjto2s6dJobHsK0n+DNtdBQLBrr+0fCuMPQ0RfdV9bz1u5RwjhPJI8EMKRSvJg4jGYXAh9X6q5f33FnQfpf8LOV+Bv/ZOJnTvV9nPPOS8Eoa9vcN990K6duh0aat/fFQ4cb8+prGgITjQmgPrwD4OibM8bMVGJbE2B8gkTNAd2vKbZqEdiZ8iHajt3GwDvau5bR4yo+ymNNG2acT8jDacdVn6FcWE4gynCbtebb6rt2293YSyNkaUY9syCLdNg2YSa+zuD2Rcu2QiJ18M5r0DcUGPiEEK4JZPVKmOeq5OVlUVERASZmZmEh4cbHY5wQ+UzFUwmsCybBNn7oP0t0OUB5174y/IpEia4Vr/qgnb2hPyEO8fcuXDrrep2+b+zkf/2JpOVqJDT9Gm9iaWLTkH7610bQEN8aWLN3oHc/OE89qd39tjv2yr//7/0B8qSI12fg16P1/3k5T/z/s3hitTqr+fmdO+blur7ugPdv/MXmo1rPegfvTYOzYd/XoWIHjDgDfBTPveUf/0BAVBQYGB8XqTSn90TW+H3PmUbwXBtru3LGh35HC6Ee5GRB0I0gHaocFwccOw7yN4JWx90YRRW5WmFcClt4uDVV9V2mGZ1zvbtXRePwsKZ3Gh+3zUa2l3n6os3WOeEf2jTNMnoMOptoaZ+qfb7QFlSVfMz2uOR+l2gzc3QfDx0ewiKPHdlikGD1LYnJDy07/NRUUD8eCAIIvsbFJETtbkaOt8LYYmQuc/ucKGX1zR1lSqXaVz/L82BC1wWjxBC1JYkD4RoAO0N5HPPGvgp+MQm3ab2w8jcuS6OpRGYPVu//aAmV5SVpbYPHnRNPOUC/QqICTtJiH+GTfFOzxDkX0BE2XKNnvh9e9VVanvPHs2B7CP6jrarJ9TWoDnQ4lLIPQxnttbvHG5g/Xr9trvXa9Auqff6C8kw5GOYnANj1hkXlLOYTLD+btj5DKycaHQ0XmvSJLX9/vuaA9ma3+WDNbU1hBDCTUjyQIgGWLFCbd9yXYbmiAtu3EI0a3KvuUl3aMsWtS1zVB1v+nS1/d139se194ajRzs/nnLndV7Oi5Mf5ZN/TXXdRR0o0K+Q8CDPTR5oq6cnaAuWH/hUbZuj638Bkwk23AX73oCVyt1HlKbYv6cWs3P9CJ260S6pd2PUIGW5zX9eq9tym57EWjZUviDZ2Di82ObNantCVaUNQpq5JBYhhKgLL/3NJ4Rr6IZw7vpAbYd0cv7Fhy1S2wX7dYe0Ny7FMqPBoaZN029X9sHviOZB82+/OTcerfgmxwgLzKZNrGcO/TeZICrkLGDz5N7TWfLV9uDPGniysh/okjMA/PKLemTMmAae2gUiI+33ufscejUpZIGiY1B0ArY9amRIwsNVukyjxbBleoQQotYkeSCEo+x/RW33eq3qfo4SZZOg8ISqY15AW3ncdvh1uQSbZbJdtWRmSEAeAP7mItdc0AmalCUPMj1sSr/2/1i76gYAPWZAzxcg9kJIdOAdfmkhAwaom2fOOO7UzuJp/69aPqbK7viEcJCc40ZHIIQQNZLkgRCOUqr55N5ilIsuqvkRTtePWQ4JUdueOpzZ3WjnPgO6Gzdb2sTCs886Jx6t1FQ1eRAckOP8CzpJZHAG4HkjZrT/xwcOaA6c3QWHPoaEy+DCpQ64kmZOzPEqslduyra2wbBhaltbRNFdDW6/Wt1ofk3VHb1JiTIsxN/f4Dgag9Rf1XZ4P+PiEEKIakjyQAhnqG9BtLpqpSlokHtMd2jZMrV94YWuCcfbzZ+vtlNSqu9rm1jQVuJ3hqeegpBAJWnQJPSUcy/mFEqdkAA/zx01UakVV8HWf8MvfWruWxuxl6nttbdW3c8NtWqltufMgZUr1e2qRvG4k5uGaaacDHzHuECczU8z1z5tFQAdOqi73L3ApceK0NQxGuSBRV+EEI2CJA+EcABfX4MuPPB1CIxTlnQK9C9bEk6hvXnNzjYgNi8zfLh+23ZqQmXmzFHbE51cuHz5cggLzMbsY6FpmAeOPGh6EQAL1l1pcCAOlre7rFHsmHUJh36itguV5Ty00yTcudBkqWZK9y23GBdHXaijtqyc312TkQ3y4vXm292ntnc+B8CsWeou2xFYom60yZf4eM2B+MFwVT6M2gAx3V0elxBC1IYkD4SoJ+1UgO7dgfjLwBQKkdWMZXc03wC4bC/EXwgnV0D2Ydddu5FZtUpt1zTqoJztDZIzn9ilploJCczD7FMM+DnvQs4ydB50fYzfd14IGLjsaT1oV9TQDsWnJFff0RHLZwbZr9agXfXlrrsafgln0C5vqk22BgWpbXdMfFxxRXnLQuuYo0aG4jrdNFVhzypLB2oLw27ahGiAyzSDh94pH8BitcIfo2HTAxBUi8y0EEIYRJIHQtTTDTeo7R+/z4ch82BypuvX/vYNhb+fgn9ehbX6Jfq0H9JlqGn9ddc8BPLxqd2og3K33aa2W7RwXEy2CgpMHEhvx7GzCRDU3HkXcpbgeMg/6Wl5A0C/ooZ2KD4Hv9FsOO/Xrfb70V1XLtAub3r4sNrer1koRvuz4i6Sy1YrTGiSrM5GixhiWDwuEaApmBPS2u5wfr7dLlEHO3ao7YqkTP5JOLEUDr0HazxkWI4QolGS5IEQ9XTwoNpOOP2Csvb3H6Md83SxLkwmoGye+OllukMffqi2+/d3XUjeZtcutV1ax9W0Pv7YsbFUzcpHf07l/d9vh27PuOqijpX0MZ/eeTMxoV5SdXyzZvi3IwvsBZVPQDdqvlTDaJMd2rYjZnU4S6lFU8fm3PlVd/QWLSdD8wnQ8wmjI/E6lf4O2f6i2i7wxJo1QojGQpIHQtST7gPAnueVtb9P/O76QGyTFSXqYyHtsPm0NBfF42Waax7i17fieK9eajswsEHhVMPC2dxodqScAx1uqLm7m+rTZgsJTY7V3NHdWa2AptjIoPcdd+7zf4ZOD0CPJ+HEypr7G0w7rSM2tvq+7jpC6lR2DCROhsi+ENHS6HCcr89LENUDcg8ZHUnjcOg9td3rBePiEEKIGkjyQAiHqOPjaGc6/KPREXgVbdKlsLB+59i6teHnqEmgXz5Nw08Q6Jfr+tEvDhTkX0CT0LNGh1FrnTqp7fs0Aw0oztN3DAx13EUj2kOrayDjH9ir3HRoay1Mm1bF6wyindZxvJJBJU9oHm5rE23uw0qJxVe5qbukkUz4//s52PkMbP8PWNzo95vX0sw3SpDlkYQQ7kuSB0J4g2jNo70N+roHHnwfabhoTW26kJCq+9VGTIzabtas6n71dXHPX3jh6keZfd2Djj+5CwX4FhIRnGF0GLW2b5/afuMNzYGz2kfoAY6/8MoJkPwlJM+H0kJdrYV3PGwVQW0l/1NuOGI7LCiD92/9F/zQ0+hQXCdNk/E5e7DqfqLhbOfr+MhHcyGE+5J3KCEarMToAGD4V5qNTN2he+9V2717uyYcb3HmjNrOaeDqhydPqu0TJxp2rsokRqcQFphDQhM3HfddS4F+BUQEecHaoiERQFnmrudLjj9/wWm1fWK97lBd63I4k3baj24lCg9QvkJE39abuW7oArBmQ6kbvN+7QvRgtf33UwD4eeAiLu5GOy2nZfnsl6IsQ2IRQoj6kOSBEA0UHqIdnuy0Ce3VC2qi39YMM9U+Dd22zTXheIPgYLWtHTXQENqaCYMGOeac5YIDlO9Dk8mNq87VQqBfAWGByofphQsNDqYG2hsBs6aeHlaL8jN5VT6M+Bm63mv32gaL1Yw2WnOr48/vINppP7qVKEqLoEDNqLVrpx66xoG1JRtCGRFh5ZzE7YQGltWSMXtmkco60867T18MQJs26i53rU3h7rTLNH77bVnj4HfqTp8ol8YjhBB1JckDIepBu2b5E1e+rm7EjXV9MBU0iYsTO6ruJmpFuxyZdtRAQ2jrHaxfX3W/+gj2L0timSyOPbGLBfgWEBakDPN434E1Bp2hp2YU+0cfaQ5kHoSfe8P2mRA/yjnDkIdqlvEoVIaVu9to52pvMA/9H2x+GDJ2A3DggHpovpssZpBZNoirZ+J2YwMxQmQrzYby3vKiZkGAW903X+XWtMs0DhhQ1kjVLOl6zosIIYQ7c7OPGkJ4Bu2HqDuGaTb6veb6YMr10lzbr57LAghAP0KgpRMLq0+Z4rhzBformQmzOxXvrAezGfx9la/F3UfKaKe1aFc2Yd3tkL0b/nkRTh6we51DBEXrt61WXQzaFQ6M0rat2n71Vc2B4mzYOBWOzIOVk5WRGm4q0C+PNrFJyoZPk+o7e7kJE9T2X38ZF4cnq3RKUaepVCT/O0pWRgjh3iR5IEQ9aIt6hQVqKhKGt3B9MOU6/Qs6TINuM+H0crAUVxwaNUrtNm6cyyPzKKmpUKz+03H0qGPPn5Kitj/5xHHnDfBTbrjLb7w9UoiydMH/Nk4CICPDwFga4syfajs40jXXLM7mY81gBO0KB0YpKlLbD2rreP6jGaaRswNObQD0Uz82bHBubLV1TuLfhJfX4Oj7rrHBuJHcXKMj8CLxF8DkXLgy22b+kxBCuB9JHgjRUP3fgpB2ENLB2DjMZuj3OhRlw96P4PjGikNLlqjdFi82IDYPoh1p4Ixl4xIS9Ntz5zb8nHPnWAnyV+ZZNAlxw3L1tTViIXR9jF0p3QCr7ubT3WhvboOCNAdKbYIOc8LSGuV8m6rt3e9V3c8A2noVdtMpdjyk3/5zAlitfKMZve0uxRW7t9xJeFBZQbu2VxobjPA+Jfnw4znw+/n2y7sKIYQbkuSBEA1ihWbDYcxGuHyv0cFATjbsnw3Z22DNjUZH43FSU/WrZm3d6pzrfKepj+WIucNvvmXiQFp7Dh5vS7vWHrxSQWgbyE4yOopaGT5cbS9frjmQvsZ1QWifhKcsct11a2HiRLW9dq3tUZtpCiXpUJSjGxbvLomj6NDThAeVFT9obE+F/ZyY+GrkKpZQProE8g/DqRWw7UkjQxJCiFqR5IEQDVIKP/aAH7pD9hGjg4FAzSPQQv3a3AGapea7d3dRPB6mhWbWiXaqh6Npb5Kg4UO0k5Lgo+VTee/3O2ky8KmGncxIqX9C8nxeu+4B/MzuPf1CW/yyovAZwNqb1HaEZrk7Z2hd9o1k8oc2VwP6eh3uUhFf9+9TlX0f19zHhcqnd32z/kr8TblgCjc2ICMMXQAJE6Hj/VB4usbuonran8eK3zWbNSuxBLVDCCHcnSQPhGiA+IijQCEUHoOD39TY3+lsF+IuzKhoFhSou3ftck04nsT2Rks71cMZnnhCbQ8c2LBz5eSUcjY3iuQzraCDBxfc8lWedA5ot5EmIWdq6OymijRFMoZ97dxrmc0w8nfo8RRYsqC0kOefVw8bVTRRWwg0LKySDkO/gbDuEDVC3RccDyW5XH65usvIJOevvyp/HznViibn/gcudIMiEq7WfAS0HAcmM2TIL42G0v48VizTWKwpgtPtbpfGI4QQ9SHJAyHqSHuTOXWkpvBX7FDXB1MpzY/17nf0RzSH3KEauzvRjjqYPNn511PWkFc15ClxsN9ZmoafIMg/VzMe1gPF9gDA36+IaDdOHmiXao2N1RzQznkB1xRQbToCjq+E3W/C8XW6woRGJQm1hUD37NEcOLlRWZ4xoiuM3QGj/4SYc6HHC2DNhX3v8P136pAOI5OcRUVgMpVisZqh/e3QtIEZPk+17jbYOxtWKKNcGtvMDUf65x+1XeloHP9gl8UihBD1JckDIerorrvU9m3na4baxg9yfTCVaat5erHnGd0h7coB7lCN3V3YThv46ivXXFc7NaJVq6r71eSKAf/jhasfZeZED56yABUjZ/zNRUSFnjU4mKo9/LDa3rJFc0CXuHHRr9ecLDi+BEpPw9rbXHPNOtAVCF15Jex9BX7urWybTHDRCuj2EKT+BttmwJFFRoRZiVLuG/UmL1z9CCyfWHN3r1VS9peSzGveXD3iLtNiPIXdMo22xVWFEMIDSPJAiDpaulRtJ0ZrKtvblRQ3SL9XNBv6Dye2lf61w4sbM+20gfvuc911tVMjKl3/u5YSY5IJC8yhaZgHr7Sg4e9bRERwhtFhVMmiqfdn+zNF1LlAAHS0WVHAWUI08wJs6pwYoVMntd2tm+ZAcQ4UlteFKYKSsvVQTT5wah+kfq3sX3cjkZH5FS/TjvJwJZPJSq/W27j4nN/gzGZjgnBDTz+ttqdPNy4Or3Dqb82GX5XdhBDCnbjJ3Y4QniM/v+Y+hvIN0G+Xf0gvk6KZYqkdXtxY2S6V+MYbrr1+O02NrPB61mQL8lcKWpRYvWNMcYBfIeHBmUaHUTdWK5zZBuf/ANfkQ98XXHNd2zonVquuzoCrnw7v26e2d+7UHDg0X9/RVxN3mHZ6RxG7f1hQsWXUDWrHZnsJ9s8jNDAbmk+o+QWNxC23qO1ffjEuDq+wSTPHKL4xj24RQngSSR4IUW8NeFTsbGbNROzM47pDtk9KjXqy5y60SyW++mo9T5KbDCW56rbVUnVfGwcOqO3seq6yGOCrjDApKfGt3wncjL+5kIgg91xy8ppr1HavXpoD+cfh1/7wQxc4u9u42hMFJ/n9d3WzTx/XXbraRMVmzXyv4M76Y0FhaD+OxB+9DSPfX1NToXtLJfMR6JcHA9+t4RXeTPN9XJynO5LpYfk9d1Hx1lCQrO4c+LYhsQghRF1J8kCIejL7aNZqc7f1sM/9GjCDfyyY7G/C1q9X24156Klt4kRbbK7WSovgj0thUWc4vRVK8uHAB5Cxs+bXlgkJUdvaYd+1FeCnfC+WWLxj5IGfbzFmnxKjw6jUfM0D9K1bNQc2PwmUQGE67K5vFqqefDXJwq3P6oqxnTjhujC037u3acsv5B4DNCOgLvzD/sVDvtNsWAjyz6nYcvXoifPPL6Zz8334mKw0DTkBQY1wmcZyAYlq+/CvxsXh4bR1ddq2LWv0fw0CW4A5AoJjDIlLCCHqSpIHQtRTWKCmoFvnGcYFUpmEEXDRauh0jzKXuET/xMi20vPChS6MzY1oEyfffVd1v2ql/AA5O6AoBZYMg9PrYPuLsPJ6SFtaq1EIOep9km7Yd235m5Ubs6ISL5g36xvD8axoftg6FvCgomzJmuKpsRe59tp9NU/GD3/o2mtr5GoG33ys+edg0yP6jqHNsdN6HNp53xue7QUoPzu62gkukHSwmNZNkwj0yycgwFrzC7xZp8fV9p7njIvDw91wg9r+8kvAUgpR58Dl++Aq9y0OK4QQtiR5IEQ9FZZEQNwoCG4Hnd2w8mBEbzjwKex4Bg5/b3d4zhy1PbERTrecNk2/PaE+05qLzsJfmnHs5EPaaig8Cjl/w8rJcHCeMhqhBvVeRtNqVUcelHrBW/p5i0gNvInk08ryEx4xMsZSCmhuMttd7drrtx6v2SisqpdT2a5YopP6udpuXc2KEOepFUS7JxzGx6RMXXD18PiOzfYSHpRNoF8BRAx27cXdTaeb1HbOnqr7iWppp6cNGABkHITF3eDHHpB/2rC4hBCirrzgk6YQrqP9gNyubSEMeA/G7gK/gKpfZJTs45B/ELDAhjvtDmsLX0ENH/690Jtvqm3tNI462fESuuHYnR6Hg5oKjKVnYMMU2PUiFJys9lT1XkbTZOKfY53Yn96erPywmvu7u5BWjOmznfKb8b/+MjYcrd691fbkyZoDWfv1Hc0unj5SyfXi49W2K0YWDdKsVFvtKJ6B71V9rPlIQF3rvkfClqr7OlHL6BSOnk4kpzAEzv3SkBjchvZ3W0Qvw8LwdBbbAWgbHwAKIO8gHG9kv3yFEB5NkgdC1IG2uN5vd3aBxV3h72eMC6g64Zq7BzKVavA2tMsSapcr9HbaondgP42jVrIPwt6XNDt8oe8s6G07tNcKu55RKmvnHqEqtoUsZ9RyJsyGDfDe73fx1pJ7SSkeVrsXubNND0DyfB4b+zxg5WT1OReX2rZNbX/1lebAak0mzk+7coALRQ0B3wiIuwyKc9i4UT2kHTLtLNq3F7tRPIk3AGbwiwVzDVNrLlpV0eze+TjlSaRx4xwSZq2s2X8ub/56L3/sHAkRrV13YXfV+XFoext0VX5huMuqxB7ttKZ+RBMXz8sRQogGkF8BQtTB3r3lLQvxMSeBQvjnFQMjqobtEm55aXZdbJcl9Jj55Q2kLXqnXbqy1iylsPom/b7zykrct70Gzq3kUe/Rz+Dv6r9XtCMgnn22dqE891wJZ3KjOZ4Vz/gpLp5r7ww5xwAY0nEtPqZSCo0ZhV83WevU9rD/GRPDBb9C/7chug+c3aJLRmlrETiDNtEVoB2EVZIHx1fBoPfh6jwYu9futXaa9oFuM+HchXz+VhJK8sDK4sWOjblKpUVkFUSQfKYV89df56KLurlOd0JAFJxVRoI0c7P6wJ5Js5pIZCvjwhBCiDqS5IEQdVBSUQBe+xTfnYvUBarNjf+ptMfll6vtli2dHI4bGD5cv237xL9WSorgrGY8vX8CNB+hbieOh0sPgo9NlfbD76hti/1qAvUpZHlk515iw48T5J/LhIkGLQ/oSM2Vb0h/3yLCAjMrGzBjCG1irdpVGOPqM4zFAfzCIHmxMkVmpWtrLmgTXQcPag4cWQR/DIefekNJKQRG1u6E5zyl/Awlfc3kQV/i7+u6DNL/XptL0/ATgJUu58TW2L9RWH8f7HlFSZRbinUraUxxw3I/7sxkotJRgEII4SkkeSBEPSREaCaot5xcdUej9dGsHX1sXqVdvtfUUmwMn2lWqaOi6zfqALB7HH7JNvs+EW1hUjqE9dTvLy6AM1tg//tQaF8o61XNKn+1KWQ5/pzPeOHqx3h07Is1d/YEHZQ7Ez/fYqJDzxgcjKpPH7X9SpUDSAxO3qR8AxRBUbphP8y6ZNz6srvM3H1w5kCl/auUkw1n1/D81f/hknN+Biwuqd2Qtn0jL1z9GA9f9pJ+akpjlvG32j6xg1mz1M3GulJPXWjrCXXoAOTajwIUQghPIckDIephSKc16kYfN75p63Bzrbr16qW2bWc7eJPu3dW2j089Rx0ABIVCQNkwjYQrq16j2y8ILtsGbW5XttvfBz5mSP4BNk+HTQ/bFdt78EH9KWqaStI88gShgTmEB2XX/etwR6HRAPiZi4lyo+TBiRNq2/b/iJFLoeUk6P0ObqPghO7nurY1NOpKWyhRN3Ip/zhQoG6H1/GHLUgpnJgYfZRxfb8n0K+AK6+sd5i1Y7XSrMlpwgJzCAvMqf/7g7eJH6u2tz6qO3RWVhmskbbmyGefAds0dZKC2rs8HiGEaAhJHghRD+d2XK1uhDQ1LpCa2FZhLyqqtNvWrWq7xH40vdfYtUtta1c3qLX8NNj6JBSfgolHYPgPcG4NjydNJhj8PlyyC/q+pBSM2/UsUAhH5sBft8KJVbonxdpK/i1qqL/n56us9lBS6uIK/07m71tEZHCG0WHU7J83oLQQBv8fdLFf1cSlfDWT0bc+x48/qpsvvWTf3RG0dTp0P1ObZ+o7hkTV7cRmMwS0xmyGtrGHuLzPIkpLS2t+XUMUnCAsSCkQcSKzioRgY9TzCbV9dqXuUGMYrdZQ+zX54QEDgOQv1B39PnB5PEII0RCSPBCiHvq22Wx0CLUXqqnkbCmuspv2qWFoqBPjMUhiotr286vHqAOrFdb/G/bMgkWdoSgXWlxW+2X5IruCObDs07YmQ3N2NayYDIfnQ6mS3KnLcGlfs3JDVVAcWENPz+JnLiYiONPoMAD9sGN/f82BokzYcj+svAw2PuzqsOz11SyDePh93fd4cdU/+o5ntcDR99Xt+Kvqd54xypIRzSLTufic3wgNyHbu3erWWQT5KaMl9qfJE+EKIdpEiidUMHUvdt+yPpo3kRYjXRqLEEI0lCQPhKiluXPVdofmdZy/a6QRiyG0PSReD2fWVtlN+9TQ2dXZjZCcrLarGIBRvbPb4dgCpW3NhDP7q+9fFZMJIgfp9xUfg7U3wZ7/VhRS1A45D6wmL+BnVvrnFwVU3ckDmU0lBPjV5z/K8c47T21ra2bwzxy1nfy1q8KpWhvteobOzxZER6ttbeFVzu7Sdzz30/pdIDgGQnvQIiqZ0MAcJvRfRKtW+fU7V20c/pD84kCy8sPZdLi3864jGrchn0HUudCkfw3VV4UQwv1I8kCIWnpUM9UzMqh8omewIbHUSURbGLMVwtvBka+hsOpJqhERatubluPS3uSEhNTjBKVFsNxm8fqIBiyvNWYNtLrBZmcxbH8ETirLoWmnklS3XKHZp3zkQVD943E3pmD+2D2SZbvc46lcvuZ+Vbcixs7H1HbiNS6Lp0o+9r/SnXlvckZTkkJbeJW/NOX48QO/BoyKGbWakIBCwoMyubD7HxRlnaz/uWpUTH5xMEdOJZJvjXfidUSjVZwDQdEwfAGM2VBzfyGEcDOSPBCilk5qPrP693oKmo6EQXOqfoE7yToGO5+GpI9g5+wqu2VkqG1tgThPp73JycmpxwlSfoCCJHU7ciAE13EOt5bJBEP/D/p/bH9szbXK36UFxMSo410rTeZYrRUjD3IKPCCRVVvDFvDO0rtIz2xudCRVs1rRDeHu97JhoehpptHknmWsptbdNQ7Mb1RbyDN7k9ru837V/WojMBwihxDoV0BGbiTNI4837HxVsVo5nR1GcYkfB46357bbvKuGiKPJA/O68/EBdn8Mvw2CH7vXcwicEEIYS5IHQtSSOm/RAgmXwLD50Na166nXW6FmCPPe5yH9zyrnDgdoRr9rVyfwVMGae+qo+tzvF52Fv2zuukataFBMFTrcBqO2AZpRA6HtlJEOh+ZxctP/AAtQRTLHZOLAiXbsT2/vXQXeghPxM1uMjgLQT1fSff/k2Sy35usm00biNFMXck7rRgQsWOC4y7TSDLyZY5tDDdesa9n51oZf7KI/yM4L5O2ld7M9uRcvPLZbqavgYPvSOrI7pSt7UrvwxhsOP71nC2xX1lCyBtrRXKJq2nop7dsDu2YqGyVnwSLJAyGE55HkgRB11KvVRvhtICw5z+hQai+us2bDCiuuguRFlX4AL9CsrrZrl91hj6Mdcn76dD1OsOdtdPPHOz3h2BvFmHNg0nEIagOmYBj4NuQdhV2z4a+baBJ6GlASPYMG2b/8jV/v560l97LlaB/7g55qxZV8N20c/xqpVCKvablKZ5o6VW1v3645sEFTINEU5rJ4ajT4IwhqBXGXgo/+G96RtQa1Cx/ccovmQHEWXLoRRvwMAyoZWVMffoH0u+kx9qd3pMTixzOzE+DMFsecu5zJxCPzX+Td3+9i77GOjj23Nzh/MbS7Hbo8BvnpXHuteshZy4B6A+2/07JlAJoisH5eNNVMCNFoSPJAiDqaOvITpZG7x9hA6sLHZghu6SlYfR0kfVbpHYV26vTo0U6OzYm0lfF1a9DXxa7nNBu+0HdWQ0KqXEAYjDsAl+2E8A5wNgnyDgB5nPkgFmX0gVW3LB4AlhJSzrTgeFZzTud3cHxcRslPpV2zw/RvtxGw8rKBMwK0N8m6FTrSvlTb/TSrHBgtKAou+hNi+sKxn5yyOoF2NIZusZGCk/BTX9hwNzQbCe1vs3ttfcX1PB/wITzoLP8a+Qn8OQksDly6MfMfVu0dycnsWApK6lMYxctFdoWoPlBwHE6t143M+PBD48Jyd4cOqW27FX5qu1KPEEK4EUkeCFEnVrq32G10EPUzwLbieT6smwr5p+y6alde+O0354blLKmp+uXpdGvQ14WfZnzuyGUNiqlaPj4Q1kZpn9CvivHOzXfiay4GLEyZot4Mpq16l9jw4wT555KQ4EWTkP1i8DWXEhqYA1j59VejA6qM5qa8nRsUS9RK/gV2PgO7ZkHBCXx9HXv6WzUzEY4c0Rz4+wUl6XXwPdjp+IyPyWTlluHzOLfzGopzj8KJNY45cWkB/NSbjnF78TMXUT40X9jYeAckfQKr9N/vp+x/hYgyutxdSZ5hcQghhKNI8kCIOmrdNKnmTu6o/Y0wdKHNzmLY8oTS1HzKsX1CMmWKc0NzBu1Ig27d6nGC/DTlyeZl2yBqqLK8YvwwR4VXva53AuqwiTsu+IinJjxNRHAGn3yiPm09vvpdXrj6cR4cM5urrnJNaC4RNxIfHwj0KyDQL8+waQvTpqntjrYj2YPblzXMla5yYKiUn9X2lmd0K8VUNvWlISreK6wWOPi6esDq+Keqn3xiYntyTyxWE8ez42H5xIqlTRvk6O9AAc9dNYNWMYcbfj6vVf47Qr9cpsU9ypO4v6Qf1LYp1Lg4hBCiAdzsE48Q7qn85tnXXERseNmyCwH1HQdvoFbj4aLN6H70g5tCcTYc/Bjy1Lu0lBS1yyefuCxCh0hN1T/x2bmzjicoyYUlI+G385SbootXK8srukpwU5iYDgEtAOXedEL/73h60kzaxR5k7sfKDVNucTChgTkE+BVwxx2uC8/pOj4AgJ+5hOjQ07q6Fa705ptqe+9ezYHSQhi3Dy7dB6M2ujyuGrW/S20f+YhZmpk2dlNf6micph5jjLZGZ+Y+fceu9zfsQpW45RbYktSLg+ntSc+IB8spSFve8BOvn4rFAsWlfqScTiA2tuGnFMLOln+r7Q7/rrqfEEK4MUkeCFEL8+crf7eKTiLQv2wsfOenjQuoIZr2gbFJ4BMK/vHQ6S5I/0MZcrz+TshSbgJsRx/MrnqFR7fTooXaHlafwQL7PoW8vXBmtZJAANevTRbYBMYfhmaXAtAxfi+tYo4w7eK3uONO5W66uEQpuFVYEmA/n9aTxXQFwNdcTFToGfd7srl8IqwYDyVZENPb6GjstbpYs1FcZbf6WLxYbWuXr2XVTZoNMwQ4p25AZn4UP269jBOZZXf4K65QVidpCEs6OYWhJJ9uQUFJMO83cHXJRsEJtTS8mdkMlGpWaOn5mGGxCCFEQ0jyQIhayM1V/u6aoCmS2PlGY4JxhLBEmHAMxqyHkOaQ9DUUJkHaD7DqBjizGdA/pZw+3aBY60i7NBbAypV1PEF+Gmy7W7OdUnVfZzOb4YIf4ZyX8DNbCQ3IZvnu8yguCWbzn3sosfgpIRZ5WdXuskJifuZiIoMzjI3FVkk+HP8Zji2GP0YZHU3lbKdRlBY693qlhZCt+cHr6bxM47BhPmw81I9NSf3Izg8GMiG7AT+jFiW5kpEXSdLJtoAPEyY4JFQvpJmKUpxjXBgeQvu7qHNnwCdc3eHvZe/ZQohGQ5IHQtRBl+b/qBueXik5IAxCyqZepCxS92dugOVXQ/oyBvTXP11aaFsywc2kpsLAger25Ml1PIHVCutthpP2f7vBcTVYt4fh/JU0a5LOkh2jsOLDoAtbERWSAUB+UaCx8TmJCSvBAcbMWRg+XG2P0uYIji5V2yWaZdfcjub96dgqgjT3KvWtIZGYqLa1P2cc+0Pfseu99btALaxcCSWWABZtupyjp1opO5ddVP8TnvwbgKy8cHandnFAhF4suJ3a3j/fuDg8xBVXqO0lS4AL/1CWu2x/d5WvEUIIdyfJAyHqYFeKl3647HiPfrvgIKy4Co4uZI6mQN/EiS6Oq4600xUAvvqqjic4ux2OLVC3TWHQ/qaq+7tS3DB63L+R3MIQwESHuEP4mpXaBzmF3lh8y8wXf13LpkP9XX7lGTNg1Sp1e8kSzcH1muUHYy50WUx1FqcpTrDl33zxhbo5eHD9TpmcrLbXrdMc2PKQ2vaNcUkBye1He7Hin7I5SdYGTM1YpywdkZkfzvYjPR0QmRfrqlm2dv9/iYgwLhRPoK0blBB5FHKToPP9MMANEtJCCFFPkjwQog5W7zsXOt4L57xkdCiO1e9laG+TQCg9DX9dzy3X6Z+u2k4LcBe2JQnqPCW3tAiW24xXHrOlQTE5nH8Io0YpT5RNWDmQ3oFSiw8pZ+INDswJBn/K/LVXcTonpua+DjR7Njz7rLodaDuow6pZl27YF7itwR+r7dw9uqH42iRAbVU7WkH7wzdySdX9HCQoCEqtfry4+HGOnGkP3R+Ho/9TCp3WVe4OAI6eakVGfhMHR+pl2mm+ifIOM2aMuulJNXFcRfc7aNUt8NdV8JMb1kgRQog6kOSBELVmpaAkENpNUYaRe5sBb0GvN2125sOPfbjvPnWPbriym2hw4gAg/wwUaJbhjBwIke2r7m+Q8qfge9M78cQ3s3hn6V1sPuj6p/NOFxhPQbFrp2PMnq2v7REQgH6lh8Kz+hcERbskrnoJ0twIBzf8+7idZsT6E0/YHByxGOIuh5DOSkFWJ9u/X/k7+UwiXR7cpox0OPgZHPiyHmdTvse+3zwW8PH42WhOpf3HiRvBq6+qm2+84fpwPMqZZWWNAik2KYTwaJI8EKIG5U/cmoSc5vv7x8Iv/YwNyJm63gvDftDvK84s+2BYSvk63/WdM+0MDkkcAJzYrN8etaKeJ3K+li2h1OLPP8e6sO7AEDILXPt03iVWTuSzu27gmsGfu+RytokDf38oKLDptFs73NjXFWE1TPdnoO1U6HwXFJ5p0KkKNTUXK5Z+tFph29OQsxdGfA3j9lT6WkdTVxYxkV8UAlsegbTvYcvtyrKzdXHBErbnXsv3m5Wn6j16ODRU79PnTej0ILS9UbfCy7FjxoXkcVy9co8QQjiQJA+EqMGkScrfneP3cEGPFUCxdz85aHkZjNpKRcG1LtMgaz93Xf4dSvLAaldbwCi2U6tTGrIwQlxfIEBpd3oCfAMacDLnOnpU+duKmdKyFRe8Tmkmgzusp19b508dmTtXnzjw89PfLFfYo5mu1MkDRh/1nAFRveH0Jji+mhhNjqku04+0hVJ19z05SbB7Jqy4BLYbN5WrqCCjrGWFvR/U/oWnNkJJLmNmfEBBcTAAP/7o8PC8S4vLoCgTUn/W7S4traK/wFxWm0YIIbyBJA+EqMGWsnuXjvH78TWXJQ28/clBTC+4/DD0fAl6PAE+Ybxz9VX8Z9wsfM3FgMXgAJUnw9ocTkoKuidhtZZ9EPa+D/7hcHU29H0P+s6q+XUGCwkxOgJn8yHIv4CQgFzKR7w4w9y5cOut6ravLxQVVdVbU5iv10ynxeRQm+6CI5/B6uvYtk3dPaoOq0xqC6XqCiWu0vzDHdLUWHAB7VSqT1feoG5sfwiKztq/oDJ/jIYVl9AxanXFrnq9hzQma/8FSR8r31POXgLUg2kTbv16ntAckXkxQgjPJskDIWpQXHa/0CFuv7GBuFpoC+j+MPj4wpYHAXjosleZfskrBPnnExyYZ1ho4eHq/wvAd9/V80O/pRRW3wSb74SfB4DZDzrd4bA4nSlHs8z6sGHGxeE05ggC/AoJ9s/DWcmDhQv1iQOzWf99Zaf3S+DXVPlj9rQRHzm6n5HMeq4yOWBAWaO0CDI0U3vaufbnRjvH/r7PbKrXb3+VGlmtUKokGa4bsqCGzqJCzhG1fWy9cXG4uWnT1PYPD9+obkSd6/pghBDCgSR5IEStWGnb9JDRQRgn/hIAIoJzuKTXzzx++XME+2ZD2u8un8LRvDlka6Y1v/oqukrydXJ8JZz9S2nn7ILC/Or7u5mUFOXPypVGR+IE4ecQ6JtPgF8hZp8Sh1dzX7hQ/0TdxwdKqhtdnHMEEifApDS4It2xwbhKPZ4UT5mitnWjXdJW6zv2eKR+MTlAQXE4oAlu3/NQcKrK/sqL1KfBe4556RK8ztDyGrX992PGxeHmtCuaNLUsVzcGznF5LEII4UiSPBCiVqy0jCn/NOBpTxwdoP21FevGd03YTcf4/Twx4XmuHJ8KGbtdFkbv3pCWpm7fdhs8+GA9T1aSC8sn6vf5eUARPI2EBC8eZt3ubvx9izGZrDQJOcPnDqybaJs4MJlqMWd7yQj4vgtsuBNMnvSrUzNMOrXuWaZPPlHbe/dqDqy+Sm2bIjBimYKWLdX2A39u0h9M+qn6F29V1+NctmukA6Pyct0fUttZG42Lw6No3lyatDUuDCGEcABP+gQkhGHCArKICTutbER74xjxGphMcP4i6HA/0WEZhATk0LzJMa4a9AP8dr5LQhg3Drs52x83ZJr1vnlgzVC3E64Cn0aYGHJXrS/Fxwd8fUqIDjlNUlLNL6mNDRvsEweWmkp4WIqh8AiQD4c+ckwgrhKnGZazYQodO6qbc+fW7VQViaqiTLCcVg+M+KXe4TVEeeFQgNc/7gxmzdKZW6dW/+LDamHFnSk9AQh07cqgnikwVLNRTFiYYZF4Dh/5RxJCeA9JHghRCy2iUwgNKJtk3vddY4MxUv/Xoc87mExFpGfGYbXCxr3Nlbuv0sK6L5NWS9OmweLF6nbHjrBkSQNOmJ8G2+7R7zu3PmvEC6fxDwLAajURGpirq/FQXxs2wMCB+n01Jg4ATm5r+MWNMliT7Cg6yrJl6uadd1b/0u7d1Xa3bpoDKX/qOzYfXO/wHGqM5km4f9MaplQpxS2ycoMpsfgDcN11TozNS43UDNqoazKq0bh8HwyYA4M+MzoSIYRoMEkeCFGN8orJKWdakltQtnRfTCfjAnIHne/ikmkPsXjTZWw4OIAHv3xVeTJ7ZAHse6/mucZ1NHcuvPmmuh0bazN8uj422szPHjDPkGHXoiYmPlz2L/ald2zwUnCVJQ5qXa5jzS1qO6RrwwJxtaBI3aZ2mkuly1Fq7Nqltnfu1BxI+kptR9j8o7qY9sd2wz9tIPpcCOsKvZ+F/e9BXiXrtxarxV43JfUBlNVzGjSSqZF6V5NLf+454+JwVwF+eZA0D8I7QdvrjQ5HCCEazLMm+ArhYuUVk3MKQmkyfCaEJFfbv9FIuJhd6WlsPtyfjLxIunbLZfdbn8Gp3yFjD/R6GkISG3yZDRv01fCDguD48QafFlK0T4BCof1NDjipcLh+b/PHzvMpsfo36DQNShwA5Gvuos/9tkGxeIrU1GoO9pgGJ38BSzac/7PLYqrMN9+o01CGD4eC3D/AWgqpP8Du/8KxVXDeV/oXZakJzu/W17faqgB9MurIkar7NSbaZRpfvOYB+PsDwAeubWAGVAgh3ICMPBCiGikpAFasmIhtHgGd61udz/uknY4nIy8S8OGffUFK4gDgyDxYdydk7mnQ+VNT9Td8ZjPkOWx1SE3e9JKtjjqpcLSAWEqsDctx234fQR0TByU233TRHliZP7y38rc5pPp+Gl00X+Ztt2kOnN0OYe3g6kwYlwxBUY6JsZ60K60UFgJmf/ANgjU3QvZ2ODYfsg7qX2RSl9VYsOEqRB1F9FP+NumTetWuVtKI3H232r7zvPLaGrWZHyWEEO5PkgdCVKP8JuOxy5+HVeNh92uGxuNuzGblLcSKiUPHNY+gjv8MK6+DUxvqdd7UVGjRQr/PIR9MC08r/6kX/QX+cRB1HkS2d8CJhVP8dS2vXPsgl/X+vl4vr+z7qM4riybV79puZeRi6PkidPsPpP3GqFHqIe1SjFra5VArhvNbiuGXIbCwAxz8DEJaVPpat2DVzMlYfbP+P75JG7hkN3SfyamceJeH5vFGfAtdH4ceT0KujMazpa4IZCUgwMhIhBDC8SR5IEQN/MyFjOlVVk08/Q9jg3Ez6jBVH8a+arM0WvZWWHElnFhV5/M2+IavMkVn4bcRsP52aNITJh2DUb874MTCeYoZ0WUVvVttq/MrHZI4ANg5U23Hjq/HCdxASAtoOhTSl8GO53XFRufNs+++oaqcX/paIBfIhg3/cnyc9XT55Wq7d9kgC8IHqDszVkPmP0q7tADW3AQnV0K3x9EtZSlqJ7QV+EcpyeFjDalc6+0c8YtLCCHciyQPhKhBq5jDhAWWPYZrf6+xwbgZdb6rid3HevLZlmn6DoVHYdXNUFo2bKAkr8Y7OJNJv+2QxAHAjpcge5ey1N66O5QL+ciNg7sL9CskNLBuSy04LHEAENREbQ/14HLyK8bBid/h1AplZZQylRWiHDRIbX/3nebA6slq26f2UyCc7XvN4JCK5VwvWqbvtGKy8k1w9Hc48hlsvINjaz+vOBwT4/Qwvcu26XBsMWysYcmORizQTzN8xy/OuECEEMKBJHkgRA3aND1MWPnNS6uxxgbjhlIqipmbuHH2f6HTQ/oOhYfgTNnQ1kOfwu5X4divkHsErPp5oE5LHGQfhL0vqdunN1bdV7gVf98iQgJqX+zCoYkDgOHfQ9f/QMJ4u5ULPIq2dkPKimq7av+9KmoKFGdDSZp6YNjXjovNGQJCIPYCdTt3O2Tu1Y2YeOrFiIr2yy+7MjhvIoUOqnJRN83Itt5vGBeIEEI4kCQPhKhBYnSymjyQ5fzsaKttA8xe/jL0+0C/01yiDBf++0n4+2H46wbYMA12PgcpiyFrHyaT/kNoSiUrrNWLpRRW2aymMOA9B51cOFcwAb6FBAfkUZuCYw5PHBxfCamLoN0tMGJhjd3dWtxlanvDlCrfymbMUNv+2np4e/9P3zHhAtxJWJjanj27rHGezVSqdXdCqZoA+fz3iyvat9yCqKegIKMjcE+TBmpWZmkzybhAhBDCgSR5INxOtUuEuVD5Mo3xkWlEBGcYGou7W79ebU+fDnT8F4xYAvhCs1EQ1QHMgVBctkRa8SlI+x52PAmrrqdZyyC0b0cpKfZJiXo7vhIy/lK3/RMgfriDTi6cKjgRf99CgvzzMZmqTx44PHEAsOxy2HgH/NS75r7ubvBHars4WVcRfrjmx+HZZ9X2oUNlDasVtt+nHgjt4ZQQG2KPZnGX6dPLGr4BEK+5aTuzXPeagsJgp8fVGPTrp/6gLfTwHFtDab/+gW3XqRvy4EEI4SUkeSDcRmioMmy9RQv3+ADy6acAVppHpRLgV2x0OG5twAD99sKFQMIomJAC/d9UdlZxJ3foeBMeuux1rhq0gNDATNavh4SY05D0OZzZDMV1m++uU5ILyyfq912yrf7nE67VfAKBfgX4mCyEBmZX2c0piQOrBayZSttS9bU9hs2Uizf+q/4DraqipmlFAq8oC93Ijwvcr9BolcnG4fPVtlkKGziOX0Xrq3kZFW3tyJXG6I471HaLZuXvGzI0QwjhPSR5INyCyQS5uer2xIlV93WVzEwAqzplwSfSwGjc35w5arvi/y+oGYR3UtomE8Rfjra6efKpeDYdGkBidDI3nvsZ/3v5QyURkbkHNv4b1k6FLQ/DgU/g5BplxYS6OLkdrBnqdsKVECw3EB6j070E+BZSVOJPRFAmcyupV+iUxEFJPhz1giUaq1Nkn5TTjkCI165geHafvmNIrHNicqCKEWxmX+j+tPLeoy3yGN7fkLi8Rpg6+iQhS/3B3L/fiGDcx4kTajv0+jQYswPG1G/JYiGEcEeSPBCGSk21L5JX7pprXBtLVRasvVJpdJCVFqpjO2e40uXeRn4PV+XC4M95dvETjHh2Ja/8OJ2Nh/pxbscVjLq8o9IvPxNKTkHmVjj4nlLkbN1U2Pwg7H0HCk/XLqhDNneb535V569LGCgiHj9zAa//8m9OZsXaJQ8cnjiwlMDJtUptjr9uVPd7yxNrX01G4J837Q5rRyAcO6Z9XajabnOP4+NykFdfVds9e2oO9JgB5y2E4iPqvqFfVjSr+h0kqnGOpsLkwbcqmkVFBsTihsw+RbDuVsg5CE26Gx2OEEI4jCQPhGFmz7b/4K99ej1/Pm7AxB+7LoB+70GPx40Oxu098YTaHjiwik6+AQy/6TpmLJhF0sl2/H2kF51anyQiLhHiRyh99rxg8yILZO+GpLmw+R5Yr5mwnbW/0pUbAGh7vdoeME/mnXog/34vsPVIbwpLgnTz2sEJIw5K82HNLbD3VUDzZH7o51W+xKP01xQyTV9GQIC6WWWtmZI8iO4Mlx2E9nfBgNedGmJDPPig2j5zRnPAZAKT/uPOhv3tK9odOjg5MG+UcJ7aLjppWBju6soBC+DI57BqQs2dhRDCg0jyQBiid29NUasyVqvy9Fr7FKhZM9fGVZn84kCIuxD8A40Oxe3NmqXfruyGZMoU7RNOE916BjDl7Vdh7B7wj1R2t72t+gulLFDbhz6HDf/WrNywH85sg9RfoNlQGJ8O3Z+B9jdVeTrhxvxjsFqVN4XMTHW3w5b1LDiltouB3L32fVqMrufJ3UyrSwF/MIdB28m8p1l0RJuIGTVK85q1/4LfR0PRaRjwjjINwGOVL8kQzBVXqHuXLTMkGM9mNqN8hDRBotwg27q0189lLUetNyyEEO7BZLU6bCV1r5SVlUVERASZmZmEh4cbHY5XCAyEwkJ129cXim3qEWpvDIz6DjWZ4Pqhn3J5n0VcOWwDXOkmy0C4uWuu0Y8a0f7/zZ6tTxq1bAlHj1Zxosz9sO8tOPotFKbZH59c9k0zPwwoUNqmcGg6GM7ugOJj0OJ6GP5ZQ74cYbQvTfzn66f5a+9QVvxzAVargxIHRWchbSkc+griR0PnO6C0FBZob479of+70KGGZJYnObMdUr8Hawl0ewyTr31StOLfsyQXvi6fshAE1+a5LMz66t4ddu1S2pdfDt9rS1dkHoJds6DH05jCEyt2y6egejrytVKfJrQNpnbqNJ/G/O+pvDdZ2fZ8D85pVfaNeG0j/gdxAPkcLoR7kZEHwqVMJn3ioGNH+8QBQKymHpcRI82VJ+YWeiZu5/zuy5UbUVErX9mUFSgffbBwoT5xEBFRTeIAIKKDslLDpGMwIQ26PQXB7QATNBkCPr7Kn/LEAYA1C04sUf+/UrxkuHkjd16XlfRI3Ak4IHFQkg9pv8Hm6fDXTZC2CLbcqUx7MZshZhTK09Rr4Mqz3pU4AAjtDElfw86XIHl59X0Pfa3ZyHdiUI6zc6faXrzY5mBEWxgyF8ISEQ4Q0RPOboWD84yOxC2U12QxmSy0iimvrxFQZX8hhPBEnjz+UHiQygqb3XcfvPFG5f2PH1dvEiwWpfie7XKAzlRerDE2/CQRQZmAv+su7gUGDoT165V269bw11/6FTT8/SEjow4nDIqDc2YqfwqzlLnpFXzQLSNnq7JH1cKj+PsWEV7JUo11ShxYSuHMRji6CPZ/AqWn9MeTl0Pi+XD+j1CcBUHRDYjYjWWnQ07ZHfam24EjusPaooNs0qw7F9TJ6aEJD7PmZshQ3ugDAvIpLGzcSxI++qjyd0KTZMKDymqmJMp0OSGEd5GRB8Lppk2zTxykpFSdOCg3ebLarrL4npNs2AARwWeJDMnA12yF2ItcG4CHW7dObZeU6P//bEef1FlAOARrimGMXALRQ6g0wdPpCUkceAE/czEhgbm6fXUecXDwI1h1I/zzkn3iAMBa9k3p6+e9iQOAcM2KC0VHiYjQH64oOpiXBmhK51+01NmROYyfn9qudNUX4RiFGRXN4b2TKtruslKSq5Uv09i79VZ8yj9d933FsHiEEMIZJHkgnKpTJ3jTZkUwqxUSEmp+re3w9ylTHBdXTQoLoV3TgwT6lQ2J7/tW9S8Qdtq1q3y/pZpBAvUSfyGM/gsm58GIX6HZJeAbAZH9oO+sml8v3J6/bxEhAWryoF5zqjc9AvmVLELvEw6DP4dWY+ofoCfR3lkDvy1R/zF1U8Q2Pqp/XWhLJwblWKtXq+2hQ6vv6y+Dyuqvvbrqzfs3qNN75s+HxEY8M6R3q63qRpDM0RdCeBdJHgin8feHffvU7YCAun/o/+47tf3JJ46Jq7ZaNT1KsH/Z8PgmbVx7cS9w4ID9PqcW0vIxQ8JouOAnuCoDLtnoxIsJ1/EjPjKNyOAMwEJKSi1eUpShFNo8tkTdZ7Ut9ucH3WbAlaehzXUOi9bTDOhxvKJ9pHwGg6UUUv9P7ZR4s0tjaijtFLeSEvvjM2ao7Ysvdn48Xqvz1Ipm28iNhIWph5KTG29iJizIfoqVEEJ4C0keCKcwmfSFELt1g4KCqvtXZYLNClDt21fezxlaRKUS5J9bc0dRJe3og8ZcgVs0gG80CVFpXD/0M6x5+dWPWiotUFZQ2PoorL4Rll8M+WeVY92fVfu1uAomnYZznvHwpQfryVczdWHrU1itNiPCTDYfDQZ/6LLQXEE7ZU63GoOoGz/tSh2lZGXpp6gVFzfOWWO/bb9QaQS1NjQOIYRwBkkeCIfasMH+w8Krr+orYNeV9knjwYP1P09dWQFfn0oeW4laO3CAihsTIeolRhl3bjYDaX9V3sdSCqc2wN9Pw6rr4OAHVKwO8McI5e+ej0CXx2FsEgxfAAFhlZ+rMej/gdo+Mtf+uO4H1h/MfvZ93Jy2Zo5t0jlbHgw7zbp18MQT+n0mk7rqjvezsnzvGLgyBy7dbnQwQgjhcJI8EA4zZYp9YcOUFE0BrnpKSICoKHXbz0WfY79dfwW7UrqAX7OaOwshnKOjZn3PsHj747lH4J/XlJEG/7wIJSdtjqer7d7PQVhrp4TpUVpdqtmoZK1cHx/o8ij4RsGgz1wWliNpa+a4MuksYNYs7KYXtWihLmXojcq/ttDAbO4Z/SYkfQX+jThBKYTwWo1wvKZwhubNIS1Nv8+RT5tPn1ZHNJSUKE8xalN0sT7Kq3OnZ8azYO8zXPdSYPUvEEI4T3x/6PoEYIGASpaCO70Dtj1c+Wt9QmHQ+04NzyP5VPPcIG0Z5ByATvdB7xdcF5PwKgkJ9qvk3norLFrknVNFHi57CxrXZxGvXPVv2AR0dGGVZyGEcBEZeSAazGzWJw5CQpwzTH3UKLVtu/SjI117LfiYSgArH7y4B8JaOe9iQojqmc3gHwFZB+DMZijKhIxd6vGkbyt5kS90eQSuPAutJrosVI/S/FIIbA5tpyoFJsstnwAbb4ef+xsWmqPExKhtbZFE4UBxFwMm8K18VQHbBMLixcrDBm9z6hSAlV6tt+pXLRFCCC/jMcmDs2fPcsMNNxAREUFERAQ33HADGRkZ1b7m5ptvxmQy6f4MGjTINQE3EiaTfum9gQMhJ8c511qyRL/trA+DSUkwtOMq3r75HuL3T6j5BUII59r2EKR8DWuuh22PwpJzIX2VcqzrPfq+CZNg0hno/WLjLIZYW+d+A31mQ3BzOLVJ2Zd/AqxZSrvI8yepb9umtp8tq5epnXsfEeHScLzT4M+g1yvQ5SHIrnx+iMWin3qYlga+Xvqj2SGukmWGhBDCi3hM8uDaa69l27Zt/Prrr/z6669s27aNG264ocbXXXzxxaSlpVX8+fnnn10QrfdbuNC+MOKcOUqxpHqzFEPuUf1TMBtz5qjtZ5+tsluDWCzQKX4/HeMqWRNeCGGgEjjwPpRmwLKyiuZN+0GTIRDZFy49CCO+bdzFEGvLNwh2vQY7n4ZVVyj7tjnpTdUglU1tu+sutS2jERwgKAbyj0PyQjj8dZXdTp+GYcPU7dJS71uJITQgk7iIshorIT2NDUYIIZzEI3K/e/bs4ddff2XdunUMLKvI99FHHzF48GD27t1Lp06dqnxtQEAAcXFxrgq1UbjmGpg/X78vJaWONQisVig6C3kpZX+SIWs/5B2FgKbQ61nwb2L3sltuUeZNluvevWErOVQlvskxQgJs14UXQriPIiXT5+MDF6/2vjsRV8jcqPxdmqmsWJH0lnoszjume5hM6jS61FT45Rf1WEOL+Yoye19R/s7YBj0eq7LbypUwezZM19RANZnq8fnBTXVJ+IfwoLKlPAZ/amwwQgjhJB6RPFi7di0REREViQOAQYMGERERwZo1a6pNHixfvpzY2FgiIyMZMWIEzz33HLGxsVX2LywspLCwsGI7KyvLMV+El2jatHxun6pW9Q0sJeCj+XY7MAdOrVESBpm7oOQsyuKIZcJ7QufbKz1VSopa82DXrkq7NFApzcJPEByQ64yTCyEcwTcGrEVAoCQOHCF9hX572BfGxOFgn3yiJpw7dYLiShaXEI5iqbHHgw8qy2hq6xa1aKEs6ezpyZwOzfYTHlz2mTG2l6GxCCGEs3jEtIX09PRKb/hjY2NJT0+v5BWKMWPG8MUXX7Bs2TJmz57Nxo0bOf/883XJAVsvvPBCRV2FiIgIWrZs6ZCvwRuYTPrEQUREFYkDqxUKT8PZvyH1J9j/Pmx7HHKPqX22PgJJc+D0Kig5gy5xALDFZh6zRkKCUpSxXKCDF0PwMVloEnqWEP9cMMfU/AIhhJNp12f1hc4PwaQ0MMtKKA3iq3ncu1w70sAX/Lzj3/aWW9R2ruSD3UL5Sgxa06fD6NHGxNNQs2crf7dueoSIoAxDYxFCCGczNHkwc+ZMu4KGtn82bVIKOZkqebJktVor3V/u6quv5tJLL6V79+6MHTuWX375hX379vHTTz9V+ZrHHnuMzMzMij/JyckN/0I9XGqq/YO9UaPArl5l5h44/CXsfA42Pwwb7oHVN8DGu+CfV+BHzRzAktPVXzQgTqmBkPoTFNtXYNQWZSws1BfBaqgWUcn4+pQQGpgNnR9x3ImFEPVz7v/ALwbix8GkU9DnZSmG6AgDPtRsZKrNPu+6PBThJaw1jz6o6GpFtzLBb78poxs9zfPPK3+nnGlBkF++scEIIYSTGfrp65577mHy5MnV9mndujXbt2/n+PHjdsdOnjxJs2bNan29+Ph4WrVqxf79VRfCCwgIICAgoNbn9HZz5+prDICVRQtOM+6iFEhNgabngn+kcijlR/j7CaCo8pOVahIGAe2gUFuZ2Qf8YyEgGgrSYMT/IPUHOPApHF8H5/zH7injwIGwfr3SbtHCMctDzpgBrZseBiAsKNu+krsQwvUSx0LiSaOj8D6txsCaSvZ3nuryUJxJ+7tCOEMAUDaiM+8UhFQ9NdRWSQk0awYnTijbp04pCYXSUsdH6Sxnzih//7TtEszmAEi43NiAhBDCiQxNHsTExBATU/Ow8MGDB5OZmcmGDRsYMGAAAOvXryczM5MhQ4bU+nqnT58mOTmZ+Pj4esfcmIweDb/9ZgFMKNMKLBz//QViAw/B+r3KSIOAZjD+H+UFe+dSZeKgnNUCJh847zvYMBVih0LCOIgZDL7+Sp+CUxAYA+u/grTFyp/AcOh8P/iow5fXrdOPiJg9u+FzJt99F3rHF3MyqymhgfleM3RXCCHsVDZyL7it6+NwMtvfFQDt2hkTi1eKGghnVirt3W9C/7qt2nH8OIwbB4sXK9sWi77QpWewcjonGibnKR+ZhBDCS3lEzYMuXbpw8cUXM3XqVNatW8e6deuYOnUql112ma5YYufOnVm4cCEAOTk5TJ8+nbVr13L48GGWL1/O2LFjiYmJYcKECUZ9KR6jeXNlCGF54qBr87+xfhFC7PEn4cg8OLNWWS4tb6/mRedXcTYzBMRDm9vAWvY4IbonjFkPfV+DuBFq4gCUxAHAQU3l720Pw/5PlIrgGq++qra1FZzr68wZWLt/CHOW34qH1BMVQogG0IwbP383XLzRuFBc6MsvjY7Ai/SarbaT5lTdrxrff69fihmUBIIjpyQ6U3zkMTo02wu7nlMekAghhJfymHe4L774gh49ejBq1ChGjRpFz549+eyzz3R99u7dS2amMm/TbDazY8cOxo0bR8eOHbnpppvo2LEja9euJSxM1gCvVEk+nFhFfNOzpKUpu8w+xWx6tje7XulDlaMKclKUv3u9AJjBFAIRvaHzdLhwJVyVD5OOweCPdSMHahQ1SL+9+U44/JXucYTtSINBNi+pOyt5RaFsPdoLxh1u6MmEEMK9NddMHfQNh8Ao42JxItvCumWDGIUjNOurtkvrX5XylluU1ZS0WrRQCxK6s6sHzeeLu2+AHU8aHYoQQjiVxzxajYqK4vPPP6+2j1VzUxkUFMSSJUucHZZ3KMqAk2vgyDdccf8F9Gt5hh9PjQV8uPTCNPq22V7Ni/3VDwuBYXBlJviFVNO/Di5cBt82A0uGum/dzUqNhRaXVezSLt3Y8HmtpYQE5JNbGARBMr1FCOHlBr4Dy/dD3IUQEW10NE5z4IB+eUDhQCYTmAIBC7S7pcbu1SlfiUE7zWT6dPjmG2X6iXuy0LrpEZo3STM6ECGEcDqPSR4IJ8hPg/Q/4MA8OLmcpTuGMa7fr/j6lJB0ojU9hp3DV1+1Au3wTp9QCO8I8aOUWgXR/fRVzx2VOABlKsPEZPg2FiivYFwKq2+GK9MrrpuQAAEByqoLAKGh+tUY6iI2/DjPXvkUkcFnIOM9iKp9QU4hhPA4QREw4B0oPKWfPuZlEhJq7iMaYOTPcHIVBMY55HRWK/j5KQUVQXkwEBlZySpPBps9G3zNxTQNP0lk8FkwNTE6JCGEcCpJHjRWSfPh7xmQdwCAg8dbk5kXha9PMXlFwXxy5xQG/qds7mu/D8E3EOIvhiAXr6PkHwrjj8Ci5kDZpwjLaTi1G5qpSz8WFKhPKnJzlXmS9fmw2DFuPxHBmXRrsRsCghsevxBCuLvofkZH4BKTJ8P8+crfwsF8QiHlByjKhvZTKy/GWUfFxZCYCOUrZmdmul8hxVmzoE3MIQJ9CwjyL4CuzxkdkhBCOJXH1DwQDWQphdJCdXvz/RWJg6STiazaO5yNh/rx45axDO24koHjrlb7dpwKbW9wfeKgXHBTGGuzvKYlD/JS4aw6paJbN/VwfYanpqZCQtmww2D/PAiR2hhCCOEtviormfPVV0ZH4oXW3gpnN0HuXjj8JZTWsPJSLR09ap/scUBewmEyM6FT870EBeTj4wN0u9fokIQQwqkkeeDtSgsh5WdYMgJ+1BQ1sij/9duPdmPWd0/y6o8P8M36K7j++iI6/3svdHfA0gWOFNYaRv8N+EGz0RAWBwfnws5nIVNZKnLnTv1L5s6t2yXuugviItMBaBqW3vCYhRBCiMbAR/Nxcu1NsHs2FJ5xyKm/+gq++06/z2SCDRsccvoGaxebpDxwAPCtQ1FoIYTwQJI88FZFmbD7v7CwLay8FM7+Bbm74EzZE/zh3/LGL3dy+ezFzF87mX3pnZj9QQfG3HWrvoaBO4nuCROOwojvIKgF7HwJkr+BVddCThIATzyhdr/11rqd/rffrDSLSMfft4iQoGIHBi6EEEJ4sXYPazZKYcfjsOVRyD7okNNPmGC/EsPAgTBjhkNO3wBWWkSnEOxf/1UmhBDCk0jywNtkH4a1t8G3cbDt31B0TH98h/Kb1hQ/hOlfvc6RU63JLw5h9ZpAJkxwfbh1FhQHvsFwfCtYy6oiZm2FVTdBXiqzZum7jx5d+1MXFJQQG3GSQL98dGufCyGEEKJqnSopJJH0EWx3XA2A8pUYtJ59Fnr3dtgl6sHEqj3nkpEboSxTLYQQXk6SB97mp16QNAcoqPx4i0kV8wVLSgMAH9av98A1r5u012+fXQUb7oGCk7qnE7/9VvtThgeeJTQwh2D/fAjr5ZAwhRBCCK9nNsMlu8BkU2j4yFxI+dOhl7JalRWWym3bZmwdhN92jOaXv0dB3zeMC0IIIVxEkgeerLQY9rwFu99S91kyK+lohuaXw2UHMLW/UnckJcUDEwcAQU2g60z9vmOLYNPDJDTNxFcz8yIysnanjI88wb60DuQWhkAf+RAghBBC1FpkV5h0HIJtkvuFp8FSAimLlSmVDlBQAO3a6feZTHUbbdhQs2cDWCkoCSI94gHoeJvrLi6EEAYxWa3utOiN+8nKyiIiIoLMzEzCw8ONDkeRfxw23g8p3wClyr5ry/4bf+gN2duUtm8T6DwNujwCfoF2mfmUFC9Y+3r93XDwXf2+85ZD8xG6r7c2X2ugby4RIVlcNXA+by25371KOgshhBCewGKB1ddBynzADy7bCTkHYefLENFdKcgc0sohl5oxQ5m6YMsVn28iI6FV+DYC/ArYsOAb6DfbuRdspNzyc7gQjZgkD2rgNm9aViscXwEb7oScf+yPjzkMTVpB/hlYPgp6PgvNR4PJRGqq/dKFXpE4KPfnJEjTlmL2h2sLad8eDmpqNdX0nW4yWQATwQEF5BYEOSNSIYQQonHYPw8CY6HlJbDnQ9h6u7K/2Rjo9QxE93PYpYKDIT9fv69dOzhwwGGXsGMyFTPrypn0aLGDcf1+gmtLnXexRsxtPocLIQCZtuA5vo2HZSMrTxwAWMrujIOiYMwmSLi4ysSB1epFiQOAkf+DqGHqtk8QWK0c2LCZipEZwMKFVZ9iwwaICTtJkH8enTo6ZlilEEII0Wh1uFlJHABse0jdf/wXWDkZkheBxTE33Hl59ss5Hjzo/CUdW0SlEBmSgXycFkI0FvJu5ymKj1e+3y8aer4AkS3sDlWVOPBKo5ZDaHfAB/q+Dum/w/45PH3XUsACwMSJVb/8phtyeGTsy7xxwzQW3jXWFRELIYQQjUPzS/Tb+Qdh1fWw7z0oznHIJSZMUD7jxMfr9w8cWPvaR3WRGH2UYP88gvzzoOnFjr+AEEK4IUkeeKqInnDBcrjyFHR/FMy+usMbNjSixAGAjw9cug1Gr4f2N0PeSTj4Lk8OHYOJUkD54q+5pvKXpyfnktAklWYRx2kVe8ZVUQshhBDe79zPodmlNjtzYcu9cGa7Qy917Bi6VZcAMjOVUQhz5zruOt1a7ALAx2SBIR857sRCCOHGJHngKdreB/hDi6tgwgm49G9oNqLSrgsXKpl2La9OHJQzm5U5lCYTrL+lYnfaG9EoyQMr8+dX/tLuLXZi9inF11wCHR9xSbhCCCFEo2A2wwU/wjkv2B/7Y5j9vgZKSFA+99h+Frr1VvDzc8w1WkUnA+BvLoSQOMecVAgh3JwkDzxF/9fg6jwYvgCCmlbZbeFC++H5jSJxYCtYXcOpWUw2k/p9qW43s+/esblSVam41Bc632LfQQghhBAN0+1ROH8lYNbsVKYWkrUfji0Bq8Vhl1u3zv4zUEmJ8oxhypT6n3fGExbimqQDEBVyugERCiGEZ5Hkgacwm5U/1Zg9WxIHFUatANSpHN/++wbaNd0HWDlxwr57bPhJAEpKfcHXQY8lhBBCCKEXNwzGp4Jv2YOQ5hOgOBcOfQkb/w0HPoGSPIde0mqF227T7/vkk/qvyPzGm8UkNDmGn7mYFjFV1KQSQggvJMkDLzFjBkyfrm6bTI04cQAQ3BTG7gfUTwa//+dCmkWkAVZ8bL7zI4OVFRYslnp+khBCCCFE7QQ3g0nHoNfrMHQe+IXAnlcgdw9svB12vgj5jr0p//hj5XOR7XMYkwmGD6/bubKzTXy26nr+2jcEwgc4LkghhHBzkjzwAtOmwbPPqtu+vmBx3Kg/zxXWGkZvq9hs3TSFN2+YRqBfPlarZvkmq5XwoGwAfExFLg9TCCGEaHTMvtD1fvALh4J8sOaWHbDC7lmw8QHI3O3wy5aUwKuv6vetWqUkEVJTa3sWH9YdGMzX666CoV84OkQhhHBbkjzwcNdcA2++qW4HBEBxsXHxuJ3onnD+iorNkV1/L2tZGTiwBIDZr5nYldqN/cfbExaaW8lJhBBCCOE0fv5AgH5fypfKco5pvzt8KOWDDyqnDAvT72/RAhITa3MGE0WlASSfaQFN2js0NiGEcGeSPPBgo0ejWz0gJAQKCoyLx23FDYdzvwOgaXwkhcXlYxZ9uPO2VF58ET5bfQPvL72Tcy68pOrzCCGEEMLxzGYYuw98IvX7s7bC2ilgcc6owKwsWL9evy85WRmFUDE60ZbVyuV9vufSXj/QMuqIU+ISQgh3ZbJaG/XM+BplZWURERFBZmYm4eHhRodTYdAg/S+8qCg4LQV/q3dqHQS3YuEvMdx4fQ6jeyxl8ZbLKLX4YrEqRRKtFupfQUkIIYQQ9VdSBL8Ohqwt+v0J18GIz5166cREJXGgFRICOTk2HfNO8PF9jxEalMPRk3E8PP8Np8bV2Lnr53AhGisZeeCBOnXSJw7i4yVxUCsxgyA4ngnDD/HNvVcxacB33HXh+8RFpNO8SSr+vgWSOBBCCCGM4usPl22GdnfbHChVsvtHv1GWdHSCo0chJUW/LzdX+Vgwe7a675WHviYsKBsfk4XubZwTixBCuCtJHniYxETYt0/dbtcOjh0zLh6PFBrPBd1+p0nIWQZ1WM9Tk2bx7JVPcOcF7xkdmRBCCCEGvg1Dvy7bMCmFFU9vgl1vw1+3wIlVTllSKiFBOe2wYRagFFCuMX06+PsVwrFfyUpJw2SyUlgcwCV33OvwGIQQwp35Gh2AqL2mTeHUKXW7Vy/YutWwcDxXUDh+rSYRl/oPGXkRRAZnANA0XNZqFkIIIdxCqyshch9k7YGmAyF9NZxdqRxbcTX0mw2Jk8DsX7vzWa1K7QQfPzCVPTvLSYKcg1CcAyVlf4ozWfnGaSjOwXfQfym1KucvLvEjsUcnHh77vfLSwhBoOdrRX7UQQrg1SR54iPBwyM5Wt4cNg5UrjYvH4533Lb0KhrP8i2bEN0nHBOQWBhkdlRBCCCHKRXRQ/gBsm6HuL06DtTdBbjK0vxUCotSEQO5RJSlQok0IZEPhGSjOhHa3QpNzlL5pq2Dnf5TjJflAMeWjDQBKPv+QaetLePNNCAnI4amJswjyzwcgKy8MfGQArxCicZHkgQcIDob8fHX78svh+++Ni8drjFpO9I+3sGznBYQE5JJVEmN0REIIIYSoTOf7YM1yzY5i2P4InNkOPR+DyG7K7vSVsONJKMmGolygELCoL9v3HlxbtnrD3rcg36bQgU4pb7wBb7wBF/dcgZ9vEbmFIWQXhLEzpatDvzwhhPAEkjL1ANrEwW23SeLAYXx8uOGNOfj7F3I6J5yPf7nG6IiEEEIIUZnWE6D/HPv9KV/Az33U7X/ehbwkKDoF5KNLHADK6IIyfmE1X9ei9P91cQmXnvM9a/YPZN7KGzmS2aWuX4EQQng8GXngAdavh4ED4b77lOy3cCCzmbd+nWZ0FEIIIYSoSYdbIKovLBmEkhgoV6Q2/YNrPo+lWKl90PE+WPtn2U4T4AvmIPALh8BoaNK3bA1noNV4oievZe5NcRComSYhhBCNiCQPPMCAAU4pKiyEEEII4Vmie8Kk4/DTOVCQpO4vLVKKJ7a7C07+oXmBGXwCwTcE/CMhqj9YSwE/aDMewtZBQCwEtwCzX9XXNZkgsrtzviYhhPAQkjwQQgghhBCeIyAMxh+ATffCsSXQpDsV0xPaTICQ5eAfDSGJytQEk6nqc8UMdEXEQgjhFSR5IIQQQgghPIuPDwx4x36/yQTNRrg+HiGEaARkwpYQQgghhBBCCCGqJckDIYQQQgghhBBCVEuSB0IIIYQQQgghhKiWJA+EEEIIIYQQQghRLUkeCCGEEEIIIYQQolqSPBBCCCGEEEIIIUS1JHkghBBCCCGEEEKIaknyQAghhBBCCCGEENWS5IEQQgghhBBCCCGqJckDIYQQQgghhBBCVEuSB0IIIYQQQgghhKiWJA+EEEIIIYQQQghRLUkeCCGEEEIIIYQQolqSPBBCCCGEEEIIIUS1JHkghBBCCCGEEEKIaknyQAghhBBCCCGEENWS5IEQQgghhBBCCCGqJckDIYQQQgghhBBCVEuSB0IIIYQQQgghhKiWJA+EEEIIIYQQQghRLV+jA3B3VqsVgKysLIMjEUIIIYQQovEo//xd/nlcCGEsSR7UIDs7G4CWLVsaHIkQQgghhBCNT3Z2NhEREUaHIUSjZ7JKKq9aFouFY8eOERYWhslkMiyOrKwsWrZsSXJyMuHh4YbFITyXfA8JR5DvI+EI8n0kHEG+j7yf1WolOzub5s2b4+Mjs62FMJqMPKiBj48PLVq0MDqMCuHh4fILUjSIfA8JR5DvI+EI8n0kHEG+j7ybjDgQwn1ICk8IIYQQQgghhBDVkuSBEEIIIYQQQgghqiXJAw8REBDAU089RUBAgNGhCA8l30PCEeT7SDiCfB8JR5DvIyGEcC0pmCiEEEIIIYQQQohqycgDIYQQQgghhBBCVEuSB0IIIYQQQgghhKiWJA+EEEIIIYQQQghRLUkeeIB3332XNm3aEBgYSN++fVm1apXRIQkPMnPmTEwmk+5PXFyc0WEJN7dy5UrGjh1L8+bNMZlMLFq0SHfcarUyc+ZMmjdvTlBQEOeddx67du0yJljhtmr6Prr55pvt3p8GDRpkTLDCLb3wwgv079+fsLAwYmNjGT9+PHv37tX1kfcjIYRwDUkeuLkFCxZw//3385///IetW7cybNgwxowZw9GjR40OTXiQbt26kZaWVvFnx44dRock3Fxubi7nnHMOb7/9dqXHX375ZV577TXefvttNm7cSFxcHBdddBHZ2dkujlS4s5q+jwAuvvhi3fvTzz//7MIIhbtbsWIFd999N+vWrWPp0qWUlJQwatQocnNzK/rI+5EQQriGrLbg5gYOHEifPn147733KvZ16dKF8ePH88ILLxgYmfAUM2fOZNGiRWzbts3oUISHMplMLFy4kPHjxwPKU77mzZtz//3388gjjwBQWFhIs2bNeOmll7j99tsNjFa4K9vvI1BGHmRkZNiNSBCiKidPniQ2NpYVK1YwfPhweT8SQggXkpEHbqyoqIjNmzczatQo3f5Ro0axZs0ag6ISnmj//v00b96cNm3aMHnyZA4dOmR0SMKDJSUlkZ6erntvCggIYMSIEfLeJOps+fLlxMbG0rFjR6ZOncqJEyeMDkm4sczMTACioqIAeT8SQghXkuSBGzt16hSlpaU0a9ZMt79Zs2akp6cbFJXwNAMHDuT//u//WLJkCR999BHp6ekMGTKE06dPGx2a8FDl7z/y3iQaasyYMXzxxRcsW7aM2bNns3HjRs4//3wKCwuNDk24IavVygMPPMC5555L9+7dAXk/EkIIV/I1OgBRM5PJpNu2Wq12+4SoypgxYyraPXr0YPDgwbRr145PP/2UBx54wMDIhKeT9ybRUFdffXVFu3v37vTr149WrVrx008/MXHiRAMjE+7onnvuYfv27axevdrumLwfCSGE88nIAzcWExOD2Wy2y5yfOHHCLsMuRG2FhITQo0cP9u/fb3QowkOVr9Yh703C0eLj42nVqpW8Pwk79957L4sXL+bPP/+kRYsWFfvl/UgIIVxHkgduzN/fn759+7J06VLd/qVLlzJkyBCDohKerrCwkD179hAfH290KMJDtWnThri4ON17U1FREStWrJD3JtEgp0+fJjk5Wd6fRAWr1co999zDd999x7Jly2jTpo3uuLwfCSGE68i0BTf3wAMPcMMNN9CvXz8GDx7Mhx9+yNGjR7njjjuMDk14iOnTpzN27FgSExM5ceIEzz77LFlZWdx0001GhybcWE5ODgcOHKjYTkpKYtu2bURFRZGYmMj999/P888/T4cOHejQoQPPP/88wcHBXHvttQZGLdxNdd9HUVFRzJw5k0mTJhEfH8/hw4d5/PHHiYmJYcKECQZGLdzJ3XffzZdffsn3339PWFhYxQiDiIgIgoKCMJlM8n4khBAuIks1eoB3332Xl19+mbS0NLp3787rr7/O8OHDjQ5LeIjJkyezcuVKTp06RdOmTRk0aBCzZs2ia9euRocm3Njy5csZOXKk3f6bbrqJefPmYbVaefrpp/nggw84e/YsAwcO5J133qkoYiYEVP999N577zF+/Hi2bt1KRkYG8fHxjBw5klmzZtGyZUsDohXuqKq6BXPnzuXmm28GkPcjIYRwEUkeCCGEEEIIIYQQolpS80AIIYQQQgghhBDVkuSBEEIIIYQQQgghqiXJAyGEEEIIIYQQQlRLkgdCCCGEEEIIIYSoliQPhBBCCCGEEEIIUS1JHgghhBBCCCGEEKJakjwQQgghhBBCCCFEtSR5IIQQQgghhBBCiGpJ8kAIIYQhZs6cSa9evYwOQwghhBBC1IIkD4QQQjicyWSq9s/NN9/M9OnT+eOPPwyJ78SJE9x+++0kJiYSEBBAXFwco0ePZu3atbqvYdGiRYbEJ4QQQgjhbnyNDkAIIYT3SUtLq2gvWLCAJ598kr1791bsCwoKIjQ0lNDQUCPCY9KkSRQXF/Ppp5/Stm1bjh8/zh9//MGZM2cMiUcIIYQQwt3JyAMhhBAOFxcXV/EnIiICk8lkt8922sLNN9/M+PHjef7552nWrBmRkZE8/fTTlJSU8NBDDxEVFUWLFi2YM2eO7lqpqalcffXVNGnShOjoaMaNG8fhw4erjC0jI4PVq1fz0ksvMXLkSFq1asWAAQN47LHHuPTSSwFo3bo1ABMmTMBkMlVsA/zwww/07duXwMBA2rZtWxFjOZPJxHvvvceYMWMICgqiTZs2fPPNNw3+NxVCCCGEMJIkD4QQQriNZcuWcezYMVauXMlrr73GzJkzueyyy2jSpAnr16/njjvu4I477iA5ORmAvLw8Ro4cSWhoKCtXrmT16tWEhoZy8cUXU1RUVOk1ykc8LFq0iMLCwkr7bNy4EYC5c+eSlpZWsb1kyRKuv/567rvvPnbv3s0HH3zAvHnzeO6553SvnzFjBpMmTeLvv//m+uuv55prrmHPnj2O+mcSQgghhHA5SR4IIYRwG1FRUbz55pt06tSJW2+9lU6dOpGXl8fjjz9Ohw4deOyxx/D39+evv/4CYP78+fj4+PDxxx/To0cPunTpwty5czl69CjLly+v9Bq+vr7MmzePTz/9lMjISIYOHcrjjz/O9u3bK/o0bdoUgMjISOLi4iq2n3vuOR599FFuuukm2rZty0UXXcSsWbP44IMPdNe48sormTJlCh07dmTWrFn069ePt956ywn/YkIIIYQQriHJAyGEEG6jW7du+Piov5qaNWtGjx49KrbNZjPR0dGcOHECgM2bN3PgwAHCwsIqRhRERUVRUFDAwYMHWbVqVcX+0NBQvvjiC0CpeXDs2DEWL17M6NGjWb58OX369GHevHnVxrd582aeeeYZ3TmnTp1KWloaeXl5Ff0GDx6se93gwYNl5IEQQgghPJoUTBRCCOE2/Pz8dNsmk6nSfRaLBQCLxULfvn0rkgJaTZs2xd/fn23btlXsa9asWUU7MDCQiy66iIsuuognn3ySKVOm8NRTT3HzzTdXGZ/FYuHpp59m4sSJdscCAwOr/dpMJlO1x4UQQggh3JkkD4QQQnisPn36sGDBAmJjYwkPD6+0T/v27Wt1rq5du+qWZvTz86O0tNTuenv37q3xnOvWrePGG2/Ubffu3btWcQghhBBCuCOZtiCEEMJjXXfddcTExDBuesKNLwAAAdZJREFU3DhWrVpFUlISK1asYNq0aaSkpFT6mtOnT3P++efz+eefs337dpKSkvjmm294+eWXGTduXEW/1q1b88cff5Cens7Zs2cBePLJJ/m///s/Zs6cya5du9izZw8LFizgiSee0F3jm2++Yc6cOezbt4+nnnqKDRs2cM899zjvH0IIIYQQwskkeSCEEMJjBQcHs3LlShITE5k4cSJdunTh1ltvJT8/v8qRCKGhoQwcOJDXX3+d4cOH0717d2bMmMHUqVN5++23K/rNnj2bpUuX0rJly4pRA6NHj+bHH39k6dKl9O/fn0GDBvHaa6/RqlUr3TWefvpp5s+fT8+ePfn000/54osv6Nq1q/P+IYQQQgghnMxktVqtRgchhBBCeAuTycTChQsZP3680aEIIYQQQjiMjDwQQgghhBBCCCFEtSR5IIQQQgghhBBCiGrJagtCCCGEA8lsQCGEEEJ4Ixl5IIQQQgghhBBCiGpJ8kAIIYQQQgghhBDVkuSBEEIIIYQQQgghqiXJAyGEEEIIIYQQQlRLkgdCCCGEEEIIIYSoliQPhBBCCCGEEEIIUS1JHgghhBBCCCGEEKJakjwQQgghhBBCCCFEtSR5IIQQQgghhBBCiGr9P61/zeD1dywIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHUCAYAAAANwniNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACGc0lEQVR4nOzdd3gU5d7G8e/upldCCy1UkSJVmoAISJOmiAqKgAiIiKiIlWM5iq/i0YNyFAGVZgMRBURFFGmCoHRUQLAAoSS0QBIIabvz/jHZJSEBkpBkNuT+XNe4s7OzM7/dneDe+zzzjM0wDAMRERERERG5ILvVBYiIiIiIiHg7BScREREREZFLUHASERERERG5BAUnERERERGRS1BwEhERERERuQQFJxERERERkUtQcBIREREREbkEBScREREREZFLUHASERERERG5BAUnESk2Zs+ejc1mY9OmTVaXkmcdOnSgQ4cOlu3f5XLx0Ucf0blzZ8qWLYuvry/ly5enV69efPXVV7hcLstquxzz5s3jmmuuITAwEJvNxrZt2wptX6tWrcJms/H5559fdL0TJ04wbtw46tevT3BwMOHh4dStW5dBgwbx66+/AmCz2XI1rVq1in379nnuv/DCCznuc+jQoZ518iIhIYFXX32VVq1aUapUKXx9fYmMjOSmm25izpw5pKSk5Pi83377DZvNhq+vLzExMZ7lQ4YMydXrGjJkyAVreuGFF7DZbNjtdv75559sj585c4awsLBLbiev3O/z7Nmz8/xc97GxatWqAqtHRLyPj9UFiIiUBFOmTLFs38nJyfTp04fvv/+eO++8k6lTp1KhQgWOHTvG0qVLueOOO5g3bx633HKLZTXmx7Fjxxg0aBA33XQTU6ZMwd/fn6uvvtrSmk6fPs11113H6dOneeKJJ2jcuDFnz55lz549LFiwgG3bttGoUSPWr1+f5XkvvfQSK1euZMWKFVmW169fn7i4OABCQ0OZPXs2zz//PHa7Pcs+58+fT1hYGAkJCbmu9c8//+Smm27i6NGjjBgxgmeeeYaIiAhiYmL47rvvGDp0KLt27eKll17K9tzp06cDkJ6ezocffshTTz0FwHPPPcfIkSM9623ZsoUHH3yQV155hY4dO3qWlytX7pL1hYSEMGvWrGz7nz9/Pmlpafj6+ub6tYqIFAQFJxGRPDIMg+TkZAIDA3P9nPr16xdiRRc3duxYvvvuOz744AMGDx6c5bG+ffvyxBNPcPbs2QLZV1JSEkFBQQWyrUvZs2cPaWlpDBw4kPbt2xfINi+3/vnz5/PXX3+xYsWKLEEBzM/B3bJ33XXXZXmsXLly2O32bMsBT3Dq378/06dPZ/ny5XTp0sXz+Lx583A6nfTp04ePP/44V3Wmp6fTp08f4uLi2LBhA/Xq1cvyeL9+/Xj++efZunVrtuempKTwySef0LhxY44fP87MmTM9walWrVrUqlXLs25ycjIAtWvXzvG1XUz//v354IMPePHFF7MExRkzZnDrrbeyePHiPG1PRORyqaueiFxx/vzzTwYMGED58uXx9/enXr16vPPOO1nWSU5O5rHHHqNJkyaEh4dTunRpWrduzZdffpltezabjdGjRzNt2jTq1auHv78/H3zwgafr4MqVK3nggQcoW7YsZcqUoW/fvhw+fDjLNs7vqufuFvTf//6XN954gxo1ahASEkLr1q35+eefs9Xw/vvvc/XVV+Pv70/9+vWZM2cOQ4YMoXr16hd9L2JjY5k+fTrdunXLFprcateuTaNGjYBz3SH37duXZZ2cuiJ16NCBBg0a8OOPP9KmTRuCgoIYOnQoffr0oVq1ajl2/2vVqhXXXnut575hGEyZMoUmTZoQGBhIREQEt99+e45dtDIbMmQI119/PWB+wbbZbFne38WLF9O6dWuCgoIIDQ2lS5cu2Vp53F3CtmzZwu23305ERESWL/35ceLECQAqVqyY4+OZA0Be1alThzZt2jBz5swsy2fOnEnfvn0JDw/P9bYWLlzIzp07eeaZZ7KFJrdq1arRp0+fbMsXLVrEiRMnGD58OPfccw979uxh7dq1eXotuTF06FAOHDjAsmXLPMvc+xo6dGiOz4mOjmbgwIFZ/vYnTpyY7Vg8fPgw/fr1IzQ0lPDwcPr3709sbGyO29y0aRM333wzpUuXJiAggKZNm/LZZ58V3AsVkWJDwUlErig7d+6kRYsW/P7770ycOJGvv/6anj178vDDD/Piiy961ktJSSEuLo7HH3+cRYsWMXfuXK6//nr69u3Lhx9+mG27ixYtYurUqTz//PN89913tGvXzvPY8OHD8fX1Zc6cObz22musWrWKgQMH5qred955h2XLljFp0iQ++eQTzpw5Q48ePYiPj/es89577zFixAgaNWrEggULePbZZ3nxxRdzdT7FypUrSUtLy/ELcEGIiYlh4MCBDBgwgCVLljBq1CiGDh1KdHR0tm5nf/zxBxs2bODee+/1LLv//vsZM2YMnTt3ZtGiRUyZMoUdO3bQpk0bjhw5csH9Pvfcc54w/Morr7B+/XpPd8g5c+Zwyy23EBYWxty5c5kxYwYnT56kQ4cOOX7B79u3L1dddRXz589n2rRpl/V+tG7dGoDBgwd7AkZBGjZsGIsWLeLkyZMA7N69m3Xr1jFs2LA8bccdRm6++eY81zBjxgz8/f25++67PedWzZgxI8/buZTatWvTrl27LEFx5syZVK9enU6dOmVb/9ixY7Rp04bvv/+el156icWLF9O5c2cef/xxRo8e7Vnv7NmzdO7cme+//54JEyYwf/58KlSoQP/+/bNtc+XKlbRt25ZTp04xbdo0vvzyS5o0aUL//v3zdS6UiBRzhohIMTFr1iwDMDZu3HjBdbp162ZUqVLFiI+Pz7J89OjRRkBAgBEXF5fj89LT0420tDRj2LBhRtOmTbM8Bhjh4eHZnuuuZ9SoUVmWv/baawZgxMTEeJa1b9/eaN++vef+3r17DcBo2LChkZ6e7lm+YcMGAzDmzp1rGIZhOJ1Oo0KFCkarVq2y7GP//v2Gr6+vUa1atQu+F4ZhGK+++qoBGEuXLr3oeue/pr1792ZZvnLlSgMwVq5cmeU1Acby5cuzrJuWlmZERkYaAwYMyLL8ySefNPz8/Izjx48bhmEY69evNwBj4sSJWdY7cOCAERgYaDz55JMXrdVd0/z58z3LnE6nUalSJaNhw4aG0+n0LE9MTDTKly9vtGnTxrPs3//+twEYzz///EX3c7H95WT8+PGGn5+fARiAUaNGDWPkyJHG9u3bL/ice+65xwgODs7xMfex8vrrrxuJiYlGSEiIMXnyZMMwDOOJJ54watSoYbhcLuPBBx80cvu/9ZtuuskAjOTk5CzLXS6XkZaW5pkyH5uGYRj79u0z7Ha7ceedd3qWtW/f3ggODjYSEhKy7Se371lm7s/l2LFjxqxZswx/f3/jxIkTRnp6ulGxYkXjhRdeMAzDMIKDg4177rnH87ynn37aAIxffvkly/YeeOABw2azGbt37zYMwzCmTp1qAMaXX36ZZb377rvPAIxZs2Z5ltWtW9do2rSpkZaWlmXdXr16GRUrVvQcYzn9fYjIlUctTiJyxUhOTmb58uXceuutBAUFkZ6e7pl69OhBcnJylm5w8+fPp23btoSEhODj44Ovry8zZsxg165d2bZ94403EhERkeN+z//V3t3tbf/+/ZesuWfPnjgcjgs+d/fu3cTGxtKvX78sz6tatSpt27a95PYLW0REBDfeeGOWZT4+PgwcOJAFCxZ4Ws6cTicfffQRt9xyC2XKlAHg66+/xmazMXDgwCyfVYUKFWjcuHG+RijbvXs3hw8fZtCgQVm6xYWEhHDbbbfx888/k5SUlOU5t912W573czHPPfcc0dHRzJw5k/vvv5+QkBCmTZtGs2bNmDt37mVtOyQkhDvuuIOZM2d6Bma49957cxxNz+VyZXlfnU7nJbf/v//9D19fX8/UuHHjLI/PmjULl8uVpavc0KFDOXPmDPPmzbus15aTO+64Az8/Pz755BOWLFlCbGzsBUfSW7FiBfXr16dly5ZZlg8ZMgTDMDwtoCtXriQ0NDTb3+2AAQOy3P/rr7/4448/uPvuuwGy/XsSExPD7t27C+iVikhxoOAkIleMEydOkJ6ezttvv53ly5+vry89evQA4Pjx4wAsWLCAfv36UblyZT7++GPWr1/Pxo0bGTp0qOeE9swudM4K4AkCbv7+/gC5GnDhUs91d/WKjIzM9tyclp2vatWqAOzdu/eS6+bHhd4X9/v46aefAvDdd98RExOTpZvekSNHMAyDyMjIbJ/Xzz//7Pms8uJi5xhVqlQJl8vl6eZ2qddwOSIjI7n33nuZNm0av/76K6tXr8bPz49HHnnksrc9bNgwtmzZwssvv8yxY8cuGCTGjx+f5T3NfP6W+7g4P9wPGDCAjRs3snHjxiznooEZxGbPnk2lSpVo1qwZp06d4tSpU3Tu3Jng4OBC6a4XHBxM//79mTlzJjNmzKBz585Uq1Ytx3VPnDhxwc/d/bj7Nqe/nQoVKmS57+4q+vjjj2c7PkeNGgWQr2NURIovjaonIleMiIgIHA4HgwYN4sEHH8xxnRo1agDw8ccfU6NGDebNm5fl1/oLXbcmr9fHKSjuYJXT+T4XOpk9s44dO+Lr68uiRYuyDBN9IQEBAUD29+FCXxAv9L64f/mfNWsW999/P7NmzaJSpUp07drVs07ZsmWx2WysWbPGExgzy2nZpbjfr8zXFnI7fPgwdrs9W8thUXy2N9xwA127dmXRokUcPXqU8uXL53tbbdu2pU6dOowfP54uXboQFRWV43ojRoygV69envuZ388uXbrw3nvvsXjxYh5//HHP8vLly3tqCw0NzXIc/PDDD56gdX7gB/j555/ZuXNngY8gOXToUKZPn86vv/7KJ598csH1ypQpc8HPHczjzb3ehg0bsq13/t+Te/1x48bRt2/fHPdZp06d3L0IEbkiKDiJyBUjKCiIjh07snXrVho1aoSfn98F17XZbPj5+WX50hwbG5vjqHpWqlOnDhUqVOCzzz5j7NixnuXR0dGsW7fO82v6hVSoUIHhw4czdepUPvzwwxxH1vv77785c+YMjRo18ozS9+uvv2b5UpifoZ/vvfdeHnjgAdauXctXX33F2LFjs3RL7NWrF6+++iqHDh3K1hUxv+rUqUPlypWZM2cOjz/+uOfzPXPmDF988YVnpL3CcuTIEc/Q4pk5nU7+/PNPgoKCKFWq1GXv59lnn+Xzzz+/4A8EYLa0XOj4uPXWW6lfvz6vvPIKvXr1om7dupfc54wZM7Db7SxYsCDbCH4HDx5k0KBBzJw5k//+9795ezGX0Lp1a4YOHUp8fDy33nrrBdfr1KkTEyZMYMuWLVlayz788ENsNptnePiOHTvy2WefsXjx4izd9ebMmZNle3Xq1KF27dps376dV155pUBfk4gUTwpOIlLsrFixIttw2QA9evTgf//7H9dffz3t2rXjgQceoHr16iQmJvLXX3/x1Vdfec5z6NWrFwsWLGDUqFHcfvvtHDhwgJdeeomKFSvy559/FvErujC73c6LL77I/fffz+23387QoUM5deoUL774IhUrVszV8NZvvPEG//zzD0OGDOG7777j1ltvJTIykuPHj7Ns2TJmzZrFp59+SqNGjWjRogV16tTh8ccfJz09nYiICBYuXJiv4abvuusuxo4dy1133UVKSkq2LmVt27ZlxIgR3HvvvWzatIkbbriB4OBgYmJiWLt2LQ0bNuSBBx7I0z7tdjuvvfYad999N7169eL+++8nJSWF119/nVOnTvHqq6/m+XWcL6fh4gHat2/PRx99xLvvvsuAAQNo0aIF4eHhHDx4kOnTp7Njxw6ef/75iwb63Bo4cGCuR27MicPhYNGiRXTr1o2WLVty33330aFDByIiIjh16hS//PIL27dv9wxVfuLECb788ku6det2wQslv/nmm3z44YdMmDChwC9Om5tugI8++igffvghPXv2ZPz48VSrVo1vvvmGKVOm8MADD3gujjx48GDefPNNBg8ezMsvv0zt2rVZsmQJ3333XbZtvvvuu3Tv3p1u3boxZMgQKleuTFxcHLt27WLLli3Mnz+/QF+niHg3BScRKXbcF9s83969e6lfvz5btmzhpZde4tlnn+Xo0aOUKlWK2rVre85zArM15OjRo0ybNo2ZM2dSs2ZNnn76aQ4ePJhl2HJvMGLECGw2G6+99hq33nor1atX5+mnn+bLL78kOjr6ks8PCAjgm2++4ZNPPuGDDz7g/vvvJyEhgYiICJo3b87MmTPp3bs3YH6h/uqrrxg9ejQjR47E39+fO++8k8mTJ9OzZ8881R0eHs6tt97KnDlzaNu2reeLa2bvvvsu1113He+++y5TpkzB5XJRqVIl2rZtm+0k/9waMGAAwcHBTJgwgf79++NwOLjuuutYuXIlbdq0ydc2M5s4cWKOy1euXEnPnj2JjY1lyZIlTJ06lZMnTxIaGkqjRo346KOPLivsFLTatWuzbds23nnnHRYuXMj06dNJSkqidOnSNG7cmJdfftkTdj/++GNSUlK4//77L7i9ESNGMHLkSL766qsLdm0rTOXKlWPdunWMGzeOcePGkZCQQM2aNXnttdeytNYGBQWxYsUKHnnkEZ5++mlsNhtdu3bl008/zXZ8dOzYkQ0bNvDyyy8zZswYTp48SZkyZahfv36BtZKKSPFhMwzDsLoIERHJm1OnTnH11VfTp08f3nvvPavLERERueKpxUlExMvFxsby8ssv07FjR8qUKcP+/ft58803SUxMLJBR2kREROTSFJxERLycv78/+/btY9SoUcTFxREUFMR1113HtGnTuOaaa6wuT0REpERQVz0REREREZFL0AVwRURERERELkHBSURERERE5BIUnERERERERC6hxA0O4XK5OHz4MKGhoZ4ryouIiIiISMljGAaJiYlUqlTpkheVL3HB6fDhw0RFRVldhoiIiIiIeIkDBw5QpUqVi65T4oJTaGgoYL45YWFhFlcjIiIiIiJWSUhIICoqypMRLqbEBSd397ywsDAFJxERERERydUpPBocQkRERERE5BIUnERERERERC5BwUlEREREROQSStw5TiIiIiLifQzDID09HafTaXUpcoXx9fXF4XBc9nYUnERERETEUqmpqcTExJCUlGR1KXIFstlsVKlShZCQkMvajoKTiIiIiFjG5XKxd+9eHA4HlSpVws/PL1cjnInkhmEYHDt2jIMHD1K7du3LanlScBIRERERy6SmpuJyuYiKiiIoKMjqcuQKVK5cOfbt20daWtplBScNDiEiIiIilrPb9bVUCkdBtWDqCBUREREREbkEBScREREREZFLUHASEREREfECHTp0YMyYMVaXIRegwSFERERERPLgUufM3HPPPcyePTvP212wYAG+vr75rMo0ZMgQTp06xaJFiy5rO5KdgpOVDMO81ZCbIiIiIsVGTEyMZ37evHk8//zz7N6927MsMDAwy/ppaWm5CkSlS5cuuCKlwKmrnpX2roY3r4EF98PWj+HkfqsrEhEREbGcYRgkpaYX+WS4f9S+hAoVKnim8PBwbDab535ycjKlSpXis88+o0OHDgQEBPDxxx9z4sQJ7rrrLqpUqUJQUBANGzZk7ty5WbZ7fle96tWr88orrzB06FBCQ0OpWrUq77333mW9t6tXr6Zly5b4+/tTsWJFnn76adLT0z2Pf/755zRs2JDAwEDKlClD586dOXPmDACrVq2iZcuWBAcHU6pUKdq2bcv+/SXn+6tanKy0dw0kHIJfPzUngFJVofoNUKMdVG8H4ZWtrVFERESkiJ1Nc1L/+e+KfL87x3cjyK9gvh4/9dRTTJw4kVmzZuHv709ycjLNmjXjqaeeIiwsjG+++YZBgwZRs2ZNWrVqdcHtTJw4kZdeeol//etffP755zzwwAPccMMN1K1bN881HTp0iB49ejBkyBA+/PBD/vjjD+677z4CAgJ44YUXiImJ4a677uK1117j1ltvJTExkTVr1mAYBunp6fTp04f77ruPuXPnkpqayoYNG0rUxYoVnKzU7jGofj3sW2OGqMNb4FQ0bPvYnAAqNILGd0KD2yC0grX1ioiIiEiujBkzhr59+2ZZ9vjjj3vmH3roIZYuXcr8+fMvGpx69OjBqFGjADOMvfnmm6xatSpfwWnKlClERUUxefJkbDYbdevW5fDhwzz11FM8//zzxMTEkJ6eTt++falWrRoADRs2BCAuLo74+Hh69epFrVq1AKhXr16eayjOFJys5BcEtTqaE0DKaYj+2ezCt28NxGyH2F/N6ftnoWZHaNQf6vUCv2BraxcREREpJIG+DnaO72bJfgtK8+bNs9x3Op28+uqrzJs3j0OHDpGSkkJKSgrBwRf/TteoUSPPvLtL4NGjR/NV065du2jdunWWVqK2bdty+vRpDh48SOPGjenUqRMNGzakW7dudO3aldtvv52IiAhKly7NkCFD6NatG126dKFz587069ePihUr5quW4kjnOHkT/xCo3Rm6vgQjVsHjf0GP/0KVlmC44O/lsHAEvF4bFoyAfT9ZXbGIiIhIgbPZbAT5+RT5VJDdzs4PRBMnTuTNN9/kySefZMWKFWzbto1u3bqRmpp60e2cP6iEzWbD5XLlqybDMLK9Rvd5XTabDYfDwbJly/j222+pX78+b7/9NnXq1GHv3r0AzJo1i/Xr19OmTRvmzZvH1Vdfzc8//5yvWoojBSdvFlwGWt4Hw5fBQ1ugwziIqAFpZ+DXeTC7B8zsDn+vODdCn4iIiIh4nTVr1nDLLbcwcOBAGjduTM2aNfnzzz+LtIb69euzbt26LINgrFu3jtDQUCpXNs+rt9lstG3blhdffJGtW7fi5+fHwoULPes3bdqUcePGsW7dOho0aMCcOXOK9DVYSV31iosytaDD09D+KTi4CbZ+BNvnQvQ6+OhWqNwc2j8JtbtqeHMRERERL3PVVVfxxRdfsG7dOiIiInjjjTeIjY0tlPOE4uPj2bZtW5ZlpUuXZtSoUUyaNImHHnqI0aNHs3v3bv79738zduxY7HY7v/zyC8uXL6dr166UL1+eX375hWPHjlGvXj327t3Le++9x80330ylSpXYvXs3e/bsYfDgwQVev7dScCpubDaIamFOHZ6Gn/4Hm2fDoU0wpx9UbAw3PAF1eoJdDYoiIiIi3uC5555j7969dOvWjaCgIEaMGEGfPn2Ij48v8H2tWrWKpk2bZlnmvijvkiVLeOKJJ2jcuDGlS5dm2LBhPPvsswCEhYXx448/MmnSJBISEqhWrRoTJ06ke/fuHDlyhD/++IMPPviAEydOULFiRUaPHs39999f4PV7K5uR2wHrrxAJCQmEh4cTHx9PWFiY1eUUjMQjsP5t2DjT7MYHENkQur9qjtonIiIi4qWSk5PZu3cvNWrUICAgwOpy5Ap0sWMsL9lATRJXgtBI6Pp/MOY3c4hzv1A48hvM7gnzh8CpA1ZXKCIiIiJSrCk4XUmCy0Cn5+GR7dB8KNjssGMhTG4Bq16FtLNWVygiIiIiUiwpOF2JgstArzdhxGqo1hbSz8KqCWaA2rFQI/CJiIiIiOSRgtOVrGIjGPIN3D4TwqpA/AGz697sXnB4m9XViYiIiIgUGwpOVzqbDRrcBqM3mkOZ+wTA/rXwXgdY+AAkHLa6QhERERERr6fgVFL4BUHHf5kBqsHtgAHb58DbzWDlK5By2uoKRURERES8loJTSVOqKtw+A4Yvh6hWkJYEq/9jBqgtH4HLaXWFIiIiIiJeR8GppKrSHIZ+B3d8ABHV4XQsLB4N794AOxaBy2V1hSIiIiIiXkPBqSSz2eCaPvDgBvM6UAHhcOR3mH8PTGkF2+aAM83qKkVERERELKfgJODjD20egoe3QfunIaAUHN8Dix6At5rChvd1DSgRERGRAtahQwfGjBnjuV+9enUmTZp00efYbDYWLVp02fsuqO2UJApOck5Qaeg4Dh79HbqMh+Dy5hDmSx6HSQ1hzUSNwiciIiIlXu/evencuXOOj61fvx6bzcaWLVvyvN2NGzcyYsSIyy0vixdeeIEmTZpkWx4TE0P37t0LdF/nmz17NqVKlSrUfRQlBSfJzj8U2j4CY36DnhPNASXOHIPl4+GNejDzJvjlPUg8YnWlIiIiIkVu2LBhrFixgv3792d7bObMmTRp0oRrr702z9stV64cQUFBBVHiJVWoUAF/f/8i2deVQsFJLsw3AFoMh4e2QJ9pEHWduTx6PXz7BLxR17yY7sYZcOZ4/vfjckH8Idi7BjbPhmXPw6d3w9TrzZC2aBT8+Dr8/gUc3grJ8QXy8kRERMRLGQaknin6yTByVV6vXr0oX748s2fPzrI8KSmJefPmMWzYME6cOMFdd91FlSpVCAoKomHDhsydO/ei2z2/q96ff/7JDTfcQEBAAPXr12fZsmXZnvPUU09x9dVXExQURM2aNXnuuedISzPPUZ89ezYvvvgi27dvx2azYbPZPDWf31Xvt99+48YbbyQwMJAyZcowYsQITp8+d7maIUOG0KdPH/773/9SsWJFypQpw4MPPujZV35ER0dzyy23EBISQlhYGP369ePIkXM/zG/fvp2OHTsSGhpKWFgYzZo1Y9OmTQDs37+f3r17ExERQXBwMNdccw1LlizJdy254VOoW5crg8MXmtxlTvEHYeeX8PsCOLQJ9q0xp2/GQlBZCK9iTmGVIbyyOR8SaV4n6sxRs+Xq9DHz9sxROH0UTu6H9IucQxW9PvuyoDJQuyt0e8XsYigiIiJXjrQkeKVS0e/3X4fBL/iSq/n4+DB48GBmz57N888/j81mA2D+/PmkpqZy9913k5SURLNmzXjqqacICwvjm2++YdCgQdSsWZNWrVpdch8ul4u+fftStmxZfv75ZxISErKcD+UWGhrK7NmzqVSpEr/99hv33XcfoaGhPPnkk/Tv35/ff/+dpUuX8sMPPwAQHh6ebRtJSUncdNNNXHfddWzcuJGjR48yfPhwRo8enSUcrly5kooVK7Jy5Ur++usv+vfvT5MmTbjvvvsu+XrOZxgGffr0ITg4mNWrV5Oens6oUaPo378/q1atAuDuu++madOmTJ06FYfDwbZt2/D19QXgwQcfJDU1lR9//JHg4GB27txJSEhInuvICwUnyZvwKtD6QXM6uR92LIQdCyBmOyQdN6eYbXnfrs0BEdWgdE0oXcu8jagOqachbi/E/ZMx/W2GrqQTsH0u/L0Cbp4MV3ct6FcqIiIickFDhw7l9ddfZ9WqVXTs2BEwu+n17duXiIgIIiIiePzxxz3rP/TQQyxdupT58+fnKjj98MMP7Nq1i3379lGlShUAXnnllWznJT377LOe+erVq/PYY48xb948nnzySQIDAwkJCcHHx4cKFSpccF+ffPIJZ8+e5cMPPyQ42AyOkydPpnfv3vznP/8hMjISgIiICCZPnozD4aBu3br07NmT5cuX5ys4/fDDD/z666/s3buXqKgoAD766COuueYaNm7cSIsWLYiOjuaJJ56gbt26ANSuXdvz/OjoaG677TYaNmwIQM2aNfNcQ14pOEn+RVSD68eYU1Kc2RqVcMi89cwfgtNHzPOmQspDcLlzk/t+qarm5PDN3X6TE8wue0seN0f/m3MHNBsCXV8G/8L9pUFERESKgG+Q2fpjxX5zqW7durRp04aZM2fSsWNH/v77b9asWcP3338PgNPp5NVXX2XevHkcOnSIlJQUUlJSPMHkUnbt2kXVqlU9oQmgdevW2db7/PPPmTRpEn/99RenT58mPT2dsLCwXL8O974aN26cpba2bdvicrnYvXu3Jzhdc801OBwOzzoVK1bkt99+y9O+Mu8zKirKE5oA6tevT6lSpdi1axctWrRg7NixDB8+nI8++ojOnTtzxx13UKtWLQAefvhhHnjgAb7//ns6d+7MbbfdRqNGjfJVS25Zeo7Tjz/+SO/evalUqVKuhkRcsGABXbp0oVy5coSFhdG6dWu+++67oilWLi6oNFRsBHW6Q8v7oMuLcNt0GPotPLwF7l8Nd8+HPlPMx9qMhkb9oFZHKFMr96EJICAMaraH+3+E60aZyzbPhmnXQ/QvhfLyREREpAjZbGaXuaKeMrrc5dawYcP44osvSEhIYNasWVSrVo1OnToBMHHiRN58802efPJJVqxYwbZt2+jWrRupqam52raRw/lWtvPq+/nnn7nzzjvp3r07X3/9NVu3buWZZ57J9T4y7+v8bee0T3c3ucyPuVyuPO3rUvvMvPyFF15gx44d9OzZkxUrVlC/fn0WLlwIwPDhw/nnn38YNGgQv/32G82bN+ftt9/OVy25ZWlwOnPmDI0bN2by5Mm5Wv/HH3+kS5cuLFmyhM2bN9OxY0d69+7N1q1bC7lS8Uq+gXDTBBi8GMKqwMm9MOsm+OEFSM/bPxgiIiIiedWvXz8cDgdz5szhgw8+4N577/V86V+zZg233HILAwcOpHHjxtSsWZM///wz19uuX78+0dHRHD58ruVt/fqs533/9NNPVKtWjWeeeYbmzZtTu3btbCP9+fn54XQ6L7mvbdu2cebMmSzbttvtXH311bmuOS/cr+/AgQOeZTt37iQ+Pp569ep5ll199dU8+uijfP/99/Tt25dZs2Z5HouKimLkyJEsWLCAxx57jPfff79QanWztKte9+7d8zR+/PkXBHvllVf48ssv+eqrr2jatGkBVyfFRs328MBPsPRp87yntW/CP6vMQBWQt6ZqERERkdwKCQmhf//+/Otf/yI+Pp4hQ4Z4Hrvqqqv44osvWLduHREREbzxxhvExsZmCQUX07lzZ+rUqcPgwYOZOHEiCQkJPPPMM1nWueqqq4iOjubTTz+lRYsWfPPNN54WGbfq1auzd+9etm3bRpUqVQgNDc02DPndd9/Nv//9b+655x5eeOEFjh07xkMPPcSgQYM83fTyy+l0sm3btizL/Pz86Ny5M40aNeLuu+9m0qRJnsEh2rdvT/PmzTl79ixPPPEEt99+OzVq1ODgwYNs3LiR2267DYAxY8bQvXt3rr76ak6ePMmKFSty/d7mV7EejtzlcpGYmEjp0hceVS0lJYWEhIQsk1yBAkvBrdOg34cQGGGeA/XFcHBd/BcWERERkcsxbNgwTp48SefOnalatapn+XPPPce1115Lt27d6NChAxUqVKBPnz653q7dbmfhwoWkpKTQsmVLhg8fzssvv5xlnVtuuYVHH32U0aNH06RJE9atW8dzzz2XZZ3bbruNm266iY4dO1KuXLkch0QPCgriu+++Iy4ujhYtWnD77bfTqVOnXPcKu5jTp0/TtGnTLFOPHj08p+lERERwww030LlzZ2rWrMm8efMAcDgcnDhxgsGDB3P11VfTr18/unfvzosvvgiYgezBBx+kXr163HTTTdSpU4cpU6Zcdr0XYzNy6kBpAZvNxsKFC/N0QL3++uu8+uqr7Nq1i/Lly+e4zgsvvOB5gzOLj4/P84lzUkwc2gyzekB6MrQeDd1evvRzRERExBLJycns3buXGjVqEBAQYHU5cgW62DGWkJBAeHh4rrJBsW1xmjt3Li+88ALz5s27YGgCGDduHPHx8Z4pcz9KuUJVbgZ9pprz6yfDlg+trUdEREREir1iORy5+4rM8+fPp3Pnzhdd19/fP1s/TikBGvQ1hypfNQG+HmteF6r69VZXJSIiIiLFVLFrcZo7dy5Dhgxhzpw59OzZ0+pyxJu1fwqu6QuuNJg3yLyAroiIiIhIPlganE6fPs22bds8I224R/yIjo4GzG52gwcP9qw/d+5cz8gi1113HbGxscTGxhIfH29F+eLtbDbzulGVroWzcTDnTkjWsSIiIiIieWdpcNq0aZNndA2AsWPH0rRpU55//nkAYmJiPCEK4N133yU9PZ0HH3yQihUreqZHHnnEkvqlGPANhDvnQGglOL4b5t8LznSrqxIREZHzeMl4ZXIFKqhjy2tG1SsqeRk5Q64gh7fBrO6QlgStRkL3/1hdkYiIiGAOK71nzx7Kly9PmTJlrC5HrkDx8fEcPnyYq666Cl9f3yyP5SUbFMvBIUTyrFITuPVd+GwQ/DINqreDer2srkpERKTEczgclCpViqNHjwLmNYVsNpvFVcmVwuVycezYMYKCgvDxubzoo+AkJUf9m6HtGPhpEnzzmDnKXmApi4sSERGRChUqAHjCk0hBstvtVK1a9bIDuYKTlCwdxsEfX8OJv2DZc3Dz21ZXJCIiUuLZbDYqVqxI+fLlSUtLs7ocucL4+flht1/+0A4KTlKy+AbAzZNh1k3mhXEb3AY1O1hdlYiIiGB223M4HFaXIZKjYncdJ5HLVq01tLjPnF/8MKSesbYeEREREfF6Ck5SMnX+N4RHwan9sOJlq6sRERERES+n4CQlk38o9Jpkzv88BQ5stLQcEREREfFuCk5SctXuDI3vAgxYPBrSU6yuSERERES8lIKTlGzdXoHgcnDsD1gz0epqRERERMRLKThJyRZUGnr815xfMxFif7e2HhERERHxSgpOIvVvgbq9wJVudtlzpltdkYiIiIh4GQUnEZsNek6EgHA4vBV+mWZ1RSIiIiLiZRScRABCK0CXl8z5lS/DqWhr6xERERERr6LgJOLWdBBUbQNpSbDkCTAMqysSERERES+h4CTiZrdD70lg94U9S2Hnl1ZXJCIiIiJeQsFJJLNydeD6R835b5+C5Hhr6xERERERr6DgJHK+do9B6VpwOhaWj7e6GhERERHxAgpOIufzDYBeb5rzG2fAgY3W1iMiIiIillNwEslJzfbQeABgwFePgDPN6opERERExEIKTiIX0vX/ILA0HN0B6ydbXY2IiIiIWEjBSeRCgstAt5fN+VX/gbi91tYjIiIiIpZRcBK5mMZ3QfV2kH4WvnlM13YSERERKaEUnEQuxmaDXpPA4Q9/L4df51ldkYiIiIhYQMFJ5FLKXgXtnzTnlzwBJ/dbW4+IiIiIFDkFJ5HcaDsGolpBSgIsGAHOdKsrEhEREZEipOAkkhsOH+j7HviFwoGfYe2bVlckIiIiIkVIwUkktyKqQ8//mvOrJsDBzZaWIyIiIiJFR8FJJC8a9Ydr+oLhhAXDIeW01RWJiIiISBFQcBLJC5sNer0BYVUg7h9Y+rTVFYmIiIhIEVBwEsmrwAi4dRpgg60fwa6vrK5IRERERAqZgpNIftRoB20fMecXPwQJMdbWIyIiIiKFSsFJJL86PgMVG8PZk7DoAXC5rK5IRERERAqJgpNIfvn4Qd/p4BMI/6yEr8dAWrLVVYmIiIhIIVBwErkc5a6GHq+b81s+gOmd4Ngea2sSERERkQKn4CRyua4dBAMXQHA5OPI7vNcets2xuioRERERKUAKTiIF4apOMHIt1GgPaUnmOU8L7oeURKsrExEREZECYDMMw7C6iKKUkJBAeHg48fHxhIWFWV2OXGlcTlj7Bqx8BQwXlK4Fd8yGio0u/Jz0VDgdCwmHzSkxxrw9fQRKVYNrboXIa8xrSImIiIhIgclLNlBwEikM+9fBF8Mh4RA4/CCiBrjSwXCa4cqVbk7ONEg+dentlakNDfqaIap8vUIvX0RERKQkUHC6CAUnKTJJcWaXvT1LL72uww9CK0JYpXO3wWXh4Cb4cxk4U86tW66eGaCa3AWlqhZe/SIiIiJXOAWni1BwkiJlGHB4K6SeAbtPxuTINO8DQWUgqPSFu+IlJ8Dub2HHQvjrB3Clmcv9QqD/x1CrY9G9HhEREZEriILTRSg4SbF29hTsXgIbp8OhzWZLVd/3zBYoEREREcmTvGQDjaonUpwEloImA+Deb6F+H3Cmwvx7zSAlIiIiIoVGwUmkOPLxh9tnQvNhgAHfPAar/mN2DRQRERGRAmdpcPrxxx/p3bs3lSpVwmazsWjRoks+Z/Xq1TRr1oyAgABq1qzJtGnTCr9QEW9kd0DPidD+afP+qldgyRPgcllbl4iIiMgVyNLgdObMGRo3bszkyZNztf7evXvp0aMH7dq1Y+vWrfzrX//i4Ycf5osvvijkSkW8lM0GHcdBj/8CNtj4PnwxzLw2lIiIiIgUGB8rd969e3e6d++e6/WnTZtG1apVmTRpEgD16tVj06ZN/Pe//+W2224rpCpFioGW90FgBCwcCTsWQHI8DJgHDl+rKxMRERG5IhSrc5zWr19P165dsyzr1q0bmzZtIi0tLcfnpKSkkJCQkGUSuSI1vB3u/gx8g+Hv5fDDC1ZXJCIiInLFKFbBKTY2lsjIyCzLIiMjSU9P5/jx4zk+Z8KECYSHh3umqKiooihVxBq1bjSHJwdYPxn+WGJtPSIiIiJXiGIVnABs510k1H0ZqvOXu40bN474+HjPdODAgUKvUcRS9XrBdQ+a84segFPR1tYjIiIicgUoVsGpQoUKxMbGZll29OhRfHx8KFOmTI7P8ff3JywsLMskcsXr/AJUbgbJp8zrPGmwCBEREZHLUqyCU+vWrVm2bFmWZd9//z3NmzfH11cnwYt4+PjB7bMgIBwObdL5TiIiIiKXydLgdPr0abZt28a2bdsAc7jxbdu2ER1tdi0aN24cgwcP9qw/cuRI9u/fz9ixY9m1axczZ85kxowZPP7441aUL+LdIqpBn4zrnP38DvzxjbX1iIiIiBRjlganTZs20bRpU5o2bQrA2LFjadq0Kc8//zwAMTExnhAFUKNGDZYsWcKqVato0qQJL730Em+99ZaGIhe5kLo9oPVoc37RA3Byn6XliIiIiBRXNsM9ukIJkZCQQHh4OPHx8TrfSUqG9FSY1d3sslfpWhj6ndmVT0RERKSEy0s2KFbnOIlIPvj4wR2zIKAUHN4CP/zb6opEREREih0FJ5GSoFRVuNV9vtMU+Gu5tfWIiIiIFDMKTiIlRZ3u0HKEOf/1o5CaZG09IiIiIsWIgpNISdLpeQirDKf2w+pXra5GREREpNhQcBIpSfxDoedEc37dZIj51dp6RERERIoJBSeRkqZOd6h/CxhO+OoRcDmtrkhERETE6yk4iZRE3V8D/3BzlL0N71tdjYiIiIjXU3ASKYlCK0CXF8z55ePh1AFLyxERERHxdgpOIiXVtUMg6jpIOwNLHoeSdS1sERERkTxRcBIpqex26D0J7L6wZyns/NLqikRERES8loKTSElWvh5c/6g5/+1TcPaUpeWIiIiIeCsFJ5GSrt1jUOYqOB0Ly1+0uhoRERERr6TgJFLS+QZA7/+Z85tmQvQv1tYjIiIi4oUUnEQEql8PTQea80seA2e6tfWIiIiIeBkFJxExdX4RAsIh9jez5UlEREREPBScRMQUXBY6PW/Or/g/OH3M2npEREREvIiCk4ic0+xeqNgYUuLhh39bXY2IiIiI11BwEpFz7A7oMdGc3/aJBooQERERyaDgJCJZRbWApoPM+SWPgctpbT0iIiIiXkDBSUSy6/yCBooQERERyUTBSUSyyzxQxPKXNFCEiIiIlHgKTiKSMw0UISIiIuKh4CQiOdNAESIiIiIeCk4icmEaKEJEREQEUHASkUvJPFDEL9OsrkZERETEEgpOInJxwWWh84vm/A8vwtE/rK1HRERExAIKTiJyac2GwFVdwJkCC0eAM83qikRERESKlIKTiFyazQa3TIbACIjZDqtfs7oiERERkSKl4CQiuRNaAXq+Yc6vmQgHN1lbj4iIiEgRUnASkdxr0Bca3gGGExaMgNQzVlckIiIiUiQUnEQkb3q8DqGVIO5vWKYL44qIiEjJoOAkInkTGAF93jHnN74Pfy23th4RERGRIqDgJCJ5V+tGaDnCnP/yQUiKs7YeERERkUKm4CQi+dP5RShTGxJjYMnjVlcjIiIiUqgUnEQkf/yC4NZ3weaA37+ALR9ZXZGIiIhIoVFwEpH8q9IM2j9pzn/1MGyfZ209IiIiIoVEwUlELs8NT0KzIWC4YNFIhScRERG5IvlYXYCIFHN2O/R8E7DB5lmw8H7AgMZ3Wl2ZiIiISIFRi5OIXD67HXq+Ac2HAgYsHAnb5lhdlYiIiEiBUXASkYJht0OPidB8GGDAolGw9ROrqxIREREpEApOIlJw7HbomSk8ffkgbP3Y6qpERERELpuCk4gULJvtvPA0GjbPtroqERERkcui4CQiBc8dnloMBwz46hFY/ToYhtWViYiIiOSL5cFpypQp1KhRg4CAAJo1a8aaNWsuuv4nn3xC48aNCQoKomLFitx7772cOHGiiKoVkVyz2aDHf6HdY+b9lf8H34wFl9PaukRERETywdLgNG/ePMaMGcMzzzzD1q1badeuHd27dyc6OjrH9deuXcvgwYMZNmwYO3bsYP78+WzcuJHhw4cXceUikis2G3R6Hrq/Dthg00z4bDCknbW6MhEREZE8sTQ4vfHGGwwbNozhw4dTr149Jk2aRFRUFFOnTs1x/Z9//pnq1avz8MMPU6NGDa6//nruv/9+Nm3aVMSVi0ietBoBd8wGhx/88TV82AeS4qyuSkRERCTXLAtOqampbN68ma5du2ZZ3rVrV9atW5fjc9q0acPBgwdZsmQJhmFw5MgRPv/8c3r27HnB/aSkpJCQkJBlEhELXNMHBi0E/3A48DPM6g7xB62uSkRERCRXLAtOx48fx+l0EhkZmWV5ZGQksbGxOT6nTZs2fPLJJ/Tv3x8/Pz8qVKhAqVKlePvtty+4nwkTJhAeHu6ZoqKiCvR1iEgeVL8ehn4LoZXg2B8wvQsc2Wl1VSIiIiKXZPngEDabLct9wzCyLXPbuXMnDz/8MM8//zybN29m6dKl7N27l5EjR15w++PGjSM+Pt4zHThwoEDrF5E8irwGhn0PZetA4mGY3QNitltdlYiIiMhF+Vi147Jly+JwOLK1Lh09ejRbK5TbhAkTaNu2LU888QQAjRo1Ijg4mHbt2vF///d/VKxYMdtz/P398ff3L/gXICL5VyoKhi6FT26HQ5vhg94waBFUvtbqykRERERyZFmLk5+fH82aNWPZsmVZli9btow2bdrk+JykpCTs9qwlOxwOwGypEpFiJKi0ec5TlZaQHG8OGHFQA72IiIiId7K0q97YsWOZPn06M2fOZNeuXTz66KNER0d7ut6NGzeOwYMHe9bv3bs3CxYsYOrUqfzzzz/89NNPPPzww7Rs2ZJKlSpZ9TJEJL8CwmHQAqjaBlIywlP0L1ZXJSIiIpKNZV31APr378+JEycYP348MTExNGjQgCVLllCtWjUAYmJislzTaciQISQmJjJ58mQee+wxSpUqxY033sh//vMfq16CiFwu/1AY+DnM6Q/71sDHfeHu+VAt55ZnERERESvYjBLWxy0hIYHw8HDi4+MJCwuzuhwRcUtNgrl3wt7V4BsEAz6DGu2srkpERESuYHnJBpaPqiciAoBfEAyYB7U6QVoSfHIH/L3S6qpEREREAAUnS/2w8wjDP9jIlFV/WV2KiHfwDYQ750DtbpB+1gxPmz+wuioRERERBScrxSYk88Ouo2zZf8rqUkS8h28A9P8IrukLrjT46mFY8iQ4062uTEREREowBScLlQs1ry91/HSKxZWIeBkff7h9JnR81ry/4V345DZIirO2LhERESmxFJwsVDbEDE7HEhWcRLKx2aD9E9D/Y/ANhn9WwfROcGy31ZWJiIhICaTgZKFyIedanErY4IYiuVevNwz7DsKrQtw/ML0z7Pne6qpERESkhFFwslDZUD8AUtJdJKbo/A2RC6rQEO5bkXGh3ASY0w9+egv0g4OIiIgUEQUnCwX5+RDs5wDguLrriVxcSDkY/CVcOxgwYNlzsHg0pKdaXZmIiIiUAApOFnMPEKHznERywccPer8FN/0HbHbY+jF8dKsGjRAREZFCp+BksbKe85z0q7lIrthscN1IGPAZ+IXC/rXw/o1wbI/VlYmIiMgVTMHJYudanJItrkSkmKndBYZ9bw4acXIvzOhsjrwnIiIiUggUnCymFieRyxBZ3xw0IqoVJMfDR31h00yrqxIREZErkIKTxXQRXJHLFFIOBi+Ghv3AcMLXj8LSceByWV2ZiIiIXEEUnCymi+CKFADfAOj7HnR81rz/8xRY+pSGKxcREZECo+BkMbU4iRQQmw3aPwF9pgE22PAe/PCCwpOIiIgUCAUni5UNMS+CqxYnkQLS5C7o9YY5/9MkWPNfS8sRERGRK4OCk8XOtTilYuiXcZGC0XwodH3ZnF/xf7B+irX1iIiISLGn4GQx9zlOqU4XCWfTLa5G5ArSZjR0+Jc5/9042DTL2npERESkWFNwsliAr4NQfx8Ajuk8J5GC1f5JaPOwOf/1o/DrZ9bWIyIiIsWWgpMXOHcRXAUnkQJls0GX8dB8GGDAwpGw6yurqxIREZFiSMHJC5y7CK6Ck0iBs9mgx3+h8QDzOk/z74VDW6yuSkRERIqZfAWnAwcOcPDgQc/9DRs2MGbMGN57770CK6wkUYuTSCGz2+Hmt6FOT3ClwZejIT3V6qpERESkGMlXcBowYAArV64EIDY2li5durBhwwb+9a9/MX78+AItsCRwD0muFieRQuTwgZvfgqAycHQHrH3T6opERESkGMlXcPr9999p2bIlAJ999hkNGjRg3bp1zJkzh9mzZxdkfSWCLoIrUkSCy0L318z5H1+HIzutrUdERESKjXwFp7S0NPz9zS/7P/zwAzfffDMAdevWJSYmpuCqKyHc5zipq55IEWhwG1zd3eyyt3g0uJxWVyQiIiLFQL6C0zXXXMO0adNYs2YNy5Yt46abbgLg8OHDlClTpkALLAkyXwRXRAqZzQa93gD/MDi0GX6eanVFIiIiUgzkKzj95z//4d1336VDhw7cddddNG7cGIDFixd7uvBJ7qnFSaSIhVWCrv9nzq/4P4j7x9p6RERExOv55OdJHTp04Pjx4yQkJBAREeFZPmLECIKCggqsuJLC3eJ04kwKLpeB3W6zuCKREuDawfD757D3R1j8MNzzldkaJSIiIpKDfLU4nT17lpSUFE9o2r9/P5MmTWL37t2UL1++QAssCcpkjKqX5jSIP5tmcTUiJYTNBr3fAp9A2LcGNs+2uiIRERHxYvkKTrfccgsffvghAKdOnaJVq1ZMnDiRPn36MHWqzhfIK38fB+GBvoBG1hMpUqVrQKfnzPllz0P8IWvrEREREa+Vr+C0ZcsW2rVrB8Dnn39OZGQk+/fv58MPP+Stt94q0AJLCve1nHSek0gRazUSqrSAlAT4ZiwYhtUViYiIiBfKV3BKSkoiNDQUgO+//56+fftit9u57rrr2L9/f4EWWFJ4BohQi5NI0bI74ObJ4PCDPUthxwKrKxIREREvlK/gdNVVV7Fo0SIOHDjAd999R9euXQE4evQoYWFhBVpgSaEhyUUsVL4utHvMnP/uGUhJtLYeERER8Tr5Ck7PP/88jz/+ONWrV6dly5a0bt0aMFufmjZtWqAFlhQaklzEYm3HQEQNSIyB1f+xuhoRERHxMvkKTrfffjvR0dFs2rSJ7777zrO8U6dOvPnmmwVWXElyrsVJwUnEEr4B0ON1c/7nqXB0l7X1iIiIiFfJV3ACqFChAk2bNuXw4cMcOmSORNWyZUvq1q1bYMWVJOXU4iRivdpdoG4vcKXDkic0UISIiIh45Cs4uVwuxo8fT3h4ONWqVaNq1aqUKlWKl156CZfLVdA1lghqcRLxEt1eOXdtp9+/sLoaERER8RL5Ck7PPPMMkydP5tVXX2Xr1q1s2bKFV155hbfffpvnnnuuoGssEXSOk4iXiKgGN2QaKCI5wdp6RERExCv45OdJH3zwAdOnT+fmm2/2LGvcuDGVK1dm1KhRvPzyywVWYEnhbnE6cSYVl8vAbrdZXJFICdbmYdg2B+L+MQeK6KZ/00REREq6fLU4xcXF5XguU926dYmLi7vsokqiMhkXwHW6DE4maUhyEUv5+EP3TANFHNlpbT0iIiJiuXwFp8aNGzN58uRsyydPnkyjRo0uu6iSyNdhJyLIF9C1nES8Qu3OUK83GE5Y8rgGihARESnh8tVV77XXXqNnz5788MMPtG7dGpvNxrp16zhw4ABLliwp6BpLjLIh/pxMSuP46RTqEGp1OSLSbQL8+QPs/wl+mw+N+lldkYiIiFgkXy1O7du3Z8+ePdx6662cOnWKuLg4+vbty44dO5g1a1ZB11hiuM9z0gARIl6iVBS0f8Kc//5ZSI63th4RERGxTL6v41SpUiVefvllvvjiCxYsWMD//d//cfLkST744IM8bWfKlCnUqFGDgIAAmjVrxpo1ay66fkpKCs888wzVqlXD39+fWrVqMXPmzPy+DK/iHllPQ5KLeJHWo6HMVXD6CHxxH6Tr71NERKQkyndwKgjz5s1jzJgxPPPMM2zdupV27drRvXt3oqOjL/icfv36sXz5cmbMmMHu3buZO3fuFXPRXQ1JLuKFfPzhlinmtZ3+/A4+uwfSdR6iiIhISWNpcHrjjTcYNmwYw4cPp169ekyaNImoqCimTp2a4/pLly5l9erVLFmyhM6dO1O9enVatmxJmzZtirjywuHpqqcWJxHvUrUV3DUXfAJgz7cwf4jCk4iISAljWXBKTU1l8+bNdO3aNcvyrl27sm7duhyfs3jxYpo3b85rr71G5cqVufrqq3n88cc5e/bsBfeTkpJCQkJClslblc0YklwtTiJeqFZHuHMOOPxh9zfw+b3gTLO6KhERESkieRpVr2/fvhd9/NSpU7ne1vHjx3E6nURGRmZZHhkZSWxsbI7P+eeff1i7di0BAQEsXLiQ48ePM2rUKOLi4i54ntOECRN48cUXc12XldwtThqOXMRLXdUJ7poDcwfAH1/D50Ph9png8LW6MhERESlkeWpxCg8Pv+hUrVo1Bg8enKcCbDZblvuGYWRb5uZyubDZbHzyySe0bNmSHj168MYbbzB79uwLtjqNGzeO+Ph4z3TgwIE81VeUdI6TSDFwVWe48xNw+MGuxfDFMLU8iYiIlAB5anEqyKHGy5Yti8PhyNa6dPTo0WytUG4VK1akcuXKhIeHe5bVq1cPwzA4ePAgtWvXzvYcf39//P39C6zuwlQ+o8Up7kwKTpeBw55zgBQRi9XuAv0/hk/vhp1fgs0OfaeDI1+XxhMREZFiwLJznPz8/GjWrBnLli3LsnzZsmUXHOyhbdu2HD58mNOnT3uW7dmzB7vdTpUqVQq13qJQOtgPmw1cBsSdUXc9Ea92dTfo/xHYfWHHQni/I+xeCoZhdWUiIiJSCCwdVW/s2LFMnz6dmTNnsmvXLh599FGio6MZOXIkYHazy9z1b8CAAZQpU4Z7772XnTt38uOPP/LEE08wdOhQAgMDrXoZBcbHYad0kDlAhK7lJFIM1OkO/T4Ev1CI/RXm9ofpneGv5QpQIiIiVxhLg1P//v2ZNGkS48ePp0mTJvz4448sWbKEatWqARATE5Plmk4hISEsW7aMU6dO0bx5c+6++2569+7NW2+9ZdVLKHC6CK5IMVO3BzyyHdo+Ar5BcGgTfNwXZnWHvRe/oLeIiIgUHzbDKFk/iyYkJBAeHk58fDxhYWFWl5PNwOm/sPav47zRrzF9ry3+3Q9FSpTTR2Htm7BxBjgzfvyocQN0eQkqNbG0NBEREckuL9nA0hYnyc59LSe1OIkUQyHl4aYJ8Mg2aDHcPP9p74/w/o2wcoJG3xMRESnGFJy8jPtaThqSXKQYC6sEPSfCw1ugfh8wnLD6VfP8p6N/WF2diIiI5IOCk5c5d46TRtUTKfZKVYV+H8BtMyCgFMRsg3dvgHVvg8tpdXUiIiKSBwpOXkYXwRW5AjW8HUb9DFd1Mc99+v5ZmN0L4vZaXZmIiIjkkoKTl3F31dM5TiJXmLCKcPd86P0/8AuB6HUwtS1s/cTqykRERCQXFJy8jFqcRK5gNhs0GwIP/ATV2kLaGfhyFCx7Hlwuq6sTERGRi1Bw8jLuFqe4pFTSnfoiJXJFiqgO93wN7Z827//0P5g/GFKTLC1LRERELkzBycuUDvbDbgPDMMOTiFyh7HboOA76vg8OP9j1FczuCYlHrK5MREREcqDg5GUcdhulg9VdT6TEaNQPBn8JgaXh8BaY3gmO7LS6KhERETmPgpMXOncRXLU4iZQI1drA8B+gzFUQfwBmdIW/frC6KhEREclEwckL6SK4IiVQmVowbBlUux5SE+GTfrDhfbPfroiIiFhOwckLlQvRkOQiJVJQaRi0EBoPAMMJSx6HxQ9BWrLVlYmIiJR4Ck5eSC1OIiWYjx/0mQKdXwCbHbZ+BLO6Q/xBqysTEREp0RScvFBZtTiJlGw2G1z/KNz9OQRGmINGvNse9q6xujIREZESS8HJC5UNNQeHUIuTSAl3VScYsQoqNISk4/DhLbD+HZ33JCIiYgEFJy9ULiQAUIuTiGBeLHfo99Cov3ne03f/ggX36WK5IiIiRUzByQu5W5w0HLmIAOAXBLe+Czf9B2wO+G0+TO8Msb9bXZmIiEiJoeDkhdyj6sWdSSXN6bK4GhHxCjYbXDcS7vkKgsvB0R3wXgdYMxGc6VZXJyIicsVTcPJCEUF+OOw2wAxPIiIe1dvCA+ugTg9wpcHy8TDrJjj+l9WViYiIXNEUnLyQ3W6jTLAGiBCRCwgpD3fOgT7TwD8MDm6EadfDz9PApVZqERGRwqDg5KXcQ5If0wARIpITmw2a3AWj1kPNDpB+FpY+BR/eDKeira5ORETkiqPg5KV0EVwRyZXwKjBwIfT4L/gGwb41MLUt/PmD1ZWJiIhcURScvJQugisiuWa3Q8v7YORaqNISUhJgzh2w4X2rKxMREbliKDh5KbU4iUielakFQ76BJneD4YIlj8O3T4PLaXVlIiIixZ6Ck5cqG6JrOYlIPvj4wS3vQKfnzfu/TIVPB0DKaWvrEhERKeYUnLzUuRanZIsrEZFix2aDdo/BHbPBJwD2LDWHLI8/ZHVlIiIixZaCk5eqEBYAQEy8gpOI5NM1t5pd94LLQexv8P6NcHir1VWJiIgUSwpOXiqqdBAAh0+dxekyLK5GRIqtKs1h+HIoVw9Ox8KsHrB/vdVViYiIFDsKTl4qMiwAX4eNNKdBbIJanUTkMkRUg2HfQc2OkJZknvN04m+rqxIRESlWFJy8lMNuo3KpQAAOxCVZXI2IFHsB4XDnHKh0LZyNg0/ugKQ4q6sSEREpNhScvJi7u56Ck4gUCL8guOtTCI+CuL/h07shXZc8EBERyQ0FJy9WJSIjOJ08a3ElInLFCI2EAZ+BfxhEr4MvR4Oh8yhFREQuRcHJi0WVVlc9ESkEkfWh3wdgc8Bvn8GqV62uSERExOspOHmxqAh11RORQlLrRuj1hjm/+lXYNtfaekRERLycgpMX85zjdFLBSUQKQbMh0HaMOb/4Idi31spqREREvJqCkxeLijC76h1JSCE5zWlxNSJyRer0b6h/C7jSzMEiNEy5iIhIjhScvFjpYD+C/BwAHDqlASJEpBDY7XDru1C5OSSfgs/ugTT9eyMiInI+BScvZrPZdJ6TiBQ+30Do/zEElYUjv8HScVZXJCIi4nUUnLzcufOc9AuwiBSisIrQ9z3ABptnwe9fWF2RiIiIV1Fw8nLuIckPqsVJRArbVZ2g3VhzfvEjOt9JREQkEwUnL+fpqqeR9USkKHT4F1RtA6mJMP8eSEu2uiIRERGvoODk5Txd9eLUVU9EioDDB26fAUFlIPY3+P4ZqysSERHxCgpOXs7dVU8tTiJSZMIqwa3vmfMbp8OOhdbWIyIi4gUsD05TpkyhRo0aBAQE0KxZM9asWZOr5/3000/4+PjQpEmTwi3QYu6ueqeS0khITrO4GhEpMWp3husfNee/fAji/rG2HhEREYtZGpzmzZvHmDFjeOaZZ9i6dSvt2rWje/fuREdHX/R58fHxDB48mE6dOhVRpdYJ9vehdLAfoCHJRaSIdXwWoq7LON9pCKSnWF2RiIiIZSwNTm+88QbDhg1j+PDh1KtXj0mTJhEVFcXUqVMv+rz777+fAQMG0Lp16yKq1FpRERnd9XSek4gUJff5ToGlIWY7LLwfnGr5FhGRksmy4JSamsrmzZvp2rVrluVdu3Zl3bp1F3zerFmz+Pvvv/n3v/+dq/2kpKSQkJCQZSpuqmQMEHFQ5zmJSFELrwK3vQ92X/Ncp8/uUcuTiIiUSJYFp+PHj+N0OomMjMyyPDIyktjY2Byf8+eff/L000/zySef4OPjk6v9TJgwgfDwcM8UFRV12bUXNc+Q5OqqJyJWuKoz3PkJOPxh9zcw905I1b9HIiJSslg+OITNZsty3zCMbMsAnE4nAwYM4MUXX+Tqq6/O9fbHjRtHfHy8Zzpw4MBl11zUzo2sp656ImKRq7vB3Z+BbxD8vQI+uQNSEq2uSkREpMhYFpzKli2Lw+HI1rp09OjRbK1QAImJiWzatInRo0fj4+ODj48P48ePZ/v27fj4+LBixYoc9+Pv709YWFiWqbhRi5OIeIWaHWDgAvALhf1r4aNb4ewpq6sSEREpEpYFJz8/P5o1a8ayZcuyLF+2bBlt2rTJtn5YWBi//fYb27Zt80wjR46kTp06bNu2jVatWhVV6UWuquccp7MYhmFxNSJSolVrDfd8CQGl4OBG+KA3nDlhdVUiIiKFLncnChWSsWPHMmjQIJo3b07r1q157733iI6OZuTIkYDZze7QoUN8+OGH2O12GjRokOX55cuXJyAgINvyK02lUoHYbHA2zcnx06mUC/W3uiQRKckqN4MhX8OHfSD2V5jdEwYvgtAKVlcmIiJSaCw9x6l///5MmjSJ8ePH06RJE3788UeWLFlCtWrVAIiJibnkNZ1KAj8fOxXDAgA4oJH1RMQbVGgI9y6B0IpwbBdMaQ2/fQ5qFRcRkSuUzShhfb8SEhIIDw8nPj6+WJ3v1O/d9WzYG8f/7mzCLU0qW12OiIgp7h+YNwiO/G7er9MTer2h1icRESkW8pINLB9VT3JHA0SIiFcqXRPuWwkd/mVe62n3N/BOS9g2R61PIiJyRVFwKiY8Q5LHaUhyEfEyPn7Q4Sm4fzVUbALJ8bDoAZjTD+IPWV2diIhIgVBwKiY8LU46x0lEvFXkNTB8OXT6Nzj84M/vYcp18Mu7kJ5qdXUiIiKXRcGpmIgqreAkIsWAwwfajYWRa6FKC0hJgG+fhMnNYNtccDmtrlBERCRfFJyKCXdXvcOnkkl3uiyuRkTkEsrVgaHfQc83ICQSTkXDopEwtS3s+lrnP4mISLGj4FRMRIYG4Oew43QZxMQnW12OiMil2R3QYhg8vA06vwAB4ebQ5fPuhumdYe+PVlcoIiKSawpOxYTdbqNyRMYAEequJyLFiV8QXP8oPPIrtHsMfIPg0Cb4oDd8fLs5pLmIiIiXU3AqRtznOR3UyHoiUhwFloJOz5stUC3uM4cv/2sZvHMdrH4N0lOsrlBEROSCFJyKkSgvbXEyDINjifrCIyK5FBoJPf8Lo36Gmh3AmQIrX4apbeCf1VZXJyIikiMFp2LEM7Kel10Ed/zXO2nx8g98vvmg1aWISHFS9ioYtAhum2EOIHHiL/jwZvjiPjh91OrqREREslBwKkbOXcvJe7rqLdx6kFk/7QPgreV/4nRppCwRyQObDRreDqM3QssRgA1++wzebg4bp4NLo4iKiIh3UHAqRtxDkkd7SYvT7thExi34DTC/+0THJfH9jliLqxKRYikgHHq8DvetgIpNICUevnkMZnaFIzusrk5ERETBqThxtzgdS0whOc3ai0gmJqfxwMebSU5z0a52WR5oXwuAd3/8B0PXZxGR/Kp8rRmeur8OfqFwcCO8ewP88AKkesePRiIiUjIpOBUjpYJ8CfH3AeCghQNEGIbBk5//yj/Hz1ApPID/3dmUe9vWwM9hZ9uBU2zef9Ky2kTkCmB3QKsRMHoD1O0FrnRY+yZMbQ1/Lbe6OhERKaEUnIoRm81GFffIehYOST5j7V6+/T0WX4eNd+6+ltLBfpQL9afvtZUBeO9HXZNFRApAWCW48xO4cw6EVYaT++DjvvDFcDh9zOrqRESkhFFwKmY8I+tZ1OK0YW8cE779A4DnetWnadUIz2PD29UAYNmuI/xz7LQl9YnIFahuT3jwF2j1ANjs8Nt8eKcl7FtrdWUiIlKCKDgVM56R9SwYIOJoYjKj52zB6TK4pUklBl1XLcvjV5UPpVPd8hiG2SolIlJg/EOh+6swfDlENoSzcfBhH9g2x+rKRESkhFBwKmbcI+sVdVe9dKeLh+Zs5WhiCrXLhzChb0NsNlu29e67oSYAn28+yInTuiiuiBSwytfC8GVwza3gSoNFD8APL2rYchERKXQKTsVMVYu66k1Z9Te/7I0j2M/B1IHNCPLzyXG9VjVK06hKOCnpLj76eX+R1igiJYRvINw2E254wry/9g34fIhG3RMRkUKl4FTMeM5xKsKueoZhMG/jAQBeuPkariofcsF1bTYb97UzW50+XL/f8mHTReQKZbfDjc9Cn2lg94WdX8LsnpCoa8mJiEjhUHAqZtyj6iUkpxN/Nq1I9rnnyGkOnTqLv4+dXo0qXXL97g0qULlUIHFnUvliy8EiqFBESqwmd8E9iyGwNBzeAu93gtjfrK5KRESuQApOxUyQnw9lQ/yAomt1WvHHUQBa1ypDoJ/jkuv7OOwMu94cYW/Gmr24XLogrogUomptYPgPUKY2JByEGd3gjyVWVyUiIlcYBadiqEoRj6y3MiM43Vi3fK6f069FFGEBPvxz/AzLM54vIlJoytQyB42ocQOknYFPB8CaiWDohxsRESkYCk7FUFFeyyk+KY3N0ScB6Fgn98EpxN+HuzOGK39fF8QVkaIQGAEDF0CL4YABy8fDghGQlmx1ZSIicgVQcCqGoiKKbkjy1X8ew+kyqF0+xBPYcmtIm+r4Omxs2BfH1ozwJSJSqBy+0HMi9Pgv2Bzw22cwu4cGjRARkcum4FQMFWWLU3666blFhgVwS5PKAJ5R+UREikTL+2DQQggoBYc2w3sd4dAWq6sSEZFiTMGpGIoqonOcnC6DVbvN4NQxH8EJoGfDigD8sjeuwOoSEcmVmu3hvhVQtg4kHoZZ3eH3L6yuSkREiikFp2KoVvlgAPadSOJsauFdJ2nbgVOcTEojNMCHZtUi8rWNZtUjsNlg7/EzHE3UeQYiUsTcg0bU7grpyfD5UFj4AJw5YXVlIiJSzCg4FUMVwgKIDPPH6TL47VB8oe3H3U3vhqvL4evI36ESFuBLvQphAGzcq/OcRMQCAeFw16fQ5mHz/vY5MLk5bP1Yo+6JiEiuKTgVQzabjaZRZgtQYQ664L5+0415GE0vJy1rlAZgw179wisiFrE7oOtLMGwZlL8GzsbBlw/C7F5wbI/V1YmISDGg4FRMNalaCjC70xWG2PhkdsYkYLNB+zrlLmtbrTKCk85zEhHLRbWE+1dDl/HgEwj718LUNrDiZQ1bLiIiF6XgVEw1jSoFwNboU4WyffegEI2qlKJsiP9lbat5dTM47T6SSHxS2mXXJiJyWRy+0PYRePAXqN0NXGnw42swtTVs+RBSz1hdoYiIeCEFp2KqYZVwHHYbsQnJxMQX/PWcCqqbHkC5UH9qlgvGMGDTfrU6iYiXiKgGA+ZBvw8htCLE/QOLH4KJ9WDJk3D0D6srFBERL6LgVEwF+flQJzIUgG0F3OqUku5k7V/HgfxdvyknrTznOSk4iYgXsdmg/i3w4Aaz+15EdUiJhw3vwpRWMKsn/PY5pKdaXamIiFhMwakYa5pxntPWAj7PacPeOJJSnZQL9eeaSmEFss2WOs9JRLxZQJjZfe+hrTBwAdTtBTa7eQ7UF8Pgzfqw4v8gMdbqSkVExCIKTsVY06qFM7Keu5texzrlsNttBbLNFhnnOf1+KJ6k1PQC2aaISIGz2+GqTnDnJzDmd2j/tNmN78wx+PF1eLMBLBgBh7daXamIiBQxBadirEnGABG/HYonzekqsO26r99UUN30AKpEBFG5VCDpLqPQBrQQESlQ4ZWh4zgY8xvc8QFEXWcOJPHrPHivA8y8CXZ+CU79GCQiUhIoOBVjNcsGExbgQ3Kai92xiQWyzX+OnWbfiSR8HTaur315w5CfT931RKRYcvjCNX1g2Hdw3wpo2A/sPhC9Hj4bDG81hd+/sLpKEREpZApOxZjdbqNJAXfXc3fTa1mjNCH+PgWyTTd3dz1dCFdEiq3KzeC2981ufO0eh8DSEB8Nnw+F758Dl9PqCkVEpJAoOBVz7u56BTVAxMrd7vObCq6bnpu7xWlr9ClS0wuua6GISJELqwidnoOxO+H6R81l696COf3h7ClLSxMRkcKh4FTMuUfWK4ghyU+npHuGCy/I85vcapULpkywHynpLn47dKrAty8iUuR8A6HzC3DbDPAJhL+WwfROcPxPqysTEZECpuBUzDWpUgqAf46f4VTS5V1nZO2fx0hzGlQvE0TNciEFUF1WNptN5zmJyJWp4e0wdCmEVYYTf8H7N8Ke762uSkRECpCCUzEXEexHjbLBAGy7zO56nmHIC6G1ye3ceU4KTiJyhanUBEasgqqtISUB5vSDtZPAMCwuTERECoLlwWnKlCnUqFGDgIAAmjVrxpo1ay647oIFC+jSpQvlypUjLCyM1q1b89133xVhtd6pqfs8p8vorpea7uKHXQU/DPn53C1Om/edxOnSlwkRucKElIfBi6HZEMCAH/5tXvcpLdnqykRE5DJZGpzmzZvHmDFjeOaZZ9i6dSvt2rWje/fuREdH57j+jz/+SJcuXViyZAmbN2+mY8eO9O7dm61bS/aFCJtknOd0OQNErNp9lLgzqZQL9ad1zTIFU1gO6lUMI9Tfh8SUdHbFJBTafkRELOPjB70mQY//msOW//YZfNALTh+1ujIREbkMlganN954g2HDhjF8+HDq1avHpEmTiIqKYurUqTmuP2nSJJ588klatGhB7dq1eeWVV6hduzZfffVVEVfuXZpGmUOSbz9wClc+W3G+2HIQgD5NKuHjKLzDwmG30ay6Wa+664nIFctmg5b3wcAFEBAOBzea5z3F/m51ZSIikk+WBafU1FQ2b95M165dsyzv2rUr69aty9U2XC4XiYmJlC5d+oLrpKSkkJCQkGW60tStGIq/j534s2nsPXEmz88/eSbVc37Tbc2qFHR52bi76yk4icgVr2Z7GL4CSteC+AMwsxvs/tbqqkREJB8sC07Hjx/H6XQSGRmZZXlkZCSxsbG52sbEiRM5c+YM/fr1u+A6EyZMIDw83DNFRUVdVt3eyNdhp2HlcCB/5zkt3n6YNKfBNZXCqFshrICry65VRnDauC8OQydNi8iVruxVcN9yqHEDpJ6GuXfBurc1aISISDFj+eAQNpsty33DMLIty8ncuXN54YUXmDdvHuXLX3gwg3HjxhEfH++ZDhw4cNk1eyPP9ZwOnMzzc93d9G67tvBbmwAaVi6Fv4+dE2dS+ftY3lvIRESKncAIs9tes3sBA75/FhY/BOmXdxkJEREpOpYFp7Jly+JwOLK1Lh09ejRbK9T55s2bx7Bhw/jss8/o3LnzRdf19/cnLCwsy3QlalrVPG8ory1Ofx5J5NeD8fjYbdzSpFIhVJadn4/dE/TUXU9ESgyHL/R6E256FWx22PoRzO4Jx/ZYXZmIiOSCZcHJz8+PZs2asWzZsizLly1bRps2bS74vLlz5zJkyBDmzJlDz549C7vMYqNJxpDkf8QmcjbVmevnfZ7R2tShTnnKhPgXRmk5alnDHLlv4z4FJxEpQWw2uO4BGPAZ+IXCwQ0wrS2sehXSU6yuTkRELsLSrnpjx45l+vTpzJw5k127dvHoo48SHR3NyJEjAbOb3eDBgz3rz507l8GDBzNx4kSuu+46YmNjiY2NJT4+3qqX4DUqhgcQGeaP02Xw26HcvR/pThcLtxwC4PZmlQuzvGxaWTRARLrTpetHiYj1aneBUeugdldwpsKqCTCtHexfb3VlIiJyAT5W7rx///6cOHGC8ePHExMTQ4MGDViyZAnVqlUDICYmJss1nd59913S09N58MEHefDBBz3L77nnHmbPnl3U5XsVm81G06gIlu6IZWv0Sc/IdRez9q/jHE1MoVSQLx0L8aK3OWlatRQ+dhuHTp3l4MkkqkQEFfg+ktOc7DmSyI7DCfx+KJ4dhxPYFZNAaIAP3zzcjsiwgALfp4hIrpWqarY87VgI3z4Fx3fDrJug+VDo9G8ILGV1hSIikomlwQlg1KhRjBo1KsfHzg9Dq1atKvyCirEmVUtlBKdTuVr/i4zWppsbV8Lfx1GIlWUX5OdDg8rhbDtwig174wo0OE1d9TdfbjvEX0dPk55D61LK6VRmrN3Lv3rUK7B9iojki80GDfpCrY6w7HnY8iFsmgl/LIGuL0H9PuYFdUVExHKWj6onBadpxnlO2w6cuuS6CclpfL/DHJijqEbTO19hdNfbFZPAf5b+wR+xiaS7DCKCfGlXuyz3t6/JW3c15dW+DQH45Of9xCelFdh+RUQuS2AE3Pw2DPkGylwFp2NhwX3wZn1zBD4NICEiYjnLW5yk4DSsEo7DbiM2IZmY+LNUDA+84Lrf/BpDSrqLq8qH0KhKeBFWeU7rWmV498d/+GHXUZwuA4f90sPQX8rsn/YBcGPd8vxfnwZUDA/IMry9YRjMXrePP2IT+fiX/TzY8arL3qeISIGpfj2M/Mm8ztPG9+H0EXN+3dtQtTVcOxjq3wJ+wVZXKiJS4qjF6QoS5OdDnchQ4NLDkn+x+dy1m3Jz3azC0KZWWUoF+XL8dAq//HPisrcXdyaVRdvM7ocPdqxFpVKB2V6bzWZjZPtaAMxcu5fktNyPQCgiUiR8A6D9E/DoTrhzLlzdHWwOiF4Pix6AiXXhqzFwYKMuoisiUoQUnK4w5y6Ee+qC6+w7foZN+09it8GtTYt2NL3M/HzsdG9QAYCvfo257O3N3RBNSrqLhpXDuTbjulY56dWoIpVLBXLiTCrzMwKkiIjXcfhA3R4w4FN4dAd0eh4iqkNKAmyeBTM6w+QWsGYixB+yuloRkSuegtMV5tyFcE9ecJ0FGdduur52OSqEWzuyXO9G5kV3v/09hjSnK9/bSXO6+Gj9fgDubVv9oq1oPg47I26oCcB7P/5N+mXsV0SkSIRVhHaPwUNb4Z6voNGd4BsEJ/6E5ePhzWvgo1vh1/mQmmR1tSIiVyQFpyuM+0K4G/edZOD0X/hq+2FS0s91R3O5DM9oerdda11rk1urmmUoG+LPqaQ01v51PN/bWfp7LLEJyZQN8adno4qXXL9f8yhKB/txIO4sS36Pzfd+RUSKlN0ONW6Avu/C43vglnegWlvAgL9XwILhMLEOfPWIuvKJiBQwBacrTK1ywdzc2GzFWfvXcR6au5VWryznxa92sDs2kV/2xnHo1FlC/X3odk0Fi6sFh91Gz4ZmHV9vz393vVk/7QVg4HVVczW0eqCfgyFtqgPm8OWGvlyISHHjHwpNB8K9S+DhbdD+afPaUCkJsHm22ZXvnVbw0/8g8YjV1YqIFHs2o4R9Y0xISCA8PJz4+HjCwsKsLqfQHIhLYv6mA8zffJCY+GTP8rAAHxKS07mzRRSv3tbIwgrP2bQvjtunrSfU34eNz3YmwDdv15TafuAUt7zzE74OGz89fSPlQ3PX/fBUUiptXl1BUqqTD4a2pP3V5fJTvoiI93C5YP9PsPVj2PklpJ81l9scULsrNL0bruoMvhcedVVEpCTJSzZQi9MVKqp0EGO71mHtUzcy694W3HRNBXzsNhKS0wG4rZk1127KybVVI6gYHkBiSjqr9xzL8/PdrU29G1XKdWgCKBXkx10tqwIwddVfed6viIjXsduhRruMrny7off/oEoLMJyw51uYNxD+UwPm3Gm2SiVc/sA8IiIlha7jdIVz2G10rFOejnXKcywxhS+3HSLQz0Hzahceda6o2e02ejWqyPtr9vL1rzF56kJ4NCGZb34z/8d/b9saed73sOtr8MG6ffz8TxzbDpzynCMmIlLsBYRDsyHmdGw3bPsEfvsCEg6aIWrPt+Z6FZvA1TdBnZugQmMzfImISDbqqide4deDp7h58k8E+jrY/Fxngvxyl+nfWLaHt5b/SfNqEXz+QJt87fuxz7bzxZaD3HRNBaYNapavbYiIFAuGAUd+hz1LYfdSOLQZyPQ1ILC0eRHeGjeYU9mrwaJr/YmIFIW8ZAO1OIlXaFg5nKqlg4iOS2L5rqP0zhjg4mJS0p3M+cUcgnxI2+r53vfI9jX5YstBvtsZy9/HTlOrXEi+tyUi4tVsNqjQ0JxueAJOH4U/v4fd38I/q+BsHOxabE4AIZFQvZ0ZoqJamkHKnrfzUEVErhQKTuIVbDYbvRtX5J2Vf/P1r4dzFZy+2h7D8dOpVAwPuKwRAmtHhtK5XiQ/7DrCe6v/4T+3e8egGSIihS6kvDkyX9OB4EyDw1th72rYuwYO/AKnj8Dvn5sTmNeOqtAIKjXNmJpAmasUpkSkRFBwEq/Ru3El3ln5Nyt3HyMhOY2wAN8LrmsYhmdQiEGtq+HruLw++Q90qMUPu46wYOtBxnSpTcVwjTglIiWMw9dsVYpqabZGpSXDoU2w90fYtxZitkPqaTjwszm5+YVAxcZQ+VqodK15W6qauviJyBVHwUm8Rp3IUK4qH8JfR0+zbMeRi478t3HfSXYcTsDfx85dLape9r6bVYugVY3S/LI3jteW7ubN/k0ue5siIsWab4B5vlP16837Liec+AsObzNbpg5vhdhfzTC1/ydzcgsqcy5EVWkBVZpDoPcMSiQikh8KTuI1bDYbvRtV4s0f9vDVr4cvGpxmrzNbm25tWpmIYL8C2f+/etSjz5SfWLj1EHe3qkrz6qULZLsiIlcEuwPK1TGnxv3NZS6nOWLf4a3mQBOHt0Ds75B0Av5aZk5uZeuca9GKagVlamsEPxEpVjSqnniVv4+dptPE1fjYbWx8pnO2UOR0Gbyz8i8m/bAHlwFLx7SjboWC+xyf+vxX5m06wDWVwlg8+nocdnU1ERHJk/QUMzwd3mKGqYMbzZaq8wWUMluj3GGqcjPwDy3yckWkZNOoelJs1SoXQv2KYeyMSWDpjljPBWoBDp06y6OfbmPDvjgABl1XrUBDE8ATN9Vhye8x7DicwKcbo7m7VbUC3b6IyBXPxx+qNDMn7jOXnTluBqgDv8CBDXBoCySfytoqZbND+fpmiKrSEqpeB6Xzfn0+EZHCohYn8TpTV/3Nf5b+QZtaZZhz33UAfLX9MP9a+BuJyekE+zkYf0sD+l5bGVshnHw8c+1exn+9k4ggX1Y+3oFSQQXTFVBERDI408zzow5shIMbzNv46OzrRVSHWjeaU/V2EFiqqCsVkStcXrKBgpN4nQNxSbR7bSV2G6x4rAOTV/7F55sPAtAkqhT/u7MJ1coEF9r+05wuer61hj1HTjO4dTXG39Kg0PYlIiIZEmIyQlTGdHgLuNLPPW6zQ+Xm54JUleYaBl1ELpuC00UoOBUPfd75iW0HThHo6+BsmhO7DR7seBUPd6p92UOP58a6v44zYPov2G3wzcPtqFdRx4qISJFKSYR9P8HfK8zpxJ9ZHw8sDVd1hqu7mUEqSAP6iEjeKThdhIJT8TBj7V5e+nonAJXCA5h0Z1Na1ija/ymO+mQzS36LpWWN0swbcV2hdAsUEZFcOnUA/lkJfy03b5Pjzz1ms0PUdXB1V6jdDcrX03WkRCRXFJwuQsGpeDiVlMrIjzcTFRHEsz3rEx504YvhFpaDJ5Po/MZqktNcvH1XU3o3rlTkNYiISA6c6eZAE39+B3u+h2O7sj4eWhFqdoCaHc3b0EgrqhSRYkDB6SIUnCQv/vfDn7z5wx4qhgew/LH2BPlpIEoREa9zcj/8+T3s+Q72rYH05KyPRzYwA1Stjuaw57oYr4hkUHC6CAUnyYvkNCed31jNwZNnGd3xKh7vVsfqkkRE5GLSkiF6vdmd7++V5uh954uoDpWaQsUmUKkJVGysMCVSQik4XYSCk+TV0t9jGfnxZvwcdu5sGUXV0kFULxNMtTJBRJUOIsBXozqJiHitM8fhn1VmkNq3Fk7uy3m9iOpQprZ5e/7kH1I0tYpIkVNwuggFJ8krwzC4Z9ZGftxzLNtjNhtUCAsgKiKIQD8Hvg47fj42fB32jHk7AT4OOtUrT5taZTTAhIiI1ZLiIGY7xGyDw9vM2wuFKbegshASaY7cF1QagsqYo/oFlTHvB5Y2W6zcU0A4ONS1W6Q4UHC6CAUnyY/kNCeLtx9m7/Ez7D9xhv0nkog+kURiSvqln5yhYeVwRravxU0NKuCwK0CJiHiNpDg48rsZoOL2mrfu6Wxc/rbpHw5BEZkCVsYUnGk+qCyElIfgsuAfppEARSyg4HQRCk5SUAzDIO5MKvvjkjh08iwp6S7SnOaUmu4izWmQ5nRx+NRZFm07RHKaC4DqZYIYcUMt+l5bWd38RES8XXK8OfhE0nEzYCXFQdIJM1AlnciYP5kxnYKUhPztx+EPweUgpFzGbXkIqwxhlTLdVoKAUgpYIgVIwekiFJzECidOp/DB+v18uH4fp5LSACgX6s+9basz8LpqhAUU/XDrIiJSCJxpZtg6e9IMWZkDlns6c8IMYmcyptTE3G/fJxDCKkJw+YyQVT5T4Cqf0YKVEb78QxWyRC5BwekiFJzESmdS0pm38QDT1/zD4XhzuNzwQF9G3FCTIW2qE+yvPvEiIiVO2lk4fTQjSB01508fgYTDmaZDee826BOQEaLKngtYnu6DpXO+9fErnNco4qUUnC5CwUm8QZrTxeJth5m6+m/+OnoagNLBftx/Q00Gt65OoJ+68ImIyHnSzkJiDCTEwJlj5nT6qBm2zhzPOp96On/78AvJCFLnBSz/ELO1yzfT5BMAvkFm2HL4g8MPHL7gk2ne7gs2O9gdYHOA3W7eupdhM+dttqzzaimTIqLgdBEKTuJNnC6Dr389zKQf/mTv8TMAlA3xZ1SHWgxoVTVP50AZhsHZNCeJyemE+Puo9UpEpCRLTTovXB0zQ9XZU+e6EGbuTnj2JBguq6vOxAZ2n4zJkTFl3Ldd4v+NNvu5AGZ3ZLrvnhwZ4ey85Z59+Zy3bx/zccgU6Gzn7tvsnAt99kzbdofBC4VA27l9ZAmXPtmDpvu+Z73zX5M96/7d+81SwyUC6cXeJwAMMIyM2/PvG+bxY7gy7rsyHU82sr9PGfVUbWX5NdQUnC5CwUm8UbrTxcKth3hrxZ8ciDsLQGSYP22vKovLZZDuMnAZBk6XgdMFTpfLE5LMKY3E5HTSXeafs7+PnVubVubetjWoUyHUypcmIiLFgcsFKfEZQSrz+VkZ52ilJZktXmlnIf3sufm0s+BMgfRUcJ43paeCKx0Mp5eFMvEaw36AqBaWlqDgdBEKTuLN0pwuPt98kLeX/+k5Byqv7DZwZfqrbntVGe5tU4Mb65bHrmHQRUTECoa7VcIJrowgZTgztVi4MuYx513OjHXTM6bM8+l4WnwgaytK5u25XOdaPjz7y3w/U8tIlv2dty9nOudaVyCjuSV7a0vmlhbP9i/yNdtdk2ef7hoylnked51b7r5179d1/mtyZq3r/DovXEzW9yPze+VyZW1ps7lvM7ds2XNuebvo+2TALe9AZP2L1FX4FJwuQsFJioOUdCdLfovhaEIKDrvNM9ltGfM2GwF+DkIDfAgL8CE0wJewAF9CA3wI8nOwef9JZv60l6W/x3pCVPUyQQxpU53bm0cRom58IiIiIgpOF6PgJCXJwZNJfLR+P3M3RJOQbF6sN8Tfh96NK3JH8yiaRpXCphNwRUREpIRScLoIBScpic6kpLNgy0FmrdvHP8fOeJbXLh9Cv+ZR3HptZcqG+FtYoYiIiEjRU3C6CAUnKclcLoNf9sYxf9MBlvweQ3KaebKuj91Gp3rl6dOkMrUjQ6kSEXjREf3izqSy/eApth8wpz1HTuPvYyc00JewAB/C3LcBvoQF+lK9TDD1KoZSvUywzrMSERERr6HgdBEKTiKmhOQ0vtp+mM82HWT7gVPZHi8X6k+ViECqRARRJSKQsABfdsYksP3AKaLjkvK1z0BfB3UqhFKvYhj1K5q3DSqH52nYdREREZGCouB0EQpOItntjk3ks00HWPvncQ6eTOJMqvOSz6lZNpjGUaVoXCWc+pXCMQyDhOR0Es6mkZic5pk/mZTGX0cT+SM2kZT07MPRBvo6uL52WbrUi6Rj3fKUC81/l8ETp1P4+9gZ4s6k4mO34eOw4WO3Z9za8HHY8fexUybEj9JBfvg47JfeqIiIiFyxFJwuQsFJ5OIMw+BUUhoHT57l4Mkkz21cUhp1IkNoHFWKRpVLER7km6ftpjtd7Dtxhp0xieyKSWBXTAK/H0rg+OkUzzo2GzSJKkXnepF0rhdJjbLBpKQ7SU13kep0kZruIiXdvD2SkMzfx07z99Ez5u2x05xMSst1PTYbRAT5USbYjzIhfpQN8adsiLuVLZDKpcyWtlJBvhpAQ0RE5Aql4HQRCk4i3sMwDHYcTmD5rqP8sOsIvx2Kv6zt2WxQuVQgkWEBpLsMnC4X6U7zAsLpThdpToOzaU5OJqVe/HIWmQT7OagSEURkeAB2GzhdBulOA2fGBYnTXQYu18U35s5dtow7tkzL/X3shPj7EOTnQ7C/g2A/H4L8fQj2cxAS4EOIv49nqPlQz60Pgb4ObBnbMi8OX7zCnWEYJKe5MDDwc9hx2G3F7jWIiEjxV6yC05QpU3j99deJiYnhmmuuYdKkSbRr1+6C669evZqxY8eyY8cOKlWqxJNPPsnIkSNzvT8FJxHvFRufzPI/jrB811HW/nWc1Exd+3zsNvx97PhlTBFBflxVPoRa5UKoVT6Eq8qFUKNsMIF+lz5fyukyOJmUyvHTKZw4bd4eP53K0cRkDp08m9HKdjZLa1hxYbOBw2bD12HH12HDz8eeMW/ed9htGUHSDH5pTpfnNnP+s3n+k+Uykx7n/4/DL6MbpJ+PHX8fB/6+5+6npRucSU0nKdXJmZSM29T0LOHVZgNfhx0/hz2jZhsBvg6C/HwI8Xd4gqV53wc/H3uOdWV9L2xmqMzYvg0bLsMgKdVJUmo6Z9z1pJj1JKc58T3vdZi35n3PtdRsNux2sNvOXVvNvAWH3W7e2mzn5u12fDKuxeaT8RmY9+24DPOzSHO6MiZ3yHdhs9kI9HMQ4GM3b30dBPo6CPRz4OuwZwrgNs97COYgMCkZrbMp6U6S08zblDQX6S5Xlu0E+TkI9PUh0M9cBuAyDPM6lRie63e6DAPD85iByzD34zLMEOw+UGxkfs/Nec/zM9Z1Zdx3bzO3Mn/e9oxj3M/Hlun4Nj8rgLNp5441z+ed4jQ/44zP1P+8Y9Xfx47DbsduO/fZZv6c7TY8n7XdnnHfdi7wn/9+uV9zqtPF2Ux1JKc5PXU57LaMQXTc1+NzD67ji5+PHZfLIM3l/hs1jw2ny/zhxoZZAxn12jLeF8D8G8/44ejc37hZU1CmH2XcP8DkJN3p4kzG30ZSajo2my3r37iP+fdaVAP+GIZBqtNFcprZ68CZ8RpdLkh3nXtfXC7wcZjHhY/93L+FPhn/vrjnL7WvlHTzc3P/2+AyzAvM2zIdD+5jwWEz/7Z93V3DM+bz8t64/zbcn5f7BzrPa3Nl/bHOlfE36nJlPfYMDHzsWf82fBw2/Bx2fBz2jG27SM/4d9/8cdG8byPTv2MZx7+P3e659Wwn49+zCx077tfi/ozS0s3PLi2j50ia05Vx36B2+RCCLb62ZLEJTvPmzWPQoEFMmTKFtm3b8u677zJ9+nR27txJ1apVs62/d+9eGjRowH333cf999/PTz/9xKhRo5g7dy633XZbrvap4CRSPCSnmV/0/H2L9n/O59dw6JQZoo4kJGPD/B+y3WaeO3Xu4sTmF8aLyfw/NvP+uf85n0k59yX+TGrGF/mUdBJT0klMTiMxOZ3E5HROZ9xPc5aojgIiJZLdBpdozC6QfQT7+xDqb7Z0p6Q7zbCUkp7jOak5cf8gc/H9mP9u2jyh1B1AsgZTm+eHCPO1Zwn+6a5c9xS4FHu2H2rMUJCa7vIE3IJ47+02M3CY4RZP2HX3FgCyBOPixjfjPGIgI7SaYS8vn9OXD7alcVSpwikwl4pNcGrVqhXXXnstU6dO9SyrV68effr0YcKECdnWf+qpp1i8eDG7du3yLBs5ciTbt29n/fr1udqngpOIFGfusJWc5sz4ddFcZt6e+wUycwuG59e9jF9pfTK6xrm/8Phm3HdkaiEwMu0PzPsX+mpkAOlOw/PlJjX9XAtHSroLPx87QX4Ogv19CM7UchTk58Bmw/NrpLvGNOe51hL3l7gzmVoNklIv/qXO8LSYkKXlxC3Y/1wtnrr8ffD3sZPuNEh1mrWnOl0Zr8F8XS7DwOnKaE3I+MU385cFV+ZfhA0jy6/ETpdBWqbuo+77DhueX8Ldv5K7fyF3ZXRnPJvmJDnVad6mOTmb5iI13XmutcbIcoMN8POxE+Brtgr4+5qtVv6+DnzsNlLSz7V4uFs/zmbMQ/aWOndrhi1TC4wj05dg94/O5x+PZNx3b+v8L8/u20se8xmvLPNn6H6f0zKOmdRMrXZOl9mqkrmV0n3r/ozdn2mW4zXj7yPzZ2tk+hzPtSRlfcz9BTtzGMjcjdbPYSfI71yrXpCfwzPvyjKoTsZtSvpF3w93y5f7/XZd4Iuqb6bBcdx/43Ybnpbf3AYDP4edIH8HRkaQKcgAczl8PT9i2TL9iGXHltGl2n08uLtr55efj51AXwcOu83zt2+4//YzWrjcXbcLg/vzdv8b7Z53/w1lPtYytzi6/zbSMubP/8zcLd/u0OhjP/fczP9uuQzz/SuIz9zd4uebEVb9HHamDWxGwyrhl7/xy5CXbGBZ21hqaiqbN2/m6aefzrK8a9eurFu3LsfnrF+/nq5du2ZZ1q1bN2bMmEFaWhq+vtlPVk9JSSEl5Vx3m4SEhAKoXkTEGjab2YXtihrC3c/qAkS8h9NlcDo5nZR0Z5YfOXwyunxeqPU98w8G7vB2IYZhnu95Otls2T6TYv4o4e/rPufS4Tn30s/Hnu256e7uoGnnflS48L7MW3fozNLdMyN4uLs2urt3uX+wMf+tO9elMsDXQYCPA19H3s6JdGUO2pm6iXm6jWXcmj/y+GQEbzPc5nb0Vfc+0l3nuty6Q4jnB4Xzur4CnvBy/o9Z7lBYEL0t3CE/3WV4AlNezyl1h9HM5wy7u+EB2O1k+gEuU9DL6N6X18/MW1kWnI4fP47T6SQyMjLL8sjISGJjY3N8TmxsbI7rp6enc/z4cSpWrJjtORMmTODFF18suMJFREREConDbssYtTRvI5faMrX+5WZdMyD4UD6P9dls5hd8X4cZsooDu92Gn92WLQQWyj7wvstc2DLOwfK5jN/bzJauK+gHu3yy/NM9P30ahnHRRJrT+jktdxs3bhzx8fGe6cCBA5dZsYiIiIiIlDSW/VRQtmxZHA5Httalo0ePZmtVcqtQoUKO6/v4+FCmTJkcn+Pv74+/f/4vqCkiIiIiImJZi5Ofnx/NmjVj2bJlWZYvW7aMNm3a5Pic1q1bZ1v/+++/p3nz5jme3yQiIiIiIlIQLO2qN3bsWKZPn87MmTPZtWsXjz76KNHR0Z7rMo0bN47Bgwd71h85ciT79+9n7Nix7Nq1i5kzZzJjxgwef/xxq16CiIiIiIiUAJae1de/f39OnDjB+PHjiYmJoUGDBixZsoRq1aoBEBMTQ3R0tGf9GjVqsGTJEh599FHeeecdKlWqxFtvvZXraziJiIiIiIjkh6XXcbKCruMkIiIiIiKQt2xg+ah6IiIiIiIi3k7BSURERERE5BIUnERERERERC5BwUlEREREROQSFJxEREREREQuQcFJRERERETkEhScRERERERELkHBSURERERE5BJ8rC6gqLmv95uQkGBxJSIiIiIiYiV3JnBnhIspccEpMTERgKioKIsrERERERERb5CYmEh4ePhF17EZuYlXVxCXy8Xhw4cJDQ3FZrNZXQ4JCQlERUVx4MABwsLCrC5HigkdN5IfOm4kv3TsSH7ouJH8KOrjxjAMEhMTqVSpEnb7xc9iKnEtTna7nSpVqlhdRjZhYWH6R0XyTMeN5IeOG8kvHTuSHzpuJD+K8ri5VEuTmwaHEBERERERuQQFJxERERERkUtQcLKYv78///73v/H397e6FClGdNxIfui4kfzSsSP5oeNG8sObj5sSNziEiIiIiIhIXqnFSURERERE5BIUnERERERERC5BwUlEREREROQSFJxEREREREQuQcHJQlOmTKFGjRoEBATQrFkz1qxZY3VJ4kUmTJhAixYtCA0NpXz58vTp04fdu3dnWccwDF544QUqVapEYGAgHTp0YMeOHRZVLN5owoQJ2Gw2xowZ41mm40Yu5NChQwwcOJAyZcoQFBREkyZN2Lx5s+dxHTtyvvT0dJ599llq1KhBYGAgNWvWZPz48bhcLs86Om4E4Mcff6R3795UqlQJm83GokWLsjyem+MkJSWFhx56iLJlyxIcHMzNN9/MwYMHi+w1KDhZZN68eYwZM4ZnnnmGrVu30q5dO7p37050dLTVpYmXWL16NQ8++CA///wzy5YtIz09na5du3LmzBnPOq+99hpvvPEGkydPZuPGjVSoUIEuXbqQmJhoYeXiLTZu3Mh7771Ho0aNsizXcSM5OXnyJG3btsXX15dvv/2WnTt3MnHiREqVKuVZR8eOnO8///kP06ZNY/LkyezatYvXXnuN119/nbffftuzjo4bAThz5gyNGzdm8uTJOT6em+NkzJgxLFy4kE8//ZS1a9dy+vRpevXqhdPpLJoXYYglWrZsaYwcOTLLsrp16xpPP/20RRWJtzt69KgBGKtXrzYMwzBcLpdRoUIF49VXX/Wsk5ycbISHhxvTpk2zqkzxEomJiUbt2rWNZcuWGe3btzceeeQRwzB03MiFPfXUU8b1119/wcd17EhOevbsaQwdOjTLsr59+xoDBw40DEPHjeQMMBYuXOi5n5vj5NSpU4avr6/x6aefetY5dOiQYbfbjaVLlxZJ3WpxskBqaiqbN2+ma9euWZZ37dqVdevWWVSVeLv4+HgASpcuDcDevXuJjY3Nchz5+/vTvn17HUfCgw8+SM+ePencuXOW5Tpu5EIWL15M8+bNueOOOyhfvjxNmzbl/fff9zyuY0dycv3117N8+XL27NkDwPbt21m7di09evQAdNxI7uTmONm8eTNpaWlZ1qlUqRINGjQosmPJp0j2IlkcP34cp9NJZGRkluWRkZHExsZaVJV4M8MwGDt2LNdffz0NGjQA8BwrOR1H+/fvL/IaxXt8+umnbNmyhY0bN2Z7TMeNXMg///zD1KlTGTt2LP/617/YsGEDDz/8MP7+/gwePFjHjuToqaeeIj4+nrp16+JwOHA6nbz88svcddddgP7NkdzJzXESGxuLn58fERER2dYpqu/PCk4WstlsWe4bhpFtmQjA6NGj+fXXX1m7dm22x3QcSWYHDhzgkUce4fvvvycgIOCC6+m4kfO5XC6aN2/OK6+8AkDTpk3ZsWMHU6dOZfDgwZ71dOxIZvPmzePjjz9mzpw5XHPNNWzbto0xY8ZQqVIl7rnnHs96Om4kN/JznBTlsaSuehYoW7YsDocjWzo+evRotqQt8tBDD7F48WJWrlxJlSpVPMsrVKgAoONIsti8eTNHjx6lWbNm+Pj44OPjw+rVq3nrrbfw8fHxHBs6buR8FStWpH79+lmW1atXzzNokf7NkZw88cQTPP3009x55500bNiQQYMG8eijjzJhwgRAx43kTm6OkwoVKpCamsrJkycvuE5hU3CygJ+fH82aNWPZsmVZli9btow2bdpYVJV4G8MwGD16NAsWLGDFihXUqFEjy+M1atSgQoUKWY6j1P9v735ComrbOI7/jmnjzCCiSSpGlvRHLBLMIDGCdKNRUBiBWIxtxEqxReSiRKOCVrYqoTA3CoJgYSEFRrUQwiCnJrI/i/6BRkULS8uH8HoWwfBO+r7HXnhm1Of7gQPjOfeM1w0XMj/OuW//+kv379+nj/7FSktLFQqFFAwGw0dhYaGqqqoUDAaVk5ND32BWxcXFM/7lwcuXL5WdnS2JvzmY3eTkpOLiIr9OLlmyJLwdOX2DuZhLn2zevFkJCQkRY8bGxvT06dPo9VJUtqDADN3d3ZaQkGDt7e327NkzO3bsmPn9fnvz5k2sS8M8cfjwYUtOTrZ79+7Z2NhY+JicnAyPOX/+vCUnJ1tvb6+FQiGrrKy0zMxMGx8fj2HlmG/+c1c9M/oGsxsaGrL4+Hg7d+6cvXr1yrq6uszn81lnZ2d4DL2D3wUCAcvKyrKbN2/a69evrbe319LS0uzEiRPhMfQNzH7t9jo8PGzDw8MmyVpbW214eNjevn1rZnPrk9raWluxYoUNDAzYo0ePrKSkxPLz8+3nz59RmQPBKYYuXrxo2dnZtnTpUisoKAhvMw2Y/dqqc7ajo6MjPGZ6etqam5stIyPDPB6Pbd++3UKhUOyKxrz0e3Cib/Df3LhxwzZu3Ggej8dyc3Pt8uXLEdfpHfxufHzcGhoabOXKlZaYmGg5OTl28uRJm5qaCo+hb2Bmdvfu3Vm/1wQCATObW598//7d6urqLDU11bxer+3atcvevXsXtTk4ZmbRubcFAAAAAAsTa5wAAAAAwAXBCQAAAABcEJwAAAAAwAXBCQAAAABcEJwAAAAAwAXBCQAAAABcEJwAAAAAwAXBCQAAAABcEJwAAPgDjuPo+vXrsS4DABBlBCcAwIJRXV0tx3FmHGVlZbEuDQCwyMXHugAAAP5EWVmZOjo6Is55PJ4YVQMA+LfgjhMAYEHxeDzKyMiIOFJSUiT9eoyura1N5eXl8nq9Wr16tXp6eiLeHwqFVFJSIq/Xq2XLlqmmpkbfvn2LGHP16lVt2LBBHo9HmZmZqquri7j++fNn7d27Vz6fT2vXrlVfX98/O2kAQMwRnAAAi0pTU5MqKir0+PFjHThwQJWVlRoZGZEkTU5OqqysTCkpKXr48KF6eno0MDAQEYza2tp09OhR1dTUKBQKqa+vT2vWrIn4HadPn9b+/fv15MkT7dy5U1VVVfry5UtU5wkAiC7HzCzWRQAAMBfV1dXq7OxUYmJixPnGxkY1NTXJcRzV1taqra0tfG3r1q0qKCjQpUuXdOXKFTU2Nur9+/fy+/2SpP7+fu3evVujo6NKT09XVlaWDh06pLNnz85ag+M4OnXqlM6cOSNJmpiYUFJSkvr7+1lrBQCLGGucAAALyo4dOyKCkSSlpqaGXxcVFUVcKyoqUjAYlCSNjIwoPz8/HJokqbi4WNPT03rx4oUcx9Ho6KhKS0v/Zw2bNm0Kv/b7/UpKStLHjx//3ykBABYAghMAYEHx+/0zHp1z4ziOJMnMwq9nG+P1euf0eQkJCTPeOz09/Uc1AQAWFtY4AQAWlQcPHsz4OTc3V5KUl5enYDCoiYmJ8PXBwUHFxcVp3bp1SkpK0qpVq3Tnzp2o1gwAmP+44wQAWFCmpqb04cOHiHPx8fFKS0uTJPX09KiwsFDbtm1TV1eXhoaG1N7eLkmqqqpSc3OzAoGAWlpa9OnTJ9XX1+vgwYNKT0+XJLW0tKi2tlbLly9XeXm5vn79qsHBQdXX10d3ogCAeYXgBABYUG7duqXMzMyIc+vXr9fz588l/drxrru7W0eOHFFGRoa6urqUl5cnSfL5fLp9+7YaGhq0ZcsW+Xw+VVRUqLW1NfxZgUBAP3780IULF3T8+HGlpaVp37590ZsgAGBeYlc9AMCi4TiOrl27pj179sS6FADAIsMaJwAAAABwQXACAAAAABescQIALBo8fQ4A+KdwxwkAAAAAXBCcAAAAAMAFwQkAAAAAXBCcAAAAAMAFwQkAAAAAXBCcAAAAAMAFwQkAAAAAXBCcAAAAAMDF323CRuAnMdb6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Debugging prints\n",
    "print(\"Shape of test_predictions:\", test_predictions.shape)\n",
    "print(\"Shape of test_targets:\", test_targets.shape)\n",
    "\n",
    "# Plotting the predictions vs. actual values for a specific 24-hour range for all nodes\n",
    "range_hours = 24\n",
    "\n",
    "# Ensure there are enough samples for the specified range\n",
    "if test_predictions.shape[0] >= range_hours and test_targets.shape[0] >= range_hours:\n",
    "    # Select any 24-hour range\n",
    "    range_start = 0  # Change this to specify different starting points\n",
    "    range_end = range_start + range_hours\n",
    "\n",
    "    selected_predictions = test_predictions[range_start:range_end, :]\n",
    "    selected_targets = test_targets[range_start:range_end, :]\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "    for node_index in range(selected_predictions.shape[1]):\n",
    "        ax.plot(selected_targets[:, node_index], label='Actual Consumption' if node_index == 0 else \"\", color='blue', alpha=0.5)\n",
    "        ax.plot(selected_predictions[:, node_index], label='Predicted Consumption' if node_index == 0 else \"\", linestyle='dashed', color='orange', alpha=0.5)\n",
    "    \n",
    "    ax.set_title(f'LSTM-GAT Model Actual vs Predicted Consumption for All Nodes ({range_hours}-Hour Range)')\n",
    "    ax.set_xlabel('Time-Step')\n",
    "    ax.set_ylabel('Consumption (MW)')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Not enough samples to plot the {range_hours}-hour range.\")\n",
    "\n",
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_train_losses, label='Train Loss')\n",
    "plt.plot(best_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for LSTM-GAT Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f88eae-7a43-4d5e-a0ef-1b872fd21a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9f106-5cec-4f6e-bd15-56a3c99af8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9f9dd9-7e8b-49a2-95a1-9f548248f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxcscdmndmdmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfbd2df-aba9-464e-b548-b3a4be5d8e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81ef8b4-4ba5-4948-88f8-e48239537d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4db28-7736-44cb-af18-2493d31b194d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81e453d6-3763-445f-b9ba-b0758acd43c2",
   "metadata": {},
   "source": [
    "## LSTM-GAT-skip con + LSTM_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035d795-3f71-4dc7-ac51-004ec611b487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d22c765-bdbe-4484-973a-016741c9b52f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 1/100, Train Loss: 0.704412579536438, Val Loss: 0.25709661841392517\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.6328338980674744, Val Loss: 0.25656142830848694\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.6099414825439453, Val Loss: 0.25584787130355835\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.6514821648597717, Val Loss: 0.2550116181373596\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.6467693448066711, Val Loss: 0.25349828600883484\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.6496853232383728, Val Loss: 0.2529843747615814\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.6342416405677795, Val Loss: 0.250681072473526\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.6277428269386292, Val Loss: 0.2474360316991806\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.6362631916999817, Val Loss: 0.2451857179403305\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.5881099104881287, Val Loss: 0.24210837483406067\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.4949337840080261, Val Loss: 0.23831376433372498\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.48597708344459534, Val Loss: 0.23581111431121826\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.43063390254974365, Val Loss: 0.22971469163894653\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.3663605749607086, Val Loss: 0.22474415600299835\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.3446909785270691, Val Loss: 0.21756765246391296\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.32258927822113037, Val Loss: 0.20894895493984222\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.30213385820388794, Val Loss: 0.20127242803573608\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.26224392652511597, Val Loss: 0.19163280725479126\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.22006943821907043, Val Loss: 0.1824028491973877\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.19457997381687164, Val Loss: 0.17223237454891205\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.19989337027072906, Val Loss: 0.16339349746704102\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.18149816989898682, Val Loss: 0.15632179379463196\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.1557525396347046, Val Loss: 0.14865677058696747\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.15438610315322876, Val Loss: 0.1424568146467209\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.14651653170585632, Val Loss: 0.13705025613307953\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.15208688378334045, Val Loss: 0.1321122795343399\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.13865244388580322, Val Loss: 0.1302369385957718\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.15847942233085632, Val Loss: 0.1290709376335144\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.13222992420196533, Val Loss: 0.12786315381526947\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.1238986998796463, Val Loss: 0.12875495851039886\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.13989776372909546, Val Loss: 0.12937122583389282\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.12174654006958008, Val Loss: 0.1313592791557312\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.11158337444067001, Val Loss: 0.13571041822433472\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.11419761925935745, Val Loss: 0.1390051245689392\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.1116359606385231, Val Loss: 0.13961394131183624\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.11301100254058838, Val Loss: 0.13982810080051422\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.10419219732284546, Val Loss: 0.13870131969451904\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.09474219381809235, Val Loss: 0.13634835183620453\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.10913591831922531, Val Loss: 0.13225865364074707\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.09250865876674652, Val Loss: 0.12744611501693726\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.09457442909479141, Val Loss: 0.12081363797187805\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.09131580591201782, Val Loss: 0.11467856913805008\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.08902411162853241, Val Loss: 0.10740674287080765\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.08265569806098938, Val Loss: 0.10012857615947723\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.0939909890294075, Val Loss: 0.09396037459373474\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.09258950501680374, Val Loss: 0.08851844072341919\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.09003114700317383, Val Loss: 0.08295537531375885\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.09355214238166809, Val Loss: 0.07872261106967926\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.08563375473022461, Val Loss: 0.07471279799938202\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.08176160603761673, Val Loss: 0.07102883607149124\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.07729457318782806, Val Loss: 0.06715092062950134\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.09139440953731537, Val Loss: 0.06526336818933487\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.06827747821807861, Val Loss: 0.06353112310171127\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.07761621475219727, Val Loss: 0.062243569642305374\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.07773398607969284, Val Loss: 0.060246266424655914\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.08468396216630936, Val Loss: 0.05787814036011696\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.06887416541576385, Val Loss: 0.05561009794473648\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.07573676854372025, Val Loss: 0.05290350690484047\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.07422597706317902, Val Loss: 0.050709329545497894\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.07516688108444214, Val Loss: 0.04878921061754227\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.06320551037788391, Val Loss: 0.047106124460697174\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.066216379404068, Val Loss: 0.04518144577741623\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.0762244313955307, Val Loss: 0.04433676600456238\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.07872425019741058, Val Loss: 0.04371224716305733\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.06944521516561508, Val Loss: 0.043622903525829315\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.06784038245677948, Val Loss: 0.04361502826213837\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.0681772232055664, Val Loss: 0.0434538833796978\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.06635037064552307, Val Loss: 0.04362643137574196\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.07284176349639893, Val Loss: 0.04366012290120125\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.07663126289844513, Val Loss: 0.04355029761791229\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.062111422419548035, Val Loss: 0.04339071363210678\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.0678783655166626, Val Loss: 0.04396843537688255\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.06765806674957275, Val Loss: 0.04403705894947052\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.0716886892914772, Val Loss: 0.04482436552643776\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.07109688222408295, Val Loss: 0.04458284378051758\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.06274660676717758, Val Loss: 0.045060284435749054\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.07399126887321472, Val Loss: 0.044995877891778946\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.07234563678503036, Val Loss: 0.04522431641817093\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.06788752228021622, Val Loss: 0.04481695219874382\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.06390221416950226, Val Loss: 0.04585159569978714\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.06785586476325989, Val Loss: 0.0459781140089035\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.07158781588077545, Val Loss: 0.04630843177437782\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.0689954087138176, Val Loss: 0.0460086390376091\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.0633750781416893, Val Loss: 0.04589511826634407\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.06744769960641861, Val Loss: 0.04594609513878822\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.07041110843420029, Val Loss: 0.04596458375453949\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.05931803584098816, Val Loss: 0.04558129981160164\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.060908105224370956, Val Loss: 0.04574689269065857\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.0642131119966507, Val Loss: 0.04541223868727684\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.060477253049612045, Val Loss: 0.04537447541952133\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.0663580670952797, Val Loss: 0.0449591688811779\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.0799546092748642, Val Loss: 0.008737904019653797\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.07653677463531494, Val Loss: 0.008933146484196186\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.083075612783432, Val Loss: 0.009239199571311474\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.07704314589500427, Val Loss: 0.009495283477008343\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.07753563672304153, Val Loss: 0.00959311705082655\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.0833553820848465, Val Loss: 0.009773556143045425\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.07700292766094208, Val Loss: 0.009870917536318302\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.08262689411640167, Val Loss: 0.009982537478208542\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.0858970507979393, Val Loss: 0.00989539548754692\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.07423953711986542, Val Loss: 0.009755043312907219\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.08310270309448242, Val Loss: 0.009697021916508675\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.07361399382352829, Val Loss: 0.009355958551168442\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.07703546434640884, Val Loss: 0.008990226313471794\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.07241833209991455, Val Loss: 0.00849490612745285\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.07568353414535522, Val Loss: 0.007916737347841263\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.07591655105352402, Val Loss: 0.00745092798024416\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.07446775585412979, Val Loss: 0.00689173536375165\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.07044786959886551, Val Loss: 0.006281329784542322\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.06830046325922012, Val Loss: 0.0057874699123203754\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.0702185332775116, Val Loss: 0.005436496343463659\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.08135203272104263, Val Loss: 0.005091284401714802\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.0683552473783493, Val Loss: 0.005045679863542318\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.06730502098798752, Val Loss: 0.004842414520680904\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.0587146058678627, Val Loss: 0.004700300749391317\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.06853462010622025, Val Loss: 0.004459843039512634\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.0765361338853836, Val Loss: 0.004553832113742828\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.0710785761475563, Val Loss: 0.004597703460603952\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.06279610842466354, Val Loss: 0.004740327131003141\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.06098604202270508, Val Loss: 0.004966340493410826\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.0689125806093216, Val Loss: 0.004865379072725773\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.059274569153785706, Val Loss: 0.004728034138679504\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.05143750086426735, Val Loss: 0.004460079129785299\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.05601263418793678, Val Loss: 0.0042382655665278435\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.0525970533490181, Val Loss: 0.004165666177868843\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.05477031320333481, Val Loss: 0.0041970922611653805\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.05567362532019615, Val Loss: 0.004185958299785852\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.053074754774570465, Val Loss: 0.0041158911772072315\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.0562000498175621, Val Loss: 0.003972433973103762\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.052031032741069794, Val Loss: 0.004001753404736519\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.04956892505288124, Val Loss: 0.004114882554858923\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.05551638826727867, Val Loss: 0.004060597158968449\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.0549970380961895, Val Loss: 0.00408176239579916\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.047354891896247864, Val Loss: 0.004133662208914757\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.05464021861553192, Val Loss: 0.004100601654499769\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.05522492527961731, Val Loss: 0.004148144740611315\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.0493416003882885, Val Loss: 0.00413374463096261\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.046621259301900864, Val Loss: 0.004211436025798321\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.04749252647161484, Val Loss: 0.0042886026203632355\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.052231565117836, Val Loss: 0.0042811669409275055\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.04994770511984825, Val Loss: 0.004225989803671837\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.04717022553086281, Val Loss: 0.004203354939818382\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.04149085283279419, Val Loss: 0.004319275729358196\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.04828262701630592, Val Loss: 0.004314786288887262\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.04381626471877098, Val Loss: 0.004356219433248043\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.04420938342809677, Val Loss: 0.004298374522477388\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.04469391331076622, Val Loss: 0.004337623715400696\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.042956337332725525, Val Loss: 0.004287814721465111\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.04139716923236847, Val Loss: 0.0042628212831914425\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.05644320324063301, Val Loss: 0.005764182657003403\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.1666668951511383, Val Loss: 0.005960799753665924\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.060629405081272125, Val Loss: 0.011817368678748608\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.013844071608036756, 'rmse': 0.1047984852014717, 'mae': 0.08669764026999474, 'mape': 43.27120989561081, 'r2': 0.8669932347698411}\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.9060158133506775, Val Loss: 0.13903966546058655\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.6564190983772278, Val Loss: 0.14003939926624298\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.4962138533592224, Val Loss: 0.14038540422916412\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.44239917397499084, Val Loss: 0.14098714292049408\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.2657448947429657, Val Loss: 0.1409929245710373\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.30490589141845703, Val Loss: 0.14071503281593323\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.21536940336227417, Val Loss: 0.1403394639492035\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.1430939882993698, Val Loss: 0.14058491587638855\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.16995324194431305, Val Loss: 0.14054496586322784\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.24439555406570435, Val Loss: 0.1399381458759308\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.2786566913127899, Val Loss: 0.14036031067371368\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.24905706942081451, Val Loss: 0.13997793197631836\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.1681879460811615, Val Loss: 0.14002415537834167\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.1318463534116745, Val Loss: 0.14066413044929504\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.13472941517829895, Val Loss: 0.14230391383171082\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.19683025777339935, Val Loss: 0.14431138336658478\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.19711808860301971, Val Loss: 0.14609774947166443\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.16057749092578888, Val Loss: 0.1460830122232437\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.11841718852519989, Val Loss: 0.14598987996578217\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.10093886405229568, Val Loss: 0.14418622851371765\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.07311520725488663, Val Loss: 0.14307695627212524\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.6347143650054932, Val Loss: 0.13917888700962067\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.6343722939491272, Val Loss: 0.0823274552822113\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.5931713581085205, Val Loss: 0.08282341808080673\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.6122230291366577, Val Loss: 0.08329100161790848\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.44608405232429504, Val Loss: 0.08338374644517899\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.4659898579120636, Val Loss: 0.08337023854255676\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.4539283215999603, Val Loss: 0.08357882499694824\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.3819390535354614, Val Loss: 0.08342295140028\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.30005258321762085, Val Loss: 0.08338088542222977\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.26488301157951355, Val Loss: 0.08282030373811722\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.14993293583393097, Val Loss: 0.08263573795557022\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.12681260704994202, Val Loss: 0.08251774311065674\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.2344842255115509, Val Loss: 0.08269677311182022\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.2346949428319931, Val Loss: 0.08246248215436935\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.2698579430580139, Val Loss: 0.08155868202447891\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.2274167835712433, Val Loss: 0.0812162235379219\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.18553940951824188, Val Loss: 0.08136450499296188\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.09047960489988327, Val Loss: 0.08267942070960999\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.12584511935710907, Val Loss: 0.08499487489461899\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.1331060379743576, Val Loss: 0.08774647116661072\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.16301801800727844, Val Loss: 0.08908377587795258\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.1116718053817749, Val Loss: 0.08837129920721054\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.10495025664567947, Val Loss: 0.08795108646154404\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.07253829389810562, Val Loss: 0.08708221465349197\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.1055150255560875, Val Loss: 0.08468254655599594\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.07597663253545761, Val Loss: 0.08277495205402374\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.06472979485988617, Val Loss: 0.08207494020462036\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.04324176535010338, Val Loss: 0.08219505846500397\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.06043074280023575, Val Loss: 0.08267343044281006\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.05501001328229904, Val Loss: 0.08258859813213348\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.05824539065361023, Val Loss: 0.08126235753297806\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.04377050697803497, Val Loss: 0.07891114801168442\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.05654223635792732, Val Loss: 0.07633166015148163\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.031376373022794724, Val Loss: 0.07480436563491821\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.029107796028256416, Val Loss: 0.07382950186729431\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.048052605241537094, Val Loss: 0.07342424243688583\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.04458918794989586, Val Loss: 0.07275234162807465\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.038588110357522964, Val Loss: 0.07103686034679413\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.05158057063817978, Val Loss: 0.06939295679330826\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.025126075372099876, Val Loss: 0.06726919114589691\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.019652506336569786, Val Loss: 0.06629461795091629\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.016197487711906433, Val Loss: 0.06519300490617752\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.028631694614887238, Val Loss: 0.06498557329177856\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.030068598687648773, Val Loss: 0.06558547168970108\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.017473489046096802, Val Loss: 0.06525000184774399\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.0215047225356102, Val Loss: 0.0644344612956047\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.0261481124907732, Val Loss: 0.06144414842128754\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.01979958638548851, Val Loss: 0.057358983904123306\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.022856544703245163, Val Loss: 0.053391437977552414\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.017398985102772713, Val Loss: 0.05036979913711548\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.025286367163062096, Val Loss: 0.048738785088062286\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.020425945520401, Val Loss: 0.04783300310373306\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.016724197193980217, Val Loss: 0.04772275313735008\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.014766935259103775, Val Loss: 0.04812322184443474\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.016022758558392525, Val Loss: 0.04815700277686119\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.016219083219766617, Val Loss: 0.04723934084177017\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.018668467178940773, Val Loss: 0.045322466641664505\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.018759971484541893, Val Loss: 0.04268554598093033\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.016020242124795914, Val Loss: 0.038884203881025314\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.014607050456106663, Val Loss: 0.03476627916097641\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.013171510770916939, Val Loss: 0.031747967004776\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.013323801569640636, Val Loss: 0.02935308963060379\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.016128763556480408, Val Loss: 0.027948802337050438\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.014486839063465595, Val Loss: 0.026772363111376762\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.014632085338234901, Val Loss: 0.025871725752949715\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.012163798324763775, Val Loss: 0.0251817274838686\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.011487321928143501, Val Loss: 0.025238553062081337\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.011921663768589497, Val Loss: 0.025180144235491753\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.015453456901013851, Val Loss: 0.024348851293325424\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.011007717810571194, Val Loss: 0.023277925327420235\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.0162563007324934, Val Loss: 0.02179282158613205\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.012250971980392933, Val Loss: 0.020291972905397415\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.01869751513004303, Val Loss: 0.018117260187864304\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.01818564534187317, Val Loss: 0.01610051654279232\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.010346035473048687, Val Loss: 0.014477932825684547\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.011452151462435722, Val Loss: 0.01348752062767744\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.012493357062339783, Val Loss: 0.012936005368828773\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.01582111418247223, Val Loss: 0.012540461495518684\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.01038097869604826, Val Loss: 0.012465058825910091\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.01094237994402647, Val Loss: 0.012399092316627502\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.012772749178111553, Val Loss: 0.012364059686660767\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.01144220307469368, Val Loss: 0.012485542334616184\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.014485254883766174, Val Loss: 0.012499839067459106\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.011057816445827484, Val Loss: 0.012568793259561062\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.013302684761583805, Val Loss: 0.012686540372669697\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.01317120436578989, Val Loss: 0.012791123241186142\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.010422986932098866, Val Loss: 0.012880452908575535\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.010438471101224422, Val Loss: 0.013096243143081665\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.011737619526684284, Val Loss: 0.013257170096039772\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.011781852692365646, Val Loss: 0.013563855551183224\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.011405372992157936, Val Loss: 0.013775504194200039\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.012233252637088299, Val Loss: 0.014086720533668995\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.013183572329580784, Val Loss: 0.014176932163536549\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.010863212868571281, Val Loss: 0.014129959978163242\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.013249767012894154, Val Loss: 0.014305857941508293\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.009431950747966766, Val Loss: 0.014725633896887302\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.022885292768478394, Val Loss: 0.014842725358903408\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.010712018236517906, Val Loss: 0.014757840894162655\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.010052728466689587, Val Loss: 0.014892530627548695\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.012125369161367416, Val Loss: 0.014741897583007812\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.013787121511995792, Val Loss: 0.01483861356973648\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.26769188046455383, Val Loss: 0.06489147990942001\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.015496057458221912, Val Loss: 0.02385566383600235\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.08786760456860065, 'rmse': 0.27391763389849133, 'mae': 0.23127973675727845, 'mape': 70.19159287214279, 'r2': 0.37974404390576544}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.0341044664382935, Val Loss: 0.20907069742679596\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.8865976333618164, Val Loss: 0.2074883133172989\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.7565838694572449, Val Loss: 0.20632123947143555\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.7052475810050964, Val Loss: 0.20607127249240875\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.503595769405365, Val Loss: 0.2058030068874359\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.388031929731369, Val Loss: 0.20336824655532837\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.45751452445983887, Val Loss: 0.20059821009635925\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.22795048356056213, Val Loss: 0.19850820302963257\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.2846059501171112, Val Loss: 0.19976159930229187\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.24373425543308258, Val Loss: 0.19932100176811218\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.29428133368492126, Val Loss: 0.19906578958034515\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.31828662753105164, Val Loss: 0.20041421055793762\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.3511539399623871, Val Loss: 0.20335955917835236\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.3346269130706787, Val Loss: 0.20477546751499176\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.26087528467178345, Val Loss: 0.20244254171848297\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.20367363095283508, Val Loss: 0.20193688571453094\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.16143499314785004, Val Loss: 0.19830098748207092\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.17793908715248108, Val Loss: 0.19310486316680908\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.1339203119277954, Val Loss: 0.18795308470726013\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.11607715487480164, Val Loss: 0.18216541409492493\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.10173766314983368, Val Loss: 0.17569102346897125\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.10913009196519852, Val Loss: 0.1679704487323761\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.08338818699121475, Val Loss: 0.1620907038450241\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.07705795764923096, Val Loss: 0.15621107816696167\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.09087670594453812, Val Loss: 0.15250660479068756\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.08014959841966629, Val Loss: 0.15228940546512604\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.07076483964920044, Val Loss: 0.15397971868515015\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.06941182911396027, Val Loss: 0.1533280909061432\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.05086272209882736, Val Loss: 0.15262144804000854\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.047232795506715775, Val Loss: 0.1526949256658554\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.04456675797700882, Val Loss: 0.1520751714706421\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.0491793118417263, Val Loss: 0.15257272124290466\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.04327750205993652, Val Loss: 0.1530245840549469\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.04712464660406113, Val Loss: 0.15087224543094635\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.0529412142932415, Val Loss: 0.14520755410194397\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.039263129234313965, Val Loss: 0.13926392793655396\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.03374113142490387, Val Loss: 0.13492551445960999\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.030391396954655647, Val Loss: 0.13097096979618073\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.03691268339753151, Val Loss: 0.1275101602077484\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.02915172651410103, Val Loss: 0.12499232590198517\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.03060106746852398, Val Loss: 0.12256082892417908\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.03372706472873688, Val Loss: 0.1202675849199295\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.028428368270397186, Val Loss: 0.11705625057220459\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.023691417649388313, Val Loss: 0.11391889303922653\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.0355108343064785, Val Loss: 0.10876686125993729\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.025724094361066818, Val Loss: 0.10140084475278854\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.02756740339100361, Val Loss: 0.09508240967988968\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.027141256257891655, Val Loss: 0.08960242569446564\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.02709074877202511, Val Loss: 0.08674697577953339\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.026845863088965416, Val Loss: 0.08582992106676102\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.02211637981235981, Val Loss: 0.08689023554325104\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.024192051962018013, Val Loss: 0.0868026465177536\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.02480980195105076, Val Loss: 0.08562608808279037\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.027829648926854134, Val Loss: 0.08242656290531158\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.021373389288783073, Val Loss: 0.07814911007881165\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.023492055013775826, Val Loss: 0.0735083818435669\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.021738605573773384, Val Loss: 0.06913068890571594\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.025476651266217232, Val Loss: 0.06536802649497986\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.02289823442697525, Val Loss: 0.06111474707722664\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.022107576951384544, Val Loss: 0.057234421372413635\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.024538975208997726, Val Loss: 0.05329672619700432\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.022083578631281853, Val Loss: 0.05044872313737869\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.017909672111272812, Val Loss: 0.04704078659415245\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.021110007539391518, Val Loss: 0.044671352952718735\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.023043643683195114, Val Loss: 0.04290805011987686\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.02449968084692955, Val Loss: 0.04075856879353523\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.021024160087108612, Val Loss: 0.038048967719078064\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.01734173856675625, Val Loss: 0.03577516973018646\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.023353515192866325, Val Loss: 0.033950865268707275\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.018755771219730377, Val Loss: 0.031946681439876556\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.019579561427235603, Val Loss: 0.030022703111171722\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.02372744493186474, Val Loss: 0.028639204800128937\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.02479000762104988, Val Loss: 0.02756446786224842\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.022624701261520386, Val Loss: 0.026610368862748146\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.01976495422422886, Val Loss: 0.026242129504680634\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.015940405428409576, Val Loss: 0.02625066600739956\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.019095690920948982, Val Loss: 0.02573108673095703\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.02157708816230297, Val Loss: 0.025355743244290352\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.019021596759557724, Val Loss: 0.024495722725987434\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.022740157321095467, Val Loss: 0.023791199550032616\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.018973495811223984, Val Loss: 0.023175327107310295\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.021032288670539856, Val Loss: 0.02211271971464157\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.01569242589175701, Val Loss: 0.021299980580806732\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.018909893929958344, Val Loss: 0.020476382225751877\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.018816424533724785, Val Loss: 0.020099451765418053\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.019098516553640366, Val Loss: 0.019513236358761787\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.018684837967157364, Val Loss: 0.019238537177443504\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.016940053552389145, Val Loss: 0.019109467044472694\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.019129278138279915, Val Loss: 0.01887315884232521\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.015615148469805717, Val Loss: 0.01850777305662632\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.02010604552924633, Val Loss: 0.01838761568069458\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.02228393219411373, Val Loss: 0.01786213368177414\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.019293541088700294, Val Loss: 0.017780477181077003\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.01622156985104084, Val Loss: 0.017913544550538063\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.018965885043144226, Val Loss: 0.017654722556471825\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.0156587865203619, Val Loss: 0.01789354532957077\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.019250543788075447, Val Loss: 0.017529375851154327\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.01644189842045307, Val Loss: 0.017425714060664177\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.02043541520833969, Val Loss: 0.01708640530705452\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.016977665945887566, Val Loss: 0.017500119283795357\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.03018498606979847, Val Loss: 0.0024458542466163635\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.03069152683019638, Val Loss: 0.0023596074897795916\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.020298384130001068, Val Loss: 0.0023478991352021694\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.020915698260068893, Val Loss: 0.00244127563200891\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.02429048903286457, Val Loss: 0.0025946537498384714\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.023416349664330482, Val Loss: 0.0028127869591116905\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.025114234536886215, Val Loss: 0.0030320151709020138\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.019453292712569237, Val Loss: 0.003313387744128704\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.023123718798160553, Val Loss: 0.003680364927276969\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.023449024185538292, Val Loss: 0.004290620796382427\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.024669649079442024, Val Loss: 0.005362916272133589\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.02364729344844818, Val Loss: 0.0063053942285478115\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.026487860828638077, Val Loss: 0.007300244644284248\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.02300696074962616, Val Loss: 0.007589586079120636\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.02246353216469288, Val Loss: 0.007201499305665493\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.019239166751503944, Val Loss: 0.006680840160697699\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.018156245350837708, Val Loss: 0.0067933909595012665\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.01715477742254734, Val Loss: 0.006622675806283951\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.021080972626805305, Val Loss: 0.006494834087789059\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.019520189613103867, Val Loss: 0.006430207286030054\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.02093246392905712, Val Loss: 0.006124099716544151\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.019338591024279594, Val Loss: 0.005270423833280802\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.016992593184113503, Val Loss: 0.004119328688830137\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.027709372341632843, Val Loss: 0.0016851263353601098\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.031946830451488495, Val Loss: 0.00172639440279454\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.024576671421527863, Val Loss: 0.0016531043220311403\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.026301249861717224, Val Loss: 0.0017162379808723927\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.022472381591796875, Val Loss: 0.0018380677793174982\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.02026282623410225, Val Loss: 0.001943123061209917\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.020318742841482162, Val Loss: 0.0021481304429471493\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.02120307646691799, Val Loss: 0.0027125999331474304\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.01740333065390587, Val Loss: 0.003030873602256179\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.017990147694945335, Val Loss: 0.003969648852944374\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.021097593009471893, Val Loss: 0.004747288301587105\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.022367987781763077, Val Loss: 0.006118398159742355\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.026954447850584984, Val Loss: 0.00771248247474432\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.021492181345820427, Val Loss: 0.009234935976564884\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.026903066784143448, Val Loss: 0.009847477078437805\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.023847825825214386, Val Loss: 0.008273297920823097\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.02051844447851181, Val Loss: 0.005325801204890013\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.017762694507837296, Val Loss: 0.0032584420405328274\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.018810566514730453, Val Loss: 0.001454787328839302\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.017843712121248245, Val Loss: 0.0008962956489995122\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.019421493634581566, Val Loss: 0.0008275415166281164\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.021907789632678032, Val Loss: 0.0020139075350016356\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.022734515368938446, Val Loss: 0.004305550828576088\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.015946147963404655, Val Loss: 0.008004195056855679\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.014238705858588219, Val Loss: 0.010136596858501434\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.014768754132091999, Val Loss: 0.013460421934723854\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.020018024370074272, Val Loss: 0.012050233781337738\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.018760953098535538, Val Loss: 0.009307864122092724\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.01878381334245205, Val Loss: 0.00475237937644124\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.01935315690934658, Val Loss: 0.004250506870448589\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.018010327592492104, Val Loss: 0.004617395810782909\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.01629904843866825, Val Loss: 0.006191733758896589\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.019953982904553413, Val Loss: 0.0103021040558815\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.02088354527950287, Val Loss: 0.007809319067746401\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.014747575856745243, Val Loss: 0.005889051128178835\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.016962628811597824, Val Loss: 0.0027160814497619867\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.02100326679646969, Val Loss: 0.0033533305395394564\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.018220609053969383, Val Loss: 0.005917496047914028\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.012000046670436859, Val Loss: 0.011996699497103691\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.01340927928686142, Val Loss: 0.017589310184121132\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.013464990071952343, Val Loss: 0.014444679021835327\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.1849854290485382, Val Loss: 0.014681611210107803\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.027899418026208878, Val Loss: 0.004934618249535561\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.0051743804011493925, 'rmse': 0.0606638426521449, 'mae': 0.05149315893650055, 'mape': 22.692875266075134, 'r2': 0.9509877247436533}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.3015321493148804, Val Loss: 0.1840583086013794\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.1883540153503418, Val Loss: 0.18262210488319397\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.9194790124893188, Val Loss: 0.1810152232646942\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.7647957801818848, Val Loss: 0.17819103598594666\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.5748387575149536, Val Loss: 0.17498508095741272\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.42126572132110596, Val Loss: 0.17068995535373688\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.28780966997146606, Val Loss: 0.16453924775123596\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.23414312303066254, Val Loss: 0.15770667791366577\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.2014978677034378, Val Loss: 0.15073302388191223\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.27417704463005066, Val Loss: 0.14463919401168823\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.321834921836853, Val Loss: 0.1405356079339981\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.36675772070884705, Val Loss: 0.1390010416507721\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.3619801104068756, Val Loss: 0.13878151774406433\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.30790963768959045, Val Loss: 0.14128263294696808\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.2111615538597107, Val Loss: 0.1446331888437271\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.1752549409866333, Val Loss: 0.14854584634304047\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.15285472571849823, Val Loss: 0.15101315081119537\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.1489008069038391, Val Loss: 0.15075136721134186\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.15224115550518036, Val Loss: 0.14771881699562073\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.11866496503353119, Val Loss: 0.14140114188194275\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.08945481479167938, Val Loss: 0.13094905018806458\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.07231342047452927, Val Loss: 0.11777457594871521\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.07391428202390671, Val Loss: 0.10307832807302475\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.08136776089668274, Val Loss: 0.09037035703659058\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.07884275168180466, Val Loss: 0.08069461584091187\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.06870269030332565, Val Loss: 0.07647822797298431\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.05323111638426781, Val Loss: 0.07760914415121078\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.04379633441567421, Val Loss: 0.08287950605154037\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.029971539974212646, Val Loss: 0.08924068510532379\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.03406882658600807, Val Loss: 0.09247313439846039\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.03194107860326767, Val Loss: 0.09155537188053131\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.03078046254813671, Val Loss: 0.08752717822790146\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.03155534341931343, Val Loss: 0.08097133040428162\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.029724005609750748, Val Loss: 0.07370410859584808\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.02484867535531521, Val Loss: 0.0667991191148758\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.023073948919773102, Val Loss: 0.06254731118679047\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.022062543779611588, Val Loss: 0.05955321341753006\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.021842526271939278, Val Loss: 0.05744462460279465\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.02110431157052517, Val Loss: 0.05495797470211983\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.019348708912730217, Val Loss: 0.05232810974121094\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.018478650599718094, Val Loss: 0.04946742206811905\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.016821708530187607, Val Loss: 0.04570259898900986\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.015195751562714577, Val Loss: 0.04206050932407379\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.01986292190849781, Val Loss: 0.03804495930671692\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.016449622809886932, Val Loss: 0.03442026674747467\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.01606699265539646, Val Loss: 0.031059877946972847\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.013582926243543625, Val Loss: 0.02775808423757553\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.01383952796459198, Val Loss: 0.02429071068763733\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.01602834463119507, Val Loss: 0.021675368770956993\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.015114246867597103, Val Loss: 0.020517276600003242\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.013148161582648754, Val Loss: 0.019594142213463783\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.015169099904596806, Val Loss: 0.019512668251991272\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.015590946190059185, Val Loss: 0.02022196725010872\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.013064789585769176, Val Loss: 0.021178124472498894\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.013518931344151497, Val Loss: 0.022134670987725258\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.014260576106607914, Val Loss: 0.02263016439974308\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.013636624440550804, Val Loss: 0.02213979884982109\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.014712446369230747, Val Loss: 0.021248597651720047\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.014058539643883705, Val Loss: 0.020111029967665672\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.013382556848227978, Val Loss: 0.01877487823367119\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.013304537162184715, Val Loss: 0.017926830798387527\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.014532770030200481, Val Loss: 0.01735013723373413\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.012301024049520493, Val Loss: 0.01735258661210537\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.012063800357282162, Val Loss: 0.01707938313484192\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.01237637922167778, Val Loss: 0.016647396609187126\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.010937875136733055, Val Loss: 0.016308799386024475\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.014383302070200443, Val Loss: 0.015649130567908287\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.012035035528242588, Val Loss: 0.015014397911727428\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.011587022803723812, Val Loss: 0.014573453925549984\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.011811209842562675, Val Loss: 0.014277759939432144\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.011677144095301628, Val Loss: 0.013898339122533798\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.01214725710451603, Val Loss: 0.013737463392317295\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.010873893275856972, Val Loss: 0.01373083796352148\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.012756776064634323, Val Loss: 0.013418493792414665\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.012238608673214912, Val Loss: 0.013337845914065838\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.011464929208159447, Val Loss: 0.01330038346350193\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.0102818189188838, Val Loss: 0.013035142794251442\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.010741434060037136, Val Loss: 0.012934309430420399\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.011383199132978916, Val Loss: 0.012902128510177135\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.0121286166831851, Val Loss: 0.012851448729634285\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.010306267067790031, Val Loss: 0.012900999747216702\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.01144695095717907, Val Loss: 0.012823713012039661\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.01037358958274126, Val Loss: 0.012791293673217297\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.011761748231947422, Val Loss: 0.012754914350807667\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.010974586009979248, Val Loss: 0.012755448929965496\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.010627726092934608, Val Loss: 0.012730676680803299\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.008612282574176788, Val Loss: 0.012563586235046387\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.00995347835123539, Val Loss: 0.01241159439086914\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.009931878186762333, Val Loss: 0.012412283569574356\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.011805079877376556, Val Loss: 0.012422305531799793\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.008639974519610405, Val Loss: 0.012406561523675919\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.010965781286358833, Val Loss: 0.01238970085978508\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.010771989822387695, Val Loss: 0.012473986484110355\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.010885166935622692, Val Loss: 0.012377006001770496\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.011781389825046062, Val Loss: 0.012370984070003033\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.00983372051268816, Val Loss: 0.012403195723891258\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.011002333834767342, Val Loss: 0.012357688508927822\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.011514492332935333, Val Loss: 0.012499931268393993\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.009972142986953259, Val Loss: 0.01254790835082531\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.009385774843394756, Val Loss: 0.012442464008927345\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.016075825318694115, Val Loss: 0.0005078654503449798\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.01871473900973797, Val Loss: 0.0006547268712893128\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.015011669136583805, Val Loss: 0.0008147279731929302\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.01849030889570713, Val Loss: 0.0009659348288550973\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.017962774261832237, Val Loss: 0.001110513461753726\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.016098903492093086, Val Loss: 0.0011954468209296465\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.013784616254270077, Val Loss: 0.0013569558504968882\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.015237487852573395, Val Loss: 0.0015151251573115587\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.013969113118946552, Val Loss: 0.001776504097506404\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.014677724801003933, Val Loss: 0.002060872735455632\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.01105212327092886, Val Loss: 0.002357503864914179\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.013014224357903004, Val Loss: 0.002516243141144514\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.015409911051392555, Val Loss: 0.0023817969486117363\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.015254832804203033, Val Loss: 0.0020852715242654085\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.016676099970936775, Val Loss: 0.0015801058616489172\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.013917505741119385, Val Loss: 0.001449660980142653\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.013266714289784431, Val Loss: 0.0016175181372091174\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.01174300815910101, Val Loss: 0.0020156665705144405\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.011537712998688221, Val Loss: 0.0024560263846069574\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.01274754386395216, Val Loss: 0.0021376570221036673\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.011889545246958733, Val Loss: 0.001915972214192152\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.017942393198609352, Val Loss: 0.00028363033197820187\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.016812516376376152, Val Loss: 0.0003202322986908257\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.0164061039686203, Val Loss: 0.0004075296747032553\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.017048532143235207, Val Loss: 0.0005206126952543855\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.01634587161242962, Val Loss: 0.0006913591641932726\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.01606391929090023, Val Loss: 0.0009786079172044992\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.013767586089670658, Val Loss: 0.001483418745920062\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.014758509583771229, Val Loss: 0.0023228959180414677\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.014477035962045193, Val Loss: 0.0038419971242547035\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.014940118417143822, Val Loss: 0.006025178357958794\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.014477177523076534, Val Loss: 0.008950768038630486\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.01523054763674736, Val Loss: 0.012016871944069862\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.017395444214344025, Val Loss: 0.014228361658751965\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.015365407802164555, Val Loss: 0.01435953937470913\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.01520292367786169, Val Loss: 0.012167097069323063\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.014175612479448318, Val Loss: 0.008340489119291306\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.011845482513308525, Val Loss: 0.004396166652441025\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.012449276633560658, Val Loss: 0.0020136074163019657\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.01301188301295042, Val Loss: 0.0013844399945810437\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.011545415967702866, Val Loss: 0.002033209428191185\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.012096880935132504, Val Loss: 0.004874767269939184\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.1260516196489334, Val Loss: 0.0012515182606875896\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.024449395015835762, Val Loss: 0.0012587839737534523\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.0038145536091178656, 'rmse': 0.05098225761850952, 'mae': 0.043008683063089845, 'mape': 14.236525744199753, 'r2': 0.9683515331391137}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.0333949327468872, Val Loss: 0.16002434492111206\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.0237717628479004, Val Loss: 0.16032901406288147\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.9809223413467407, Val Loss: 0.16236625611782074\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.0048595666885376, Val Loss: 0.1627482920885086\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.8105907440185547, Val Loss: 0.16363686323165894\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.8780250549316406, Val Loss: 0.16490477323532104\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.6731347441673279, Val Loss: 0.16448357701301575\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.5512354969978333, Val Loss: 0.16610361635684967\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.6400091648101807, Val Loss: 0.16718778014183044\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.5716481804847717, Val Loss: 0.16670149564743042\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.5222241282463074, Val Loss: 0.16772876679897308\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.4271855354309082, Val Loss: 0.16699811816215515\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.5387605428695679, Val Loss: 0.16680869460105896\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.3046927750110626, Val Loss: 0.16580742597579956\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.2896152436733246, Val Loss: 0.16514615714550018\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.3443579077720642, Val Loss: 0.16345611214637756\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.4013676941394806, Val Loss: 0.16200527548789978\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.3665392994880676, Val Loss: 0.1597270667552948\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.33821192383766174, Val Loss: 0.15893861651420593\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.363994836807251, Val Loss: 0.15879954397678375\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.24808098375797272, Val Loss: 0.15695883333683014\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.21014760434627533, Val Loss: 0.1575789749622345\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.3396720588207245, Val Loss: 0.15915223956108093\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.2574087083339691, Val Loss: 0.1608790159225464\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.2999512255191803, Val Loss: 0.1610403209924698\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.20249079167842865, Val Loss: 0.16205623745918274\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.21930274367332458, Val Loss: 0.16227354109287262\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.15698225796222687, Val Loss: 0.16106845438480377\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.21578802168369293, Val Loss: 0.1597336083650589\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.15593834221363068, Val Loss: 0.1567268818616867\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.17050930857658386, Val Loss: 0.15430238842964172\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.18618963658809662, Val Loss: 0.15231497585773468\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.13130426406860352, Val Loss: 0.15046176314353943\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.13280408084392548, Val Loss: 0.15055179595947266\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.09841733425855637, Val Loss: 0.15064312517642975\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.12670330703258514, Val Loss: 0.14972423017024994\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.1006605252623558, Val Loss: 0.14843478798866272\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.11068032681941986, Val Loss: 0.14721082150936127\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.11025261878967285, Val Loss: 0.14503325521945953\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.10227204859256744, Val Loss: 0.14270038902759552\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.08083821088075638, Val Loss: 0.14012493193149567\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.07667771726846695, Val Loss: 0.13871710002422333\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.09598547965288162, Val Loss: 0.13678884506225586\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.081148661673069, Val Loss: 0.13360778987407684\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.06676526367664337, Val Loss: 0.1306932419538498\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.08293991535902023, Val Loss: 0.1265563666820526\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.07579383254051208, Val Loss: 0.1245686337351799\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.08190460503101349, Val Loss: 0.12099113315343857\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.05748157948255539, Val Loss: 0.11839848756790161\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.06542900949716568, Val Loss: 0.11430579423904419\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.05765819177031517, Val Loss: 0.11033093929290771\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.06953311711549759, Val Loss: 0.10747893154621124\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.06519149988889694, Val Loss: 0.10326264053583145\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.06273858994245529, Val Loss: 0.09791116416454315\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.054990388453006744, Val Loss: 0.09386364370584488\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.07261661440134048, Val Loss: 0.08900971710681915\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.07183563709259033, Val Loss: 0.08505012094974518\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.05393752455711365, Val Loss: 0.08231529593467712\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.0673183873295784, Val Loss: 0.07973705232143402\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.04977121204137802, Val Loss: 0.07769712060689926\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.06192834675312042, Val Loss: 0.07504633069038391\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.036418233066797256, Val Loss: 0.07193701714277267\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.07589428126811981, Val Loss: 0.06873634457588196\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.04733431339263916, Val Loss: 0.06529600918292999\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.04658787325024605, Val Loss: 0.06197478622198105\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.06207107752561569, Val Loss: 0.05931967869400978\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.05435233935713768, Val Loss: 0.05583909898996353\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.0608634315431118, Val Loss: 0.052945878356695175\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.059822846204042435, Val Loss: 0.04912460222840309\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.05506116896867752, Val Loss: 0.04586762934923172\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.04831238090991974, Val Loss: 0.042935315519571304\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.05580884963274002, Val Loss: 0.04033465310931206\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.06293526291847229, Val Loss: 0.037722691893577576\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.0485839918255806, Val Loss: 0.03626064211130142\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.060419272631406784, Val Loss: 0.03479771316051483\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.05556510016322136, Val Loss: 0.03462859243154526\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.048556797206401825, Val Loss: 0.034000132232904434\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.04502123221755028, Val Loss: 0.033402130007743835\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.05675455927848816, Val Loss: 0.034192945808172226\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.042463332414627075, Val Loss: 0.03479113429784775\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.052904676645994186, Val Loss: 0.03537430986762047\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.04110284894704819, Val Loss: 0.036222830414772034\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.061657972633838654, Val Loss: 0.03716510161757469\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.06866918504238129, Val Loss: 0.03835873678326607\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.047946497797966, Val Loss: 0.03939429670572281\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.03594737872481346, Val Loss: 0.04030441865324974\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.047876983880996704, Val Loss: 0.04165785014629364\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.052087362855672836, Val Loss: 0.04334037005901337\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.04410286247730255, Val Loss: 0.043828271329402924\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.05304408445954323, Val Loss: 0.04494490474462509\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.042779017239809036, Val Loss: 0.0443410687148571\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.04559694230556488, Val Loss: 0.044517792761325836\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.03999018296599388, Val Loss: 0.045703813433647156\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.05168743059039116, Val Loss: 0.04772109165787697\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.04335366189479828, Val Loss: 0.048037294298410416\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.0499550886452198, Val Loss: 0.0494743213057518\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.043136220425367355, Val Loss: 0.050111640244722366\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.05103633180260658, Val Loss: 0.051057368516922\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.05143541470170021, Val Loss: 0.03303806483745575\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.06299271434545517, Val Loss: 0.031876422464847565\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.05461190268397331, Val Loss: 0.031214740127325058\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.07228250801563263, Val Loss: 0.030219022184610367\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.05999451503157616, Val Loss: 0.029103269800543785\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.05102530121803284, Val Loss: 0.028992805629968643\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.05846437066793442, Val Loss: 0.02770436927676201\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.051726337522268295, Val Loss: 0.027311833575367928\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.06239936128258705, Val Loss: 0.026801763102412224\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.0633837953209877, Val Loss: 0.026584193110466003\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.04263066127896309, Val Loss: 0.026547593995928764\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.06497817486524582, Val Loss: 0.026754653081297874\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.05338769406080246, Val Loss: 0.02780391275882721\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.0534578338265419, Val Loss: 0.028698671609163284\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.049027714878320694, Val Loss: 0.029335131868720055\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.046188198029994965, Val Loss: 0.03048359416425228\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.045942727476358414, Val Loss: 0.03121543861925602\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.045274797827005386, Val Loss: 0.032357700169086456\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.057282913476228714, Val Loss: 0.033305857330560684\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.05309265851974487, Val Loss: 0.03272491693496704\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.045202773064374924, Val Loss: 0.030127840116620064\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.04320858418941498, Val Loss: 0.02643529884517193\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.04429744929075241, Val Loss: 0.022431286051869392\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.05001511424779892, Val Loss: 0.02226010337471962\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.04166126251220703, Val Loss: 0.022079182788729668\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.04161492735147476, Val Loss: 0.021595938131213188\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.043331049382686615, Val Loss: 0.02030842751264572\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.05393058434128761, Val Loss: 0.0182026457041502\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.04078442230820656, Val Loss: 0.017338266596198082\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.03899944946169853, Val Loss: 0.016681941226124763\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.04152974486351013, Val Loss: 0.015896059572696686\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.053102556616067886, Val Loss: 0.015149869956076145\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.032328784465789795, Val Loss: 0.01409259531646967\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.03097771666944027, Val Loss: 0.014214309863746166\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.03710357844829559, Val Loss: 0.012183605693280697\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.038523491472005844, Val Loss: 0.012209674343466759\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.047301243990659714, Val Loss: 0.014551651664078236\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.04027731716632843, Val Loss: 0.013353250920772552\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.0380123071372509, Val Loss: 0.015750231221318245\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.028885114938020706, Val Loss: 0.019776135683059692\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.03454820066690445, Val Loss: 0.020496515557169914\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.038067735731601715, Val Loss: 0.0168630201369524\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.034562185406684875, Val Loss: 0.014736817218363285\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.03134821727871895, Val Loss: 0.016158828511834145\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.03863660618662834, Val Loss: 0.016956528648734093\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.0506194569170475, Val Loss: 0.0184516292065382\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.028114352375268936, Val Loss: 0.021328529343008995\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.028023825958371162, Val Loss: 0.021570339798927307\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.0387619324028492, Val Loss: 0.019220110028982162\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.0345182791352272, Val Loss: 0.01758265122771263\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.04469851031899452, Val Loss: 0.017461420968174934\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.021376950666308403, Val Loss: 0.017929965630173683\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.030931711196899414, Val Loss: 0.01889955811202526\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.02999383956193924, Val Loss: 0.019973693415522575\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.027310902252793312, Val Loss: 0.021919099614024162\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.035237353295087814, Val Loss: 0.0035052530001848936\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.04205544665455818, Val Loss: 0.0035570329055190086\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.033932577818632126, Val Loss: 0.0036732663866132498\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.041578132659196854, Val Loss: 0.003469838760793209\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.04437357932329178, Val Loss: 0.003768232883885503\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.03643340244889259, Val Loss: 0.004280934575945139\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.031151089817285538, Val Loss: 0.0049233222380280495\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.03506788983941078, Val Loss: 0.006007728632539511\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.048366717994213104, Val Loss: 0.00692731561139226\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.03822674974799156, Val Loss: 0.008932031691074371\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.032418858259916306, Val Loss: 0.010527011007070541\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.03489428758621216, Val Loss: 0.013002907857298851\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.05081822723150253, Val Loss: 0.013158236630260944\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.028573058545589447, Val Loss: 0.01245689857751131\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.03240818530321121, Val Loss: 0.012270687147974968\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.027645006775856018, Val Loss: 0.010963985696434975\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.037259262055158615, Val Loss: 0.008213343098759651\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.03584253042936325, Val Loss: 0.00579121382907033\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.028680354356765747, Val Loss: 0.004588918294757605\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.03060161881148815, Val Loss: 0.004290029872208834\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.03796400874853134, Val Loss: 0.0035778945311903954\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.033367227762937546, Val Loss: 0.003810479771345854\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.028875285759568214, Val Loss: 0.005702306516468525\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.0320516861975193, Val Loss: 0.00638103112578392\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.1872384399175644, Val Loss: 0.0159293245524168\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.03475770726799965, Val Loss: 0.00678220484405756\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.011769247381016612, 'rmse': 0.09795514387717943, 'mae': 0.08202506229281425, 'mape': 34.117657244205475, 'r2': 0.8868137514998391}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.4926016330718994, Val Loss: 0.286102294921875\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.3353993892669678, Val Loss: 0.2858541011810303\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.2416337728500366, Val Loss: 0.2832185626029968\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.3037737607955933, Val Loss: 0.27936026453971863\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.0970362424850464, Val Loss: 0.27335211634635925\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.9601839780807495, Val Loss: 0.2693563997745514\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.7838035225868225, Val Loss: 0.2627173364162445\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.6460214853286743, Val Loss: 0.25178220868110657\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.45873796939849854, Val Loss: 0.23668122291564941\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.3744448721408844, Val Loss: 0.2236703783273697\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.2948388457298279, Val Loss: 0.20991049706935883\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.26601994037628174, Val Loss: 0.19709864258766174\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.2702234089374542, Val Loss: 0.18643540143966675\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.2824482321739197, Val Loss: 0.17650118470191956\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.3336692750453949, Val Loss: 0.16729913651943207\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.34432685375213623, Val Loss: 0.15667687356472015\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.3243355453014374, Val Loss: 0.15125945210456848\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.3039514720439911, Val Loss: 0.14498189091682434\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.23625682294368744, Val Loss: 0.1389930695295334\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.20016361773014069, Val Loss: 0.13448309898376465\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.14911630749702454, Val Loss: 0.13423487544059753\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.13438719511032104, Val Loss: 0.13583344221115112\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.13724209368228912, Val Loss: 0.14022034406661987\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.14031702280044556, Val Loss: 0.14583644270896912\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.1433844268321991, Val Loss: 0.1507183164358139\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.13784539699554443, Val Loss: 0.14912864565849304\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.11980326473712921, Val Loss: 0.14215724170207977\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.11421798169612885, Val Loss: 0.1307021826505661\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.07715298980474472, Val Loss: 0.11656621098518372\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.07317841053009033, Val Loss: 0.10396263003349304\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.06951503455638885, Val Loss: 0.09587719291448593\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.07161103188991547, Val Loss: 0.09230761975049973\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.07573793828487396, Val Loss: 0.09035313129425049\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.06559528410434723, Val Loss: 0.09103763848543167\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.05809520184993744, Val Loss: 0.09166646748781204\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.06519443541765213, Val Loss: 0.09262119233608246\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.05803722143173218, Val Loss: 0.09362539649009705\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.05663188919425011, Val Loss: 0.09403212368488312\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.04724406823515892, Val Loss: 0.09235786646604538\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.04443453252315521, Val Loss: 0.09050755202770233\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.04814814403653145, Val Loss: 0.08909130096435547\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.05111444741487503, Val Loss: 0.08711544424295425\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.049406781792640686, Val Loss: 0.08317040652036667\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.047258395701646805, Val Loss: 0.07895226031541824\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.04360092058777809, Val Loss: 0.07655844837427139\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.04402521625161171, Val Loss: 0.07436700910329819\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.04558083787560463, Val Loss: 0.07250561565160751\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.045692089945077896, Val Loss: 0.07052183151245117\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.040174324065446854, Val Loss: 0.06838659197092056\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.03572528436779976, Val Loss: 0.06728661060333252\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.041759975254535675, Val Loss: 0.06772360950708389\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.04526346176862717, Val Loss: 0.06740885972976685\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.03601515293121338, Val Loss: 0.06671708077192307\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.03708172217011452, Val Loss: 0.06589853763580322\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.03329476714134216, Val Loss: 0.06581227481365204\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.03300119563937187, Val Loss: 0.06644660234451294\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.03684758394956589, Val Loss: 0.06727284938097\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.03224450349807739, Val Loss: 0.06876666843891144\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.03732782229781151, Val Loss: 0.07072628289461136\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.03380010649561882, Val Loss: 0.07213757187128067\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.03504212573170662, Val Loss: 0.07293573766946793\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.03605296462774277, Val Loss: 0.07337797433137894\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.037970107048749924, Val Loss: 0.07341638207435608\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.03315332159399986, Val Loss: 0.07433100044727325\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.03664455562829971, Val Loss: 0.07506055384874344\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.03170200437307358, Val Loss: 0.07695002853870392\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.03323670104146004, Val Loss: 0.07934479415416718\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.03166089579463005, Val Loss: 0.08194945752620697\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.03002908080816269, Val Loss: 0.08440691977739334\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.03000798262655735, Val Loss: 0.08722761273384094\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.03574386239051819, Val Loss: 0.08948048949241638\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.03335623815655708, Val Loss: 0.09279072284698486\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.03396085649728775, Val Loss: 0.09705677628517151\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.03180529549717903, Val Loss: 0.10059114545583725\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.030751720070838928, Val Loss: 0.10482829064130783\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.05838355794548988, Val Loss: 0.012998986057937145\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.05743163824081421, Val Loss: 0.012193163856863976\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.06754305958747864, Val Loss: 0.011776115745306015\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.061410002410411835, Val Loss: 0.011043577454984188\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.059096455574035645, Val Loss: 0.010469718836247921\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.05583495646715164, Val Loss: 0.010102066211402416\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.05552324652671814, Val Loss: 0.009912850335240364\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.04966623708605766, Val Loss: 0.009921380318701267\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.05414893850684166, Val Loss: 0.010304772295057774\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.052816323935985565, Val Loss: 0.01091698557138443\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.04395008087158203, Val Loss: 0.011557086370885372\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.053835537284612656, Val Loss: 0.012668590992689133\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.04458468034863472, Val Loss: 0.014283580705523491\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.03896724060177803, Val Loss: 0.01605825312435627\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.04590742290019989, Val Loss: 0.01727832481265068\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.04204180836677551, Val Loss: 0.0180128812789917\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.04531105235219002, Val Loss: 0.018145563080906868\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.04562608525156975, Val Loss: 0.01784415729343891\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.04466980695724487, Val Loss: 0.017221510410308838\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.046613454818725586, Val Loss: 0.015395727008581161\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.03619907796382904, Val Loss: 0.01310312282294035\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.043168582022190094, Val Loss: 0.009447057731449604\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.035215433686971664, Val Loss: 0.006481033284217119\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.038677316159009933, Val Loss: 0.004665218759328127\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.04308047145605087, Val Loss: 0.004797304980456829\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.03822473809123039, Val Loss: 0.0065694283694028854\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.03509931638836861, Val Loss: 0.008211231790482998\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.03550456464290619, Val Loss: 0.009862015023827553\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.033467214554548264, Val Loss: 0.010476524941623211\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.03558335080742836, Val Loss: 0.010341821238398552\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.03065657801926136, Val Loss: 0.010003817267715931\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.026844434440135956, Val Loss: 0.010098556987941265\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.02750326320528984, Val Loss: 0.010066105052828789\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.029692627489566803, Val Loss: 0.00904670637100935\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.024290164932608604, Val Loss: 0.008599993772804737\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.02715260349214077, Val Loss: 0.008794588036835194\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.033637866377830505, Val Loss: 0.009650691412389278\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.02575831301510334, Val Loss: 0.011231843382120132\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.02455107867717743, Val Loss: 0.012350528500974178\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.0276702381670475, Val Loss: 0.013403532095253468\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.024136092513799667, Val Loss: 0.014336628839373589\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.028541389852762222, Val Loss: 0.013883449137210846\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.02894487977027893, Val Loss: 0.012683712877333164\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.023189764469861984, Val Loss: 0.011319726705551147\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.041436392813920975, Val Loss: 0.0026395421009510756\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.037615809589624405, Val Loss: 0.0027888102922588587\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.03664208576083183, Val Loss: 0.002915823832154274\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.037688735872507095, Val Loss: 0.0030480166897177696\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.039270706474781036, Val Loss: 0.0031247662845999002\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.04281698912382126, Val Loss: 0.003284430131316185\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.04069302976131439, Val Loss: 0.0033844257704913616\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.03856849670410156, Val Loss: 0.003375013591721654\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.03450919687747955, Val Loss: 0.0033705164678394794\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.03199591860175133, Val Loss: 0.003536225063726306\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.03558151051402092, Val Loss: 0.0035603318829089403\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.03260485827922821, Val Loss: 0.0035153415519744158\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.03182569891214371, Val Loss: 0.0035136386286467314\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.03618808463215828, Val Loss: 0.0036137127317488194\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.03543499857187271, Val Loss: 0.004008489195257425\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.029695352539420128, Val Loss: 0.004377793520689011\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.03420044109225273, Val Loss: 0.004485089797526598\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.030902637168765068, Val Loss: 0.004204947967082262\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.029403846710920334, Val Loss: 0.003729697782546282\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.03419932350516319, Val Loss: 0.0032594904769212008\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.029953353106975555, Val Loss: 0.003356499597430229\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.13193516433238983, Val Loss: 0.0018205019878223538\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.13196417689323425, Val Loss: 0.00524751003831625\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.13976337015628815, Val Loss: 0.017413204535841942\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.12332580983638763, Val Loss: 0.036786481738090515\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.12945938110351562, Val Loss: 0.05993044748902321\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.1321989744901657, Val Loss: 0.0819215252995491\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.12062431871891022, Val Loss: 0.1013098657131195\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.10948128253221512, Val Loss: 0.11643575131893158\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.11348811537027359, Val Loss: 0.1248626708984375\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.09336979687213898, Val Loss: 0.12928667664527893\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.08383679389953613, Val Loss: 0.1296880841255188\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.0845666155219078, Val Loss: 0.12829270958900452\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.08139678835868835, Val Loss: 0.12354009598493576\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.08294688165187836, Val Loss: 0.11410440504550934\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.07841333746910095, Val Loss: 0.09890241175889969\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.0883566290140152, Val Loss: 0.07164190709590912\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.08437826484441757, Val Loss: 0.045552581548690796\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.08402065932750702, Val Loss: 0.02947777323424816\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.07783734053373337, Val Loss: 0.02344118244946003\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.07965148985385895, Val Loss: 0.024281444028019905\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.07931540161371231, Val Loss: 0.02611488476395607\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.044102974236011505, Val Loss: 0.001570595777593553\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.043070998042821884, Val Loss: 0.0018634434090927243\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.04991547390818596, Val Loss: 0.0024863830767571926\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.03900287672877312, Val Loss: 0.003281399141997099\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.04066295176744461, Val Loss: 0.0041990079917013645\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.04029602184891701, Val Loss: 0.005539346486330032\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.04492057487368584, Val Loss: 0.007557873148471117\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.03964388743042946, Val Loss: 0.009540176019072533\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.04256552830338478, Val Loss: 0.011842025443911552\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.04113823547959328, Val Loss: 0.014629987068474293\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.03753120079636574, Val Loss: 0.01721338741481304\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.037500642240047455, Val Loss: 0.01924213208258152\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.03579351305961609, Val Loss: 0.019852114841341972\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.03838280960917473, Val Loss: 0.018812738358974457\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.041728537529706955, Val Loss: 0.01679912582039833\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.036988724023103714, Val Loss: 0.013468732126057148\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.03508254513144493, Val Loss: 0.009747682139277458\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.0346132330596447, Val Loss: 0.007174144499003887\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.03499197959899902, Val Loss: 0.006221995688974857\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.0340738371014595, Val Loss: 0.0059716892428696156\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.03212636709213257, Val Loss: 0.00707427691668272\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.015301626618020236, 'rmse': 0.0917031984549187, 'mae': 0.07076779380440712, 'mape': 25.53730845451355, 'r2': 0.8291334501149994}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.1453739404678345, Val Loss: 0.22686810791492462\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.9323968887329102, Val Loss: 0.22527194023132324\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.7242604494094849, Val Loss: 0.2218618541955948\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.5717707872390747, Val Loss: 0.2167818546295166\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.39392051100730896, Val Loss: 0.20898960530757904\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.2996712625026703, Val Loss: 0.19870875775814056\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.2338479906320572, Val Loss: 0.18716362118721008\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.23278579115867615, Val Loss: 0.17513060569763184\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.36054661870002747, Val Loss: 0.16500723361968994\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.4390503466129303, Val Loss: 0.15738779306411743\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.5022462606430054, Val Loss: 0.1548280417919159\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.41642212867736816, Val Loss: 0.15694734454154968\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.3313230872154236, Val Loss: 0.16533231735229492\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.2346607893705368, Val Loss: 0.17652736604213715\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.179632306098938, Val Loss: 0.18505559861660004\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.17474159598350525, Val Loss: 0.18887116014957428\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.1916709691286087, Val Loss: 0.1849975734949112\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.20298846065998077, Val Loss: 0.17310386896133423\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.23354098200798035, Val Loss: 0.15348055958747864\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.1837742030620575, Val Loss: 0.12929683923721313\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.1335073858499527, Val Loss: 0.10971029102802277\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.08291016519069672, Val Loss: 0.10119523853063583\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.1014849916100502, Val Loss: 0.09753628820180893\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.11153604835271835, Val Loss: 0.09400413930416107\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.10292081534862518, Val Loss: 0.08757089078426361\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.10732648521661758, Val Loss: 0.07586261630058289\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.08089370280504227, Val Loss: 0.06409046053886414\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.07625687122344971, Val Loss: 0.058145783841609955\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.06006685271859169, Val Loss: 0.054147444665431976\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.05766725540161133, Val Loss: 0.05166670307517052\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.05174059793353081, Val Loss: 0.04888667166233063\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.06503084301948547, Val Loss: 0.04870909824967384\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.05157548561692238, Val Loss: 0.04629230499267578\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.039652805775403976, Val Loss: 0.03711750730872154\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.03944015875458717, Val Loss: 0.029372772201895714\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.042363401502370834, Val Loss: 0.029358264058828354\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.04197891056537628, Val Loss: 0.032487355172634125\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.04301585629582405, Val Loss: 0.03473146632313728\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.045087605714797974, Val Loss: 0.032261405140161514\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.039831943809986115, Val Loss: 0.024917196482419968\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.04154382646083832, Val Loss: 0.02292957901954651\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.03355180472135544, Val Loss: 0.03317498415708542\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.032401178032159805, Val Loss: 0.04029881954193115\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.03884515538811684, Val Loss: 0.03371714428067207\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.03295448422431946, Val Loss: 0.029846642166376114\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.0346844457089901, Val Loss: 0.030593736097216606\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.028999829664826393, Val Loss: 0.0343003086745739\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.02588389441370964, Val Loss: 0.035274628549814224\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.025570955127477646, Val Loss: 0.03519861772656441\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.029024921357631683, Val Loss: 0.030559074133634567\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.02875087410211563, Val Loss: 0.024708017706871033\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.025949332863092422, Val Loss: 0.024110453203320503\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.028334951028227806, Val Loss: 0.028819607570767403\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.02558952383697033, Val Loss: 0.03211976960301399\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.023123880848288536, Val Loss: 0.037123315036296844\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.021430663764476776, Val Loss: 0.04132689908146858\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.02411140874028206, Val Loss: 0.04768310859799385\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.026911389082670212, Val Loss: 0.0588005967438221\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.018201198428869247, Val Loss: 0.06833748519420624\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.021870017051696777, Val Loss: 0.0772390067577362\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.01870664767920971, Val Loss: 0.07585322111845016\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.042228829115629196, Val Loss: 0.022471414878964424\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.03818726912140846, Val Loss: 0.021687574684619904\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.036022331565618515, Val Loss: 0.020815404132008553\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.04096924886107445, Val Loss: 0.020111920312047005\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.04112951457500458, Val Loss: 0.01914302632212639\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.034057602286338806, Val Loss: 0.018386458978056908\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.040072910487651825, Val Loss: 0.017407596111297607\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.042436059564352036, Val Loss: 0.016484593972563744\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.03577497601509094, Val Loss: 0.015120930038392544\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.03328375145792961, Val Loss: 0.013273687101900578\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.0408194400370121, Val Loss: 0.011211602948606014\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.03813284635543823, Val Loss: 0.009083644486963749\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.03335290029644966, Val Loss: 0.007364973891526461\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.03627406433224678, Val Loss: 0.006010683253407478\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.03625023737549782, Val Loss: 0.005179756786674261\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.03371019661426544, Val Loss: 0.005272150970995426\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.03370322659611702, Val Loss: 0.005113709717988968\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.035183053463697433, Val Loss: 0.004002662375569344\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.030003413558006287, Val Loss: 0.0037177433259785175\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.03195222467184067, Val Loss: 0.0062127443961799145\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.031163163483142853, Val Loss: 0.008187864907085896\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.02798449993133545, Val Loss: 0.0043693892657756805\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.033760055899620056, Val Loss: 0.003535793861374259\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.029365181922912598, Val Loss: 0.0037160986103117466\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.02795540727674961, Val Loss: 0.007614064961671829\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.02648754231631756, Val Loss: 0.006070066709071398\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.026580682024359703, Val Loss: 0.007166246417909861\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.030225137248635292, Val Loss: 0.006352570373564959\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.02380535937845707, Val Loss: 0.008231254294514656\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.02309454046189785, Val Loss: 0.008299272507429123\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.023683056235313416, Val Loss: 0.006953836418688297\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.025328688323497772, Val Loss: 0.006554475519806147\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.020287983119487762, Val Loss: 0.007513356860727072\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.022951764985919, Val Loss: 0.0067526898346841335\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.02227840945124626, Val Loss: 0.008212324231863022\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.021034367382526398, Val Loss: 0.012623928487300873\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.024229129776358604, Val Loss: 0.005062657408416271\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.019928984344005585, Val Loss: 0.003861277597025037\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.022321738302707672, Val Loss: 0.004383247811347246\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.018738223239779472, Val Loss: 0.01086661871522665\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.027819711714982986, Val Loss: 0.007827028632164001\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.01809467002749443, Val Loss: 0.009334780275821686\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.020020965486764908, Val Loss: 0.009077840484678745\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.02497752010822296, Val Loss: 0.01162820402532816\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.15616656839847565, Val Loss: 0.009280034340918064\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.03903421759605408, Val Loss: 0.001663048635236919\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.034759119153022766, Val Loss: 0.0013705489691346884\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.03551144152879715, Val Loss: 0.0010235109366476536\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.03368567302823067, Val Loss: 0.0007289577042683959\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.03367621824145317, Val Loss: 0.0006658012280240655\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.03038022853434086, Val Loss: 0.0014081882545724511\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.02478230744600296, Val Loss: 0.003706664079800248\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.023850243538618088, Val Loss: 0.00823130551725626\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.026936694979667664, Val Loss: 0.015417822636663914\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.032901331782341, Val Loss: 0.022634195163846016\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.03142475336790085, Val Loss: 0.02789095602929592\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.03709035739302635, Val Loss: 0.028090154752135277\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.03169830143451691, Val Loss: 0.02285180613398552\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.02530105784535408, Val Loss: 0.01531965471804142\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.02818395011126995, Val Loss: 0.01083037257194519\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.026803145185112953, Val Loss: 0.008718841709196568\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.0277099609375, Val Loss: 0.008533635176718235\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.029485143721103668, Val Loss: 0.009547893889248371\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.025116467848420143, Val Loss: 0.014516416937112808\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.02075413055717945, Val Loss: 0.01967286504805088\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.019880477339029312, Val Loss: 0.018318360671401024\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.025782311335206032, Val Loss: 0.011295661330223083\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.024557845667004585, Val Loss: 0.008353025652468204\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.021478934213519096, Val Loss: 0.008639674633741379\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.023340238258242607, Val Loss: 0.009979082271456718\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.012817647180054337, 'rmse': 0.10086421228467286, 'mae': 0.08297867216169834, 'mape': 57.508680149912834, 'r2': 0.8982858185397868}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.4040333032608032, Val Loss: 0.13871435821056366\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.9976165890693665, Val Loss: 0.1395789533853531\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.7471330761909485, Val Loss: 0.14041870832443237\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.822852611541748, Val Loss: 0.14112751185894012\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.48959285020828247, Val Loss: 0.14190316200256348\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.38839900493621826, Val Loss: 0.14230208098888397\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.2893063724040985, Val Loss: 0.14235584437847137\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.2263350635766983, Val Loss: 0.14297643303871155\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.34387776255607605, Val Loss: 0.14225083589553833\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.29120755195617676, Val Loss: 0.1424313336610794\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.3270149528980255, Val Loss: 0.14153152704238892\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.280984491109848, Val Loss: 0.1414770483970642\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.21790313720703125, Val Loss: 0.14196813106536865\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.24755406379699707, Val Loss: 0.1434350609779358\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.12498624622821808, Val Loss: 0.14450481534004211\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.19628705084323883, Val Loss: 0.14522048830986023\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.2212618589401245, Val Loss: 0.14351370930671692\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.16823746263980865, Val Loss: 0.14168809354305267\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.10138921439647675, Val Loss: 0.1391320377588272\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.09362439811229706, Val Loss: 0.1369742602109909\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.11186375468969345, Val Loss: 0.1361696869134903\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.10416015982627869, Val Loss: 0.13720864057540894\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.08789205551147461, Val Loss: 0.13954615592956543\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.1260298788547516, Val Loss: 0.13887380063533783\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.07342644780874252, Val Loss: 0.13790133595466614\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.06424017250537872, Val Loss: 0.136631578207016\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.0636141449213028, Val Loss: 0.13566334545612335\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.06807305663824081, Val Loss: 0.13480687141418457\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.05103704705834389, Val Loss: 0.13302011787891388\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.05425720661878586, Val Loss: 0.1303233802318573\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.048996701836586, Val Loss: 0.12695425748825073\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.046463873237371445, Val Loss: 0.12473238259553909\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.03033706545829773, Val Loss: 0.12363502383232117\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.029886797070503235, Val Loss: 0.12315818667411804\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.03119867853820324, Val Loss: 0.12432696670293808\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.033144012093544006, Val Loss: 0.1273539811372757\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.03842143341898918, Val Loss: 0.12729619443416595\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.028261207044124603, Val Loss: 0.1264708787202835\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.026505928486585617, Val Loss: 0.12406908720731735\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.03175071254372597, Val Loss: 0.12068788707256317\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.024677928537130356, Val Loss: 0.11695664376020432\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.03838715702295303, Val Loss: 0.11359240859746933\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.019354581832885742, Val Loss: 0.11141058802604675\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.024320458993315697, Val Loss: 0.10955105721950531\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.022701848298311234, Val Loss: 0.10763677954673767\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.01978917233645916, Val Loss: 0.1041465550661087\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.022295478731393814, Val Loss: 0.10027053207159042\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.017082683742046356, Val Loss: 0.09740239381790161\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.017250940203666687, Val Loss: 0.0951429083943367\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.019800571724772453, Val Loss: 0.0929810106754303\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.015515318140387535, Val Loss: 0.0907154455780983\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.020541921257972717, Val Loss: 0.08743245899677277\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.01415963564068079, Val Loss: 0.08330495655536652\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.015358065254986286, Val Loss: 0.07867271453142166\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.019327815622091293, Val Loss: 0.07382828742265701\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.014320499263703823, Val Loss: 0.06932619959115982\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.017164651304483414, Val Loss: 0.06582000851631165\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.01840457133948803, Val Loss: 0.06292693316936493\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.013832628726959229, Val Loss: 0.06090657413005829\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.018269991502165794, Val Loss: 0.05832699313759804\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.0212699044495821, Val Loss: 0.055467087775468826\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.01436613593250513, Val Loss: 0.052889663726091385\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.0166957825422287, Val Loss: 0.04978927597403526\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.012211802415549755, Val Loss: 0.04591858386993408\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.016286754980683327, Val Loss: 0.04178401455283165\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.014362824149429798, Val Loss: 0.03764212504029274\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.013104958459734917, Val Loss: 0.0339353084564209\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.01147447805851698, Val Loss: 0.030412912368774414\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.014673587866127491, Val Loss: 0.027253318578004837\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.015604669228196144, Val Loss: 0.024815857410430908\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.012940242886543274, Val Loss: 0.02311094105243683\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.013799917884171009, Val Loss: 0.02189481072127819\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.01704918034374714, Val Loss: 0.02107497863471508\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.011725351214408875, Val Loss: 0.020308785140514374\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.012920737266540527, Val Loss: 0.01993890479207039\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.01766590029001236, Val Loss: 0.01937245950102806\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.012973392382264137, Val Loss: 0.018824197351932526\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.014823070727288723, Val Loss: 0.018225688487291336\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.013976638205349445, Val Loss: 0.017657412216067314\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.015480046160519123, Val Loss: 0.01694152131676674\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.010826364159584045, Val Loss: 0.016492443159222603\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.014985448680818081, Val Loss: 0.01626509428024292\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.012130974791944027, Val Loss: 0.016102541238069534\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.013489080592989922, Val Loss: 0.016008924692869186\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.017717046663165092, Val Loss: 0.016026005148887634\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.013312737457454205, Val Loss: 0.016414718702435493\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.012321737594902515, Val Loss: 0.016878973692655563\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.013710228726267815, Val Loss: 0.017121698707342148\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.011722459457814693, Val Loss: 0.017624933272600174\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.012991859577596188, Val Loss: 0.018156616017222404\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.012217678129673004, Val Loss: 0.018882401287555695\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.010489693842828274, Val Loss: 0.01999690569937229\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.01713317632675171, Val Loss: 0.02104158140718937\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.012525723315775394, Val Loss: 0.021005647256970406\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.01050457451492548, Val Loss: 0.021709565073251724\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.013028078712522984, Val Loss: 0.022393876686692238\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.015716644003987312, Val Loss: 0.022756453603506088\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.011868038214743137, Val Loss: 0.023480728268623352\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.012190687470138073, Val Loss: 0.024714326485991478\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.012805490754544735, Val Loss: 0.024952387437224388\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.017582891508936882, Val Loss: 0.015382984653115273\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.0184024665504694, Val Loss: 0.014663693495094776\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.01990048959851265, Val Loss: 0.014015836641192436\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.019910970702767372, Val Loss: 0.013212049379944801\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.028743723407387733, Val Loss: 0.012307056225836277\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.020310742780566216, Val Loss: 0.011331669054925442\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.017523664981126785, Val Loss: 0.010327769443392754\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.01739761233329773, Val Loss: 0.009357384406030178\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.017233893275260925, Val Loss: 0.008865302428603172\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.01950758323073387, Val Loss: 0.008516187779605389\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.019328128546476364, Val Loss: 0.007824614644050598\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.021088194102048874, Val Loss: 0.007335867267102003\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.018309250473976135, Val Loss: 0.006538414862006903\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.02062995173037052, Val Loss: 0.00558684766292572\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.013324208557605743, Val Loss: 0.005182668566703796\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.01881813444197178, Val Loss: 0.006387913133949041\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.017835741862654686, Val Loss: 0.006977471522986889\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.015542916022241116, Val Loss: 0.006535382941365242\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.014074236154556274, Val Loss: 0.008657803758978844\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.01494835875928402, Val Loss: 0.016846483573317528\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.016070963814854622, Val Loss: 0.024932555854320526\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.01935611665248871, Val Loss: 0.02299126610159874\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.018587803468108177, Val Loss: 0.011326583102345467\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.010877076536417007, Val Loss: 0.008565560914576054\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.01777658797800541, Val Loss: 0.006576796993613243\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.01428635697811842, Val Loss: 0.003908657003194094\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.013447429053485394, Val Loss: 0.010440737009048462\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.012874765321612358, Val Loss: 0.014161071740090847\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.018580542877316475, Val Loss: 0.0018851798959076405\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.012444823980331421, Val Loss: 0.0014834498288109899\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.01638139970600605, Val Loss: 0.00518987700343132\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.01116179209202528, Val Loss: 0.011149887926876545\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.009887672029435635, Val Loss: 0.016236314550042152\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.01288987509906292, Val Loss: 0.012450918555259705\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.013298320583999157, Val Loss: 0.008537224493920803\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.013811982236802578, Val Loss: 0.006204068195074797\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.015336189419031143, Val Loss: 0.003002453362569213\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.011298117227852345, Val Loss: 0.0022423374466598034\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.010987035930156708, Val Loss: 0.0039043205324560404\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.010457566939294338, Val Loss: 0.004837122745811939\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.008848872035741806, Val Loss: 0.005009331274777651\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.010024075396358967, Val Loss: 0.006071877665817738\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.009807145223021507, Val Loss: 0.009147253818809986\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.010764037258923054, Val Loss: 0.013571454212069511\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.015002571046352386, Val Loss: 0.017421601340174675\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.010141382925212383, Val Loss: 0.014987442642450333\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.010125694796442986, Val Loss: 0.01125759445130825\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.010132264345884323, Val Loss: 0.01016341894865036\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.009138594381511211, Val Loss: 0.010070688091218472\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.010611467994749546, Val Loss: 0.01048816554248333\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.019128456711769104, Val Loss: 0.00758403493091464\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.2148599773645401, Val Loss: 0.010431971400976181\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.01772831566631794, Val Loss: 0.00791568960994482\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.007549947616644204, 'rmse': 0.08196976055296071, 'mae': 0.06707746610045433, 'mape': 54.81039494276047, 'r2': 0.9290007640797617}\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.8561151623725891, Val Loss: 0.22267146408557892\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.8903843760490417, Val Loss: 0.2200988084077835\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.8303201794624329, Val Loss: 0.21675962209701538\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.7870849370956421, Val Loss: 0.21303455531597137\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.7543022632598877, Val Loss: 0.2098093330860138\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.787932276725769, Val Loss: 0.20644213259220123\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.7180742621421814, Val Loss: 0.20249642431735992\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.6847860813140869, Val Loss: 0.19679106771945953\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.6697895526885986, Val Loss: 0.19080276787281036\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.5634628534317017, Val Loss: 0.18483556807041168\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.4973977506160736, Val Loss: 0.17792077362537384\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.4842558205127716, Val Loss: 0.1704971194267273\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.4020732641220093, Val Loss: 0.1620209813117981\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.36340898275375366, Val Loss: 0.15384924411773682\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.31411105394363403, Val Loss: 0.144845113158226\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.26552215218544006, Val Loss: 0.1359270066022873\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.25196683406829834, Val Loss: 0.12804146111011505\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.22733986377716064, Val Loss: 0.12162764370441437\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.19411778450012207, Val Loss: 0.11606581509113312\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.18570175766944885, Val Loss: 0.11070062965154648\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.18859988451004028, Val Loss: 0.10782623291015625\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.1967027485370636, Val Loss: 0.10538149625062943\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.17926821112632751, Val Loss: 0.10456401109695435\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.17772257328033447, Val Loss: 0.10574576258659363\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.1409904509782791, Val Loss: 0.10911470651626587\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.1398763209581375, Val Loss: 0.11263986676931381\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.13119257986545563, Val Loss: 0.1174081563949585\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.1215486004948616, Val Loss: 0.12307699024677277\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.09438672661781311, Val Loss: 0.12649200856685638\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.11200045049190521, Val Loss: 0.12541241943836212\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.10088349878787994, Val Loss: 0.12274729460477829\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.10047651827335358, Val Loss: 0.11627907305955887\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.10774672031402588, Val Loss: 0.10857149213552475\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.09402134269475937, Val Loss: 0.09841100126504898\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.08003310859203339, Val Loss: 0.08861829340457916\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.08419037610292435, Val Loss: 0.08111944794654846\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.07252676039934158, Val Loss: 0.074497751891613\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.0725989043712616, Val Loss: 0.07137229293584824\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.0701504647731781, Val Loss: 0.07129839807748795\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.06569511443376541, Val Loss: 0.07294300943613052\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.0751856118440628, Val Loss: 0.07722525298595428\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.07276344299316406, Val Loss: 0.08512565493583679\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.06931490451097488, Val Loss: 0.09351297467947006\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.0701017752289772, Val Loss: 0.10287534445524216\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.06308639794588089, Val Loss: 0.10707605630159378\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.057822249829769135, Val Loss: 0.1092911958694458\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.06700760126113892, Val Loss: 0.10851961374282837\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.057265426963567734, Val Loss: 0.10298696905374527\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.06215985119342804, Val Loss: 0.09743539988994598\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.06049352139234543, Val Loss: 0.08986363559961319\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.06324799358844757, Val Loss: 0.08327631652355194\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.0611032210290432, Val Loss: 0.07784177362918854\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.05217239633202553, Val Loss: 0.07638552039861679\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.058346331119537354, Val Loss: 0.07682474702596664\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.05465301126241684, Val Loss: 0.07658904790878296\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.0512395016849041, Val Loss: 0.07760896533727646\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.055822014808654785, Val Loss: 0.08262661099433899\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.062200918793678284, Val Loss: 0.09010525792837143\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.06252797693014145, Val Loss: 0.09770610183477402\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.12100507318973541, Val Loss: 0.03453633189201355\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.12699906527996063, Val Loss: 0.03300178050994873\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.11828102916479111, Val Loss: 0.03172292932868004\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.12592625617980957, Val Loss: 0.030409565195441246\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.12760186195373535, Val Loss: 0.029213372617959976\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.11934879422187805, Val Loss: 0.02834727242588997\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.13449019193649292, Val Loss: 0.027606939896941185\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.12799574434757233, Val Loss: 0.027003806084394455\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.1045437753200531, Val Loss: 0.02641504816710949\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.11657992005348206, Val Loss: 0.026048896834254265\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.12339077144861221, Val Loss: 0.02619539014995098\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.11763374507427216, Val Loss: 0.026172572746872902\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.09344906359910965, Val Loss: 0.026182793080806732\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.10950102657079697, Val Loss: 0.026468859985470772\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.10487082600593567, Val Loss: 0.02620616927742958\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.09594281017780304, Val Loss: 0.025914715602993965\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.09446204453706741, Val Loss: 0.026296032592654228\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.09345368295907974, Val Loss: 0.025507429614663124\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.0803380161523819, Val Loss: 0.02436991035938263\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.08545820415019989, Val Loss: 0.0228279996663332\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.08400192856788635, Val Loss: 0.022548459470272064\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.07979085296392441, Val Loss: 0.02429717779159546\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.07500176131725311, Val Loss: 0.026715416461229324\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.08131962269544601, Val Loss: 0.028376681730151176\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.07900954782962799, Val Loss: 0.02902377024292946\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.08305899053812027, Val Loss: 0.027296049520373344\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.06857480108737946, Val Loss: 0.024916989728808403\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.08036363869905472, Val Loss: 0.023227160796523094\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.07223061472177505, Val Loss: 0.021923433989286423\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.07167717814445496, Val Loss: 0.021249152719974518\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.07039371132850647, Val Loss: 0.02137679234147072\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.07656659930944443, Val Loss: 0.02328915148973465\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.0720958262681961, Val Loss: 0.025613298639655113\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.06010625883936882, Val Loss: 0.026290670037269592\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.06336785852909088, Val Loss: 0.025287317112088203\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.061091333627700806, Val Loss: 0.0227301437407732\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.06285124272108078, Val Loss: 0.02008310705423355\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.07734748721122742, Val Loss: 0.018289972096681595\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.05842205137014389, Val Loss: 0.017004413530230522\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.057710472494363785, Val Loss: 0.015843195840716362\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.057791780680418015, Val Loss: 0.01526607759296894\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.06369013339281082, Val Loss: 0.01549078244715929\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.06018199399113655, Val Loss: 0.015476462431252003\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.05788411200046539, Val Loss: 0.015508225187659264\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.05433636158704758, Val Loss: 0.01708008348941803\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.054151080548763275, Val Loss: 0.01822846382856369\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.05838930234313011, Val Loss: 0.019233698025345802\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.05454292893409729, Val Loss: 0.018161987885832787\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.05842622369527817, Val Loss: 0.017370447516441345\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.05361197516322136, Val Loss: 0.015325005166232586\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.054090797901153564, Val Loss: 0.013680287636816502\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.05073017254471779, Val Loss: 0.012415147386491299\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.05166969820857048, Val Loss: 0.012108598835766315\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.059575699269771576, Val Loss: 0.012863270938396454\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.05086050182580948, Val Loss: 0.014749265275895596\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.0557621531188488, Val Loss: 0.017032403498888016\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.058795273303985596, Val Loss: 0.017889469861984253\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.04967568442225456, Val Loss: 0.019086163491010666\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.05117613449692726, Val Loss: 0.018946638330817223\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.05238797515630722, Val Loss: 0.017608577385544777\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.04657091572880745, Val Loss: 0.015944169834256172\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.051617495715618134, Val Loss: 0.01554097980260849\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.0500640869140625, Val Loss: 0.014859647490084171\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.049978166818618774, Val Loss: 0.014735916629433632\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.05278235673904419, Val Loss: 0.014654960483312607\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.04517830163240433, Val Loss: 0.014616033062338829\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.050316497683525085, Val Loss: 0.014861778356134892\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.055149856954813004, Val Loss: 0.01518213003873825\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.046003539115190506, Val Loss: 0.015192514285445213\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.055412061512470245, Val Loss: 0.01564493216574192\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.050336457788944244, Val Loss: 0.01625814102590084\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.05448250100016594, Val Loss: 0.016829747706651688\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.04729798436164856, Val Loss: 0.017427077516913414\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.06421513855457306, Val Loss: 0.004971726797521114\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.05762581154704094, Val Loss: 0.005120960064232349\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.06205713376402855, Val Loss: 0.005209073424339294\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.05934500694274902, Val Loss: 0.005227253306657076\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.06730291992425919, Val Loss: 0.005309321917593479\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.057891227304935455, Val Loss: 0.005422327667474747\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.0557735301554203, Val Loss: 0.005703344475477934\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.0569247342646122, Val Loss: 0.006018026731908321\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.0477830246090889, Val Loss: 0.006597029510885477\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.05677174776792526, Val Loss: 0.007281291764229536\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.05495006963610649, Val Loss: 0.008000052534043789\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.05143805965781212, Val Loss: 0.008895584382116795\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.056762486696243286, Val Loss: 0.009945514611899853\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.05577101930975914, Val Loss: 0.011373157612979412\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.060774244368076324, Val Loss: 0.012964487075805664\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.05551125481724739, Val Loss: 0.014187152497470379\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.05271156132221222, Val Loss: 0.015063912607729435\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.05571886524558067, Val Loss: 0.015392555855214596\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.04625321552157402, Val Loss: 0.015051843598484993\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.04788093641400337, Val Loss: 0.014646234922111034\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.052576836198568344, Val Loss: 0.01485605537891388\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.13242974877357483, Val Loss: 0.003233653958886862\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.13233070075511932, Val Loss: 0.00193472346290946\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.13149003684520721, Val Loss: 0.00789062213152647\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.11664794385433197, Val Loss: 0.019779257476329803\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.12426339089870453, Val Loss: 0.035500600934028625\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.12600697576999664, Val Loss: 0.0544651634991169\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.11126924306154251, Val Loss: 0.07255333662033081\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.12841150164604187, Val Loss: 0.0890001654624939\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.11190872639417648, Val Loss: 0.1021295040845871\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.10535407811403275, Val Loss: 0.10755554586648941\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.11028043180704117, Val Loss: 0.11005887389183044\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.10443679988384247, Val Loss: 0.10493888705968857\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.1012367457151413, Val Loss: 0.09812821447849274\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.10406224429607391, Val Loss: 0.08958828449249268\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.10588625818490982, Val Loss: 0.08182359486818314\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.10165567696094513, Val Loss: 0.07712647318840027\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.10087322443723679, Val Loss: 0.07709299027919769\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.09513246268033981, Val Loss: 0.0801289975643158\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.08429446816444397, Val Loss: 0.08828333765268326\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.09015172719955444, Val Loss: 0.09440393000841141\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.08267780393362045, Val Loss: 0.09694556146860123\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.08454672247171402, Val Loss: 0.09725338965654373\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.06538930535316467, Val Loss: 0.009685809724032879\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.020173447811976074, 'rmse': 0.11885685812459737, 'mae': 0.10297891497612, 'mape': 40.0575265288353, 'r2': 0.7917692688969127}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.1633816957473755, Val Loss: 0.1768241971731186\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.2746868133544922, Val Loss: 0.17689372599124908\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.119446039199829, Val Loss: 0.1763906627893448\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.206609845161438, Val Loss: 0.1759747415781021\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.949863076210022, Val Loss: 0.17555469274520874\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.1345868110656738, Val Loss: 0.17534957826137543\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.8100695610046387, Val Loss: 0.17492122948169708\n",
      "INFO:root:Epoch 8/100, Train Loss: 1.037992238998413, Val Loss: 0.17486535012722015\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.708259105682373, Val Loss: 0.17473956942558289\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.5858155488967896, Val Loss: 0.17473569512367249\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.5657860636711121, Val Loss: 0.174398735165596\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.502355694770813, Val Loss: 0.17278477549552917\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.5486093759536743, Val Loss: 0.17120705544948578\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.3262229859828949, Val Loss: 0.16879376769065857\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.4296916425228119, Val Loss: 0.16883711516857147\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.3067799210548401, Val Loss: 0.16832634806632996\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.32652807235717773, Val Loss: 0.1672998070716858\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.3505420684814453, Val Loss: 0.1657983511686325\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.30903375148773193, Val Loss: 0.16403928399085999\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.30910882353782654, Val Loss: 0.16322967410087585\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.27536624670028687, Val Loss: 0.16300077736377716\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.2849358320236206, Val Loss: 0.16316096484661102\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.2739136815071106, Val Loss: 0.1633218675851822\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.25582292675971985, Val Loss: 0.1621440201997757\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.24439939856529236, Val Loss: 0.15986426174640656\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.18721377849578857, Val Loss: 0.15848088264465332\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.21907703578472137, Val Loss: 0.15848331153392792\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.16454516351222992, Val Loss: 0.1570058912038803\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.13400378823280334, Val Loss: 0.15525074303150177\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.17265205085277557, Val Loss: 0.15398643910884857\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.13934797048568726, Val Loss: 0.15030640363693237\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.1472417712211609, Val Loss: 0.14739547669887543\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.14122897386550903, Val Loss: 0.14514724910259247\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.17180760204792023, Val Loss: 0.14419446885585785\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.11360474675893784, Val Loss: 0.14306579530239105\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.12315903604030609, Val Loss: 0.14207348227500916\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.15917441248893738, Val Loss: 0.13928933441638947\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.09126356989145279, Val Loss: 0.1363065540790558\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.11711803823709488, Val Loss: 0.13277418911457062\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.09606239944696426, Val Loss: 0.12902246415615082\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.10578986257314682, Val Loss: 0.12571442127227783\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.1171746701002121, Val Loss: 0.1217723935842514\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.07002608478069305, Val Loss: 0.1184636577963829\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.09035684168338776, Val Loss: 0.11433511972427368\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.07956291735172272, Val Loss: 0.11119842529296875\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.0873350203037262, Val Loss: 0.108504518866539\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.09965568780899048, Val Loss: 0.10582796484231949\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.08102096617221832, Val Loss: 0.10546737164258957\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.07774443179368973, Val Loss: 0.10421653836965561\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.06344303488731384, Val Loss: 0.1027325987815857\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.07362888753414154, Val Loss: 0.10070407390594482\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.06773919612169266, Val Loss: 0.09841331839561462\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.06841283291578293, Val Loss: 0.09696858376264572\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.07967391610145569, Val Loss: 0.09385418891906738\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.059476159512996674, Val Loss: 0.09084013849496841\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.06968946009874344, Val Loss: 0.0871739536523819\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.060144707560539246, Val Loss: 0.08293742686510086\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.06762206554412842, Val Loss: 0.07954785972833633\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.08110782504081726, Val Loss: 0.075891874730587\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.061594799160957336, Val Loss: 0.07206621766090393\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.05359697341918945, Val Loss: 0.06800178438425064\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.0631229430437088, Val Loss: 0.06433127820491791\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.06758467108011246, Val Loss: 0.060229167342185974\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.053072020411491394, Val Loss: 0.056880515068769455\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.06503045558929443, Val Loss: 0.05415293574333191\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.0602736696600914, Val Loss: 0.05176796019077301\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.06408383697271347, Val Loss: 0.04979308322072029\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.06409497559070587, Val Loss: 0.04808666184544563\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.048613134771585464, Val Loss: 0.04677394777536392\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.04043770208954811, Val Loss: 0.04513068497180939\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.04909665882587433, Val Loss: 0.044654667377471924\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.058959778398275375, Val Loss: 0.04430829733610153\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.05858326703310013, Val Loss: 0.04367871209979057\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.03948380425572395, Val Loss: 0.04236898571252823\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.057962533086538315, Val Loss: 0.040863897651433945\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.05251051113009453, Val Loss: 0.039722736924886703\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.048840854316949844, Val Loss: 0.03871507570147514\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.07007622718811035, Val Loss: 0.0375184565782547\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.09389369189739227, Val Loss: 0.036951642483472824\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.06405965238809586, Val Loss: 0.03656071051955223\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.06400714069604874, Val Loss: 0.03649672865867615\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.04716852679848671, Val Loss: 0.03600168973207474\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.03923281282186508, Val Loss: 0.03606395423412323\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.048490848392248154, Val Loss: 0.035597193986177444\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.040239106863737106, Val Loss: 0.03582239896059036\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.061205968260765076, Val Loss: 0.035603392869234085\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.058004483580589294, Val Loss: 0.035615257918834686\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.05178076773881912, Val Loss: 0.03517414256930351\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.05665738135576248, Val Loss: 0.03452594205737114\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.05954921990633011, Val Loss: 0.03438570350408554\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.049385711550712585, Val Loss: 0.03399607539176941\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.04405340924859047, Val Loss: 0.03388826921582222\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.06838831305503845, Val Loss: 0.0339188314974308\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.06967271864414215, Val Loss: 0.03409021347761154\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.05167161300778389, Val Loss: 0.033907320350408554\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.04735611379146576, Val Loss: 0.033847417682409286\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.04841431975364685, Val Loss: 0.033571112900972366\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.05840691551566124, Val Loss: 0.03355114161968231\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.047262273728847504, Val Loss: 0.033804286271333694\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.0422588512301445, Val Loss: 0.03403405845165253\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.05809354409575462, Val Loss: 0.010503385215997696\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.0446588359773159, Val Loss: 0.010634885169565678\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.06050051003694534, Val Loss: 0.01105665136128664\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.05993286147713661, Val Loss: 0.011286154389381409\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.06933457404375076, Val Loss: 0.01105100754648447\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.05564587563276291, Val Loss: 0.010992730036377907\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.044712722301483154, Val Loss: 0.01143290102481842\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.0714128240942955, Val Loss: 0.010770927183330059\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.05190667137503624, Val Loss: 0.011103506200015545\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.04795600473880768, Val Loss: 0.011618842370808125\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.03924264386296272, Val Loss: 0.011437149718403816\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.05351528152823448, Val Loss: 0.011278576217591763\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.05964428186416626, Val Loss: 0.011017910204827785\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.06186847388744354, Val Loss: 0.010662754066288471\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.04369955509901047, Val Loss: 0.010550808161497116\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.04219511151313782, Val Loss: 0.010558933019638062\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.04453078284859657, Val Loss: 0.009944329969584942\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.060145165771245956, Val Loss: 0.009229613468050957\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.033083632588386536, Val Loss: 0.00841047614812851\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.052724689245224, Val Loss: 0.00816857535392046\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.04901058226823807, Val Loss: 0.009658564813435078\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.053238026797771454, Val Loss: 0.009888346306979656\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.04167388007044792, Val Loss: 0.009961969219148159\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.05031505599617958, Val Loss: 0.009692835621535778\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.04760953411459923, Val Loss: 0.00881818775087595\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.055317655205726624, Val Loss: 0.008602319285273552\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.03804640844464302, Val Loss: 0.01126632746309042\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.04344354569911957, Val Loss: 0.015045610256493092\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.06800061464309692, Val Loss: 0.01415998861193657\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.048493463546037674, Val Loss: 0.012618270702660084\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.06869522482156754, Val Loss: 0.008887331932783127\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.04512876272201538, Val Loss: 0.010624956339597702\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.05440158396959305, Val Loss: 0.011513200588524342\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.04615969955921173, Val Loss: 0.010289072059094906\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.03783053159713745, Val Loss: 0.01018054410815239\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.041614290326833725, Val Loss: 0.010889521799981594\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.03750033304095268, Val Loss: 0.012103205546736717\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.03799622878432274, Val Loss: 0.012996216304600239\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.04946130886673927, Val Loss: 0.014750848524272442\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.04217150807380676, Val Loss: 0.015536959283053875\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.06177058070898056, Val Loss: 0.006284371018409729\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.0466163270175457, Val Loss: 0.00618547759950161\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.05262310802936554, Val Loss: 0.006001705769449472\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.060452546924352646, Val Loss: 0.005972878076136112\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.045886117964982986, Val Loss: 0.006096560973674059\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.04216024652123451, Val Loss: 0.006272342521697283\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.047717802226543427, Val Loss: 0.006233434192836285\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.04353219270706177, Val Loss: 0.00615058233961463\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.04779850319027901, Val Loss: 0.006513550411909819\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.03894006833434105, Val Loss: 0.006645240355283022\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.057488154619932175, Val Loss: 0.006982932798564434\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.06275714188814163, Val Loss: 0.007159616332501173\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.059740565717220306, Val Loss: 0.007462925277650356\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.04533814638853073, Val Loss: 0.00779535248875618\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.040326133370399475, Val Loss: 0.008340788073837757\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.0634138286113739, Val Loss: 0.008838442154228687\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.05238715559244156, Val Loss: 0.008885212242603302\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.042985398322343826, Val Loss: 0.00909500103443861\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.03751739487051964, Val Loss: 0.009883735328912735\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.05007423087954521, Val Loss: 0.01060918252915144\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.03796897828578949, Val Loss: 0.01143314316868782\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.03983665630221367, Val Loss: 0.012376002036035061\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.039817456156015396, Val Loss: 0.015120359137654305\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.03828594833612442, Val Loss: 0.018960997462272644\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.19779933989048004, Val Loss: 0.02232086844742298\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.04065580293536186, Val Loss: 0.014370158314704895\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.013443499524146318, 'rmse': 0.107922650599992, 'mae': 0.09407467171549797, 'mape': 32.27405160665512, 'r2': 0.8804930721289542}\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.7233165502548218, Val Loss: 0.2384852170944214\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.7816927433013916, Val Loss: 0.23940162360668182\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.829585075378418, Val Loss: 0.23993784189224243\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.6843816637992859, Val Loss: 0.23890504240989685\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.7158384919166565, Val Loss: 0.2386218011379242\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.6317805051803589, Val Loss: 0.23643232882022858\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.6401503682136536, Val Loss: 0.23421700298786163\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.3602961301803589, Val Loss: 0.2321828156709671\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.6352284550666809, Val Loss: 0.2299477905035019\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.6518617272377014, Val Loss: 0.22891153395175934\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.5586467385292053, Val Loss: 0.2268042117357254\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.433547705411911, Val Loss: 0.22309687733650208\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.3939558267593384, Val Loss: 0.2197013646364212\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.4218936264514923, Val Loss: 0.21830753982067108\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.31798750162124634, Val Loss: 0.21474723517894745\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.2498776763677597, Val Loss: 0.2093261182308197\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.2350800484418869, Val Loss: 0.20718111097812653\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.24440737068653107, Val Loss: 0.2002381533384323\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.30799534916877747, Val Loss: 0.194944366812706\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.2860158085823059, Val Loss: 0.1902363896369934\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.3525894582271576, Val Loss: 0.18896113336086273\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.22735896706581116, Val Loss: 0.1868600994348526\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.1846057027578354, Val Loss: 0.18282286822795868\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.2465023398399353, Val Loss: 0.17865635454654694\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.2208855301141739, Val Loss: 0.17826759815216064\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.23205941915512085, Val Loss: 0.17978404462337494\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.21918533742427826, Val Loss: 0.1777038723230362\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.1549060344696045, Val Loss: 0.17545630037784576\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.16720731556415558, Val Loss: 0.17289167642593384\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.19379107654094696, Val Loss: 0.17328579723834991\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.1809072494506836, Val Loss: 0.17158126831054688\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.15653307735919952, Val Loss: 0.17131280899047852\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.13424739241600037, Val Loss: 0.1702079027891159\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.12441051751375198, Val Loss: 0.16978134214878082\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.14676721394062042, Val Loss: 0.16700388491153717\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.15990537405014038, Val Loss: 0.16027650237083435\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.12060514092445374, Val Loss: 0.1545356810092926\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.12612773478031158, Val Loss: 0.14720937609672546\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.12565185129642487, Val Loss: 0.14323732256889343\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.14312364161014557, Val Loss: 0.1383543163537979\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.13451360166072845, Val Loss: 0.1346445083618164\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.14028584957122803, Val Loss: 0.1285581737756729\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.10717974603176117, Val Loss: 0.12248189747333527\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.10720418393611908, Val Loss: 0.11680899560451508\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.12110714614391327, Val Loss: 0.11295875906944275\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.11588045954704285, Val Loss: 0.10689353197813034\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.13406656682491302, Val Loss: 0.10226430743932724\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.0958016961812973, Val Loss: 0.09832736104726791\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.10064978152513504, Val Loss: 0.09390358626842499\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.0870606079697609, Val Loss: 0.08857448399066925\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.1001952588558197, Val Loss: 0.08516564220190048\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.12049292027950287, Val Loss: 0.0822954997420311\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.1125791147351265, Val Loss: 0.07955960929393768\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.10210571438074112, Val Loss: 0.07604367285966873\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.09467212110757828, Val Loss: 0.07358463108539581\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.08446888625621796, Val Loss: 0.07019070535898209\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.0807284340262413, Val Loss: 0.0667298436164856\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.08122089505195618, Val Loss: 0.06557031720876694\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.09125570952892303, Val Loss: 0.06393740326166153\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.09856297075748444, Val Loss: 0.06166994944214821\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.07706102728843689, Val Loss: 0.05889555439352989\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.07579883933067322, Val Loss: 0.05556685850024223\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.07386008650064468, Val Loss: 0.05364571884274483\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.09037051349878311, Val Loss: 0.05050765722990036\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.09037955105304718, Val Loss: 0.049358200281858444\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.08118543773889542, Val Loss: 0.04735825955867767\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.07078562676906586, Val Loss: 0.044587187469005585\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.08635157346725464, Val Loss: 0.04217435047030449\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.07713533192873001, Val Loss: 0.03950075805187225\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.06967289000749588, Val Loss: 0.037153180688619614\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.07375194132328033, Val Loss: 0.03414427861571312\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.06931526958942413, Val Loss: 0.03198767080903053\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.06490324437618256, Val Loss: 0.029364723712205887\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.0731043592095375, Val Loss: 0.02738361246883869\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.09078050404787064, Val Loss: 0.026014788076281548\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.08380067348480225, Val Loss: 0.023353327065706253\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.07375416159629822, Val Loss: 0.022640231996774673\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.07786243408918381, Val Loss: 0.021370060741901398\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.08130320906639099, Val Loss: 0.0205395370721817\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.08189011365175247, Val Loss: 0.019860398024320602\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.08115220069885254, Val Loss: 0.02009551413357258\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.0743359848856926, Val Loss: 0.01913239248096943\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.06355037540197372, Val Loss: 0.019442738965153694\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.07534459978342056, Val Loss: 0.018942739814519882\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.06112143397331238, Val Loss: 0.018792329356074333\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.07426603138446808, Val Loss: 0.01833646185696125\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.07463116198778152, Val Loss: 0.018404752016067505\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.06973906606435776, Val Loss: 0.01758633181452751\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.06297646462917328, Val Loss: 0.017900563776493073\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.07988609373569489, Val Loss: 0.017675362527370453\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.09242410957813263, Val Loss: 0.01705358363687992\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.07457900792360306, Val Loss: 0.017527174204587936\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.07442127168178558, Val Loss: 0.016974059864878654\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.07285615801811218, Val Loss: 0.017518840730190277\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.07286768406629562, Val Loss: 0.018458545207977295\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.07767973095178604, Val Loss: 0.017209377139806747\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.06717532873153687, Val Loss: 0.01724025420844555\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.07070526480674744, Val Loss: 0.01647934503853321\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.09325821697711945, Val Loss: 0.01509195938706398\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.07820872962474823, Val Loss: 0.015540089458227158\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.07356484979391098, Val Loss: 0.00725398026406765\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.06756697595119476, Val Loss: 0.007513363379985094\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.09143675118684769, Val Loss: 0.00816613994538784\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.06164289638400078, Val Loss: 0.008333918638527393\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.06614566594362259, Val Loss: 0.008328611962497234\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.0832405686378479, Val Loss: 0.008663751184940338\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.07741700857877731, Val Loss: 0.00867669191211462\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.07624103873968124, Val Loss: 0.009199099615216255\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.08693508803844452, Val Loss: 0.008929675444960594\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.08819504082202911, Val Loss: 0.01034726295620203\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.07103090733289719, Val Loss: 0.010548418387770653\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.06725383549928665, Val Loss: 0.011970125138759613\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.06425174325704575, Val Loss: 0.013174130581319332\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.06900565326213837, Val Loss: 0.014507818035781384\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.08104830980300903, Val Loss: 0.013955564238131046\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.06941451877355576, Val Loss: 0.011681974865496159\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.05779630318284035, Val Loss: 0.009213147684931755\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.07984846085309982, Val Loss: 0.00868252757936716\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.08590368181467056, Val Loss: 0.010740148834884167\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.07188587635755539, Val Loss: 0.014559526927769184\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.05875026434659958, Val Loss: 0.01708259992301464\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.07005314528942108, Val Loss: 0.0017105783335864544\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.08569587767124176, Val Loss: 0.0017436129273846745\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.0738646388053894, Val Loss: 0.0017945817671716213\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.06544480472803116, Val Loss: 0.0015916276024654508\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.07043520361185074, Val Loss: 0.0017218574648723006\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.06510438024997711, Val Loss: 0.001956343650817871\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.08203072845935822, Val Loss: 0.0017704477068036795\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.08479398488998413, Val Loss: 0.0015700443182140589\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.0713641569018364, Val Loss: 0.0014589764177799225\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.07504110783338547, Val Loss: 0.0012482203310355544\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.06441034376621246, Val Loss: 0.0012806110316887498\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.0734042078256607, Val Loss: 0.0013095943722873926\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.07541115581989288, Val Loss: 0.001312645268626511\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.06478150188922882, Val Loss: 0.0016156693454831839\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.061378639191389084, Val Loss: 0.002092130947858095\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.06580730527639389, Val Loss: 0.0026992603670805693\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.05973472073674202, Val Loss: 0.0032741150353103876\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.061157017946243286, Val Loss: 0.004849264398217201\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.06210583820939064, Val Loss: 0.005865043960511684\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.060273025184869766, Val Loss: 0.006897375453263521\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.06662797927856445, Val Loss: 0.00640764320269227\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.05945742502808571, Val Loss: 0.005625131074339151\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.06267470121383667, Val Loss: 0.005027194507420063\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.06847413629293442, Val Loss: 0.0036486953031271696\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.0587235651910305, Val Loss: 0.0029986363369971514\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.05029620975255966, Val Loss: 0.0032709178049117327\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.057429470121860504, Val Loss: 0.0045959060080349445\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.05381237715482712, Val Loss: 0.004905316513031721\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.05790999159216881, Val Loss: 0.003404599614441395\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.060784533619880676, Val Loss: 0.0033287585247308016\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.14194263517856598, Val Loss: 0.006557781714946032\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.07490602880716324, Val Loss: 0.012022750452160835\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.008313248679041863, 'rmse': 0.08602552635168201, 'mae': 0.07253507189452649, 'mape': 26.00846618413925, 'r2': 0.942143579061395}\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.7664183974266052, Val Loss: 0.16963620483875275\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.4941363036632538, Val Loss: 0.16821525990962982\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.3124619424343109, Val Loss: 0.1662801206111908\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.21262532472610474, Val Loss: 0.16474151611328125\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.1807011067867279, Val Loss: 0.16427752375602722\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.246391162276268, Val Loss: 0.1637994945049286\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.27607297897338867, Val Loss: 0.16411878168582916\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.29514357447624207, Val Loss: 0.16345851123332977\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.29742053151130676, Val Loss: 0.16263458132743835\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.2144276648759842, Val Loss: 0.1617628037929535\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.17001421749591827, Val Loss: 0.16080890595912933\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.15547314286231995, Val Loss: 0.15897126495838165\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.15418916940689087, Val Loss: 0.15273314714431763\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.12658388912677765, Val Loss: 0.14163900911808014\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.08049320429563522, Val Loss: 0.12830661237239838\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.07666496932506561, Val Loss: 0.12036003172397614\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.10094573348760605, Val Loss: 0.11959648132324219\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.0948009118437767, Val Loss: 0.12188957631587982\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.06158662959933281, Val Loss: 0.12091337889432907\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.0398525707423687, Val Loss: 0.12254314869642258\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.041395943611860275, Val Loss: 0.1306968331336975\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.04943815618753433, Val Loss: 0.13565969467163086\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.04108916595578194, Val Loss: 0.12590770423412323\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.026843642815947533, Val Loss: 0.11011878401041031\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.022491715848445892, Val Loss: 0.10338578373193741\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.02850121073424816, Val Loss: 0.10709279775619507\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.023656515404582024, Val Loss: 0.10620829463005066\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.016968131065368652, Val Loss: 0.10172612965106964\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.01505797915160656, Val Loss: 0.10075818002223969\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.01589442603290081, Val Loss: 0.09854812175035477\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.016627365723252296, Val Loss: 0.09286989271640778\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.015058960765600204, Val Loss: 0.0843183770775795\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.0132784154266119, Val Loss: 0.07511462271213531\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.011129787191748619, Val Loss: 0.06898161768913269\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.01208622194826603, Val Loss: 0.06687452644109726\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.0110995564609766, Val Loss: 0.06505020707845688\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.010738033801317215, Val Loss: 0.06494948267936707\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.0104398587718606, Val Loss: 0.06536367535591125\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.009011557325720787, Val Loss: 0.06491079181432724\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.010208760388195515, Val Loss: 0.06354930251836777\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.009922992438077927, Val Loss: 0.060591921210289\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.009016095660626888, Val Loss: 0.056584540754556656\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.007768563460558653, Val Loss: 0.054564617574214935\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.009118488989770412, Val Loss: 0.054112523794174194\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.00925426371395588, Val Loss: 0.049015529453754425\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.008664833381772041, Val Loss: 0.040670767426490784\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.008001968264579773, Val Loss: 0.03480236232280731\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.007661414798349142, Val Loss: 0.03500013425946236\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.0072268275544047356, Val Loss: 0.037773553282022476\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.008184093050658703, Val Loss: 0.03632470220327377\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.007749253883957863, Val Loss: 0.03085271269083023\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.007860134355723858, Val Loss: 0.025356292724609375\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.006444024387747049, Val Loss: 0.02166699804365635\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.006649198941886425, Val Loss: 0.020701153203845024\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.006503056734800339, Val Loss: 0.02102605253458023\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.006755746901035309, Val Loss: 0.021820418536663055\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.006798307411372662, Val Loss: 0.020766787230968475\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.007308280095458031, Val Loss: 0.018574299290776253\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.006851955316960812, Val Loss: 0.016399063169956207\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.00624687597155571, Val Loss: 0.014505056664347649\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.006872190162539482, Val Loss: 0.01362722646445036\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.00716438377276063, Val Loss: 0.013361172750592232\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.006143969018012285, Val Loss: 0.013238133862614632\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.007514121476560831, Val Loss: 0.013191048055887222\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.005890365224331617, Val Loss: 0.012893220409750938\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.00513240322470665, Val Loss: 0.01235155388712883\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.006101015955209732, Val Loss: 0.01176323089748621\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.006557369139045477, Val Loss: 0.010873114690184593\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.007019738666713238, Val Loss: 0.009599619545042515\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.006395550910383463, Val Loss: 0.008639251813292503\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.006549170706421137, Val Loss: 0.008129175752401352\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.006357861217111349, Val Loss: 0.007843384519219398\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.0066408454440534115, Val Loss: 0.00774633651599288\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.0063460711389780045, Val Loss: 0.007715899497270584\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.007359372451901436, Val Loss: 0.00770984310656786\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.006146079394966364, Val Loss: 0.007562441751360893\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.006212035659700632, Val Loss: 0.007477996405214071\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.006018339656293392, Val Loss: 0.007379089016467333\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.0060164774768054485, Val Loss: 0.007284095510840416\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.005992584861814976, Val Loss: 0.007120209746062756\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.005403275601565838, Val Loss: 0.006963145453482866\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.0058306679129600525, Val Loss: 0.006785145495086908\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.006496643181890249, Val Loss: 0.006575125269591808\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.006246313452720642, Val Loss: 0.006419822108000517\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.005380225833505392, Val Loss: 0.00628757243975997\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.006126533728092909, Val Loss: 0.006151114124804735\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.005622625816613436, Val Loss: 0.006024735514074564\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.005925987381488085, Val Loss: 0.005942263174802065\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.0065874578431248665, Val Loss: 0.005853093229234219\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.005888400133699179, Val Loss: 0.005765768699347973\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.006361009087413549, Val Loss: 0.0057496544905006886\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.006104836706072092, Val Loss: 0.00577675411477685\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.006031682714819908, Val Loss: 0.005761368665844202\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.006578029599040747, Val Loss: 0.0057342746295034885\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.005870869383215904, Val Loss: 0.005729821976274252\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.00612960010766983, Val Loss: 0.0057013570331037045\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.007030321750789881, Val Loss: 0.005723159294575453\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.00490576820448041, Val Loss: 0.0057069058530032635\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.00628163106739521, Val Loss: 0.0057241469621658325\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.006664563436061144, Val Loss: 0.005761082749813795\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.011402723379433155, Val Loss: 0.0005176594131626189\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.011364329606294632, Val Loss: 0.0006966853979974985\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.01167246513068676, Val Loss: 0.000867554743308574\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.010615128092467785, Val Loss: 0.0009658343042246997\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.010090886615216732, Val Loss: 0.0010288418270647526\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.009752747602760792, Val Loss: 0.0010615276405587792\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.009049820713698864, Val Loss: 0.0010789686348289251\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.009243758395314217, Val Loss: 0.0011936562368646264\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.008525019511580467, Val Loss: 0.0013507540570572019\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.008940855972468853, Val Loss: 0.001530167763121426\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.009380447678267956, Val Loss: 0.0017087558517232537\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.009167911484837532, Val Loss: 0.0018313919426873326\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.008884699083864689, Val Loss: 0.0019215334905311465\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.008236090652644634, Val Loss: 0.001888712984509766\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.008013659156858921, Val Loss: 0.0020543988794088364\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.008761337026953697, Val Loss: 0.002929053269326687\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.008201229386031628, Val Loss: 0.004270466975867748\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.00751030258834362, Val Loss: 0.00491336127743125\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.008969374001026154, Val Loss: 0.004129523877054453\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.007139157969504595, Val Loss: 0.0024876827374100685\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.00732012465596199, Val Loss: 0.0035332473926246166\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.010114902630448341, Val Loss: 0.00040651141898706555\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.009548371657729149, Val Loss: 0.0006242701783776283\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.010184574872255325, Val Loss: 0.0008509135222993791\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.010735212825238705, Val Loss: 0.001128139323554933\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.010667553171515465, Val Loss: 0.0013807191280648112\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.008822276256978512, Val Loss: 0.0015319385565817356\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.008630508556962013, Val Loss: 0.001669138204306364\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.008962615393102169, Val Loss: 0.0017999544506892562\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.008528164587914944, Val Loss: 0.00201567099429667\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.009279102087020874, Val Loss: 0.0022338039707392454\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.00952686183154583, Val Loss: 0.0022036510054022074\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.008663929998874664, Val Loss: 0.0019249963806942105\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.008521136827766895, Val Loss: 0.0022472694981843233\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.00752546451985836, Val Loss: 0.0038737724535167217\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.007799081038683653, Val Loss: 0.005426426418125629\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.008265266194939613, Val Loss: 0.0050839935429394245\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.00817163661122322, Val Loss: 0.0019881348125636578\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.007454614154994488, Val Loss: 0.001431940821930766\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.0071976156905293465, Val Loss: 0.0027007092721760273\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.007477134931832552, Val Loss: 0.0023201433941721916\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.006678654812276363, Val Loss: 0.0019100212957710028\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.1640365570783615, Val Loss: 0.0017062093829736114\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.018771443516016006, Val Loss: 0.00105342420283705\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.0023714064038358627, 'rmse': 0.04247494450428003, 'mae': 0.03544713780283928, 'mape': 15.700494423508644, 'r2': 0.9837661109781933}\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.5865570306777954, Val Loss: 0.19747155904769897\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.5083418488502502, Val Loss: 0.19601260125637054\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.43795913457870483, Val Loss: 0.19572500884532928\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.42475414276123047, Val Loss: 0.1952366977930069\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.33256253600120544, Val Loss: 0.1934630572795868\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.21705646812915802, Val Loss: 0.19169585406780243\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.2285275161266327, Val Loss: 0.19066546857357025\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.2581208348274231, Val Loss: 0.1869850754737854\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.41295304894447327, Val Loss: 0.18410971760749817\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.22685396671295166, Val Loss: 0.18147678673267365\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.1546848565340042, Val Loss: 0.17846767604351044\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.20927794277668, Val Loss: 0.17784450948238373\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.1102607324719429, Val Loss: 0.17788952589035034\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.13915234804153442, Val Loss: 0.17616987228393555\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.18838611245155334, Val Loss: 0.1749013364315033\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.19921939074993134, Val Loss: 0.17452919483184814\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.09330736845731735, Val Loss: 0.17376035451889038\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.07751122862100601, Val Loss: 0.17228463292121887\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.075919970870018, Val Loss: 0.16612179577350616\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.0898236557841301, Val Loss: 0.15617060661315918\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.10286234319210052, Val Loss: 0.15123383700847626\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.07269544899463654, Val Loss: 0.15399876236915588\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.06301058828830719, Val Loss: 0.15432895720005035\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.03982596844434738, Val Loss: 0.14885565638542175\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.06147828325629234, Val Loss: 0.13851001858711243\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.04293835908174515, Val Loss: 0.12871943414211273\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.05153977870941162, Val Loss: 0.12510477006435394\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.027971701696515083, Val Loss: 0.12631849944591522\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.036840494722127914, Val Loss: 0.12407676130533218\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.04352398216724396, Val Loss: 0.11784151196479797\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.028238100931048393, Val Loss: 0.11236758530139923\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.045470599085092545, Val Loss: 0.11078834533691406\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.028995025902986526, Val Loss: 0.11327017098665237\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.025041397660970688, Val Loss: 0.11282870173454285\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.02281975746154785, Val Loss: 0.10916361212730408\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.027118349447846413, Val Loss: 0.10132749378681183\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.016618499532341957, Val Loss: 0.0952547937631607\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.018710073083639145, Val Loss: 0.09145542234182358\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.018283119425177574, Val Loss: 0.09103983640670776\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.01589300110936165, Val Loss: 0.08976881206035614\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.018931332975625992, Val Loss: 0.08455828577280045\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.01814771257340908, Val Loss: 0.07775725424289703\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.01611495576798916, Val Loss: 0.07222221791744232\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.01939832791686058, Val Loss: 0.06985029578208923\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.01769459806382656, Val Loss: 0.07001401484012604\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.012311328202486038, Val Loss: 0.06968043744564056\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.016186509281396866, Val Loss: 0.0684569701552391\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.015475062653422356, Val Loss: 0.06494488567113876\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.016318103298544884, Val Loss: 0.059665270149707794\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.019941985607147217, Val Loss: 0.05260678380727768\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.01268017292022705, Val Loss: 0.04593575745820999\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.013317463919520378, Val Loss: 0.04126724228262901\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.013103694655001163, Val Loss: 0.037869684398174286\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.014710967428982258, Val Loss: 0.034667160362005234\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.014408673159778118, Val Loss: 0.033329229801893234\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.010840312577784061, Val Loss: 0.03232394531369209\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.011417125351727009, Val Loss: 0.03141303360462189\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.010948537848889828, Val Loss: 0.030321041122078896\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.011570962145924568, Val Loss: 0.028930217027664185\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.01038769818842411, Val Loss: 0.02707557938992977\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.013101094402372837, Val Loss: 0.024989543482661247\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.010907645337283611, Val Loss: 0.022771131247282028\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.012433788739144802, Val Loss: 0.021034833043813705\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.011464954353868961, Val Loss: 0.019546527415513992\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.010929669253528118, Val Loss: 0.01769900880753994\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.01054622046649456, Val Loss: 0.016943782567977905\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.010277020744979382, Val Loss: 0.01685723103582859\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.01126963458955288, Val Loss: 0.017156345769762993\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.009356153197586536, Val Loss: 0.01694200187921524\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.01146680861711502, Val Loss: 0.017138587310910225\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.009930997155606747, Val Loss: 0.017524931579828262\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.00949135236442089, Val Loss: 0.017229996621608734\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.012039384804666042, Val Loss: 0.016885992139577866\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.012254549190402031, Val Loss: 0.016191191971302032\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.009321106597781181, Val Loss: 0.015890000388026237\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.010713429190218449, Val Loss: 0.015274816192686558\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.012014062143862247, Val Loss: 0.015118710696697235\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.00992644764482975, Val Loss: 0.015335986390709877\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.01062430627644062, Val Loss: 0.015438459813594818\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.011868275701999664, Val Loss: 0.015716172754764557\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.00891964789479971, Val Loss: 0.015671903267502785\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.009058908559381962, Val Loss: 0.01616411656141281\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.010184593498706818, Val Loss: 0.01666746474802494\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.010212510824203491, Val Loss: 0.017093928530812263\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.009866985492408276, Val Loss: 0.017636394128203392\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.011133263818919659, Val Loss: 0.018387064337730408\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.007646129932254553, Val Loss: 0.018319521099328995\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.00813998095691204, Val Loss: 0.018325649201869965\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.008692807517945766, Val Loss: 0.01846698857843876\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.010510090738534927, Val Loss: 0.018589772284030914\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.011551398783922195, Val Loss: 0.018473293632268906\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.011571379378437996, Val Loss: 0.018697695806622505\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.011468825861811638, Val Loss: 0.01888919249176979\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.008444735780358315, Val Loss: 0.018989117816090584\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.008152322843670845, Val Loss: 0.019170399755239487\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.015514408238232136, Val Loss: 0.01930922083556652\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.011035844683647156, Val Loss: 0.019436094909906387\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.01569625735282898, Val Loss: 0.006420301739126444\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.020196985453367233, Val Loss: 0.0062686484307050705\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.014680124819278717, Val Loss: 0.0061662266962230206\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.01547249872237444, Val Loss: 0.005929057486355305\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.011602411046624184, Val Loss: 0.005561452824622393\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.015073810704052448, Val Loss: 0.005189281422644854\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.013362680561840534, Val Loss: 0.0049179308116436005\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.01464037038385868, Val Loss: 0.004633828531950712\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.01347600668668747, Val Loss: 0.0044126990251243114\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.015030537731945515, Val Loss: 0.004272443242371082\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.013234557583928108, Val Loss: 0.0038263860624283552\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.01319036539644003, Val Loss: 0.003218302736058831\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.011513140983879566, Val Loss: 0.0029035836923867464\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.011186166666448116, Val Loss: 0.002731922548264265\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.015476052649319172, Val Loss: 0.0028613265603780746\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.010196736082434654, Val Loss: 0.0034150106366723776\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.009628715924918652, Val Loss: 0.0038225455209612846\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.011726481840014458, Val Loss: 0.005176891572773457\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.012048245407640934, Val Loss: 0.007896571420133114\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.009539716877043247, Val Loss: 0.011495044454932213\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.010560405440628529, Val Loss: 0.013920336961746216\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.012500268407166004, Val Loss: 0.014759507030248642\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.012839209288358688, Val Loss: 0.014859925024211407\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.011943609453737736, Val Loss: 0.012270186096429825\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.014294518157839775, Val Loss: 0.007940389215946198\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.008645263500511646, Val Loss: 0.007842657156288624\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.012072659097611904, Val Loss: 0.006320815067738295\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.008569908328354359, Val Loss: 0.005617282819002867\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.010895410552620888, Val Loss: 0.009084579534828663\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.013672309927642345, Val Loss: 0.01006068754941225\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.010232977569103241, Val Loss: 0.011427907273173332\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.008783862926065922, Val Loss: 0.01730388216674328\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.015199411660432816, Val Loss: 0.013773872517049313\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.009945971891283989, Val Loss: 0.014750145375728607\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.01095365546643734, Val Loss: 0.0040704128332436085\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.22073176503181458, Val Loss: 0.004078055266290903\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.022010738030076027, Val Loss: 0.0031157047487795353\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.005891491519287228, 'rmse': 0.07230575726659969, 'mae': 0.05892303884029389, 'mape': 22.059293687343597, 'r2': 0.9439918827822428}\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.6724385023117065, Val Loss: 0.16410697996616364\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.48018836975097656, Val Loss: 0.16387170553207397\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.36732205748558044, Val Loss: 0.16325785219669342\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.3098157048225403, Val Loss: 0.16152548789978027\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.26694735884666443, Val Loss: 0.15980347990989685\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.19571250677108765, Val Loss: 0.15789678692817688\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.17344772815704346, Val Loss: 0.15558744966983795\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.18457520008087158, Val Loss: 0.15428484976291656\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.13019810616970062, Val Loss: 0.15390270948410034\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.11849967390298843, Val Loss: 0.1535494029521942\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.13290181756019592, Val Loss: 0.15432535111904144\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.1634114384651184, Val Loss: 0.15434396266937256\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.12113876640796661, Val Loss: 0.15396088361740112\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.1004805937409401, Val Loss: 0.15441416203975677\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.10837659239768982, Val Loss: 0.15605279803276062\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.12421420961618423, Val Loss: 0.15718330442905426\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.07331139594316483, Val Loss: 0.15759941935539246\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.05209866538643837, Val Loss: 0.1563226282596588\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.057878389954566956, Val Loss: 0.15218327939510345\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.07470167428255081, Val Loss: 0.1491946130990982\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.0786745548248291, Val Loss: 0.14909960329532623\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.06186019256711006, Val Loss: 0.1525747925043106\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.05137736350297928, Val Loss: 0.1570841670036316\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.05756404995918274, Val Loss: 0.1589856743812561\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.04697457700967789, Val Loss: 0.15521812438964844\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.05742749199271202, Val Loss: 0.14422644674777985\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.03791375830769539, Val Loss: 0.13452786207199097\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.036366019397974014, Val Loss: 0.1288820505142212\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.031910236924886703, Val Loss: 0.12555821239948273\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.03394197300076485, Val Loss: 0.12237507849931717\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.027898527681827545, Val Loss: 0.11577273160219193\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.02221663109958172, Val Loss: 0.10888190567493439\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.028603361919522285, Val Loss: 0.10481339693069458\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.03346426412463188, Val Loss: 0.1030893549323082\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.025152496993541718, Val Loss: 0.10188127309083939\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.016435280442237854, Val Loss: 0.10088185966014862\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.024877816438674927, Val Loss: 0.09737718850374222\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.017179075628519058, Val Loss: 0.09454982727766037\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.018012721091508865, Val Loss: 0.09067709743976593\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.016769004985690117, Val Loss: 0.08833647519350052\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.016396403312683105, Val Loss: 0.08644423633813858\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.014087000861763954, Val Loss: 0.08309803903102875\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.013930936343967915, Val Loss: 0.07808583974838257\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.012625807896256447, Val Loss: 0.07458765804767609\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.016314448788762093, Val Loss: 0.07233903557062149\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.010657072998583317, Val Loss: 0.0704035833477974\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.012630616314709187, Val Loss: 0.06662128120660782\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.0108387041836977, Val Loss: 0.06257080286741257\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.011987946927547455, Val Loss: 0.05931374430656433\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.012353610247373581, Val Loss: 0.056799475103616714\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.014501459896564484, Val Loss: 0.054449353367090225\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.013033806346356869, Val Loss: 0.053429003804922104\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.012383980676531792, Val Loss: 0.05347169563174248\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.00835216511040926, Val Loss: 0.05325890704989433\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.011466385796666145, Val Loss: 0.05084383860230446\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.011340754106640816, Val Loss: 0.04792750999331474\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.010299106128513813, Val Loss: 0.04387856647372246\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.006585282273590565, Val Loss: 0.040983084589242935\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.011919145472347736, Val Loss: 0.03833150491118431\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.010909637436270714, Val Loss: 0.036541540175676346\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.009576338343322277, Val Loss: 0.03497923165559769\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.010430984199047089, Val Loss: 0.03350936248898506\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.012034091167151928, Val Loss: 0.0314665324985981\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.009727406315505505, Val Loss: 0.02954590693116188\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.010129068978130817, Val Loss: 0.028156915679574013\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.010787615552544594, Val Loss: 0.027403278276324272\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.00843400601297617, Val Loss: 0.02738855592906475\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.009611614979803562, Val Loss: 0.027326785027980804\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.008130297064781189, Val Loss: 0.02732761763036251\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.007895519956946373, Val Loss: 0.02735498733818531\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.008722818456590176, Val Loss: 0.027275150641798973\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.009688720107078552, Val Loss: 0.027462441474199295\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.010478131473064423, Val Loss: 0.02722158655524254\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.007471938617527485, Val Loss: 0.027082320302724838\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.00789756141602993, Val Loss: 0.026594627648591995\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.009881814941763878, Val Loss: 0.026934968307614326\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.008166930638253689, Val Loss: 0.026952048763632774\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.01059564296156168, Val Loss: 0.02746727131307125\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.011311000213027, Val Loss: 0.02813049592077732\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.010462707839906216, Val Loss: 0.02861366793513298\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.009818914346396923, Val Loss: 0.02939276583492756\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.009540527127683163, Val Loss: 0.030010299757122993\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.008183796890079975, Val Loss: 0.030569087713956833\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.00848514586687088, Val Loss: 0.031570546329021454\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.007809923961758614, Val Loss: 0.03242514654994011\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.006812520325183868, Val Loss: 0.032670632004737854\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.0078285438939929, Val Loss: 0.03380751982331276\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.008948064409196377, Val Loss: 0.03457358479499817\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.009160367771983147, Val Loss: 0.0346592552959919\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.007455036044120789, Val Loss: 0.03521464392542839\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.011479486711323261, Val Loss: 0.03581602871417999\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.00925701204687357, Val Loss: 0.035577066242694855\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.0085830083116889, Val Loss: 0.0361936017870903\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.007191304583102465, Val Loss: 0.03551322966814041\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.008521143347024918, Val Loss: 0.03595760092139244\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.02340983785688877, Val Loss: 0.006779718678444624\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.01641874946653843, Val Loss: 0.006767926272004843\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.019167974591255188, Val Loss: 0.006701260339468718\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.017657766118645668, Val Loss: 0.00657509732991457\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.018608510494232178, Val Loss: 0.006338662467896938\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.019384091719985008, Val Loss: 0.006507443729788065\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.016623256728053093, Val Loss: 0.0063561974093317986\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.014259499497711658, Val Loss: 0.006596462335437536\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.01835969276726246, Val Loss: 0.00646809209138155\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.012234166264533997, Val Loss: 0.006995741277933121\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.019057990983128548, Val Loss: 0.006902595981955528\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.01993654854595661, Val Loss: 0.006298772990703583\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.01763598434627056, Val Loss: 0.004875039216130972\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.01585332490503788, Val Loss: 0.0042713712900877\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.01441887579858303, Val Loss: 0.004967732820659876\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.012370205484330654, Val Loss: 0.006815039087086916\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.012658667750656605, Val Loss: 0.007877958007156849\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.015185745432972908, Val Loss: 0.00730162812396884\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.011110355146229267, Val Loss: 0.00728190690279007\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.010430027730762959, Val Loss: 0.006597557105123997\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.01031012088060379, Val Loss: 0.008227571845054626\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.009873980656266212, Val Loss: 0.011263750493526459\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.015255081467330456, Val Loss: 0.011693477630615234\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.01262618973851204, Val Loss: 0.01037562731653452\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.010812141932547092, Val Loss: 0.011509022675454617\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.009588858112692833, Val Loss: 0.011604445986449718\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.009904607199132442, Val Loss: 0.01203568559139967\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.009753054939210415, Val Loss: 0.014707562513649464\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.015941612422466278, Val Loss: 0.013451420702040195\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.01550162024796009, Val Loss: 0.00808298122137785\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.008660122752189636, Val Loss: 0.005808154586702585\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.011808803305029869, Val Loss: 0.01083983015269041\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.015909621492028236, Val Loss: 0.01386810652911663\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.010349053889513016, Val Loss: 0.017849158495664597\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.01671280898153782, Val Loss: 0.0014552661450579762\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.01756906323134899, Val Loss: 0.0014220717130228877\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.014224186539649963, Val Loss: 0.0014801010256633162\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.01489553228020668, Val Loss: 0.0015773733612149954\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.01317691896110773, Val Loss: 0.0018489110516384244\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.01600898988544941, Val Loss: 0.0023201655130833387\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.015005597844719887, Val Loss: 0.0031135757453739643\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.010251643136143684, Val Loss: 0.00410075718536973\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.013749872334301472, Val Loss: 0.005792100448161364\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.01467919908463955, Val Loss: 0.007991820573806763\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.01642506755888462, Val Loss: 0.009672032669186592\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.013611494563519955, Val Loss: 0.009800446219742298\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.01483706571161747, Val Loss: 0.008345028385519981\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.013533273711800575, Val Loss: 0.0061471303924918175\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.01132055651396513, Val Loss: 0.004539468791335821\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.013025647029280663, Val Loss: 0.0035740812309086323\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.011069347150623798, Val Loss: 0.00543172424659133\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.010512200184166431, Val Loss: 0.011019713245332241\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.017144599929451942, Val Loss: 0.019105903804302216\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.011592034250497818, Val Loss: 0.024027258157730103\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.011369485408067703, Val Loss: 0.02404438517987728\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.011803681030869484, Val Loss: 0.019523389637470245\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.2024926245212555, Val Loss: 0.007303574122488499\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.023705385625362396, Val Loss: 0.004041207022964954\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.007876708009280264, 'rmse': 0.0767604139875653, 'mae': 0.06474818661808968, 'mape': 25.439449846744537, 'r2': 0.9236710745078287}\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.8251775503158569, Val Loss: 0.23709650337696075\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.8167146444320679, Val Loss: 0.2376520186662674\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.7742038369178772, Val Loss: 0.2389051914215088\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.7567148804664612, Val Loss: 0.2388482689857483\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.7258142232894897, Val Loss: 0.23754757642745972\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.6606293320655823, Val Loss: 0.23580454289913177\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.5515938401222229, Val Loss: 0.23428697884082794\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.5248203873634338, Val Loss: 0.22868266701698303\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.398207426071167, Val Loss: 0.22317329049110413\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.34281259775161743, Val Loss: 0.21436649560928345\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.2692592442035675, Val Loss: 0.20614123344421387\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.1995255947113037, Val Loss: 0.19479048252105713\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.15188708901405334, Val Loss: 0.18271949887275696\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.13591139018535614, Val Loss: 0.1703883409500122\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.1367892175912857, Val Loss: 0.1582030951976776\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.13590902090072632, Val Loss: 0.14745153486728668\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.1484508216381073, Val Loss: 0.13699369132518768\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.16952331364154816, Val Loss: 0.13001812994480133\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.1587410569190979, Val Loss: 0.12502409517765045\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.1357315331697464, Val Loss: 0.12085094302892685\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.13207463920116425, Val Loss: 0.1185101866722107\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.10186698287725449, Val Loss: 0.11754748225212097\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.0931657925248146, Val Loss: 0.11699153482913971\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.07833917438983917, Val Loss: 0.11756925284862518\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.07008688896894455, Val Loss: 0.1161569207906723\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.07086203992366791, Val Loss: 0.11243872344493866\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.07759969681501389, Val Loss: 0.10599227249622345\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.06797125190496445, Val Loss: 0.09741432964801788\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.060487743467092514, Val Loss: 0.08767079561948776\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.059588100761175156, Val Loss: 0.07740657031536102\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.05036449059844017, Val Loss: 0.0674719288945198\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.0462879054248333, Val Loss: 0.05872116610407829\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.04823879897594452, Val Loss: 0.05021463707089424\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.041886311024427414, Val Loss: 0.04223673418164253\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.040194008499383926, Val Loss: 0.03610195964574814\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.037485409528017044, Val Loss: 0.03116692416369915\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.037940945476293564, Val Loss: 0.027579637244343758\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.035109661519527435, Val Loss: 0.025411488488316536\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.03524026647210121, Val Loss: 0.02390127442777157\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.03315933793783188, Val Loss: 0.024276867508888245\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.03346807137131691, Val Loss: 0.025693140923976898\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.03282717615365982, Val Loss: 0.02783292718231678\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.031359460204839706, Val Loss: 0.03045625425875187\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.029564158990979195, Val Loss: 0.031937506049871445\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.026039093732833862, Val Loss: 0.03256630152463913\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.02863353118300438, Val Loss: 0.03200610727071762\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.027997642755508423, Val Loss: 0.03130260109901428\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.025626983493566513, Val Loss: 0.030207939445972443\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.025609057396650314, Val Loss: 0.029668837785720825\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.025385944172739983, Val Loss: 0.029813436791300774\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.026852000504732132, Val Loss: 0.030844882130622864\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.023592425510287285, Val Loss: 0.03238966315984726\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.021796124055981636, Val Loss: 0.033383000642061234\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.026220159605145454, Val Loss: 0.03492867946624756\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.02306220307946205, Val Loss: 0.03551514819264412\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.02479499951004982, Val Loss: 0.035869061946868896\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.022874753922224045, Val Loss: 0.03721117228269577\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.02198602631688118, Val Loss: 0.03843087702989578\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.026145126670598984, Val Loss: 0.04040650278329849\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.046234823763370514, Val Loss: 0.027859805151820183\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.04735017567873001, Val Loss: 0.016091689467430115\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.04706978425383568, Val Loss: 0.01590771973133087\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.05046053230762482, Val Loss: 0.015705494210124016\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.04568623751401901, Val Loss: 0.015477878041565418\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.047199901193380356, Val Loss: 0.015425337478518486\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.04281138628721237, Val Loss: 0.015545115806162357\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.049113135784864426, Val Loss: 0.016051901504397392\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.04262905940413475, Val Loss: 0.017004411667585373\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.04366393759846687, Val Loss: 0.018147651106119156\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.042777810245752335, Val Loss: 0.019855497404932976\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.038088664412498474, Val Loss: 0.022382259368896484\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.03917795047163963, Val Loss: 0.025239234790205956\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.04023224860429764, Val Loss: 0.028695616871118546\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.038298800587654114, Val Loss: 0.03120344877243042\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.03717248514294624, Val Loss: 0.032605864107608795\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.03681971877813339, Val Loss: 0.03234395384788513\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.03564807027578354, Val Loss: 0.029095463454723358\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.03468746691942215, Val Loss: 0.024996744468808174\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.035051628947257996, Val Loss: 0.02169397845864296\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.03242925927042961, Val Loss: 0.021412907168269157\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.03225664794445038, Val Loss: 0.02397320419549942\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.033687736839056015, Val Loss: 0.02915443666279316\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.028140047565102577, Val Loss: 0.034517038613557816\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.030153999105095863, Val Loss: 0.03814542293548584\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.02831246331334114, Val Loss: 0.03727377951145172\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.15917035937309265, Val Loss: 0.17164552211761475\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.048571959137916565, Val Loss: 0.060750238597393036\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.07251154519617557, 'rmse': 0.2363586843732599, 'mae': 0.19426380097866058, 'mape': 48.62951397895813, 'r2': 0.7942087573760223}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.122828483581543, Val Loss: 0.2387993037700653\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.9618577361106873, Val Loss: 0.23979279398918152\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.8936386108398438, Val Loss: 0.23864541947841644\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.8697436451911926, Val Loss: 0.23970657587051392\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.7401654720306396, Val Loss: 0.2393907606601715\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.5351172685623169, Val Loss: 0.23837879300117493\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.4705541729927063, Val Loss: 0.23600594699382782\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.44205862283706665, Val Loss: 0.23374715447425842\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.28983139991760254, Val Loss: 0.23162223398685455\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.35387641191482544, Val Loss: 0.22872880101203918\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.3254966735839844, Val Loss: 0.2258339375257492\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.2648770809173584, Val Loss: 0.2230951339006424\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.3198617100715637, Val Loss: 0.2208762764930725\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.3332189619541168, Val Loss: 0.21872927248477936\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.2517744302749634, Val Loss: 0.21564222872257233\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.1929204910993576, Val Loss: 0.21344222128391266\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.27665361762046814, Val Loss: 0.21156391501426697\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.18237225711345673, Val Loss: 0.208525151014328\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.15194599330425262, Val Loss: 0.20456430315971375\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.24287205934524536, Val Loss: 0.2004118263721466\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.16005857288837433, Val Loss: 0.19657060503959656\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.12112706154584885, Val Loss: 0.1927219182252884\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.10672368109226227, Val Loss: 0.18831054866313934\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.12929831445217133, Val Loss: 0.18411651253700256\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.1563011109828949, Val Loss: 0.1792537420988083\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.07858141511678696, Val Loss: 0.17280131578445435\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.08262534439563751, Val Loss: 0.16737432777881622\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.07508490234613419, Val Loss: 0.1627635508775711\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.0683688223361969, Val Loss: 0.15908654034137726\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.09780759364366531, Val Loss: 0.15612760186195374\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.06485769897699356, Val Loss: 0.15344461798667908\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.05737665668129921, Val Loss: 0.14985939860343933\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.07567659765481949, Val Loss: 0.14348556101322174\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.04497188702225685, Val Loss: 0.13768480718135834\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.040029581636190414, Val Loss: 0.13354001939296722\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.05439002066850662, Val Loss: 0.1312723457813263\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.05190202221274376, Val Loss: 0.13239212334156036\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.039079464972019196, Val Loss: 0.13335613906383514\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.037870537489652634, Val Loss: 0.1314396858215332\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.05098852142691612, Val Loss: 0.1279967725276947\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.047560714185237885, Val Loss: 0.12226314097642899\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.03556886315345764, Val Loss: 0.11711061745882034\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.033733926713466644, Val Loss: 0.11351826786994934\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.046509433537721634, Val Loss: 0.11066004633903503\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.042698025703430176, Val Loss: 0.10919693112373352\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.03703315556049347, Val Loss: 0.10767360031604767\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.03757427632808685, Val Loss: 0.10601948201656342\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.02707933820784092, Val Loss: 0.1020532101392746\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.029661551117897034, Val Loss: 0.09672915935516357\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.040817614644765854, Val Loss: 0.08923239260911942\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.03054247610270977, Val Loss: 0.08183189481496811\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.02464815229177475, Val Loss: 0.07573196291923523\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.04057874530553818, Val Loss: 0.07139585167169571\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.03322705626487732, Val Loss: 0.06834830343723297\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.035104572772979736, Val Loss: 0.06751790642738342\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.026519590988755226, Val Loss: 0.06795679777860641\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.024249760434031487, Val Loss: 0.06764708459377289\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.02296951226890087, Val Loss: 0.06655425578355789\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.023532850667834282, Val Loss: 0.06459016352891922\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.023641832172870636, Val Loss: 0.062176868319511414\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.028472859412431717, Val Loss: 0.05915229022502899\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.02375037595629692, Val Loss: 0.05611463263630867\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.019788751378655434, Val Loss: 0.052813347429037094\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.021997900679707527, Val Loss: 0.050821658223867416\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.0283232182264328, Val Loss: 0.048313893377780914\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.022945886477828026, Val Loss: 0.04561340808868408\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.029735704883933067, Val Loss: 0.042500197887420654\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.01573246717453003, Val Loss: 0.03991460055112839\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.019265679642558098, Val Loss: 0.037341054528951645\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.018561720848083496, Val Loss: 0.03544080629944801\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.025741659104824066, Val Loss: 0.033711861819028854\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.019680261611938477, Val Loss: 0.03265020623803139\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.022766081616282463, Val Loss: 0.03205280750989914\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.03086308389902115, Val Loss: 0.03126057982444763\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.01903633028268814, Val Loss: 0.03166097775101662\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.025978468358516693, Val Loss: 0.03181923180818558\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.025324180722236633, Val Loss: 0.032501593232154846\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.021244646981358528, Val Loss: 0.033530671149492264\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.017614472657442093, Val Loss: 0.034715764224529266\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.014966053888201714, Val Loss: 0.035931624472141266\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.020365571603178978, Val Loss: 0.036912743002176285\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.02132846973836422, Val Loss: 0.03862370550632477\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.019998617470264435, Val Loss: 0.0393170565366745\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.020152399316430092, Val Loss: 0.03952160105109215\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.016681788489222527, Val Loss: 0.040277063846588135\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.018289966508746147, Val Loss: 0.040834955871105194\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.01775122620165348, Val Loss: 0.04208634793758392\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.017260607331991196, Val Loss: 0.042761508375406265\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.028569720685482025, Val Loss: 0.044785741716623306\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.019215606153011322, Val Loss: 0.04448099434375763\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.021258937194943428, Val Loss: 0.044496871531009674\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.024209806695580482, Val Loss: 0.04469388723373413\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.024393482133746147, Val Loss: 0.04608598351478577\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.0174560509622097, Val Loss: 0.0459275022149086\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.02174011804163456, Val Loss: 0.024056296795606613\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.029274756088852882, Val Loss: 0.023001201450824738\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.030750947073101997, Val Loss: 0.022315971553325653\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.029181061312556267, Val Loss: 0.021362710744142532\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.035476379096508026, Val Loss: 0.021265147253870964\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.028743090108036995, Val Loss: 0.020231075584888458\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.02807389758527279, Val Loss: 0.01930326037108898\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.03525035083293915, Val Loss: 0.018542639911174774\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.022273067384958267, Val Loss: 0.01688523218035698\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.02354966476559639, Val Loss: 0.015742095187306404\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.03681567683815956, Val Loss: 0.014674901030957699\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.027365146204829216, Val Loss: 0.013500016182661057\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.018825598061084747, Val Loss: 0.012492339126765728\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.02662891149520874, Val Loss: 0.01118606235831976\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.019527748227119446, Val Loss: 0.00988482590764761\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.019507594406604767, Val Loss: 0.009381629526615143\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.030765635892748833, Val Loss: 0.00952744297683239\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.02170688286423683, Val Loss: 0.009784949012100697\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.024132387712597847, Val Loss: 0.010273988358676434\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.023769348859786987, Val Loss: 0.011388693936169147\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.018363043665885925, Val Loss: 0.011986354365944862\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.020590655505657196, Val Loss: 0.014627708122134209\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.0290126521140337, Val Loss: 0.01552918367087841\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.02044302225112915, Val Loss: 0.013288398273289204\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.023235129192471504, Val Loss: 0.010565073229372501\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.01839277520775795, Val Loss: 0.010456287302076817\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.02043061889708042, Val Loss: 0.010340518318116665\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.018171196803450584, Val Loss: 0.012014856562018394\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.01621406152844429, Val Loss: 0.01741986908018589\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.022119488567113876, Val Loss: 0.018027588725090027\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.022249331697821617, Val Loss: 0.013227112591266632\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.02190585248172283, Val Loss: 0.011545366607606411\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.02677902951836586, Val Loss: 0.01038216333836317\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.014158951118588448, Val Loss: 0.011723456904292107\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.013325640931725502, Val Loss: 0.012983899563550949\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.013541268184781075, Val Loss: 0.0148557024076581\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.02088102512061596, Val Loss: 0.010713492520153522\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.2203419953584671, Val Loss: 0.0018597637536004186\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.22015534341335297, Val Loss: 0.008299716748297215\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.2116083800792694, Val Loss: 0.028410501778125763\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.22203212976455688, Val Loss: 0.048325829207897186\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.20179204642772675, Val Loss: 0.06195992976427078\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.20189368724822998, Val Loss: 0.052449703216552734\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.1545713245868683, Val Loss: 0.03103742189705372\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.13782815635204315, Val Loss: 0.01758953370153904\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.1043323203921318, Val Loss: 0.051609717309474945\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.07463251799345016, Val Loss: 0.1978020817041397\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.07109592854976654, Val Loss: 0.5105847716331482\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.07578151673078537, Val Loss: 0.9946591854095459\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.09796517342329025, Val Loss: 1.5566589832305908\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.13304904103279114, Val Loss: 2.07098650932312\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.1387174427509308, Val Loss: 2.2842769622802734\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.15781807899475098, Val Loss: 2.0982487201690674\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.14139267802238464, Val Loss: 1.537585973739624\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.10981433093547821, Val Loss: 0.7984672784805298\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.07543352991342545, Val Loss: 0.24652528762817383\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.06490489840507507, Val Loss: 0.0704125463962555\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.06856060028076172, Val Loss: 0.14221836626529694\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.029384972527623177, Val Loss: 0.008130072616040707\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.012313435063697397, 'rmse': 0.10235183008028367, 'mae': 0.0842245914041996, 'mape': 31.92585200071335, 'r2': 0.8721139870685404}\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.9368500113487244, Val Loss: 0.28105995059013367\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.9570465087890625, Val Loss: 0.2795390486717224\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.9200125932693481, Val Loss: 0.27752435207366943\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.9155058860778809, Val Loss: 0.27574634552001953\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.9224259853363037, Val Loss: 0.27463021874427795\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.8677312731742859, Val Loss: 0.2751022279262543\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.8791755437850952, Val Loss: 0.27362409234046936\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.8331995606422424, Val Loss: 0.26833438873291016\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.8505233526229858, Val Loss: 0.2644304037094116\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.7889992594718933, Val Loss: 0.26178938150405884\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.8384865522384644, Val Loss: 0.2587735950946808\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.6896616816520691, Val Loss: 0.252704381942749\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.721538782119751, Val Loss: 0.24929390847682953\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.6033175587654114, Val Loss: 0.2439107596874237\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.5849425792694092, Val Loss: 0.23772016167640686\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.5316234230995178, Val Loss: 0.22835178673267365\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.5311970710754395, Val Loss: 0.21954835951328278\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.4881523847579956, Val Loss: 0.21075884997844696\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.3914956748485565, Val Loss: 0.20295390486717224\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.3714052438735962, Val Loss: 0.1943182498216629\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.3113097548484802, Val Loss: 0.18513187766075134\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.2803528308868408, Val Loss: 0.17544856667518616\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.2743765413761139, Val Loss: 0.16827093064785004\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.2545180916786194, Val Loss: 0.16180460155010223\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.22336919605731964, Val Loss: 0.15515056252479553\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.20295663177967072, Val Loss: 0.14754611253738403\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.1817847341299057, Val Loss: 0.14205169677734375\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.1910616159439087, Val Loss: 0.13555783033370972\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.17440323531627655, Val Loss: 0.1285579651594162\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.18130233883857727, Val Loss: 0.12264953553676605\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.17278535664081573, Val Loss: 0.11723530292510986\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.15898282825946808, Val Loss: 0.1114577054977417\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.1738034188747406, Val Loss: 0.10597889870405197\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.15437859296798706, Val Loss: 0.10006916522979736\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.15850111842155457, Val Loss: 0.0952293649315834\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.14496764540672302, Val Loss: 0.09152857214212418\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.15775170922279358, Val Loss: 0.08669722825288773\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.14002929627895355, Val Loss: 0.08432556688785553\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.13553261756896973, Val Loss: 0.0815034955739975\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.12895910441875458, Val Loss: 0.07922495156526566\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.12547439336776733, Val Loss: 0.07781046628952026\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.12648268043994904, Val Loss: 0.07686401158571243\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.13218651711940765, Val Loss: 0.075582355260849\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.12394220381975174, Val Loss: 0.07518157362937927\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.12132105231285095, Val Loss: 0.07418255507946014\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.12029197067022324, Val Loss: 0.07350724190473557\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.11775562167167664, Val Loss: 0.0732438713312149\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.11861974000930786, Val Loss: 0.07328512519598007\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.11700942367315292, Val Loss: 0.07277076691389084\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.11496637761592865, Val Loss: 0.07258988916873932\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.11020054668188095, Val Loss: 0.07277518510818481\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.10358844697475433, Val Loss: 0.07280261814594269\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.10743620246648788, Val Loss: 0.07340838015079498\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.10865199565887451, Val Loss: 0.07345728576183319\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.11075073480606079, Val Loss: 0.07308387756347656\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.10991205275058746, Val Loss: 0.07351399213075638\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.10293988883495331, Val Loss: 0.07463027536869049\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.10234402120113373, Val Loss: 0.07432519644498825\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.10075625777244568, Val Loss: 0.07486880570650101\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.09873464703559875, Val Loss: 0.07399914413690567\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.10855484753847122, Val Loss: 0.07312887907028198\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.09750426560640335, Val Loss: 0.07192175835371017\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.10763733834028244, Val Loss: 0.07088516652584076\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.09568586200475693, Val Loss: 0.06989937275648117\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.09429024159908295, Val Loss: 0.06860284507274628\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.09846091270446777, Val Loss: 0.06805090606212616\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.10229966044425964, Val Loss: 0.06681401282548904\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.09541287273168564, Val Loss: 0.06528637558221817\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.0972239300608635, Val Loss: 0.064771868288517\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.0933598205447197, Val Loss: 0.06464880704879761\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.0978386253118515, Val Loss: 0.06408455967903137\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.1060582846403122, Val Loss: 0.06306972354650497\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.09726424515247345, Val Loss: 0.06315278261899948\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.09130612760782242, Val Loss: 0.06314607709646225\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.0912124365568161, Val Loss: 0.06248009204864502\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.08790626376867294, Val Loss: 0.06152576953172684\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.09682850539684296, Val Loss: 0.06162445619702339\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.0921197459101677, Val Loss: 0.06140879541635513\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.0987110361456871, Val Loss: 0.060835886746644974\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.08913976699113846, Val Loss: 0.06000563129782677\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.09138449281454086, Val Loss: 0.060122691094875336\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.0924067422747612, Val Loss: 0.060035377740859985\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.0953081026673317, Val Loss: 0.05939298868179321\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.10050898790359497, Val Loss: 0.05876319110393524\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.09354015439748764, Val Loss: 0.05929885804653168\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.09779054671525955, Val Loss: 0.059417642652988434\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.1040591150522232, Val Loss: 0.0591016486287117\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.09038128703832626, Val Loss: 0.059314046055078506\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.08668240159749985, Val Loss: 0.059604350477457047\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.09470688551664352, Val Loss: 0.06059412285685539\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.09462571144104004, Val Loss: 0.060341425240039825\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.09717582911252975, Val Loss: 0.06054291874170303\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.09557085484266281, Val Loss: 0.06048312038183212\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.09517522901296616, Val Loss: 0.060835592448711395\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.08397648483514786, Val Loss: 0.061063945293426514\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.09900423884391785, Val Loss: 0.061108093708753586\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.09809927642345428, Val Loss: 0.06153947860002518\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.0848807767033577, Val Loss: 0.060940247029066086\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.08815977722406387, Val Loss: 0.06134818494319916\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.08363945037126541, Val Loss: 0.06126244738698006\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.12316367030143738, Val Loss: 0.017576294019818306\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.13331305980682373, Val Loss: 0.018670817837119102\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.13550904393196106, Val Loss: 0.019461799412965775\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.12005311995744705, Val Loss: 0.019795285537838936\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.11362095177173615, Val Loss: 0.019687557592988014\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.1116359755396843, Val Loss: 0.020106196403503418\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.12000517547130585, Val Loss: 0.020652730017900467\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.14095823466777802, Val Loss: 0.020653212442994118\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.12122467160224915, Val Loss: 0.020390164107084274\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.11844488978385925, Val Loss: 0.02044549211859703\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.12454721331596375, Val Loss: 0.01954650692641735\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.11133617162704468, Val Loss: 0.018603820353746414\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.11854007840156555, Val Loss: 0.017362909391522408\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.10673675686120987, Val Loss: 0.01655927486717701\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.1205238401889801, Val Loss: 0.015637030825018883\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.11243146657943726, Val Loss: 0.014287739992141724\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.10606295615434647, Val Loss: 0.013412640430033207\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.10158383846282959, Val Loss: 0.01248025894165039\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.1032751128077507, Val Loss: 0.012066982686519623\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.10640047490596771, Val Loss: 0.011322414502501488\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.09104017913341522, Val Loss: 0.010879646055400372\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.09809833765029907, Val Loss: 0.010699471458792686\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.09468097984790802, Val Loss: 0.011075280606746674\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.09123200178146362, Val Loss: 0.011234802193939686\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.09055564552545547, Val Loss: 0.012228742241859436\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.09351672977209091, Val Loss: 0.013012916781008244\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.08506093174219131, Val Loss: 0.014455265365540981\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.09724925458431244, Val Loss: 0.016078108921647072\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.0854729562997818, Val Loss: 0.017914310097694397\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.09394322335720062, Val Loss: 0.018893389031291008\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.08696971833705902, Val Loss: 0.019998418167233467\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.08156846463680267, Val Loss: 0.02064608410000801\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.07964570075273514, Val Loss: 0.021159758791327477\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.08455763012170792, Val Loss: 0.02111649513244629\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.07822693884372711, Val Loss: 0.02178509719669819\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.08185286819934845, Val Loss: 0.022215086966753006\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.07572448253631592, Val Loss: 0.02272718958556652\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.08034887164831161, Val Loss: 0.02287369593977928\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.07791483402252197, Val Loss: 0.02328534796833992\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.07714438438415527, Val Loss: 0.023155903443694115\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.07539136707782745, Val Loss: 0.02334405481815338\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.06509166210889816, Val Loss: 0.02265068329870701\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.09764266014099121, Val Loss: 0.00903521291911602\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.09422516077756882, Val Loss: 0.00914599560201168\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.10689103603363037, Val Loss: 0.009241994470357895\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.10510357469320297, Val Loss: 0.009244205430150032\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.11349503695964813, Val Loss: 0.008996685035526752\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.10820919275283813, Val Loss: 0.009043808095157146\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.09572583436965942, Val Loss: 0.008947357535362244\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.10699370503425598, Val Loss: 0.00884111039340496\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.09795961529016495, Val Loss: 0.008778330869972706\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.09387697279453278, Val Loss: 0.008446508087217808\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.10000360757112503, Val Loss: 0.008650938980281353\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.09854073077440262, Val Loss: 0.008571378886699677\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.10256794095039368, Val Loss: 0.008696718141436577\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.0887342244386673, Val Loss: 0.008508874103426933\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.0889064148068428, Val Loss: 0.008109062910079956\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.09791766852140427, Val Loss: 0.00826731976121664\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.09088101238012314, Val Loss: 0.00855106022208929\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.09101198613643646, Val Loss: 0.009144233539700508\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.0908338874578476, Val Loss: 0.009291109628975391\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.09410641342401505, Val Loss: 0.009931742213666439\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.08206849545240402, Val Loss: 0.01042571384459734\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.08631538599729538, Val Loss: 0.010861552320420742\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.08329968899488449, Val Loss: 0.010934414342045784\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.08183898776769638, Val Loss: 0.010961378924548626\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.07963249087333679, Val Loss: 0.010379153303802013\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.09388482570648193, Val Loss: 0.010162543505430222\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.08714388310909271, Val Loss: 0.009335696697235107\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.07898668199777603, Val Loss: 0.00917283445596695\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.08266061544418335, Val Loss: 0.009426210075616837\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.07754945009946823, Val Loss: 0.009109451435506344\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.07802603393793106, Val Loss: 0.009243136271834373\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.07852301001548767, Val Loss: 0.009188873693346977\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.07528483867645264, Val Loss: 0.00928936805576086\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.07514818757772446, Val Loss: 0.00945181492716074\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.0722198635339737, Val Loss: 0.009148946963250637\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.1999073475599289, Val Loss: 0.024904340505599976\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.10134763270616531, Val Loss: 0.030534040182828903\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.024529680237174036, 'rmse': 0.14669913957560365, 'mae': 0.1286424830555916, 'mape': 50.384254455566406, 'r2': 0.8028565879563763}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.2330172061920166, Val Loss: 0.16365905106067657\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.0511137247085571, Val Loss: 0.16349583864212036\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.2940963506698608, Val Loss: 0.16450418531894684\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.4196503162384033, Val Loss: 0.16511303186416626\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.4221285581588745, Val Loss: 0.16593606770038605\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.0161138772964478, Val Loss: 0.16664215922355652\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.9778673648834229, Val Loss: 0.16779601573944092\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.9712908267974854, Val Loss: 0.16865861415863037\n",
      "INFO:root:Epoch 9/100, Train Loss: 1.0291770696640015, Val Loss: 0.17000940442085266\n",
      "INFO:root:Epoch 10/100, Train Loss: 1.033628225326538, Val Loss: 0.1716710776090622\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.8329986333847046, Val Loss: 0.17250458896160126\n",
      "INFO:root:Epoch 12/100, Train Loss: 1.0619901418685913, Val Loss: 0.17212465405464172\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.7461672425270081, Val Loss: 0.17225465178489685\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.8578488826751709, Val Loss: 0.1732834279537201\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.8390994071960449, Val Loss: 0.17398086190223694\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.7260345816612244, Val Loss: 0.17342694103717804\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.7344710230827332, Val Loss: 0.17340412735939026\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.6483147740364075, Val Loss: 0.17349927127361298\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.5464373230934143, Val Loss: 0.17353425920009613\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.4729216992855072, Val Loss: 0.17273780703544617\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.5063422918319702, Val Loss: 0.17185348272323608\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.5193973183631897, Val Loss: 0.17233167588710785\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.0945258140563965, Val Loss: 0.15462465584278107\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.30503511428833, Val Loss: 0.1553037464618683\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.1640050411224365, Val Loss: 0.1561843454837799\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.0629163980484009, Val Loss: 0.15633711218833923\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.1058261394500732, Val Loss: 0.15680861473083496\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.0714346170425415, Val Loss: 0.1581917554140091\n",
      "INFO:root:Epoch 7/100, Train Loss: 1.1251189708709717, Val Loss: 0.15845395624637604\n",
      "INFO:root:Epoch 8/100, Train Loss: 1.1233770847320557, Val Loss: 0.15926499664783478\n",
      "INFO:root:Epoch 9/100, Train Loss: 1.1304913759231567, Val Loss: 0.1602165848016739\n",
      "INFO:root:Epoch 10/100, Train Loss: 1.0858246088027954, Val Loss: 0.16003690659999847\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.887079656124115, Val Loss: 0.1602599024772644\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.7959445118904114, Val Loss: 0.16126649081707\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.8070606589317322, Val Loss: 0.1612168699502945\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.7855969667434692, Val Loss: 0.16139017045497894\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.7259806394577026, Val Loss: 0.16184692084789276\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.6293970942497253, Val Loss: 0.16204042732715607\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.49851641058921814, Val Loss: 0.16151538491249084\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.5795405507087708, Val Loss: 0.16180913150310516\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.6171648502349854, Val Loss: 0.1624312400817871\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.6341423988342285, Val Loss: 0.16248086094856262\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.4581115245819092, Val Loss: 0.16229920089244843\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.2240873575210571, Val Loss: 0.09787039458751678\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.2287143468856812, Val Loss: 0.09762513637542725\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.2356352806091309, Val Loss: 0.09833680093288422\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.202392339706421, Val Loss: 0.09875693172216415\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.1409066915512085, Val Loss: 0.09987417608499527\n",
      "INFO:root:Epoch 6/100, Train Loss: 1.1196610927581787, Val Loss: 0.10091539472341537\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.9705333709716797, Val Loss: 0.10070294141769409\n",
      "INFO:root:Epoch 8/100, Train Loss: 1.0485097169876099, Val Loss: 0.10158883780241013\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.996138334274292, Val Loss: 0.10246036946773529\n",
      "INFO:root:Epoch 10/100, Train Loss: 1.0670905113220215, Val Loss: 0.10180198401212692\n",
      "INFO:root:Epoch 11/100, Train Loss: 1.0216655731201172, Val Loss: 0.10205817222595215\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.9939000606536865, Val Loss: 0.10243182629346848\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.8739766478538513, Val Loss: 0.10387971997261047\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.760583221912384, Val Loss: 0.10520906001329422\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.6144320368766785, Val Loss: 0.10529784113168716\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.7211875915527344, Val Loss: 0.10603116452693939\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.6186203956604004, Val Loss: 0.1059991717338562\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.6229335069656372, Val Loss: 0.10607635974884033\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.4181949496269226, Val Loss: 0.10515343397855759\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.5995292067527771, Val Loss: 0.10642752796411514\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.4058572053909302, Val Loss: 0.10585761070251465\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.38384032249450684, Val Loss: 0.10531213134527206\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.6360189914703369, Val Loss: 2.8133704662323\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.9279335141181946, Val Loss: 0.4099530577659607\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.7276544719934464, 'rmse': 0.6854141602863956, 'mae': 0.5184909403324127, 'mape': 103.96214485168457, 'r2': -0.40145372724972805}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.8919442892074585, Val Loss: 0.2267816811800003\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.4348989725112915, Val Loss: 0.22569149732589722\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.9186090230941772, Val Loss: 0.22381927073001862\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.7628286480903625, Val Loss: 0.22220070660114288\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.44602417945861816, Val Loss: 0.21893294155597687\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.34338244795799255, Val Loss: 0.21659907698631287\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.4820672273635864, Val Loss: 0.21294726431369781\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.48481079936027527, Val Loss: 0.20855498313903809\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.5050051212310791, Val Loss: 0.2050429880619049\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.38244131207466125, Val Loss: 0.20347058773040771\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.43425729870796204, Val Loss: 0.200462207198143\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.31918540596961975, Val Loss: 0.19800783693790436\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.20639930665493011, Val Loss: 0.1963886171579361\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.161721870303154, Val Loss: 0.19364595413208008\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.19274815917015076, Val Loss: 0.19139966368675232\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.22404880821704865, Val Loss: 0.18893250823020935\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.21045657992362976, Val Loss: 0.18626441061496735\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.21382801234722137, Val Loss: 0.18239113688468933\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.1810881346464157, Val Loss: 0.17819926142692566\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.10496710985898972, Val Loss: 0.17331011593341827\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.10996337234973907, Val Loss: 0.1699027568101883\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.15534786880016327, Val Loss: 0.1692228466272354\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.0942334458231926, Val Loss: 0.17002619802951813\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.08372655510902405, Val Loss: 0.16824164986610413\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.09651198238134384, Val Loss: 0.16572360694408417\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.04231216758489609, Val Loss: 0.16353581845760345\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.062022846192121506, Val Loss: 0.1625152826309204\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.06821021437644958, Val Loss: 0.161746084690094\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.05387618765234947, Val Loss: 0.1606302112340927\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.05345918610692024, Val Loss: 0.1575043499469757\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.04400576278567314, Val Loss: 0.15617609024047852\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.041940271854400635, Val Loss: 0.15559831261634827\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.033776674419641495, Val Loss: 0.1561744660139084\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.034165650606155396, Val Loss: 0.15573956072330475\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.02997353859245777, Val Loss: 0.15387120842933655\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.024720672518014908, Val Loss: 0.1516062170267105\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.027967888861894608, Val Loss: 0.15069495141506195\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.019651830196380615, Val Loss: 0.1508130431175232\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.022300587967038155, Val Loss: 0.15182217955589294\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.02546336129307747, Val Loss: 0.1489664763212204\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.017432695254683495, Val Loss: 0.1451665461063385\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.01829034648835659, Val Loss: 0.1410764902830124\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.02735174261033535, Val Loss: 0.13918465375900269\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.013728904537856579, Val Loss: 0.1364629715681076\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.016314012929797173, Val Loss: 0.13336840271949768\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.02106955647468567, Val Loss: 0.13039448857307434\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.02093634195625782, Val Loss: 0.12628242373466492\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.011817596852779388, Val Loss: 0.12307099997997284\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.018668673932552338, Val Loss: 0.1223958358168602\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.01035894826054573, Val Loss: 0.1205313429236412\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.01570161059498787, Val Loss: 0.11834882944822311\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.014298143796622753, Val Loss: 0.11554394662380219\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.015115780755877495, Val Loss: 0.11223246902227402\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.01293184980750084, Val Loss: 0.1109485849738121\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.01130963396281004, Val Loss: 0.11043383926153183\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.015336273238062859, Val Loss: 0.10628847777843475\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.010241580195724964, Val Loss: 0.0997326448559761\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.012589294463396072, Val Loss: 0.09292701631784439\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.011700755916535854, Val Loss: 0.08838902413845062\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.01252817828208208, Val Loss: 0.08632463216781616\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.014527290128171444, Val Loss: 0.08712981641292572\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.012306921184062958, Val Loss: 0.08824022114276886\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.013138143345713615, Val Loss: 0.08746647834777832\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.015123870223760605, Val Loss: 0.08320703357458115\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.010745447129011154, Val Loss: 0.07648423314094543\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.011453143320977688, Val Loss: 0.07035177201032639\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.011287322267889977, Val Loss: 0.06549965590238571\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.010025120340287685, Val Loss: 0.06169990450143814\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.009310515597462654, Val Loss: 0.058703888207674026\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.009931000880897045, Val Loss: 0.056140828877687454\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.009371863678097725, Val Loss: 0.05389212444424629\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.011133680120110512, Val Loss: 0.051589906215667725\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.010968123562633991, Val Loss: 0.04929817467927933\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.011734467931091785, Val Loss: 0.04659498855471611\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.008695709519088268, Val Loss: 0.04351595416665077\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.008386022411286831, Val Loss: 0.04053686931729317\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.008777248673141003, Val Loss: 0.03809574991464615\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.01459574420005083, Val Loss: 0.035521622747182846\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.009441979229450226, Val Loss: 0.03342116251587868\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.009736565873026848, Val Loss: 0.031527064740657806\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.009581207297742367, Val Loss: 0.030021946877241135\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.009561851620674133, Val Loss: 0.02827671729028225\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.010285355150699615, Val Loss: 0.026434147730469704\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.009407857432961464, Val Loss: 0.024857819080352783\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.010766759514808655, Val Loss: 0.023272152990102768\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.012469401583075523, Val Loss: 0.02194722183048725\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.009282024577260017, Val Loss: 0.02078486792743206\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.007211937103420496, Val Loss: 0.019581696018576622\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.008603780530393124, Val Loss: 0.01859952136874199\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.010720436461269855, Val Loss: 0.01787271350622177\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.007455697748810053, Val Loss: 0.016962463036179543\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.010572749190032482, Val Loss: 0.016128726303577423\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.010021037422120571, Val Loss: 0.015587621368467808\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.008202641271054745, Val Loss: 0.014904004521667957\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.007187809329479933, Val Loss: 0.014596650376915932\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.009192180819809437, Val Loss: 0.014205429702997208\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.009635210037231445, Val Loss: 0.01378227025270462\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.009799642488360405, Val Loss: 0.013481571339070797\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.0066329436376690865, Val Loss: 0.013217833824455738\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.008026637136936188, Val Loss: 0.013131024315953255\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.014698131009936333, Val Loss: 0.00464221928268671\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.01137210987508297, Val Loss: 0.0044915503822267056\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.011295780539512634, Val Loss: 0.004278658423572779\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.010788296349346638, Val Loss: 0.004167154897004366\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.012708175927400589, Val Loss: 0.004305538255721331\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.0123911052942276, Val Loss: 0.00449629919603467\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.01174369640648365, Val Loss: 0.00455085001885891\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.01037492323666811, Val Loss: 0.0052517252042889595\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.011527488008141518, Val Loss: 0.006305061746388674\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.013955788686871529, Val Loss: 0.007785477675497532\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.01587468571960926, Val Loss: 0.007851025089621544\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.012040632776916027, Val Loss: 0.007313344161957502\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.010269489139318466, Val Loss: 0.006117087788879871\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.012811688706278801, Val Loss: 0.004503033589571714\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.012282848358154297, Val Loss: 0.004328847862780094\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.008918100968003273, Val Loss: 0.004364600405097008\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.011586258187890053, Val Loss: 0.004172350279986858\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.012379270978271961, Val Loss: 0.003371060360223055\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.011451314203441143, Val Loss: 0.005236454773694277\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.008923185057938099, Val Loss: 0.008052661083638668\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.00883092638105154, Val Loss: 0.007271556183695793\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.012320565059781075, Val Loss: 0.007698364555835724\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.010154006071388721, Val Loss: 0.009716328233480453\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.013936839997768402, Val Loss: 0.002823835238814354\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.007195369806140661, Val Loss: 0.005382852628827095\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.014892209321260452, Val Loss: 0.009424080140888691\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.009355363436043262, Val Loss: 0.015840863808989525\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.016235634684562683, Val Loss: 0.007311650086194277\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.007394750136882067, Val Loss: 0.007768129929900169\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.012067509815096855, Val Loss: 0.003597111674025655\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.012802804820239544, Val Loss: 0.006571347359567881\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.00747285969555378, Val Loss: 0.009732719510793686\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.01166705135256052, Val Loss: 0.008620211854577065\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.010015266947448254, Val Loss: 0.005664687138050795\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.010832221247255802, Val Loss: 0.008164411410689354\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.01249450258910656, Val Loss: 0.01564965955913067\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.011394171975553036, Val Loss: 0.010684141889214516\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.008371536619961262, Val Loss: 0.009107295423746109\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.0076071168296039104, Val Loss: 0.008904821239411831\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.01643236353993416, Val Loss: 0.0061935195699334145\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.006970277521759272, Val Loss: 0.019566189497709274\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.014890427701175213, Val Loss: 0.013576348312199116\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.00993835087865591, Val Loss: 0.0077117448672652245\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.008950495161116123, Val Loss: 0.006209432613104582\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.014356797561049461, Val Loss: 0.0013558707432821393\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.01119578629732132, Val Loss: 0.0013320836005732417\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.015635143965482712, Val Loss: 0.0014268067898228765\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.013538463041186333, Val Loss: 0.001337993424385786\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.009990187361836433, Val Loss: 0.0011474268976598978\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.013163712806999683, Val Loss: 0.0009262918028980494\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.008600987493991852, Val Loss: 0.0007722862064838409\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.008078940212726593, Val Loss: 0.0007344525074586272\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.008284223265945911, Val Loss: 0.0013825696660205722\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.007536428049206734, Val Loss: 0.0025217875372618437\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.013891267590224743, Val Loss: 0.0032804603688418865\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.01152838859707117, Val Loss: 0.0033653867430984974\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.012669035233557224, Val Loss: 0.0023875380866229534\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.008902698755264282, Val Loss: 0.00239195441827178\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.008275550790131092, Val Loss: 0.0032057634089142084\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.012653257697820663, Val Loss: 0.0032787604723125696\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.011040914803743362, Val Loss: 0.0025126037653535604\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.007753997575491667, Val Loss: 0.003120191628113389\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.011265511624515057, Val Loss: 0.003223452717065811\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.007841470651328564, Val Loss: 0.0030774592887610197\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.012563006021082401, Val Loss: 0.002771620871499181\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.008456121198832989, Val Loss: 0.003231658600270748\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.014027456752955914, Val Loss: 0.003973973449319601\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.009747070260345936, Val Loss: 0.006985245272517204\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.011183485388755798, Val Loss: 0.005813032388687134\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.013247926719486713, Val Loss: 0.002473850967362523\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.012347693555057049, Val Loss: 0.011570852249860764\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.02584761008620262, Val Loss: 0.0016593983164057136\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.1795649528503418, Val Loss: 0.0012302736286073923\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.011276551522314548, Val Loss: 0.0007336477283388376\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.010476783849298954, Val Loss: 0.000847599352709949\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.011123589240014553, Val Loss: 0.001362483948469162\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.01455674972385168, Val Loss: 0.0017020035302266479\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.00779381487518549, Val Loss: 0.002358651254326105\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.008737596683204174, Val Loss: 0.0029047150164842606\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.012243163771927357, Val Loss: 0.003619128605350852\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.01205618865787983, Val Loss: 0.004325181245803833\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.016475599259138107, Val Loss: 0.004364587366580963\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.016778552904725075, Val Loss: 0.0030101125594228506\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.013025013729929924, Val Loss: 0.002137470059096813\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.007481916807591915, Val Loss: 0.002948179841041565\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.01252405159175396, Val Loss: 0.00465042982250452\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.015937313437461853, Val Loss: 0.00545515026897192\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.01533439103513956, Val Loss: 0.005194518249481916\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.00968456082046032, Val Loss: 0.008410351350903511\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.006117606069892645, Val Loss: 0.01443404983729124\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.021217186003923416, Val Loss: 0.01311144232749939\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.01264779083430767, Val Loss: 0.00764398043975234\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.007777965161949396, Val Loss: 0.005140810739248991\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.017134392634034157, Val Loss: 0.008967334404587746\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.004496438091155142, 'rmse': 0.0586090873247667, 'mae': 0.047095677256584166, 'mape': 17.32991773635149, 'r2': 0.9614628317673318}\n",
      "INFO:root:Epoch 1/100, Train Loss: 1.679439663887024, Val Loss: 0.15499168634414673\n",
      "INFO:root:Epoch 2/100, Train Loss: 1.3985310792922974, Val Loss: 0.15564261376857758\n",
      "INFO:root:Epoch 3/100, Train Loss: 1.3432350158691406, Val Loss: 0.15665031969547272\n",
      "INFO:root:Epoch 4/100, Train Loss: 1.4369769096374512, Val Loss: 0.15801739692687988\n",
      "INFO:root:Epoch 5/100, Train Loss: 1.2215337753295898, Val Loss: 0.15831905603408813\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.9261258840560913, Val Loss: 0.15834665298461914\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.9477898478507996, Val Loss: 0.15813015401363373\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.7115477323532104, Val Loss: 0.15824851393699646\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.7052085995674133, Val Loss: 0.15696828067302704\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.38910508155822754, Val Loss: 0.1575426310300827\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.38220155239105225, Val Loss: 0.15735913813114166\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.3652908504009247, Val Loss: 0.1562047004699707\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.3517356216907501, Val Loss: 0.154723659157753\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.346919983625412, Val Loss: 0.15370340645313263\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.4173215329647064, Val Loss: 0.151905819773674\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.3382337987422943, Val Loss: 0.15120552480220795\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.41088980436325073, Val Loss: 0.15032519400119781\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.3048936724662781, Val Loss: 0.15075451135635376\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.3921370804309845, Val Loss: 0.150069460272789\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.2761487662792206, Val Loss: 0.14967350661754608\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.21412520110607147, Val Loss: 0.1483522355556488\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.18233822286128998, Val Loss: 0.14835207164287567\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.15019652247428894, Val Loss: 0.14796054363250732\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.14131759107112885, Val Loss: 0.1475648283958435\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.17723801732063293, Val Loss: 0.1470801681280136\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.1496962457895279, Val Loss: 0.1473991423845291\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.15680085122585297, Val Loss: 0.14731553196907043\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.1490125209093094, Val Loss: 0.14708292484283447\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.14695893228054047, Val Loss: 0.146824911236763\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.1441570520401001, Val Loss: 0.14517876505851746\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.11614019423723221, Val Loss: 0.14446495473384857\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.09899451583623886, Val Loss: 0.143464133143425\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.09769301116466522, Val Loss: 0.14282578229904175\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.09363514184951782, Val Loss: 0.1405722200870514\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.09491530805826187, Val Loss: 0.1389388144016266\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.10784711688756943, Val Loss: 0.13900326192378998\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.09073607623577118, Val Loss: 0.13794468343257904\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.09429480880498886, Val Loss: 0.13776928186416626\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.07774633169174194, Val Loss: 0.1374615728855133\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.10971728712320328, Val Loss: 0.1367785781621933\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.08796698600053787, Val Loss: 0.13639919459819794\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.08555037528276443, Val Loss: 0.13522298634052277\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.0797438994050026, Val Loss: 0.1339796632528305\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.06496980041265488, Val Loss: 0.1320451945066452\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.09450376033782959, Val Loss: 0.13052818179130554\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.05925770103931427, Val Loss: 0.12855835258960724\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.07084182649850845, Val Loss: 0.12732379138469696\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.06980995088815689, Val Loss: 0.12565425038337708\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.06732767820358276, Val Loss: 0.12533512711524963\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.07549972087144852, Val Loss: 0.12503454089164734\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.06394121050834656, Val Loss: 0.12376637011766434\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.06917183101177216, Val Loss: 0.12158728390932083\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.061036959290504456, Val Loss: 0.12041613459587097\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.06912018358707428, Val Loss: 0.11930499970912933\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.0730925053358078, Val Loss: 0.11705365777015686\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.08918401598930359, Val Loss: 0.1142842099070549\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.0696825161576271, Val Loss: 0.11161167174577713\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.05280492827296257, Val Loss: 0.10802510380744934\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.07203056663274765, Val Loss: 0.10507114976644516\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.061451029032468796, Val Loss: 0.10109732300043106\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.054687269032001495, Val Loss: 0.09805762767791748\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.06639569252729416, Val Loss: 0.09433382004499435\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.06676876544952393, Val Loss: 0.09024487435817719\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.0534471720457077, Val Loss: 0.08641047775745392\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.0423106886446476, Val Loss: 0.08281128853559494\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.06720516830682755, Val Loss: 0.0793813094496727\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.053529635071754456, Val Loss: 0.07587256282567978\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.051182035356760025, Val Loss: 0.0728045254945755\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.05675552040338516, Val Loss: 0.06921631842851639\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.05791833996772766, Val Loss: 0.06650455296039581\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.0464622788131237, Val Loss: 0.06327728927135468\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.051226478070020676, Val Loss: 0.060225959867239\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.05926158279180527, Val Loss: 0.05735200271010399\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.0560753233730793, Val Loss: 0.05468152463436127\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.057955287396907806, Val Loss: 0.05190049484372139\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.05430794134736061, Val Loss: 0.049304526299238205\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.04862155020236969, Val Loss: 0.047036536037921906\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.056486111134290695, Val Loss: 0.0444076731801033\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.04722384363412857, Val Loss: 0.0427926629781723\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.04921625182032585, Val Loss: 0.04059052839875221\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.053723856806755066, Val Loss: 0.03828383982181549\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.055514633655548096, Val Loss: 0.03612499684095383\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.057717788964509964, Val Loss: 0.0344206839799881\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.0559336394071579, Val Loss: 0.03311629220843315\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.05136614292860031, Val Loss: 0.031517788767814636\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.05559900403022766, Val Loss: 0.030479472130537033\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.05660809949040413, Val Loss: 0.029063330963253975\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.04716303199529648, Val Loss: 0.02819962613284588\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.06778034567832947, Val Loss: 0.027501024305820465\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.055444106459617615, Val Loss: 0.02706488035619259\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.04568769037723541, Val Loss: 0.02692677080631256\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.047537945210933685, Val Loss: 0.02684318833053112\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.04521762207150459, Val Loss: 0.02669527567923069\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.054254014045000076, Val Loss: 0.027388380840420723\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.048443421721458435, Val Loss: 0.027679961174726486\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.05589842423796654, Val Loss: 0.02827892266213894\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.04492664337158203, Val Loss: 0.028982345014810562\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.055704839527606964, Val Loss: 0.030399123206734657\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.04917171224951744, Val Loss: 0.030598407611250877\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.05501917004585266, Val Loss: 0.029957860708236694\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.06636153161525726, Val Loss: 0.014110900461673737\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.051239609718322754, Val Loss: 0.013371096923947334\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.06149378418922424, Val Loss: 0.012235641479492188\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.06153397262096405, Val Loss: 0.011676354333758354\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.05031464993953705, Val Loss: 0.010777381248772144\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.05286185443401337, Val Loss: 0.010200800374150276\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.05018175393342972, Val Loss: 0.009570691734552383\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.06567323207855225, Val Loss: 0.00934761855751276\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.05500704422593117, Val Loss: 0.009056917391717434\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.05117295682430267, Val Loss: 0.008972233161330223\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.06558574736118317, Val Loss: 0.00931030884385109\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.04241140931844711, Val Loss: 0.009629675187170506\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.04989204555749893, Val Loss: 0.009971286170184612\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.0625946968793869, Val Loss: 0.011595209129154682\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.05698498338460922, Val Loss: 0.013025349006056786\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.04769137129187584, Val Loss: 0.014273019507527351\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.05644630268216133, Val Loss: 0.012415249831974506\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.06073949113488197, Val Loss: 0.010153106413781643\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.05646549537777901, Val Loss: 0.006945972330868244\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.04734095558524132, Val Loss: 0.005237672012299299\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.04945558309555054, Val Loss: 0.005445251706987619\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.05019623413681984, Val Loss: 0.006123674102127552\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.04509137570858002, Val Loss: 0.006508751306682825\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.056281525641679764, Val Loss: 0.0057099927216768265\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.05099807679653168, Val Loss: 0.004895555786788464\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.046757813543081284, Val Loss: 0.005684019066393375\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.055263616144657135, Val Loss: 0.0062040709890425205\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.053712062537670135, Val Loss: 0.006215736269950867\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.04328896850347519, Val Loss: 0.006031789351254702\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.04114682227373123, Val Loss: 0.005658138543367386\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.043944548815488815, Val Loss: 0.005740671884268522\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.0428556352853775, Val Loss: 0.007752567064017057\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.04783238098025322, Val Loss: 0.008817007765173912\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.049463365226984024, Val Loss: 0.011544096283614635\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.03782764822244644, Val Loss: 0.014495331794023514\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.046520352363586426, Val Loss: 0.014327763579785824\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.04312356188893318, Val Loss: 0.0126867750659585\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.04008115828037262, Val Loss: 0.010996202006936073\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.041708555072546005, Val Loss: 0.009524999186396599\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.04417846351861954, Val Loss: 0.009031003341078758\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.04327147454023361, Val Loss: 0.00921610463410616\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.03854447603225708, Val Loss: 0.008409128524363041\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.036771904677152634, Val Loss: 0.007653803564608097\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.0369039885699749, Val Loss: 0.0070612807758152485\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.044015899300575256, Val Loss: 0.008008696138858795\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.057948485016822815, Val Loss: 0.0014982123393565416\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.04032931849360466, Val Loss: 0.0012763163540512323\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.043374404311180115, Val Loss: 0.001094924402423203\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.04989929124712944, Val Loss: 0.0010191018227487803\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.054240647703409195, Val Loss: 0.0011184271425008774\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.04861941188573837, Val Loss: 0.0010517885675653815\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.04796651005744934, Val Loss: 0.0010432099224999547\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.03958384692668915, Val Loss: 0.001231444883160293\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.040784142911434174, Val Loss: 0.0015189741970971227\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.04297894984483719, Val Loss: 0.0018330742605030537\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.045715440064668655, Val Loss: 0.002051203977316618\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.052998293191194534, Val Loss: 0.0020088208839297295\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.04135807603597641, Val Loss: 0.001694042352028191\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.04618050530552864, Val Loss: 0.0016157516511157155\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.04519500955939293, Val Loss: 0.0017348519759252667\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.06130701303482056, Val Loss: 0.0016450845869258046\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.041415002197027206, Val Loss: 0.0014452495379373431\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.046691056340932846, Val Loss: 0.0012566226068884134\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.05298938229680061, Val Loss: 0.0012095215497538447\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.045774854719638824, Val Loss: 0.0010787128703668714\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.0452212318778038, Val Loss: 0.0009957676520571113\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.05454146862030029, Val Loss: 0.0019564235117286444\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.04262658581137657, Val Loss: 0.0056947022676467896\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.040492769330739975, Val Loss: 0.009665314108133316\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.05192777141928673, Val Loss: 0.008538942784070969\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.05011994019150734, Val Loss: 0.005857996642589569\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.037249479442834854, Val Loss: 0.005658118519932032\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.046136535704135895, Val Loss: 0.006253507919609547\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.03833722323179245, Val Loss: 0.006114564836025238\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.043995410203933716, Val Loss: 0.0036967131309211254\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.0434347465634346, Val Loss: 0.0019803179893642664\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.03505000099539757, Val Loss: 0.0035006252583116293\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.04206857085227966, Val Loss: 0.007028167136013508\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.041324466466903687, Val Loss: 0.008054479956626892\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.04101162403821945, Val Loss: 0.006309068761765957\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.04151837155222893, Val Loss: 0.0035038210917264223\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.03359997645020485, Val Loss: 0.004175596870481968\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.0414993017911911, Val Loss: 0.005473505239933729\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.04392290487885475, Val Loss: 0.0064333234913647175\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.033932000398635864, Val Loss: 0.006314875558018684\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.04296531900763512, Val Loss: 0.006423636805266142\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.13964098691940308, Val Loss: 0.009051299653947353\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Epoch 1/100, Train Loss: 0.0454852432012558, Val Loss: 0.004832320846617222\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Avg Validation Metrics: {'mse': 0.00835625883191824, 'rmse': 0.080084112278591, 'mae': 0.06860961690545082, 'mape': 25.36105841398239, 'r2': 0.9235051817302342}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.0023714064038358627\n",
      "Best Parameters: {'weight_decay': 0.0001, 'num_heads': 16, 'lstm_num_layers': 1, 'lstm_hidden_dim': 256, 'lstm_dropout': 0.1, 'learning_rate': 0.0005, 'gat_hidden_dim': 128, 'gat_dropout': 0.1, 'combined_dim': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 1/100, Train Loss: 1.3109115362167358, Val Loss: 1.3015830516815186\n",
      "INFO:root:Epoch 2/100, Train Loss: 0.8422613739967346, Val Loss: 1.294285535812378\n",
      "INFO:root:Epoch 3/100, Train Loss: 0.5076543688774109, Val Loss: 1.2834768295288086\n",
      "INFO:root:Epoch 4/100, Train Loss: 0.25940147042274475, Val Loss: 1.2681849002838135\n",
      "INFO:root:Epoch 5/100, Train Loss: 0.19836381077766418, Val Loss: 1.2475671768188477\n",
      "INFO:root:Epoch 6/100, Train Loss: 0.25592073798179626, Val Loss: 1.2228093147277832\n",
      "INFO:root:Epoch 7/100, Train Loss: 0.4115837514400482, Val Loss: 1.198229432106018\n",
      "INFO:root:Epoch 8/100, Train Loss: 0.4605790674686432, Val Loss: 1.1777737140655518\n",
      "INFO:root:Epoch 9/100, Train Loss: 0.4938683807849884, Val Loss: 1.1647961139678955\n",
      "INFO:root:Epoch 10/100, Train Loss: 0.4068116247653961, Val Loss: 1.161933183670044\n",
      "INFO:root:Epoch 11/100, Train Loss: 0.29245707392692566, Val Loss: 1.1677112579345703\n",
      "INFO:root:Epoch 12/100, Train Loss: 0.1484036147594452, Val Loss: 1.1788171529769897\n",
      "INFO:root:Epoch 13/100, Train Loss: 0.11056512594223022, Val Loss: 1.188759684562683\n",
      "INFO:root:Epoch 14/100, Train Loss: 0.18182754516601562, Val Loss: 1.1880589723587036\n",
      "INFO:root:Epoch 15/100, Train Loss: 0.21340972185134888, Val Loss: 1.171107292175293\n",
      "INFO:root:Epoch 16/100, Train Loss: 0.21457374095916748, Val Loss: 1.1355485916137695\n",
      "INFO:root:Epoch 17/100, Train Loss: 0.145451158285141, Val Loss: 1.0854496955871582\n",
      "INFO:root:Epoch 18/100, Train Loss: 0.08785053342580795, Val Loss: 1.0272935628890991\n",
      "INFO:root:Epoch 19/100, Train Loss: 0.06559513509273529, Val Loss: 0.9683891534805298\n",
      "INFO:root:Epoch 20/100, Train Loss: 0.06865625828504562, Val Loss: 0.9189000129699707\n",
      "INFO:root:Epoch 21/100, Train Loss: 0.08435048907995224, Val Loss: 0.8832703828811646\n",
      "INFO:root:Epoch 22/100, Train Loss: 0.07247031480073929, Val Loss: 0.8699696660041809\n",
      "INFO:root:Epoch 23/100, Train Loss: 0.051747944205999374, Val Loss: 0.8740212321281433\n",
      "INFO:root:Epoch 24/100, Train Loss: 0.03724401444196701, Val Loss: 0.8820934891700745\n",
      "INFO:root:Epoch 25/100, Train Loss: 0.03464815020561218, Val Loss: 0.8815006017684937\n",
      "INFO:root:Epoch 26/100, Train Loss: 0.038921888917684555, Val Loss: 0.8610086441040039\n",
      "INFO:root:Epoch 27/100, Train Loss: 0.036057084798812866, Val Loss: 0.8217027187347412\n",
      "INFO:root:Epoch 28/100, Train Loss: 0.03583917394280434, Val Loss: 0.7709059119224548\n",
      "INFO:root:Epoch 29/100, Train Loss: 0.029131576418876648, Val Loss: 0.7221353054046631\n",
      "INFO:root:Epoch 30/100, Train Loss: 0.0210708137601614, Val Loss: 0.6836994290351868\n",
      "INFO:root:Epoch 31/100, Train Loss: 0.018352067098021507, Val Loss: 0.6530880331993103\n",
      "INFO:root:Epoch 32/100, Train Loss: 0.018637187778949738, Val Loss: 0.6243436932563782\n",
      "INFO:root:Epoch 33/100, Train Loss: 0.019652776420116425, Val Loss: 0.5940256118774414\n",
      "INFO:root:Epoch 34/100, Train Loss: 0.01799972727894783, Val Loss: 0.562233030796051\n",
      "INFO:root:Epoch 35/100, Train Loss: 0.013683645986020565, Val Loss: 0.5387294292449951\n",
      "INFO:root:Epoch 36/100, Train Loss: 0.012590217404067516, Val Loss: 0.5237469673156738\n",
      "INFO:root:Epoch 37/100, Train Loss: 0.012340150773525238, Val Loss: 0.511214554309845\n",
      "INFO:root:Epoch 38/100, Train Loss: 0.012421016581356525, Val Loss: 0.49918603897094727\n",
      "INFO:root:Epoch 39/100, Train Loss: 0.01399325393140316, Val Loss: 0.4792177677154541\n",
      "INFO:root:Epoch 40/100, Train Loss: 0.01314358226954937, Val Loss: 0.45133891701698303\n",
      "INFO:root:Epoch 41/100, Train Loss: 0.011507369577884674, Val Loss: 0.4190996587276459\n",
      "INFO:root:Epoch 42/100, Train Loss: 0.010352789424359798, Val Loss: 0.38963383436203003\n",
      "INFO:root:Epoch 43/100, Train Loss: 0.00936125312000513, Val Loss: 0.3644770383834839\n",
      "INFO:root:Epoch 44/100, Train Loss: 0.009800150990486145, Val Loss: 0.34550610184669495\n",
      "INFO:root:Epoch 45/100, Train Loss: 0.009884518571197987, Val Loss: 0.32488715648651123\n",
      "INFO:root:Epoch 46/100, Train Loss: 0.010968951508402824, Val Loss: 0.3075564503669739\n",
      "INFO:root:Epoch 47/100, Train Loss: 0.009568067267537117, Val Loss: 0.2923588454723358\n",
      "INFO:root:Epoch 48/100, Train Loss: 0.010006600059568882, Val Loss: 0.2806231677532196\n",
      "INFO:root:Epoch 49/100, Train Loss: 0.009378370828926563, Val Loss: 0.27202948927879333\n",
      "INFO:root:Epoch 50/100, Train Loss: 0.00953897275030613, Val Loss: 0.25934645533561707\n",
      "INFO:root:Epoch 51/100, Train Loss: 0.009920566342771053, Val Loss: 0.2463189661502838\n",
      "INFO:root:Epoch 52/100, Train Loss: 0.008246459998190403, Val Loss: 0.2324509471654892\n",
      "INFO:root:Epoch 53/100, Train Loss: 0.008137679658830166, Val Loss: 0.21868155896663666\n",
      "INFO:root:Epoch 54/100, Train Loss: 0.007898159325122833, Val Loss: 0.20442451536655426\n",
      "INFO:root:Epoch 55/100, Train Loss: 0.00918982457369566, Val Loss: 0.18842782080173492\n",
      "INFO:root:Epoch 56/100, Train Loss: 0.007146022282540798, Val Loss: 0.17193607985973358\n",
      "INFO:root:Epoch 57/100, Train Loss: 0.007493552751839161, Val Loss: 0.15807665884494781\n",
      "INFO:root:Epoch 58/100, Train Loss: 0.008609049953520298, Val Loss: 0.14636678993701935\n",
      "INFO:root:Epoch 59/100, Train Loss: 0.00781811960041523, Val Loss: 0.1376659870147705\n",
      "INFO:root:Epoch 60/100, Train Loss: 0.007953657768666744, Val Loss: 0.13058248162269592\n",
      "INFO:root:Epoch 61/100, Train Loss: 0.007738168817013502, Val Loss: 0.1238902136683464\n",
      "INFO:root:Epoch 62/100, Train Loss: 0.006701494101434946, Val Loss: 0.11726131290197372\n",
      "INFO:root:Epoch 63/100, Train Loss: 0.006838688161224127, Val Loss: 0.11148523539304733\n",
      "INFO:root:Epoch 64/100, Train Loss: 0.008637298829853535, Val Loss: 0.10702454298734665\n",
      "INFO:root:Epoch 65/100, Train Loss: 0.006956189405173063, Val Loss: 0.10254889726638794\n",
      "INFO:root:Epoch 66/100, Train Loss: 0.006698243319988251, Val Loss: 0.09952165186405182\n",
      "INFO:root:Epoch 67/100, Train Loss: 0.007345264777541161, Val Loss: 0.09614644944667816\n",
      "INFO:root:Epoch 68/100, Train Loss: 0.00735308276489377, Val Loss: 0.09318304806947708\n",
      "INFO:root:Epoch 69/100, Train Loss: 0.007513817399740219, Val Loss: 0.09057779610157013\n",
      "INFO:root:Epoch 70/100, Train Loss: 0.006533866282552481, Val Loss: 0.08745461702346802\n",
      "INFO:root:Epoch 71/100, Train Loss: 0.0065940916538238525, Val Loss: 0.08501067757606506\n",
      "INFO:root:Epoch 72/100, Train Loss: 0.008015616796910763, Val Loss: 0.08358877897262573\n",
      "INFO:root:Epoch 73/100, Train Loss: 0.007211063988506794, Val Loss: 0.08176686614751816\n",
      "INFO:root:Epoch 74/100, Train Loss: 0.007158752530813217, Val Loss: 0.07928355038166046\n",
      "INFO:root:Epoch 75/100, Train Loss: 0.007195600774139166, Val Loss: 0.07682295143604279\n",
      "INFO:root:Epoch 76/100, Train Loss: 0.0073784408159554005, Val Loss: 0.07442280650138855\n",
      "INFO:root:Epoch 77/100, Train Loss: 0.007918552495539188, Val Loss: 0.07213055342435837\n",
      "INFO:root:Epoch 78/100, Train Loss: 0.006775799673050642, Val Loss: 0.0697849690914154\n",
      "INFO:root:Epoch 79/100, Train Loss: 0.007198874838650227, Val Loss: 0.06797221302986145\n",
      "INFO:root:Epoch 80/100, Train Loss: 0.006937449332326651, Val Loss: 0.0662255808711052\n",
      "INFO:root:Epoch 81/100, Train Loss: 0.007254499942064285, Val Loss: 0.0649091899394989\n",
      "INFO:root:Epoch 82/100, Train Loss: 0.006949408911168575, Val Loss: 0.06402688473463058\n",
      "INFO:root:Epoch 83/100, Train Loss: 0.007113923784345388, Val Loss: 0.06345319002866745\n",
      "INFO:root:Epoch 84/100, Train Loss: 0.006511833984404802, Val Loss: 0.06277596950531006\n",
      "INFO:root:Epoch 85/100, Train Loss: 0.0064293802715837955, Val Loss: 0.06215912476181984\n",
      "INFO:root:Epoch 86/100, Train Loss: 0.007387476973235607, Val Loss: 0.06111115589737892\n",
      "INFO:root:Epoch 87/100, Train Loss: 0.006782640237361193, Val Loss: 0.060417499393224716\n",
      "INFO:root:Epoch 88/100, Train Loss: 0.0069238245487213135, Val Loss: 0.059856805950403214\n",
      "INFO:root:Epoch 89/100, Train Loss: 0.006880678236484528, Val Loss: 0.05955096334218979\n",
      "INFO:root:Epoch 90/100, Train Loss: 0.007076795678585768, Val Loss: 0.05915732681751251\n",
      "INFO:root:Epoch 91/100, Train Loss: 0.006678682751953602, Val Loss: 0.05866513028740883\n",
      "INFO:root:Epoch 92/100, Train Loss: 0.006620354950428009, Val Loss: 0.058148760348558426\n",
      "INFO:root:Epoch 93/100, Train Loss: 0.00684512360021472, Val Loss: 0.057824451476335526\n",
      "INFO:root:Epoch 94/100, Train Loss: 0.007604103069752455, Val Loss: 0.05758877471089363\n",
      "INFO:root:Epoch 95/100, Train Loss: 0.00558854453265667, Val Loss: 0.05735118314623833\n",
      "INFO:root:Epoch 96/100, Train Loss: 0.0061248354613780975, Val Loss: 0.05735054612159729\n",
      "INFO:root:Epoch 97/100, Train Loss: 0.006721212528645992, Val Loss: 0.05714201554656029\n",
      "INFO:root:Epoch 98/100, Train Loss: 0.006861557252705097, Val Loss: 0.05696379020810127\n",
      "INFO:root:Epoch 99/100, Train Loss: 0.006979046389460564, Val Loss: 0.0565933920443058\n",
      "INFO:root:Epoch 100/100, Train Loss: 0.006970936898142099, Val Loss: 0.05640183389186859\n",
      "INFO:root:Test MSE: 0.43960052728652954, Test RMSE: 0.6630237758078736, Test MAE: 0.6441996693611145, Test MAPE: 217.51699447631836, Test R2: 0.5104838913585039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics: (0.43960052728652954, 0.6630237758078736, 0.6441996693611145, 217.51699447631836, 0.5104838913585039)\n",
      "Shape of test_predictions: (27, 27, 1)\n",
      "Shape of test_targets: (27, 27, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, ParameterSampler\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model\n",
    "class LSTM_GAT_Model(nn.Module):\n",
    "    def __init__(self, static_input_dim, lstm_input_dim, lstm_hidden_dim, lstm_num_layers, gat_input_dim, gat_hidden_dim, num_heads, combined_dim, output_dim, lstm_dropout=0.3, gat_dropout=0.3):\n",
    "        super(LSTM_GAT_Model, self).__init__()\n",
    "\n",
    "        # LSTM for time series features\n",
    "        self.lstm = nn.LSTM(lstm_input_dim, lstm_hidden_dim, lstm_num_layers, batch_first=True, dropout=lstm_dropout if lstm_num_layers > 1 else 0.0)\n",
    "        self.lstm_bn = nn.BatchNorm1d(lstm_hidden_dim)\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Linear(lstm_hidden_dim, 1)\n",
    "\n",
    "        # Fully connected layer to combine LSTM output with static features\n",
    "        self.fc1 = nn.Linear(lstm_hidden_dim + static_input_dim, gat_input_dim)\n",
    "        self.fc1_bn = nn.BatchNorm1d(gat_input_dim)\n",
    "        self.dropout1 = nn.Dropout(lstm_dropout)\n",
    "\n",
    "        # GAT for combined features\n",
    "        self.gat = pyg_nn.GATConv(gat_input_dim, gat_hidden_dim, heads=num_heads)\n",
    "        self.gat_bn = nn.BatchNorm1d(gat_hidden_dim * num_heads)\n",
    "        self.dropout2 = nn.Dropout(gat_dropout)\n",
    "\n",
    "        # Fully connected layer for final output\n",
    "        self.fc2 = nn.Linear(gat_hidden_dim * num_heads + gat_input_dim, combined_dim)  # Adjusted for skip connection\n",
    "        self.fc2_bn = nn.BatchNorm1d(combined_dim)\n",
    "        self.fc3 = nn.Linear(combined_dim, output_dim)\n",
    "\n",
    "    def forward(self, data, sequences):\n",
    "        sequences = sequences.to(device)\n",
    "        data = data.to(device)\n",
    "\n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(sequences)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Use the last hidden state from LSTM\n",
    "        lstm_out = self.lstm_bn(lstm_out)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attn_weights = F.softmax(self.attention(lstm_out), dim=1)\n",
    "        attn_out = torch.sum(lstm_out.unsqueeze(1) * attn_weights.unsqueeze(2), dim=1)  # Weighted sum of LSTM outputs\n",
    "\n",
    "        # Ensure data.x has the correct shape and expand it to match the batch size\n",
    "        static_features = data.x.unsqueeze(0).expand(sequences.size(0), -1, -1)  # (batch_size, num_nodes, static_input_dim)\n",
    "\n",
    "        # Combine LSTM output with static features\n",
    "        attn_out_expanded = attn_out.unsqueeze(1).expand(-1, static_features.size(1), -1)  # (batch_size, num_nodes, lstm_hidden_dim)\n",
    "        combined_features = torch.cat([attn_out_expanded, static_features], dim=2)  # Concatenate along the feature dimension\n",
    "\n",
    "        # Fully connected layer to reduce dimension\n",
    "        combined_features = combined_features.view(-1, combined_features.size(2))  # Flatten batch and num_nodes dimensions\n",
    "        combined_features = self.fc1(combined_features)\n",
    "        combined_features = self.fc1_bn(combined_features)\n",
    "        combined_features = self.dropout1(combined_features)\n",
    "\n",
    "        # GAT forward pass\n",
    "        gat_out = self.gat(combined_features, data.edge_index, data.edge_attr)\n",
    "        gat_out = self.gat_bn(gat_out)\n",
    "        gat_out = self.dropout2(gat_out)\n",
    "\n",
    "        # Combine GAT outputs with the original combined features (skip connection)\n",
    "        combined_gat = torch.cat([gat_out, combined_features], dim=1)\n",
    "\n",
    "        # Fully connected layers for final output\n",
    "        combined_gat = self.fc2(combined_gat)\n",
    "        combined_gat = self.fc2_bn(combined_gat)\n",
    "        output = self.fc3(combined_gat)\n",
    "\n",
    "        output = output.view(sequences.size(0), -1, self.fc3.out_features)  # Reshape to (batch_size, num_nodes, output_dim)\n",
    "        return output  # Return node-specific outputs\n",
    "\n",
    "# Compute metrics\n",
    "def compute_metrics(output, target, criterion):\n",
    "    mse = criterion(output, target).item()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = torch.mean(torch.abs(output - target)).item()\n",
    "    mape = torch.mean(torch.abs((output - target) / (target + 1e-5))).item() * 100\n",
    "    return mse, rmse, mae, mape\n",
    "\n",
    "# Hyperparameter space for random search\n",
    "param_distributions = {\n",
    "    'lstm_hidden_dim': [64, 128, 256],\n",
    "    'lstm_num_layers': [1, 2, 3],\n",
    "    'gat_hidden_dim': [32, 64, 128],\n",
    "    'num_heads': [4, 8, 16],\n",
    "    'combined_dim': [64, 128, 256],\n",
    "    'lstm_dropout': [0.1, 0.2, 0.3],\n",
    "    'gat_dropout': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "    'weight_decay': [1e-4, 5e-4, 1e-3]\n",
    "}\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define test_loader outside the function\n",
    "test_loader = DataLoader(TensorDataset(test_sequences_tensor, test_targets_tensor), batch_size=48, shuffle=False)\n",
    "\n",
    "# Training and evaluation function with cross-validation\n",
    "def cross_val_evaluate(param_sample, graph_data):\n",
    "    lstm_hidden_dim = param_sample['lstm_hidden_dim']\n",
    "    lstm_num_layers = param_sample['lstm_num_layers']\n",
    "    gat_hidden_dim = param_sample['gat_hidden_dim']\n",
    "    num_heads = param_sample['num_heads']\n",
    "    combined_dim = param_sample['combined_dim']\n",
    "    lstm_dropout = param_sample['lstm_dropout']\n",
    "    gat_dropout = param_sample['gat_dropout']\n",
    "    learning_rate = param_sample['learning_rate']\n",
    "    weight_decay = param_sample['weight_decay']\n",
    "\n",
    "    model = LSTM_GAT_Model(\n",
    "        static_input_dim=8,\n",
    "        lstm_input_dim=27,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        gat_input_dim=lstm_hidden_dim + 8,  # Corrected static_input_dim here\n",
    "        gat_hidden_dim=gat_hidden_dim,\n",
    "        num_heads=num_heads,\n",
    "        combined_dim=combined_dim,\n",
    "        output_dim=1,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "        gat_dropout=gat_dropout\n",
    "    ).to(device)  # Move model to device\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    num_epochs = 100\n",
    "    batch_size = 48\n",
    "    early_stopping_patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    aggregated_metrics = {'mse': [], 'rmse': [], 'mae': [], 'mape': [], 'r2': []}\n",
    "\n",
    "    for train_index, val_index in kf.split(train_sequences_tensor):\n",
    "        train_sequences, val_sequences = train_sequences_tensor[train_index].to(device), train_sequences_tensor[val_index].to(device)\n",
    "        train_targets, val_targets = train_targets_tensor[train_index].to(device), train_targets_tensor[val_index].to(device)\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(train_sequences, train_targets), batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(TensorDataset(val_sequences, val_targets), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize the scheduler here, after train_loader is defined\n",
    "        scheduler = OneCycleLR(optimizer, max_lr=learning_rate, epochs=num_epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "        # Lists to store losses\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for sequences, targets in train_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                loss = criterion(output, targets_expanded)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for sequences, targets in val_loader:\n",
    "                    sequences, targets = sequences.to(device), targets.to(device)\n",
    "                    output = model(graph_data, sequences)\n",
    "\n",
    "                    # Ensure the target shape matches the output shape\n",
    "                    targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                    loss = criterion(output, targets_expanded)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            logging.info(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "            # Learning rate scheduling\n",
    "            scheduler.step()\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= early_stopping_patience:\n",
    "                    logging.info('Early stopping triggered')\n",
    "                    break\n",
    "\n",
    "        # Load the best model\n",
    "        model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "        # Validation evaluation\n",
    "        model.eval()\n",
    "        val_mse, val_rmse, val_mae, val_mape = 0, 0, 0, 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                mse, rmse, mae, mape = compute_metrics(output, targets_expanded, criterion)\n",
    "                val_mse += mse\n",
    "                val_rmse += rmse\n",
    "                val_mae += mae\n",
    "                val_mape += mape\n",
    "\n",
    "                all_predictions.append(output.cpu().numpy())\n",
    "                all_targets.append(targets_expanded.cpu().numpy())\n",
    "\n",
    "        # Compute overall R-squared\n",
    "        all_predictions = np.vstack(all_predictions)\n",
    "        all_targets = np.vstack(all_targets)\n",
    "\n",
    "        # Flatten the arrays to 2D for r2_score computation\n",
    "        all_predictions_flat = all_predictions.reshape(-1, 1)\n",
    "        all_targets_flat = all_targets.reshape(-1, 1)\n",
    "\n",
    "        val_r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "\n",
    "        val_mse /= len(val_loader)\n",
    "        val_rmse /= len(val_loader)\n",
    "        val_mae /= len(val_loader)\n",
    "        val_mape /= len(val_loader)\n",
    "\n",
    "        aggregated_metrics['mse'].append(val_mse)\n",
    "        aggregated_metrics['rmse'].append(val_rmse)\n",
    "        aggregated_metrics['mae'].append(val_mae)\n",
    "        aggregated_metrics['mape'].append(val_mape)\n",
    "        aggregated_metrics['r2'].append(val_r2)\n",
    "\n",
    "    avg_metrics = {metric: np.mean(aggregated_metrics[metric]) for metric in aggregated_metrics}\n",
    "    logging.info(f'Avg Validation Metrics: {avg_metrics}')\n",
    "\n",
    "    return avg_metrics\n",
    "\n",
    "# Random search for hyperparameter tuning\n",
    "param_samples = list(ParameterSampler(param_distributions, n_iter=20, random_state=42))\n",
    "best_score = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for param_sample in param_samples:\n",
    "    avg_metrics = cross_val_evaluate(param_sample, graph_data)\n",
    "    if avg_metrics['mse'] < best_score:\n",
    "        best_score = avg_metrics['mse']\n",
    "        best_params = param_sample\n",
    "\n",
    "print(f'Best Score: {best_score}')\n",
    "print(f'Best Parameters: {best_params}')\n",
    "\n",
    "# Train on the full training set with the best hyperparameters\n",
    "def train_on_full_train_set(best_params, graph_data):\n",
    "    lstm_hidden_dim = best_params['lstm_hidden_dim']\n",
    "    lstm_num_layers = best_params['lstm_num_layers']\n",
    "    gat_hidden_dim = best_params['gat_hidden_dim']\n",
    "    num_heads = best_params['num_heads']\n",
    "    combined_dim = best_params['combined_dim']\n",
    "    lstm_dropout = best_params['lstm_dropout']\n",
    "    gat_dropout = best_params['gat_dropout']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "    weight_decay = best_params['weight_decay']\n",
    "    num_epochs = 100  # Define num_epochs\n",
    "    batch_size = 48  # Define batch_size\n",
    "\n",
    "    model = LSTM_GAT_Model(\n",
    "        static_input_dim=8,\n",
    "        lstm_input_dim=27,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        gat_input_dim=lstm_hidden_dim + 8,  # Corrected static_input_dim here\n",
    "        gat_hidden_dim=gat_hidden_dim,\n",
    "        num_heads=num_heads,\n",
    "        combined_dim=combined_dim,\n",
    "        output_dim=1,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "        gat_dropout=gat_dropout\n",
    "    ).to(device)  # Move model to device\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    train_loader = DataLoader(TensorDataset(train_sequences_tensor, train_targets_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize the scheduler here, after train_loader is defined\n",
    "    scheduler = OneCycleLR(optimizer, max_lr=learning_rate, epochs=num_epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "    early_stopping_patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    val_loader = DataLoader(TensorDataset(val_sequences_tensor, val_targets_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Lists to store losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, targets in train_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(graph_data, sequences)\n",
    "\n",
    "            # Ensure the target shape matches the output shape\n",
    "            targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "            loss = criterion(output, targets_expanded)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                loss = criterion(output, targets_expanded)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        logging.info(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        scheduler.step()\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), 'best_model_full_train.pth')\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= early_stopping_patience:\n",
    "                logging.info('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load('best_model_full_train.pth'))\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "best_model, best_train_losses, best_val_losses = train_on_full_train_set(best_params, graph_data)\n",
    "\n",
    "# Test evaluation\n",
    "def evaluate_on_test_set(model, graph_data, criterion):\n",
    "    model.eval()\n",
    "    test_mse, test_rmse, test_mae, test_mape = 0, 0, 0, 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in test_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            output = model(graph_data, sequences)\n",
    "\n",
    "            # Ensure the target shape matches the output shape\n",
    "            targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "            mse, rmse, mae, mape = compute_metrics(output, targets_expanded, criterion)\n",
    "            test_mse += mse\n",
    "            test_rmse += rmse\n",
    "            test_mae += mae\n",
    "            test_mape += mape\n",
    "\n",
    "            all_predictions.append(output.cpu().numpy())\n",
    "            all_targets.append(targets_expanded.cpu().numpy())\n",
    "\n",
    "    # Compute overall R-squared\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "\n",
    "    # Flatten the arrays to 2D for r2_score computation\n",
    "    all_predictions_flat = all_predictions.reshape(-1, 1)\n",
    "    all_targets_flat = all_targets.reshape(-1, 1)\n",
    "\n",
    "    test_r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "\n",
    "    test_mse /= len(test_loader)\n",
    "    test_rmse /= len(test_loader)\n",
    "    test_mae /= len(test_loader)\n",
    "    test_mape /= len(test_loader)\n",
    "\n",
    "    logging.info(f'Test MSE: {test_mse}, Test RMSE: {test_rmse}, Test MAE: {test_mae}, Test MAPE: {test_mape}, Test R2: {test_r2}')\n",
    "\n",
    "    return (test_mse, test_rmse, test_mae, test_mape, test_r2), all_predictions, all_targets\n",
    "\n",
    "# Pass criterion as an argument\n",
    "test_metrics, test_predictions, test_targets = evaluate_on_test_set(best_model, graph_data, nn.MSELoss())\n",
    "\n",
    "# Debugging prints\n",
    "print(f'Test Metrics: {test_metrics}')\n",
    "print(\"Shape of test_predictions:\", test_predictions.shape)\n",
    "print(\"Shape of test_targets:\", test_targets.shape)\n",
    "\n",
    "# Plotting the predictions vs. actual values for the last 24 hours\n",
    "last_hours = 24\n",
    "\n",
    "if test_predictions.shape[0] >= last_hours and test_targets.shape[0] >= last_hours:\n",
    "    last_predictions = test_predictions[-last_hours:, :]\n",
    "    last_targets = test_targets[-last_hours:, :]\n",
    "    node_index = 24\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(last_targets[:, node_index], label=f'Actual Node {node_index}')\n",
    "    plt.plot(last_predictions[:, node_index], label=f'Predicted Node {node_index}', linestyle='dashed')\n",
    "\n",
    "    plt.xlabel('Time-Step')\n",
    "    plt.ylabel('Consumption')\n",
    "    plt.title(f'LSTM-GAT Model Predicted vs Actual Consumption for Node {node_index} (Last {last_hours} Hours)')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Not enough samples to plot the last {last_hours} hours.\")\n",
    "\n",
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_train_losses, label='Train Loss')\n",
    "plt.plot(best_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for LSTM-GAT Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "858d0d20-764e-45fc-983e-e1ddbfaeea63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_predictions: (27, 27, 1)\n",
      "Shape of test_targets: (27, 27, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Debugging prints\n",
    "print(\"Shape of test_predictions:\", test_predictions.shape)\n",
    "print(\"Shape of test_targets:\", test_targets.shape)\n",
    "\n",
    "# Plotting the predictions vs. actual values for a specific 24-hour range for all nodes\n",
    "range_hours = 24\n",
    "\n",
    "# Ensure there are enough samples for the specified range\n",
    "if test_predictions.shape[0] >= range_hours and test_targets.shape[0] >= range_hours:\n",
    "    # Select any 24-hour range\n",
    "    range_start = 0  # Change this to specify different starting points\n",
    "    range_end = range_start + range_hours\n",
    "\n",
    "    selected_predictions = test_predictions[range_start:range_end, :]\n",
    "    selected_targets = test_targets[range_start:range_end, :]\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "    for node_index in range(selected_predictions.shape[1]):\n",
    "        ax.plot(selected_targets[:, node_index], label='Actual Consumption' if node_index == 0 else \"\", color='blue', alpha=0.5)\n",
    "        ax.plot(selected_predictions[:, node_index], label='Predicted Consumption' if node_index == 0 else \"\", linestyle='dashed', color='orange', alpha=0.5)\n",
    "    \n",
    "    ax.set_title(f'Actual vs Predicted Consumption for All Nodes ({range_hours}-Hour Range)')\n",
    "    ax.set_xlabel('Time-Step')\n",
    "    ax.set_ylabel('Consumption (MW)')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Not enough samples to plot the {range_hours}-hour range.\")\n",
    "\n",
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_train_losses, label='Train Loss')\n",
    "plt.plot(best_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for LSTM-GAT Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791c4d80-25b1-4c18-81c2-dac6356d4584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fda906-51bf-4501-a66e-e0768305e91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d095a7af-69c9-4f0c-91c8-4db48c628ae2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033bc03-8a08-4cf3-b447-d950c2b6fd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c9551-937f-4d5d-a72c-8f3346beae8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f449af6-39a0-4d40-8fe8-69936252c7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2973f05d-f2b0-4451-a643-04c61105d1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff6557-6ad4-49d5-a425-d8f493e25413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02b4c0-869a-4cfd-8e2c-36ff2df4cf2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e36d6-7c5d-48fa-92c3-bae8ea5107d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c381f57-ba29-4574-b1b1-60e43f9e7494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_predictions: (27, 27, 1)\n",
      "Shape of test_targets: (27, 27, 1)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Debugging prints\n",
    "print(\"Shape of test_predictions:\", test_predictions.shape)\n",
    "print(\"Shape of test_targets:\", test_targets.shape)\n",
    "\n",
    "# Plotting the predictions vs. actual values for a specific 24-hour range for all nodes\n",
    "range_hours = 24\n",
    "\n",
    "# Ensure there are enough samples for the specified range\n",
    "if test_predictions.shape[0] >= range_hours and test_targets.shape[0] >= range_hours:\n",
    "    # Select any 24-hour range\n",
    "    range_start = 0  # Change this to specify different starting points\n",
    "    range_end = range_start + range_hours\n",
    "\n",
    "    selected_predictions = test_predictions[range_start:range_end, :]\n",
    "    selected_targets = test_targets[range_start:range_end, :]\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "    for node_index in range(selected_predictions.shape[1]):\n",
    "        ax.plot(selected_targets[:, node_index], label='Actual Consumption' if node_index == 0 else \"\", color='blue', alpha=0.5)\n",
    "        ax.plot(selected_predictions[:, node_index], label='Predicted Consumption' if node_index == 0 else \"\", linestyle='dashed', color='orange', alpha=0.5)\n",
    "    \n",
    "    ax.set_title(f'LSTM-GAT Model Actual vs Predicted Consumption for All Nodes ({range_hours}-Hour Range)')\n",
    "    ax.set_xlabel('Time-Step')\n",
    "    ax.set_ylabel('Consumption (MW)')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.savefig('actual_vs_predicted_consumption.png')\n",
    "    plt.close()\n",
    "else:\n",
    "    print(f\"Not enough samples to plot the {range_hours}-hour range.\")\n",
    "\n",
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_train_losses, label='Train Loss')\n",
    "plt.plot(best_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for LSTM-GAT Model')\n",
    "plt.legend()\n",
    "plt.savefig('learning_curve.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97652e89-3904-4a92-a50d-fea35fa8bdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718dd4eb-610e-4afc-a31d-6cea91d5b3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1302b686-e3bc-464e-bd56-87e8f16e715e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e094604c-ede2-4b08-9309-961b65b95a71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdtadhgwgfetheht' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gdtadhgwgfetheht\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gdtadhgwgfetheht' is not defined"
     ]
    }
   ],
   "source": [
    "gdtadhgwgfetheht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4883cd-5827-4492-9d5e-f3a3c279b8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2972d6-fc24-4c12-9b25-5fce5e1e8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, ParameterSampler\n",
    "from torch.optim.lr_scheduler import OneCycleLR, ReduceLROnPlateau\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model\n",
    "class LSTM_GAT_Model(nn.Module):\n",
    "    def __init__(self, static_input_dim, lstm_input_dim, lstm_hidden_dim, lstm_num_layers, gat_input_dim, gat_hidden_dim, num_heads, combined_dim, output_dim, lstm_dropout=0.3, gat_dropout=0.3):\n",
    "        super(LSTM_GAT_Model, self).__init__()\n",
    "\n",
    "        # LSTM for time series features\n",
    "        self.lstm = nn.LSTM(lstm_input_dim, lstm_hidden_dim, lstm_num_layers, batch_first=True, dropout=lstm_dropout if lstm_num_layers > 1 else 0.0)\n",
    "        self.lstm_bn = nn.BatchNorm1d(lstm_hidden_dim)\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Linear(lstm_hidden_dim, 1)\n",
    "\n",
    "        # Fully connected layer to combine LSTM output with static features\n",
    "        self.fc1 = nn.Linear(lstm_hidden_dim + static_input_dim, gat_input_dim)\n",
    "        self.fc1_bn = nn.BatchNorm1d(gat_input_dim)\n",
    "        self.dropout1 = nn.Dropout(lstm_dropout)\n",
    "\n",
    "        # GAT for combined features\n",
    "        self.gat = pyg_nn.GATConv(gat_input_dim, gat_hidden_dim, heads=num_heads)\n",
    "        self.gat_bn = nn.BatchNorm1d(gat_hidden_dim * num_heads)\n",
    "        self.dropout2 = nn.Dropout(gat_dropout)\n",
    "\n",
    "        # Fully connected layer for final output\n",
    "        self.fc2 = nn.Linear(gat_hidden_dim * num_heads + gat_input_dim, combined_dim)  # Adjusted for skip connection\n",
    "        self.fc2_bn = nn.BatchNorm1d(combined_dim)\n",
    "        self.fc3 = nn.Linear(combined_dim, output_dim)\n",
    "\n",
    "    def forward(self, data, sequences):\n",
    "        sequences = sequences.to(device)\n",
    "        data = data.to(device)\n",
    "\n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(sequences)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Use the last hidden state from LSTM\n",
    "        lstm_out = self.lstm_bn(lstm_out)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attn_weights = F.softmax(self.attention(lstm_out), dim=1)\n",
    "        attn_out = torch.sum(lstm_out.unsqueeze(1) * attn_weights.unsqueeze(2), dim=1)  # Weighted sum of LSTM outputs\n",
    "\n",
    "        # Ensure data.x has the correct shape and expand it to match the batch size\n",
    "        static_features = data.x.unsqueeze(0).expand(sequences.size(0), -1, -1)  # (batch_size, num_nodes, static_input_dim)\n",
    "\n",
    "        # Combine LSTM output with static features\n",
    "        attn_out_expanded = attn_out.unsqueeze(1).expand(-1, static_features.size(1), -1)  # (batch_size, num_nodes, lstm_hidden_dim)\n",
    "        combined_features = torch.cat([attn_out_expanded, static_features], dim=2)  # Concatenate along the feature dimension\n",
    "\n",
    "        # Fully connected layer to reduce dimension\n",
    "        combined_features = combined_features.view(-1, combined_features.size(2))  # Flatten batch and num_nodes dimensions\n",
    "        combined_features = self.fc1(combined_features)\n",
    "        combined_features = self.fc1_bn(combined_features)\n",
    "        combined_features = self.dropout1(combined_features)\n",
    "\n",
    "        # GAT forward pass\n",
    "        gat_out = self.gat(combined_features, data.edge_index, data.edge_attr)\n",
    "        gat_out = self.gat_bn(gat_out)\n",
    "        gat_out = self.dropout2(gat_out)\n",
    "\n",
    "        # Combine GAT outputs with the original combined features (skip connection)\n",
    "        combined_gat = torch.cat([gat_out, combined_features], dim=1)\n",
    "\n",
    "        # Fully connected layers for final output\n",
    "        combined_gat = self.fc2(combined_gat)\n",
    "        combined_gat = self.fc2_bn(combined_gat)\n",
    "        output = self.fc3(combined_gat)\n",
    "\n",
    "        output = output.view(sequences.size(0), -1, self.fc3.out_features)  # Reshape to (batch_size, num_nodes, output_dim)\n",
    "        return output  # Return node-specific outputs\n",
    "\n",
    "# Compute metrics\n",
    "def compute_metrics(output, target, criterion):\n",
    "    mse = criterion(output, target).item()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = torch.mean(torch.abs(output - target)).item()\n",
    "    mape = torch.mean(torch.abs((output - target) / (target + 1e-5))).item() * 100\n",
    "    return mse, rmse, mae, mape\n",
    "\n",
    "# Hyperparameter space for random search\n",
    "param_distributions = {\n",
    "    'lstm_hidden_dim': [64, 128, 256],\n",
    "    'lstm_num_layers': [1, 2, 3],\n",
    "    'gat_hidden_dim': [32, 64, 128],\n",
    "    'num_heads': [4, 8, 16],\n",
    "    'combined_dim': [64, 128, 256],\n",
    "    'lstm_dropout': [0.1, 0.2, 0.3],\n",
    "    'gat_dropout': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "    'weight_decay': [1e-4, 5e-4, 1e-3]\n",
    "}\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define test_loader outside the function\n",
    "test_loader = DataLoader(TensorDataset(test_sequences_tensor, test_targets_tensor), batch_size=48, shuffle=False)\n",
    "\n",
    "# Training and evaluation function with cross-validation\n",
    "def cross_val_evaluate(param_sample, graph_data):\n",
    "    lstm_hidden_dim = param_sample['lstm_hidden_dim']\n",
    "    lstm_num_layers = param_sample['lstm_num_layers']\n",
    "    gat_hidden_dim = param_sample['gat_hidden_dim']\n",
    "    num_heads = param_sample['num_heads']\n",
    "    combined_dim = param_sample['combined_dim']\n",
    "    lstm_dropout = param_sample['lstm_dropout']\n",
    "    gat_dropout = param_sample['gat_dropout']\n",
    "    learning_rate = param_sample['learning_rate']\n",
    "    weight_decay = param_sample['weight_decay']\n",
    "\n",
    "    model = LSTM_GAT_Model(\n",
    "        static_input_dim=8,\n",
    "        lstm_input_dim=27,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        gat_input_dim=lstm_hidden_dim + 8,  # Corrected static_input_dim here\n",
    "        gat_hidden_dim=gat_hidden_dim,\n",
    "        num_heads=num_heads,\n",
    "        combined_dim=combined_dim,\n",
    "        output_dim=1,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "        gat_dropout=gat_dropout\n",
    "    ).to(device)  # Move model to device\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    num_epochs = 100\n",
    "    batch_size = 48\n",
    "    early_stopping_patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    aggregated_metrics = {'mse': [], 'rmse': [], 'mae': [], 'mape': [], 'r2': []}\n",
    "\n",
    "    for train_index, val_index in kf.split(train_sequences_tensor):\n",
    "        train_sequences, val_sequences = train_sequences_tensor[train_index].to(device), train_sequences_tensor[val_index].to(device)\n",
    "        train_targets, val_targets = train_targets_tensor[train_index].to(device), train_targets_tensor[val_index].to(device)\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(train_sequences, train_targets), batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(TensorDataset(val_sequences, val_targets), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize the scheduler here, after train_loader is defined\n",
    "        scheduler = OneCycleLR(optimizer, max_lr=learning_rate, epochs=num_epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "        # Lists to store losses\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for sequences, targets in train_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                loss = criterion(output, targets_expanded)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for sequences, targets in val_loader:\n",
    "                    sequences, targets = sequences.to(device), targets.to(device)\n",
    "                    output = model(graph_data, sequences)\n",
    "\n",
    "                    # Ensure the target shape matches the output shape\n",
    "                    targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                    loss = criterion(output, targets_expanded)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            logging.info(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "            # Learning rate scheduling\n",
    "            scheduler.step()\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= early_stopping_patience:\n",
    "                    logging.info('Early stopping triggered')\n",
    "                    break\n",
    "\n",
    "        # Load the best model\n",
    "        model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "        # Validation evaluation\n",
    "        model.eval()\n",
    "        val_mse, val_rmse, val_mae, val_mape = 0, 0, 0, 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                mse, rmse, mae, mape = compute_metrics(output, targets_expanded, criterion)\n",
    "                val_mse += mse\n",
    "                val_rmse += rmse\n",
    "                val_mae += mae\n",
    "                val_mape += mape\n",
    "\n",
    "                all_predictions.append(output.cpu().numpy())\n",
    "                all_targets.append(targets_expanded.cpu().numpy())\n",
    "\n",
    "        # Compute overall R-squared\n",
    "        all_predictions = np.vstack(all_predictions)\n",
    "        all_targets = np.vstack(all_targets)\n",
    "\n",
    "        # Flatten the arrays to 2D for r2_score computation\n",
    "        all_predictions_flat = all_predictions.reshape(-1, 1)\n",
    "        all_targets_flat = all_targets.reshape(-1, 1)\n",
    "\n",
    "        val_r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "\n",
    "        val_mse /= len(val_loader)\n",
    "        val_rmse /= len(val_loader)\n",
    "        val_mae /= len(val_loader)\n",
    "        val_mape /= len(val_loader)\n",
    "\n",
    "        aggregated_metrics['mse'].append(val_mse)\n",
    "        aggregated_metrics['rmse'].append(val_rmse)\n",
    "        aggregated_metrics['mae'].append(val_mae)\n",
    "        aggregated_metrics['mape'].append(val_mape)\n",
    "        aggregated_metrics['r2'].append(val_r2)\n",
    "\n",
    "    avg_metrics = {metric: np.mean(aggregated_metrics[metric]) for metric in aggregated_metrics}\n",
    "    logging.info(f'Avg Validation Metrics: {avg_metrics}')\n",
    "\n",
    "    return avg_metrics\n",
    "\n",
    "# Random search for hyperparameter tuning\n",
    "param_samples = list(ParameterSampler(param_distributions, n_iter=20, random_state=42))\n",
    "best_score = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for param_sample in param_samples:\n",
    "    avg_metrics = cross_val_evaluate(param_sample, graph_data)\n",
    "    if avg_metrics['mse'] < best_score:\n",
    "        best_score = avg_metrics['mse']\n",
    "        best_params = param_sample\n",
    "\n",
    "print(f'Best Score: {best_score}')\n",
    "print(f'Best Parameters: {best_params}')\n",
    "\n",
    "# Train on the full training set with the best hyperparameters\n",
    "def train_on_full_train_set(best_params, graph_data):\n",
    "    lstm_hidden_dim = best_params['lstm_hidden_dim']\n",
    "    lstm_num_layers = best_params['lstm_num_layers']\n",
    "    gat_hidden_dim = best_params['gat_hidden_dim']\n",
    "    num_heads = best_params['num_heads']\n",
    "    combined_dim = best_params['combined_dim']\n",
    "    lstm_dropout = best_params['lstm_dropout']\n",
    "    gat_dropout = best_params['gat_dropout']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "    weight_decay = best_params['weight_decay']\n",
    "    num_epochs = 100  # Define num_epochs\n",
    "    batch_size = 48  # Define batch_size\n",
    "\n",
    "    model = LSTM_GAT_Model(\n",
    "        static_input_dim=8,\n",
    "        lstm_input_dim=27,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        gat_input_dim=lstm_hidden_dim + 8,  # Corrected static_input_dim here\n",
    "        gat_hidden_dim=gat_hidden_dim,\n",
    "        num_heads=num_heads,\n",
    "        combined_dim=combined_dim,\n",
    "        output_dim=1,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "        gat_dropout=gat_dropout\n",
    "    ).to(device)  # Move model to device\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    train_loader = DataLoader(TensorDataset(train_sequences_tensor, train_targets_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize the scheduler here, after train_loader is defined\n",
    "    scheduler = OneCycleLR(optimizer, max_lr=learning_rate, epochs=num_epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "    early_stopping_patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    val_loader = DataLoader(TensorDataset(val_sequences_tensor, val_targets_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Lists to store losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, targets in train_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(graph_data, sequences)\n",
    "\n",
    "            # Ensure the target shape matches the output shape\n",
    "            targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "            loss = criterion(output, targets_expanded)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                loss = criterion(output, targets_expanded)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        logging.info(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        scheduler.step()\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), 'best_model_full_train.pth')\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= early_stopping_patience:\n",
    "                logging.info('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load('best_model_full_train.pth'))\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "best_model, best_train_losses, best_val_losses = train_on_full_train_set(best_params, graph_data)\n",
    "\n",
    "# Test evaluation\n",
    "def evaluate_on_test_set(model, graph_data, criterion):\n",
    "    model.eval()\n",
    "    test_mse, test_rmse, test_mae, test_mape = 0, 0, 0, 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in test_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            output = model(graph_data, sequences)\n",
    "\n",
    "            # Ensure the target shape matches the output shape\n",
    "            targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "            mse, rmse, mae, mape = compute_metrics(output, targets_expanded, criterion)\n",
    "            test_mse += mse\n",
    "            test_rmse += rmse\n",
    "            test_mae += mae\n",
    "            test_mape += mape\n",
    "\n",
    "            all_predictions.append(output.cpu().numpy())\n",
    "            all_targets.append(targets_expanded.cpu().numpy())\n",
    "\n",
    "    # Compute overall R-squared\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "\n",
    "    # Flatten the arrays to 2D for r2_score computation\n",
    "    all_predictions_flat = all_predictions.reshape(-1, 1)\n",
    "    all_targets_flat = all_targets.reshape(-1, 1)\n",
    "\n",
    "    test_r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "\n",
    "    test_mse /= len(test_loader)\n",
    "    test_rmse /= len(test_loader)\n",
    "    test_mae /= len(test_loader)\n",
    "    test_mape /= len(test_loader)\n",
    "\n",
    "    logging.info(f'Test MSE: {test_mse}, Test RMSE: {test_rmse}, Test MAE: {test_mae}, Test MAPE: {test_mape}, Test R2: {test_r2}')\n",
    "\n",
    "    return (test_mse, test_rmse, test_mae, test_mape, test_r2), all_predictions, all_targets\n",
    "\n",
    "# Pass criterion as an argument\n",
    "test_metrics, test_predictions, test_targets = evaluate_on_test_set(best_model, graph_data, nn.MSELoss())\n",
    "\n",
    "# Debugging prints\n",
    "print(f'Test Metrics: {test_metrics}')\n",
    "print(\"Shape of test_predictions:\", test_predictions.shape)\n",
    "print(\"Shape of test_targets:\", test_targets.shape)\n",
    "\n",
    "# Plotting the predictions vs. actual values for the last 24 hours\n",
    "last_hours = 24\n",
    "\n",
    "if test_predictions.shape[0] >= last_hours and test_targets.shape[0] >= last_hours:\n",
    "    last_predictions = test_predictions[-last_hours:, :]\n",
    "    last_targets = test_targets[-last_hours:, :]\n",
    "    node_index = 24\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(last_targets[:, node_index], label=f'Actual Node {node_index}')\n",
    "    plt.plot(last_predictions[:, node_index], label=f'Predicted Node {node_index}', linestyle='dashed')\n",
    "\n",
    "    plt.xlabel('Time-Step')\n",
    "    plt.ylabel('Consumption')\n",
    "    plt.title(f'LSTM-GAT Model Predicted vs Actual Consumption for Node {node_index} (Last {last_hours} Hours)')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Not enough samples to plot the last {last_hours} hours.\")\n",
    "\n",
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_train_losses, label='Train Loss')\n",
    "plt.plot(best_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for LSTM-GAT Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e5886-f390-4bb7-8b99-a95e25c6acd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184822e-2d1c-4c5f-8824-d5e54c7a725a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124177ab-f6d4-4f59-823a-7efc83d7779d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8e8bb-e8ad-4bdc-93d8-78ff6c286176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11dfeca-e0e8-4468-821a-29a746bab0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16658623-f2ca-4791-9d2b-af5d5d03daf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239861e-afdf-4c75-ba12-08eb2fd8d0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe911ef-0781-40f5-901d-f06da7d0b6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee5caa-6455-4ef1-b699-61099c627fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioyhiuggtcykjk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88efaf65-4b31-4381-bc3c-b60c2e07d2bf",
   "metadata": {},
   "source": [
    "## LSTM-GAT + skip con + LSTM-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31b7236-fbd8-4015-846e-ad1206e08e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, ParameterSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model\n",
    "class LSTM_GAT_Model(nn.Module):\n",
    "    def __init__(self, static_input_dim, lstm_input_dim, lstm_hidden_dim, lstm_num_layers, gat_input_dim, gat_hidden_dim, num_heads, combined_dim, output_dim, lstm_dropout=0.3, gat_dropout=0.3):\n",
    "        super(LSTM_GAT_Model, self).__init__()\n",
    "\n",
    "        # LSTM for time series features\n",
    "        self.lstm = nn.LSTM(lstm_input_dim, lstm_hidden_dim, lstm_num_layers, batch_first=True, dropout=lstm_dropout if lstm_num_layers > 1 else 0.0)\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Linear(lstm_hidden_dim, 1)\n",
    "\n",
    "        # Fully connected layer to combine LSTM output with static features\n",
    "        self.fc1 = nn.Linear(lstm_hidden_dim + static_input_dim, gat_input_dim)\n",
    "        self.dropout1 = nn.Dropout(lstm_dropout)\n",
    "\n",
    "        # GAT for combined features\n",
    "        self.gat = pyg_nn.GATConv(gat_input_dim, gat_hidden_dim, heads=num_heads)\n",
    "        self.dropout2 = nn.Dropout(gat_dropout)\n",
    "\n",
    "        # Fully connected layer for final output\n",
    "        self.fc2 = nn.Linear(gat_hidden_dim * num_heads + gat_input_dim, combined_dim)  # Adjusted for skip connection\n",
    "        self.fc3 = nn.Linear(combined_dim, output_dim)\n",
    "\n",
    "    def forward(self, data, sequences):\n",
    "        sequences = sequences.to(device)\n",
    "        data = data.to(device)\n",
    "\n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(sequences)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attn_weights = F.softmax(self.attention(lstm_out), dim=1)\n",
    "        attn_out = torch.sum(lstm_out * attn_weights, dim=1)  # Weighted sum of LSTM outputs\n",
    "\n",
    "        # Ensure data.x has the correct shape and expand it to match the batch size\n",
    "        static_features = data.x.unsqueeze(0).expand(sequences.size(0), -1, -1)  # (batch_size, num_nodes, static_input_dim)\n",
    "\n",
    "        # Combine LSTM output with static features\n",
    "        attn_out_expanded = attn_out.unsqueeze(1).expand(-1, static_features.size(1), -1)  # (batch_size, num_nodes, lstm_hidden_dim)\n",
    "        combined_features = torch.cat([attn_out_expanded, static_features], dim=2)  # Concatenate along the feature dimension\n",
    "\n",
    "        # Fully connected layer to reduce dimension\n",
    "        combined_features = combined_features.view(-1, combined_features.size(2))  # Flatten batch and num_nodes dimensions\n",
    "        combined_features = self.fc1(combined_features)\n",
    "        combined_features = self.dropout1(combined_features)\n",
    "\n",
    "        # GAT forward pass\n",
    "        gat_out = self.gat(combined_features, data.edge_index, data.edge_attr)\n",
    "        gat_out = self.dropout2(gat_out)\n",
    "\n",
    "        # Combine GAT outputs with the original combined features (skip connection)\n",
    "        combined_gat = torch.cat([gat_out, combined_features], dim=1)\n",
    "\n",
    "        # Fully connected layers for final output\n",
    "        combined_gat = self.fc2(combined_gat)\n",
    "        output = self.fc3(combined_gat)\n",
    "\n",
    "        output = output.view(sequences.size(0), -1, self.fc3.out_features)  # Reshape to (batch_size, num_nodes, output_dim)\n",
    "        return output  # Return node-specific outputs\n",
    "\n",
    "# Compute metrics\n",
    "def compute_metrics(output, target, criterion):\n",
    "    mse = criterion(output, target).item()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = torch.mean(torch.abs(output - target)).item()\n",
    "    mape = torch.mean(torch.abs((output - target) / (target + 1e-5))).item() * 100\n",
    "    return mse, rmse, mae, mape\n",
    "\n",
    "# Hyperparameter space for random search\n",
    "param_distributions = {\n",
    "    'lstm_hidden_dim': [64, 128, 256],\n",
    "    'lstm_num_layers': [1, 2, 3],\n",
    "    'gat_hidden_dim': [32, 64, 128],\n",
    "    'num_heads': [4, 8, 16],\n",
    "    'combined_dim': [64, 128, 256],\n",
    "    'lstm_dropout': [0.1, 0.2, 0.3],\n",
    "    'gat_dropout': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "    'weight_decay': [1e-4, 5e-4, 1e-3]\n",
    "}\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define test_loader outside the function\n",
    "test_loader = DataLoader(TensorDataset(test_sequences_tensor, test_targets_tensor), batch_size=48, shuffle=False)\n",
    "\n",
    "# Training and evaluation function with cross-validation\n",
    "def cross_val_evaluate(param_sample, graph_data):\n",
    "    lstm_hidden_dim = param_sample['lstm_hidden_dim']\n",
    "    lstm_num_layers = param_sample['lstm_num_layers']\n",
    "    gat_hidden_dim = param_sample['gat_hidden_dim']\n",
    "    num_heads = param_sample['num_heads']\n",
    "    combined_dim = param_sample['combined_dim']\n",
    "    lstm_dropout = param_sample['lstm_dropout']\n",
    "    gat_dropout = param_sample['gat_dropout']\n",
    "    learning_rate = param_sample['learning_rate']\n",
    "    weight_decay = param_sample['weight_decay']\n",
    "\n",
    "    model = LSTM_GAT_Model(\n",
    "        static_input_dim=8,\n",
    "        lstm_input_dim=27,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        gat_input_dim=lstm_hidden_dim + 8,  # Corrected static_input_dim here\n",
    "        gat_hidden_dim=gat_hidden_dim,\n",
    "        num_heads=num_heads,\n",
    "        combined_dim=combined_dim,\n",
    "        output_dim=1,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "        gat_dropout=gat_dropout\n",
    "    ).to(device)  # Move model to device\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "    num_epochs = 100\n",
    "    batch_size = 48\n",
    "    early_stopping_patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    aggregated_metrics = {'mse': [], 'rmse': [], 'mae': [], 'mape': [], 'r2': []}\n",
    "\n",
    "    for train_index, val_index in kf.split(train_sequences_tensor):\n",
    "        train_sequences, val_sequences = train_sequences_tensor[train_index].to(device), train_sequences_tensor[val_index].to(device)\n",
    "        train_targets, val_targets = train_targets_tensor[train_index].to(device), train_targets_tensor[val_index].to(device)\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(train_sequences, train_targets), batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(TensorDataset(val_sequences, val_targets), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Lists to store losses\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for sequences, targets in train_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                loss = criterion(output, targets_expanded)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for sequences, targets in val_loader:\n",
    "                    sequences, targets = sequences.to(device), targets.to(device)\n",
    "                    output = model(graph_data, sequences)\n",
    "\n",
    "                    # Ensure the target shape matches the output shape\n",
    "                    targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                    loss = criterion(output, targets_expanded)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            logging.info(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "            # Learning rate scheduling\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= early_stopping_patience:\n",
    "                    logging.info('Early stopping triggered')\n",
    "                    break\n",
    "\n",
    "        # Load the best model\n",
    "        model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "        # Validation evaluation\n",
    "        model.eval()\n",
    "        val_mse, val_rmse, val_mae, val_mape = 0, 0, 0, 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                mse, rmse, mae, mape = compute_metrics(output, targets_expanded, criterion)\n",
    "                val_mse += mse\n",
    "                val_rmse += rmse\n",
    "                val_mae += mae\n",
    "                val_mape += mape\n",
    "\n",
    "                all_predictions.append(output.cpu().numpy())\n",
    "                all_targets.append(targets_expanded.cpu().numpy())\n",
    "\n",
    "        # Compute overall R-squared\n",
    "        all_predictions = np.vstack(all_predictions)\n",
    "        all_targets = np.vstack(all_targets)\n",
    "\n",
    "        # Flatten the arrays to 2D for r2_score computation\n",
    "        all_predictions_flat = all_predictions.reshape(-1, 1)\n",
    "        all_targets_flat = all_targets.reshape(-1, 1)\n",
    "\n",
    "        val_r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "\n",
    "        val_mse /= len(val_loader)\n",
    "        val_rmse /= len(val_loader)\n",
    "        val_mae /= len(val_loader)\n",
    "        val_mape /= len(val_loader)\n",
    "\n",
    "        aggregated_metrics['mse'].append(val_mse)\n",
    "        aggregated_metrics['rmse'].append(val_rmse)\n",
    "        aggregated_metrics['mae'].append(val_mae)\n",
    "        aggregated_metrics['mape'].append(val_mape)\n",
    "        aggregated_metrics['r2'].append(val_r2)\n",
    "\n",
    "    avg_metrics = {metric: np.mean(aggregated_metrics[metric]) for metric in aggregated_metrics}\n",
    "    logging.info(f'Avg Validation Metrics: {avg_metrics}')\n",
    "\n",
    "    return avg_metrics\n",
    "\n",
    "# Random search for hyperparameter tuning\n",
    "param_samples = list(ParameterSampler(param_distributions, n_iter=20, random_state=42))\n",
    "best_score = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for param_sample in param_samples:\n",
    "    avg_metrics = cross_val_evaluate(param_sample, graph_data)\n",
    "    if avg_metrics['mse'] < best_score:\n",
    "        best_score = avg_metrics['mse']\n",
    "        best_params = param_sample\n",
    "\n",
    "print(f'Best Score: {best_score}')\n",
    "print(f'Best Parameters: {best_params}')\n",
    "\n",
    "# Train on the full training set with the best hyperparameters\n",
    "def train_on_full_train_set(best_params, graph_data):\n",
    "    lstm_hidden_dim = best_params['lstm_hidden_dim']\n",
    "    lstm_num_layers = best_params['lstm_num_layers']\n",
    "    gat_hidden_dim = best_params['gat_hidden_dim']\n",
    "    num_heads = best_params['num_heads']\n",
    "    combined_dim = best_params['combined_dim']\n",
    "    lstm_dropout = best_params['lstm_dropout']\n",
    "    gat_dropout = best_params['gat_dropout']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "    weight_decay = best_params['weight_decay']\n",
    "\n",
    "    model = LSTM_GAT_Model(\n",
    "        static_input_dim=8,\n",
    "        lstm_input_dim=27,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        gat_input_dim=lstm_hidden_dim + 8,  # Corrected static_input_dim here\n",
    "        gat_hidden_dim=gat_hidden_dim,\n",
    "        num_heads=num_heads,\n",
    "        combined_dim=combined_dim,\n",
    "        output_dim=1,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "        gat_dropout=gat_dropout\n",
    "    ).to(device)  # Move model to device\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "    num_epochs = 100\n",
    "    batch_size = 48\n",
    "    early_stopping_patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(train_sequences_tensor, train_targets_tensor), batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(TensorDataset(val_sequences_tensor, val_targets_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Lists to store losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, targets in train_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(graph_data, sequences)\n",
    "\n",
    "            # Ensure the target shape matches the output shape\n",
    "            targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "            loss = criterion(output, targets_expanded)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                loss = criterion(output, targets_expanded)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        logging.info(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), 'best_model_full_train.pth')\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= early_stopping_patience:\n",
    "                logging.info('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load('best_model_full_train.pth'))\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "best_model, best_train_losses, best_val_losses = train_on_full_train_set(best_params, graph_data)\n",
    "\n",
    "# Test evaluation\n",
    "def evaluate_on_test_set(model, graph_data, criterion):\n",
    "    model.eval()\n",
    "    test_mse, test_rmse, test_mae, test_mape = 0, 0, 0, 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in test_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            output = model(graph_data, sequences)\n",
    "\n",
    "            # Ensure the target shape matches the output shape\n",
    "            targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "            mse, rmse, mae, mape = compute_metrics(output, targets_expanded, criterion)\n",
    "            test_mse += mse\n",
    "            test_rmse += rmse\n",
    "            test_mae += mae\n",
    "            test_mape += mape\n",
    "\n",
    "            all_predictions.append(output.cpu().numpy())\n",
    "            all_targets.append(targets_expanded.cpu().numpy())\n",
    "\n",
    "    # Compute overall R-squared\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "\n",
    "    # Flatten the arrays to 2D for r2_score computation\n",
    "    all_predictions_flat = all_predictions.reshape(-1, 1)\n",
    "    all_targets_flat = all_targets.reshape(-1, 1)\n",
    "\n",
    "    test_r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "\n",
    "    test_mse /= len(test_loader)\n",
    "    test_rmse /= len(test_loader)\n",
    "    test_mae /= len(test_loader)\n",
    "    test_mape /= len(test_loader)\n",
    "\n",
    "    logging.info(f'Test MSE: {test_mse}, Test RMSE: {test_rmse}, Test MAE: {test_mae}, Test MAPE: {test_mape}, Test R2: {test_r2}')\n",
    "\n",
    "    return (test_mse, test_rmse, test_mae, test_mape, test_r2), all_predictions, all_targets\n",
    "\n",
    "# Pass criterion as an argument\n",
    "test_metrics, test_predictions, test_targets = evaluate_on_test_set(best_model, graph_data, nn.MSELoss())\n",
    "\n",
    "# Debugging prints\n",
    "print(f'Test Metrics: {test_metrics}')\n",
    "print(\"Shape of test_predictions:\", test_predictions.shape)\n",
    "print(\"Shape of test_targets:\", test_targets.shape)\n",
    "\n",
    "# Plotting the predictions vs. actual values for the last 24 hours\n",
    "last_hours = 24\n",
    "\n",
    "if test_predictions.shape[0] >= last_hours and test_targets.shape[0] >= last_hours:\n",
    "    last_predictions = test_predictions[-last_hours:, :]\n",
    "    last_targets = test_targets[-last_hours:, :]\n",
    "    node_index = 24\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(last_targets[:, node_index], label=f'Actual Node {node_index}')\n",
    "    plt.plot(last_predictions[:, node_index], label=f'Predicted Node {node_index}', linestyle='dashed')\n",
    "\n",
    "    plt.xlabel('Time-Step')\n",
    "    plt.ylabel('Consumption')\n",
    "    plt.title(f'LSTM-GAT Model Predicted vs Actual Consumption for Node {node_index} (Last {last_hours} Hours)')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Not enough samples to plot the last {last_hours} hours.\")\n",
    "\n",
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_train_losses, label='Train Loss')\n",
    "plt.plot(best_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for LSTM-GAT Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af166672-4083-45b4-af6a-314ee92957ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c19b2b-2e30-40d7-bc3a-fb3706c5e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging prints\n",
    "print(\"Shape of test_predictions:\", test_predictions.shape)\n",
    "print(\"Shape of test_targets:\", test_targets.shape)\n",
    "\n",
    "# Plotting the predictions vs. actual values for a specific 24-hour range for all nodes\n",
    "range_hours = 24\n",
    "\n",
    "# Ensure there are enough samples for the specified range\n",
    "if test_predictions.shape[0] >= range_hours and test_targets.shape[0] >= range_hours:\n",
    "    # Select any 24-hour range\n",
    "    range_start = 0  # Change this to specify different starting points\n",
    "    range_end = range_start + range_hours\n",
    "\n",
    "    selected_predictions = test_predictions[range_start:range_end, :]\n",
    "    selected_targets = test_targets[range_start:range_end, :]\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "    for node_index in range(selected_predictions.shape[1]):\n",
    "        ax.plot(selected_targets[:, node_index], label='Actual Consumption' if node_index == 0 else \"\", color='blue', alpha=0.5)\n",
    "        ax.plot(selected_predictions[:, node_index], label='Predicted Consumption' if node_index == 0 else \"\", linestyle='dashed', color='orange', alpha=0.5)\n",
    "    \n",
    "    ax.set_title(f'Actual vs Predicted Consumption for All Nodes ({range_hours}-Hour Range)')\n",
    "    ax.set_xlabel('Time-Step')\n",
    "    ax.set_ylabel('Consumption (MW)')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Not enough samples to plot the {range_hours}-hour range.\")\n",
    "\n",
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_train_losses, label='Train Loss')\n",
    "plt.plot(best_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for LSTM-GAT Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af95e83-2358-4613-b908-b42e62e82caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a9a43-53cc-4265-8e15-a3df2dcbf624",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmmnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d468403-ecb5-4a69-987f-9834434bd865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3225130e-0d05-42ad-b77d-d3202eb37a3c",
   "metadata": {},
   "source": [
    "## LSTM-GAT (no skip connection and LSTM attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc57aa8a-eacf-4837-b4cd-69908319945f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, ParameterSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model\n",
    "class LSTM_GAT_Model(nn.Module):\n",
    "    def __init__(self, static_input_dim, lstm_input_dim, lstm_hidden_dim, lstm_num_layers, gat_input_dim, gat_hidden_dim, num_heads, combined_dim, output_dim, lstm_dropout=0.3, gat_dropout=0.3):\n",
    "        super(LSTM_GAT_Model, self).__init__()\n",
    "\n",
    "        # LSTM for time series features\n",
    "        self.lstm = nn.LSTM(lstm_input_dim, lstm_hidden_dim, lstm_num_layers, batch_first=True, dropout=lstm_dropout if lstm_num_layers > 1 else 0.0)\n",
    "\n",
    "        # Fully connected layer to combine LSTM output with static features\n",
    "        self.fc1 = nn.Linear(lstm_hidden_dim + static_input_dim, gat_input_dim)\n",
    "        self.dropout1 = nn.Dropout(lstm_dropout)\n",
    "\n",
    "        # GAT for combined features\n",
    "        self.gat = pyg_nn.GATConv(gat_input_dim, gat_hidden_dim, heads=num_heads)\n",
    "        self.dropout2 = nn.Dropout(gat_dropout)\n",
    "\n",
    "        # Fully connected layer for final output\n",
    "        self.fc2 = nn.Linear(gat_hidden_dim * num_heads, combined_dim)  # Adjusted for removing skip connection\n",
    "        self.fc3 = nn.Linear(combined_dim, output_dim)\n",
    "\n",
    "    def forward(self, data, sequences):\n",
    "        sequences = sequences.to(device)\n",
    "        data = data.to(device)\n",
    "\n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(sequences)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Take the last output of LSTM\n",
    "\n",
    "        # Ensure data.x has the correct shape and expand it to match the batch size\n",
    "        static_features = data.x.unsqueeze(0).expand(sequences.size(0), -1, -1)  # (batch_size, num_nodes, static_input_dim)\n",
    "\n",
    "        # Combine LSTM output with static features\n",
    "        lstm_out_expanded = lstm_out.unsqueeze(1).expand(-1, static_features.size(1), -1)  # (batch_size, num_nodes, lstm_hidden_dim)\n",
    "        combined_features = torch.cat([lstm_out_expanded, static_features], dim=2)  # Concatenate along the feature dimension\n",
    "\n",
    "        # Fully connected layer to reduce dimension\n",
    "        combined_features = combined_features.view(-1, combined_features.size(2))  # Flatten batch and num_nodes dimensions\n",
    "        combined_features = self.fc1(combined_features)\n",
    "        combined_features = self.dropout1(combined_features)\n",
    "\n",
    "        # GAT forward pass\n",
    "        gat_out = self.gat(combined_features, data.edge_index, data.edge_attr)\n",
    "        gat_out = self.dropout2(gat_out)\n",
    "\n",
    "        # Fully connected layers for final output\n",
    "        combined_gat = self.fc2(gat_out)\n",
    "        output = self.fc3(combined_gat)\n",
    "\n",
    "        output = output.view(sequences.size(0), -1, self.fc3.out_features)  # Reshape to (batch_size, num_nodes, output_dim)\n",
    "        return output  # Return node-specific outputs\n",
    "\n",
    "# Compute metrics\n",
    "def compute_metrics(output, target, criterion):\n",
    "    mse = criterion(output, target).item()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = torch.mean(torch.abs(output - target)).item()\n",
    "    mape = torch.mean(torch.abs((output - target) / (target + 1e-5))).item() * 100\n",
    "    return mse, rmse, mae, mape\n",
    "\n",
    "# Hyperparameter space for random search\n",
    "param_distributions = {\n",
    "    'lstm_hidden_dim': [64, 128, 256],\n",
    "    'lstm_num_layers': [1, 2, 3],\n",
    "    'gat_hidden_dim': [32, 64, 128],\n",
    "    'num_heads': [4, 8, 16],\n",
    "    'combined_dim': [64, 128, 256],\n",
    "    'lstm_dropout': [0.1, 0.2, 0.3],\n",
    "    'gat_dropout': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "    'weight_decay': [1e-4, 5e-4, 1e-3]\n",
    "}\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define test_loader outside the function\n",
    "test_loader = DataLoader(TensorDataset(test_sequences_tensor, test_targets_tensor), batch_size=48, shuffle=False)\n",
    "\n",
    "# Training and evaluation function with cross-validation\n",
    "def cross_val_evaluate(param_sample, graph_data):\n",
    "    lstm_hidden_dim = param_sample['lstm_hidden_dim']\n",
    "    lstm_num_layers = param_sample['lstm_num_layers']\n",
    "    gat_hidden_dim = param_sample['gat_hidden_dim']\n",
    "    num_heads = param_sample['num_heads']\n",
    "    combined_dim = param_sample['combined_dim']\n",
    "    lstm_dropout = param_sample['lstm_dropout']\n",
    "    gat_dropout = param_sample['gat_dropout']\n",
    "    learning_rate = param_sample['learning_rate']\n",
    "    weight_decay = param_sample['weight_decay']\n",
    "\n",
    "    model = LSTM_GAT_Model(\n",
    "        static_input_dim=8,\n",
    "        lstm_input_dim=27,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        gat_input_dim=lstm_hidden_dim + 8,  # Corrected static_input_dim here\n",
    "        gat_hidden_dim=gat_hidden_dim,\n",
    "        num_heads=num_heads,\n",
    "        combined_dim=combined_dim,\n",
    "        output_dim=1,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "        gat_dropout=gat_dropout\n",
    "    ).to(device)  # Move model to device\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "    num_epochs = 100\n",
    "    batch_size = 48\n",
    "    early_stopping_patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    aggregated_metrics = {'mse': [], 'rmse': [], 'mae': [], 'mape': [], 'r2': []}\n",
    "\n",
    "    for train_index, val_index in kf.split(train_sequences_tensor):\n",
    "        train_sequences, val_sequences = train_sequences_tensor[train_index].to(device), train_sequences_tensor[val_index].to(device)\n",
    "        train_targets, val_targets = train_targets_tensor[train_index].to(device), train_targets_tensor[val_index].to(device)\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(train_sequences, train_targets), batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(TensorDataset(val_sequences, val_targets), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Lists to store losses\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for sequences, targets in train_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                loss = criterion(output, targets_expanded)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for sequences, targets in val_loader:\n",
    "                    sequences, targets = sequences.to(device), targets.to(device)\n",
    "                    output = model(graph_data, sequences)\n",
    "\n",
    "                    # Ensure the target shape matches the output shape\n",
    "                    targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                    loss = criterion(output, targets_expanded)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            logging.info(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "            # Learning rate scheduling\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= early_stopping_patience:\n",
    "                    logging.info('Early stopping triggered')\n",
    "                    break\n",
    "\n",
    "        # Load the best model\n",
    "        model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "        # Validation evaluation\n",
    "        model.eval()\n",
    "        val_mse, val_rmse, val_mae, val_mape = 0, 0, 0, 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                mse, rmse, mae, mape = compute_metrics(output, targets_expanded, criterion)\n",
    "                val_mse += mse\n",
    "                val_rmse += rmse\n",
    "                val_mae += mae\n",
    "                val_mape += mape\n",
    "\n",
    "                all_predictions.append(output.cpu().numpy())\n",
    "                all_targets.append(targets_expanded.cpu().numpy())\n",
    "\n",
    "        # Compute overall R-squared\n",
    "        all_predictions = np.vstack(all_predictions)\n",
    "        all_targets = np.vstack(all_targets)\n",
    "\n",
    "        # Flatten the arrays to 2D for r2_score computation\n",
    "        all_predictions_flat = all_predictions.reshape(-1, 1)\n",
    "        all_targets_flat = all_targets.reshape(-1, 1)\n",
    "\n",
    "        val_r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "\n",
    "        val_mse /= len(val_loader)\n",
    "        val_rmse /= len(val_loader)\n",
    "        val_mae /= len(val_loader)\n",
    "        val_mape /= len(val_loader)\n",
    "\n",
    "        aggregated_metrics['mse'].append(val_mse)\n",
    "        aggregated_metrics['rmse'].append(val_rmse)\n",
    "        aggregated_metrics['mae'].append(val_mae)\n",
    "        aggregated_metrics['mape'].append(val_mape)\n",
    "        aggregated_metrics['r2'].append(val_r2)\n",
    "\n",
    "    avg_metrics = {metric: np.mean(aggregated_metrics[metric]) for metric in aggregated_metrics}\n",
    "    logging.info(f'Avg Validation Metrics: {avg_metrics}')\n",
    "\n",
    "    return avg_metrics\n",
    "\n",
    "# Random search for hyperparameter tuning\n",
    "param_samples = list(ParameterSampler(param_distributions, n_iter=20, random_state=42))\n",
    "best_score = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for param_sample in param_samples:\n",
    "    avg_metrics = cross_val_evaluate(param_sample, graph_data)\n",
    "    if avg_metrics['mse'] < best_score:\n",
    "        best_score = avg_metrics['mse']\n",
    "        best_params = param_sample\n",
    "\n",
    "print(f'Best Score: {best_score}')\n",
    "print(f'Best Parameters: {best_params}')\n",
    "\n",
    "# Train on the full training set with the best hyperparameters\n",
    "def train_on_full_train_set(best_params, graph_data):\n",
    "    lstm_hidden_dim = best_params['lstm_hidden_dim']\n",
    "    lstm_num_layers = best_params['lstm_num_layers']\n",
    "    gat_hidden_dim = best_params['gat_hidden_dim']\n",
    "    num_heads = best_params['num_heads']\n",
    "    combined_dim = best_params['combined_dim']\n",
    "    lstm_dropout = best_params['lstm_dropout']\n",
    "    gat_dropout = best_params['gat_dropout']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "    weight_decay = best_params['weight_decay']\n",
    "\n",
    "    model = LSTM_GAT_Model(\n",
    "        static_input_dim=8,\n",
    "        lstm_input_dim=27,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        gat_input_dim=lstm_hidden_dim + 8,  # Corrected static_input_dim here\n",
    "        gat_hidden_dim=gat_hidden_dim,\n",
    "        num_heads=num_heads,\n",
    "        combined_dim=combined_dim,\n",
    "        output_dim=1,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "        gat_dropout=gat_dropout\n",
    "    ).to(device)  # Move model to device\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "    num_epochs = 100\n",
    "    batch_size = 48\n",
    "    early_stopping_patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(train_sequences_tensor, train_targets_tensor), batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(TensorDataset(val_sequences_tensor, val_targets_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Lists to store losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, targets in train_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(graph_data, sequences)\n",
    "\n",
    "            # Ensure the target shape matches the output shape\n",
    "            targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "            loss = criterion(output, targets_expanded)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                loss = criterion(output, targets_expanded)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        logging.info(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), 'best_model_full_train.pth')\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= early_stopping_patience:\n",
    "                logging.info('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load('best_model_full_train.pth'))\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "best_model, best_train_losses, best_val_losses = train_on_full_train_set(best_params, graph_data)\n",
    "\n",
    "# Test evaluation\n",
    "def evaluate_on_test_set(model, graph_data, criterion):\n",
    "    model.eval()\n",
    "    test_mse, test_rmse, test_mae, test_mape = 0, 0, 0, 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in test_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            output = model(graph_data, sequences)\n",
    "\n",
    "            # Ensure the target shape matches the output shape\n",
    "            targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "            mse, rmse, mae, mape = compute_metrics(output, targets_expanded, criterion)\n",
    "            test_mse += mse\n",
    "            test_rmse += rmse\n",
    "            test_mae += mae\n",
    "            test_mape += mape\n",
    "\n",
    "            all_predictions.append(output.cpu().numpy())\n",
    "            all_targets.append(targets_expanded.cpu().numpy())\n",
    "\n",
    "    # Compute overall R-squared\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "\n",
    "    # Flatten the arrays to 2D for r2_score computation\n",
    "    all_predictions_flat = all_predictions.reshape(-1, 1)\n",
    "    all_targets_flat = all_targets.reshape(-1, 1)\n",
    "\n",
    "    test_r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "\n",
    "    test_mse /= len(test_loader)\n",
    "    test_rmse /= len(test_loader)\n",
    "    test_mae /= len(test_loader)\n",
    "    test_mape /= len(test_loader)\n",
    "\n",
    "    logging.info(f'Test MSE: {test_mse}, Test RMSE: {test_rmse}, Test MAE: {test_mae}, Test MAPE: {test_mape}, Test R2: {test_r2}')\n",
    "\n",
    "    return (test_mse, test_rmse, test_mae, test_mape, test_r2), all_predictions, all_targets\n",
    "\n",
    "# Pass criterion as an argument\n",
    "test_metrics, test_predictions, test_targets = evaluate_on_test_set(best_model, graph_data, nn.MSELoss())\n",
    "\n",
    "# Debugging prints\n",
    "print(f'Test Metrics: {test_metrics}')\n",
    "print(\"Shape of test_predictions:\", test_predictions.shape)\n",
    "print(\"Shape of test_targets:\", test_targets.shape)\n",
    "\n",
    "# Plotting the predictions vs. actual values for the last 24 hours\n",
    "last_hours = 24\n",
    "\n",
    "if test_predictions.shape[0] >= last_hours and test_targets.shape[0] >= last_hours:\n",
    "    last_predictions = test_predictions[-last_hours:, :]\n",
    "    last_targets = test_targets[-last_hours:, :]\n",
    "    node_index = 24\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(last_targets[:, node_index], label=f'Actual Node {node_index}')\n",
    "    plt.plot(last_predictions[:, node_index], label=f'Predicted Node {node_index}', linestyle='dashed')\n",
    "\n",
    "    plt.xlabel('Time-Step')\n",
    "    plt.ylabel('Consumption')\n",
    "    plt.title(f'LSTM-GAT Model Predicted vs Actual Consumption for Node {node_index} (Last {last_hours} Hours)')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Not enough samples to plot the last {last_hours} hours.\")\n",
    "\n",
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_train_losses, label='Train Loss')\n",
    "plt.plot(best_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for LSTM-GAT Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a1e72-3a4c-407f-a0b3-a72cfe7d5bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a25d74-b11a-4f2b-991d-ec6b0b3e17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging prints\n",
    "print(\"Shape of test_predictions:\", test_predictions.shape)\n",
    "print(\"Shape of test_targets:\", test_targets.shape)\n",
    "\n",
    "# Plotting the predictions vs. actual values for a specific 24-hour range for all nodes\n",
    "range_hours = 24\n",
    "\n",
    "# Ensure there are enough samples for the specified range\n",
    "if test_predictions.shape[0] >= range_hours and test_targets.shape[0] >= range_hours:\n",
    "    # Select any 24-hour range\n",
    "    range_start = 0  # Change this to specify different starting points\n",
    "    range_end = range_start + range_hours\n",
    "\n",
    "    selected_predictions = test_predictions[range_start:range_end, :]\n",
    "    selected_targets = test_targets[range_start:range_end, :]\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "    for node_index in range(selected_predictions.shape[1]):\n",
    "        ax.plot(selected_targets[:, node_index], label='Actual Consumption' if node_index == 0 else \"\", color='blue', alpha=0.5)\n",
    "        ax.plot(selected_predictions[:, node_index], label='Predicted Consumption' if node_index == 0 else \"\", linestyle='dashed', color='orange', alpha=0.5)\n",
    "    \n",
    "    ax.set_title(f'Actual vs Predicted Consumption for All Nodes ({range_hours}-Hour Range)')\n",
    "    ax.set_xlabel('Time-Step')\n",
    "    ax.set_ylabel('Consumption (MW)')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Not enough samples to plot the {range_hours}-hour range.\")\n",
    "\n",
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_train_losses, label='Train Loss')\n",
    "plt.plot(best_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for LSTM-GAT Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b9fe9-93fb-403a-ae8a-1363e8f609e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7aa0e9b-e77a-439d-ae79-2ef2ac4cb036",
   "metadata": {},
   "source": [
    "## LSTM-GAT + Skip connection (no LSTM attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c493f30a-0ef8-425d-931d-af153d49d161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227d278-f0ba-447c-b42b-3b317567fc37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, ParameterSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model\n",
    "class LSTM_GAT_Model(nn.Module):\n",
    "    def __init__(self, static_input_dim, lstm_input_dim, lstm_hidden_dim, lstm_num_layers, gat_input_dim, gat_hidden_dim, num_heads, combined_dim, output_dim, lstm_dropout=0.3, gat_dropout=0.3):\n",
    "        super(LSTM_GAT_Model, self).__init__()\n",
    "\n",
    "        # LSTM for time series features\n",
    "        self.lstm = nn.LSTM(lstm_input_dim, lstm_hidden_dim, lstm_num_layers, batch_first=True, dropout=lstm_dropout if lstm_num_layers > 1 else 0.0)\n",
    "\n",
    "        # Fully connected layer to combine LSTM output with static features\n",
    "        self.fc1 = nn.Linear(lstm_hidden_dim + static_input_dim, gat_input_dim)\n",
    "        self.dropout1 = nn.Dropout(lstm_dropout)\n",
    "\n",
    "        # GAT for combined features\n",
    "        self.gat = pyg_nn.GATConv(gat_input_dim, gat_hidden_dim, heads=num_heads)\n",
    "        self.dropout2 = nn.Dropout(gat_dropout)\n",
    "\n",
    "        # Fully connected layer for final output\n",
    "        self.fc2 = nn.Linear(gat_hidden_dim * num_heads + gat_input_dim, combined_dim)  # Adjusted for skip connection\n",
    "        self.fc3 = nn.Linear(combined_dim, output_dim)\n",
    "\n",
    "    def forward(self, data, sequences):\n",
    "        sequences = sequences.to(device)\n",
    "        data = data.to(device)\n",
    "\n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(sequences)\n",
    "        \n",
    "        # Use the last output of the LSTM directly\n",
    "        lstm_out_last = lstm_out[:, -1, :]\n",
    "\n",
    "        # Ensure data.x has the correct shape and expand it to match the batch size\n",
    "        static_features = data.x.unsqueeze(0).expand(sequences.size(0), -1, -1)  # (batch_size, num_nodes, static_input_dim)\n",
    "\n",
    "        # Combine LSTM output with static features\n",
    "        lstm_out_expanded = lstm_out_last.unsqueeze(1).expand(-1, static_features.size(1), -1)  # (batch_size, num_nodes, lstm_hidden_dim)\n",
    "        combined_features = torch.cat([lstm_out_expanded, static_features], dim=2)  # Concatenate along the feature dimension\n",
    "\n",
    "        # Fully connected layer to reduce dimension\n",
    "        combined_features = combined_features.view(-1, combined_features.size(2))  # Flatten batch and num_nodes dimensions\n",
    "        combined_features = self.fc1(combined_features)\n",
    "        combined_features = self.dropout1(combined_features)\n",
    "\n",
    "        # GAT forward pass\n",
    "        gat_out = self.gat(combined_features, data.edge_index, data.edge_attr)\n",
    "        gat_out = self.dropout2(gat_out)\n",
    "\n",
    "        # Combine GAT outputs with the original combined features (skip connection)\n",
    "        combined_gat = torch.cat([gat_out, combined_features], dim=1)\n",
    "\n",
    "        # Fully connected layers for final output\n",
    "        combined_gat = self.fc2(combined_gat)\n",
    "        output = self.fc3(combined_gat)\n",
    "\n",
    "        output = output.view(sequences.size(0), -1, self.fc3.out_features)  # Reshape to (batch_size, num_nodes, output_dim)\n",
    "        return output  # Return node-specific outputs\n",
    "\n",
    "# Compute metrics\n",
    "def compute_metrics(output, target, criterion):\n",
    "    mse = criterion(output, target).item()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = torch.mean(torch.abs(output - target)).item()\n",
    "    mape = torch.mean(torch.abs((output - target) / (target + 1e-5))).item() * 100\n",
    "    return mse, rmse, mae, mape\n",
    "\n",
    "# Hyperparameter space for random search\n",
    "param_distributions = {\n",
    "    'lstm_hidden_dim': [64, 128, 256],\n",
    "    'lstm_num_layers': [1, 2, 3],\n",
    "    'gat_hidden_dim': [32, 64, 128],\n",
    "    'num_heads': [4, 8, 16],\n",
    "    'combined_dim': [64, 128, 256],\n",
    "    'lstm_dropout': [0.1, 0.2, 0.3],\n",
    "    'gat_dropout': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "    'weight_decay': [1e-4, 5e-4, 1e-3]\n",
    "}\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define test_loader outside the function\n",
    "test_loader = DataLoader(TensorDataset(test_sequences_tensor, test_targets_tensor), batch_size=48, shuffle=False)\n",
    "\n",
    "# Training and evaluation function with cross-validation\n",
    "def cross_val_evaluate(param_sample, graph_data):\n",
    "    lstm_hidden_dim = param_sample['lstm_hidden_dim']\n",
    "    lstm_num_layers = param_sample['lstm_num_layers']\n",
    "    gat_hidden_dim = param_sample['gat_hidden_dim']\n",
    "    num_heads = param_sample['num_heads']\n",
    "    combined_dim = param_sample['combined_dim']\n",
    "    lstm_dropout = param_sample['lstm_dropout']\n",
    "    gat_dropout = param_sample['gat_dropout']\n",
    "    learning_rate = param_sample['learning_rate']\n",
    "    weight_decay = param_sample['weight_decay']\n",
    "\n",
    "    model = LSTM_GAT_Model(\n",
    "        static_input_dim=8,\n",
    "        lstm_input_dim=27,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        gat_input_dim=lstm_hidden_dim + 8,  # Corrected static_input_dim here\n",
    "        gat_hidden_dim=gat_hidden_dim,\n",
    "        num_heads=num_heads,\n",
    "        combined_dim=combined_dim,\n",
    "        output_dim=1,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "        gat_dropout=gat_dropout\n",
    "    ).to(device)  # Move model to device\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "    num_epochs = 100\n",
    "    batch_size = 48\n",
    "    early_stopping_patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    aggregated_metrics = {'mse': [], 'rmse': [], 'mae': [], 'mape': [], 'r2': []}\n",
    "\n",
    "    for train_index, val_index in kf.split(train_sequences_tensor):\n",
    "        train_sequences, val_sequences = train_sequences_tensor[train_index].to(device), train_sequences_tensor[val_index].to(device)\n",
    "        train_targets, val_targets = train_targets_tensor[train_index].to(device), train_targets_tensor[val_index].to(device)\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(train_sequences, train_targets), batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(TensorDataset(val_sequences, val_targets), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Lists to store losses\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for sequences, targets in train_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                loss = criterion(output, targets_expanded)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for sequences, targets in val_loader:\n",
    "                    sequences, targets = sequences.to(device), targets.to(device)\n",
    "                    output = model(graph_data, sequences)\n",
    "\n",
    "                    # Ensure the target shape matches the output shape\n",
    "                    targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                    loss = criterion(output, targets_expanded)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            logging.info(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "            # Learning rate scheduling\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= early_stopping_patience:\n",
    "                    logging.info('Early stopping triggered')\n",
    "                    break\n",
    "\n",
    "        # Load the best model\n",
    "        model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "        # Validation evaluation\n",
    "        model.eval()\n",
    "        val_mse, val_rmse, val_mae, val_mape = 0, 0, 0, 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                mse, rmse, mae, mape = compute_metrics(output, targets_expanded, criterion)\n",
    "                val_mse += mse\n",
    "                val_rmse += rmse\n",
    "                val_mae += mae\n",
    "                val_mape += mape\n",
    "\n",
    "                all_predictions.append(output.cpu().numpy())\n",
    "                all_targets.append(targets_expanded.cpu().numpy())\n",
    "\n",
    "        # Compute overall R-squared\n",
    "        all_predictions = np.vstack(all_predictions)\n",
    "        all_targets = np.vstack(all_targets)\n",
    "\n",
    "        # Flatten the arrays to 2D for r2_score computation\n",
    "        all_predictions_flat = all_predictions.reshape(-1, 1)\n",
    "        all_targets_flat = all_targets.reshape(-1, 1)\n",
    "\n",
    "        val_r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "\n",
    "        val_mse /= len(val_loader)\n",
    "        val_rmse /= len(val_loader)\n",
    "        val_mae /= len(val_loader)\n",
    "        val_mape /= len(val_loader)\n",
    "\n",
    "        aggregated_metrics['mse'].append(val_mse)\n",
    "        aggregated_metrics['rmse'].append(val_rmse)\n",
    "        aggregated_metrics['mae'].append(val_mae)\n",
    "        aggregated_metrics['mape'].append(val_mape)\n",
    "        aggregated_metrics['r2'].append(val_r2)\n",
    "\n",
    "    avg_metrics = {metric: np.mean(aggregated_metrics[metric]) for metric in aggregated_metrics}\n",
    "    logging.info(f'Avg Validation Metrics: {avg_metrics}')\n",
    "\n",
    "    return avg_metrics\n",
    "\n",
    "# Random search for hyperparameter tuning\n",
    "param_samples = list(ParameterSampler(param_distributions, n_iter=20, random_state=42))\n",
    "best_score = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for param_sample in param_samples:\n",
    "    avg_metrics = cross_val_evaluate(param_sample, graph_data)\n",
    "    if avg_metrics['mse'] < best_score:\n",
    "        best_score = avg_metrics['mse']\n",
    "        best_params = param_sample\n",
    "\n",
    "print(f'Best Score: {best_score}')\n",
    "print(f'Best Parameters: {best_params}')\n",
    "\n",
    "# Train on the full training set with the best hyperparameters\n",
    "def train_on_full_train_set(best_params, graph_data):\n",
    "    lstm_hidden_dim = best_params['lstm_hidden_dim']\n",
    "    lstm_num_layers = best_params['lstm_num_layers']\n",
    "    gat_hidden_dim = best_params['gat_hidden_dim']\n",
    "    num_heads = best_params['num_heads']\n",
    "    combined_dim = best_params['combined_dim']\n",
    "    lstm_dropout = best_params['lstm_dropout']\n",
    "    gat_dropout = best_params['gat_dropout']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "    weight_decay = best_params['weight_decay']\n",
    "\n",
    "    model = LSTM_GAT_Model(\n",
    "        static_input_dim=8,\n",
    "        lstm_input_dim=27,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        gat_input_dim=lstm_hidden_dim + 8,  # Corrected static_input_dim here\n",
    "        gat_hidden_dim=gat_hidden_dim,\n",
    "        num_heads=num_heads,\n",
    "        combined_dim=combined_dim,\n",
    "        output_dim=1,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "        gat_dropout=gat_dropout\n",
    "    ).to(device)  # Move model to device\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "    num_epochs = 100\n",
    "    batch_size = 48\n",
    "    early_stopping_patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(train_sequences_tensor, train_targets_tensor), batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(TensorDataset(val_sequences_tensor, val_targets_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Lists to store losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, targets in train_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(graph_data, sequences)\n",
    "\n",
    "            # Ensure the target shape matches the output shape\n",
    "            targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "            loss = criterion(output, targets_expanded)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                loss = criterion(output, targets_expanded)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        logging.info(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), 'best_model_full_train.pth')\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= early_stopping_patience:\n",
    "                logging.info('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load('best_model_full_train.pth'))\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "best_model, best_train_losses, best_val_losses = train_on_full_train_set(best_params, graph_data)\n",
    "\n",
    "# Test evaluation\n",
    "def evaluate_on_test_set(model, graph_data, criterion):\n",
    "    model.eval()\n",
    "    test_mse, test_rmse, test_mae, test_mape = 0, 0, 0, 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in test_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            output = model(graph_data, sequences)\n",
    "\n",
    "            # Ensure the target shape matches the output shape\n",
    "            targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "            mse, rmse, mae, mape = compute_metrics(output, targets_expanded, criterion)\n",
    "            test_mse += mse\n",
    "            test_rmse += rmse\n",
    "            test_mae += mae\n",
    "            test_mape += mape\n",
    "\n",
    "            all_predictions.append(output.cpu().numpy())\n",
    "            all_targets.append(targets_expanded.cpu().numpy())\n",
    "\n",
    "    # Compute overall R-squared\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "\n",
    "    # Flatten the arrays to 2D for r2_score computation\n",
    "    all_predictions_flat = all_predictions.reshape(-1, 1)\n",
    "    all_targets_flat = all_targets.reshape(-1, 1)\n",
    "\n",
    "    test_r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "\n",
    "    test_mse /= len(test_loader)\n",
    "    test_rmse /= len(test_loader)\n",
    "    test_mae /= len(test_loader)\n",
    "    test_mape /= len(test_loader)\n",
    "\n",
    "    logging.info(f'Test MSE: {test_mse}, Test RMSE: {test_rmse}, Test MAE: {test_mae}, Test MAPE: {test_mape}, Test R2: {test_r2}')\n",
    "\n",
    "    return (test_mse, test_rmse, test_mae, test_mape, test_r2), all_predictions, all_targets\n",
    "\n",
    "# Pass criterion as an argument\n",
    "test_metrics, test_predictions, test_targets = evaluate_on_test_set(best_model, graph_data, nn.MSELoss())\n",
    "\n",
    "# Debugging prints\n",
    "print(f'Test Metrics: {test_metrics}')\n",
    "print(\"Shape of test_predictions:\", test_predictions.shape)\n",
    "print(\"Shape of test_targets:\", test_targets.shape)\n",
    "\n",
    "# Plotting the predictions vs. actual values for the last 24 hours\n",
    "last_hours = 24\n",
    "\n",
    "if test_predictions.shape[0] >= last_hours and test_targets.shape[0] >= last_hours:\n",
    "    last_predictions = test_predictions[-last_hours:, :]\n",
    "    last_targets = test_targets[-last_hours:, :]\n",
    "    node_index = 24\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(last_targets[:, node_index], label=f'Actual Node {node_index}')\n",
    "    plt.plot(last_predictions[:, node_index], label=f'Predicted Node {node_index}', linestyle='dashed')\n",
    "\n",
    "    plt.xlabel('Time-Step')\n",
    "    plt.ylabel('Consumption')\n",
    "    plt.title(f'LSTM-GAT Model Predicted vs Actual Consumption for Node {node_index} (Last {last_hours} Hours)')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Not enough samples to plot the last {last_hours} hours.\")\n",
    "\n",
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_train_losses, label='Train Loss')\n",
    "plt.plot(best_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for LSTM-GAT Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75739df1-dcfd-441e-871c-9047afdb4691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951952cf-b534-4a6c-85a7-ceb1fb7d582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging prints\n",
    "print(\"Shape of test_predictions:\", test_predictions.shape)\n",
    "print(\"Shape of test_targets:\", test_targets.shape)\n",
    "\n",
    "# Plotting the predictions vs. actual values for a specific 24-hour range for all nodes\n",
    "range_hours = 24\n",
    "\n",
    "# Ensure there are enough samples for the specified range\n",
    "if test_predictions.shape[0] >= range_hours and test_targets.shape[0] >= range_hours:\n",
    "    # Select any 24-hour range\n",
    "    range_start = 0  # Change this to specify different starting points\n",
    "    range_end = range_start + range_hours\n",
    "\n",
    "    selected_predictions = test_predictions[range_start:range_end, :]\n",
    "    selected_targets = test_targets[range_start:range_end, :]\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "    for node_index in range(selected_predictions.shape[1]):\n",
    "        ax.plot(selected_targets[:, node_index], label='Actual Consumption' if node_index == 0 else \"\", color='blue', alpha=0.5)\n",
    "        ax.plot(selected_predictions[:, node_index], label='Predicted Consumption' if node_index == 0 else \"\", linestyle='dashed', color='orange', alpha=0.5)\n",
    "    \n",
    "    ax.set_title(f'Actual vs Predicted Consumption for All Nodes ({range_hours}-Hour Range)')\n",
    "    ax.set_xlabel('Time-Step')\n",
    "    ax.set_ylabel('Consumption (MW)')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Not enough samples to plot the {range_hours}-hour range.\")\n",
    "\n",
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_train_losses, label='Train Loss')\n",
    "plt.plot(best_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for LSTM-GAT Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bca69e-d988-4398-918a-b18d324a8706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d52093-509d-441e-8ada-abe7b5f318cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78c45a39-9f91-4978-90b3-95c4f9ee9899",
   "metadata": {},
   "source": [
    "## LSTM-GAT-LSTM attention (no skip connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1209cb69-6882-497d-8037-8ab2ff26bca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bad972-78c4-419d-80a1-43f0133cd7e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, ParameterSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model\n",
    "class LSTM_GAT_Model(nn.Module):\n",
    "    def __init__(self, static_input_dim, lstm_input_dim, lstm_hidden_dim, lstm_num_layers, gat_input_dim, gat_hidden_dim, num_heads, combined_dim, output_dim, lstm_dropout=0.3, gat_dropout=0.3):\n",
    "        super(LSTM_GAT_Model, self).__init__()\n",
    "\n",
    "        # LSTM for time series features\n",
    "        self.lstm = nn.LSTM(lstm_input_dim, lstm_hidden_dim, lstm_num_layers, batch_first=True, dropout=lstm_dropout if lstm_num_layers > 1 else 0.0)\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Linear(lstm_hidden_dim, 1)\n",
    "\n",
    "        # Fully connected layer to combine LSTM output with static features\n",
    "        self.fc1 = nn.Linear(lstm_hidden_dim + static_input_dim, gat_input_dim)\n",
    "        self.dropout1 = nn.Dropout(lstm_dropout)\n",
    "\n",
    "        # GAT for combined features\n",
    "        self.gat = pyg_nn.GATConv(gat_input_dim, gat_hidden_dim, heads=num_heads)\n",
    "        self.dropout2 = nn.Dropout(gat_dropout)\n",
    "\n",
    "        # Fully connected layer for final output\n",
    "        self.fc2 = nn.Linear(gat_hidden_dim * num_heads, combined_dim)\n",
    "        self.fc3 = nn.Linear(combined_dim, output_dim)\n",
    "\n",
    "    def forward(self, data, sequences):\n",
    "        sequences = sequences.to(device)\n",
    "        data = data.to(device)\n",
    "\n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(sequences)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attn_weights = F.softmax(self.attention(lstm_out), dim=1)\n",
    "        attn_out = torch.sum(lstm_out * attn_weights, dim=1)  # Weighted sum of LSTM outputs\n",
    "\n",
    "        # Ensure data.x has the correct shape and expand it to match the batch size\n",
    "        static_features = data.x.unsqueeze(0).expand(sequences.size(0), -1, -1)  # (batch_size, num_nodes, static_input_dim)\n",
    "\n",
    "        # Combine LSTM output with static features\n",
    "        attn_out_expanded = attn_out.unsqueeze(1).expand(-1, static_features.size(1), -1)  # (batch_size, num_nodes, lstm_hidden_dim)\n",
    "        combined_features = torch.cat([attn_out_expanded, static_features], dim=2)  # Concatenate along the feature dimension\n",
    "\n",
    "        # Fully connected layer to reduce dimension\n",
    "        combined_features = combined_features.view(-1, combined_features.size(2))  # Flatten batch and num_nodes dimensions\n",
    "        combined_features = self.fc1(combined_features)\n",
    "        combined_features = self.dropout1(combined_features)\n",
    "\n",
    "        # GAT forward pass\n",
    "        gat_out = self.gat(combined_features, data.edge_index, data.edge_attr)\n",
    "        gat_out = self.dropout2(gat_out)\n",
    "\n",
    "        # Fully connected layers for final output\n",
    "        combined_gat = self.fc2(gat_out)\n",
    "        output = self.fc3(combined_gat)\n",
    "\n",
    "        output = output.view(sequences.size(0), -1, self.fc3.out_features)  # Reshape to (batch_size, num_nodes, output_dim)\n",
    "        return output  # Return node-specific outputs\n",
    "\n",
    "# Compute metrics\n",
    "def compute_metrics(output, target, criterion):\n",
    "    mse = criterion(output, target).item()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = torch.mean(torch.abs(output - target)).item()\n",
    "    mape = torch.mean(torch.abs((output - target) / (target + 1e-5))).item() * 100\n",
    "    return mse, rmse, mae, mape\n",
    "\n",
    "# Hyperparameter space for random search\n",
    "param_distributions = {\n",
    "    'lstm_hidden_dim': [64, 128, 256],\n",
    "    'lstm_num_layers': [1, 2, 3],\n",
    "    'gat_hidden_dim': [32, 64, 128],\n",
    "    'num_heads': [4, 8, 16],\n",
    "    'combined_dim': [64, 128, 256],\n",
    "    'lstm_dropout': [0.1, 0.2, 0.3],\n",
    "    'gat_dropout': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "    'weight_decay': [1e-4, 5e-4, 1e-3]\n",
    "}\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define test_loader outside the function\n",
    "test_loader = DataLoader(TensorDataset(test_sequences_tensor, test_targets_tensor), batch_size=48, shuffle=False)\n",
    "\n",
    "# Training and evaluation function with cross-validation\n",
    "def cross_val_evaluate(param_sample, graph_data):\n",
    "    lstm_hidden_dim = param_sample['lstm_hidden_dim']\n",
    "    lstm_num_layers = param_sample['lstm_num_layers']\n",
    "    gat_hidden_dim = param_sample['gat_hidden_dim']\n",
    "    num_heads = param_sample['num_heads']\n",
    "    combined_dim = param_sample['combined_dim']\n",
    "    lstm_dropout = param_sample['lstm_dropout']\n",
    "    gat_dropout = param_sample['gat_dropout']\n",
    "    learning_rate = param_sample['learning_rate']\n",
    "    weight_decay = param_sample['weight_decay']\n",
    "\n",
    "    model = LSTM_GAT_Model(\n",
    "        static_input_dim=8,\n",
    "        lstm_input_dim=27,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        gat_input_dim=lstm_hidden_dim + 8,  # Corrected static_input_dim here\n",
    "        gat_hidden_dim=gat_hidden_dim,\n",
    "        num_heads=num_heads,\n",
    "        combined_dim=combined_dim,\n",
    "        output_dim=1,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "        gat_dropout=gat_dropout\n",
    "    ).to(device)  # Move model to device\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "    num_epochs = 100\n",
    "    batch_size = 48\n",
    "    early_stopping_patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    aggregated_metrics = {'mse': [], 'rmse': [], 'mae': [], 'mape': [], 'r2': []}\n",
    "\n",
    "    for train_index, val_index in kf.split(train_sequences_tensor):\n",
    "        train_sequences, val_sequences = train_sequences_tensor[train_index].to(device), train_sequences_tensor[val_index].to(device)\n",
    "        train_targets, val_targets = train_targets_tensor[train_index].to(device), train_targets_tensor[val_index].to(device)\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(train_sequences, train_targets), batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(TensorDataset(val_sequences, val_targets), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Lists to store losses\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for sequences, targets in train_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                loss = criterion(output, targets_expanded)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for sequences, targets in val_loader:\n",
    "                    sequences, targets = sequences.to(device), targets.to(device)\n",
    "                    output = model(graph_data, sequences)\n",
    "\n",
    "                    # Ensure the target shape matches the output shape\n",
    "                    targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                    loss = criterion(output, targets_expanded)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            logging.info(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "            # Learning rate scheduling\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= early_stopping_patience:\n",
    "                    logging.info('Early stopping triggered')\n",
    "                    break\n",
    "\n",
    "        # Load the best model\n",
    "        model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "        # Validation evaluation\n",
    "        model.eval()\n",
    "        val_mse, val_rmse, val_mae, val_mape = 0, 0, 0, 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                mse, rmse, mae, mape = compute_metrics(output, targets_expanded, criterion)\n",
    "                val_mse += mse\n",
    "                val_rmse += rmse\n",
    "                val_mae += mae\n",
    "                val_mape += mape\n",
    "\n",
    "                all_predictions.append(output.cpu().numpy())\n",
    "                all_targets.append(targets_expanded.cpu().numpy())\n",
    "\n",
    "        # Compute overall R-squared\n",
    "        all_predictions = np.vstack(all_predictions)\n",
    "        all_targets = np.vstack(all_targets)\n",
    "\n",
    "        # Flatten the arrays to 2D for r2_score computation\n",
    "        all_predictions_flat = all_predictions.reshape(-1, 1)\n",
    "        all_targets_flat = all_targets.reshape(-1, 1)\n",
    "\n",
    "        val_r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "\n",
    "        val_mse /= len(val_loader)\n",
    "        val_rmse /= len(val_loader)\n",
    "        val_mae /= len(val_loader)\n",
    "        val_mape /= len(val_loader)\n",
    "\n",
    "        aggregated_metrics['mse'].append(val_mse)\n",
    "        aggregated_metrics['rmse'].append(val_rmse)\n",
    "        aggregated_metrics['mae'].append(val_mae)\n",
    "        aggregated_metrics['mape'].append(val_mape)\n",
    "        aggregated_metrics['r2'].append(val_r2)\n",
    "\n",
    "    avg_metrics = {metric: np.mean(aggregated_metrics[metric]) for metric in aggregated_metrics}\n",
    "    logging.info(f'Avg Validation Metrics: {avg_metrics}')\n",
    "\n",
    "    return avg_metrics\n",
    "\n",
    "# Random search for hyperparameter tuning\n",
    "param_samples = list(ParameterSampler(param_distributions, n_iter=20, random_state=42))\n",
    "best_score = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for param_sample in param_samples:\n",
    "    avg_metrics = cross_val_evaluate(param_sample, graph_data)\n",
    "    if avg_metrics['mse'] < best_score:\n",
    "        best_score = avg_metrics['mse']\n",
    "        best_params = param_sample\n",
    "\n",
    "print(f'Best Score: {best_score}')\n",
    "print(f'Best Parameters: {best_params}')\n",
    "\n",
    "# Train on the full training set with the best hyperparameters\n",
    "def train_on_full_train_set(best_params, graph_data):\n",
    "    lstm_hidden_dim = best_params['lstm_hidden_dim']\n",
    "    lstm_num_layers = best_params['lstm_num_layers']\n",
    "    gat_hidden_dim = best_params['gat_hidden_dim']\n",
    "    num_heads = best_params['num_heads']\n",
    "    combined_dim = best_params['combined_dim']\n",
    "    lstm_dropout = best_params['lstm_dropout']\n",
    "    gat_dropout = best_params['gat_dropout']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "    weight_decay = best_params['weight_decay']\n",
    "\n",
    "    model = LSTM_GAT_Model(\n",
    "        static_input_dim=8,\n",
    "        lstm_input_dim=27,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        gat_input_dim=lstm_hidden_dim + 8,  # Corrected static_input_dim here\n",
    "        gat_hidden_dim=gat_hidden_dim,\n",
    "        num_heads=num_heads,\n",
    "        combined_dim=combined_dim,\n",
    "        output_dim=1,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "        gat_dropout=gat_dropout\n",
    "    ).to(device)  # Move model to device\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "    num_epochs = 100\n",
    "    batch_size = 48\n",
    "    early_stopping_patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(train_sequences_tensor, train_targets_tensor), batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(TensorDataset(val_sequences_tensor, val_targets_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Lists to store losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, targets in train_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(graph_data, sequences)\n",
    "\n",
    "            # Ensure the target shape matches the output shape\n",
    "            targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "            loss = criterion(output, targets_expanded)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(graph_data, sequences)\n",
    "\n",
    "                # Ensure the target shape matches the output shape\n",
    "                targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "                loss = criterion(output, targets_expanded)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        logging.info(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), 'best_model_full_train.pth')\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= early_stopping_patience:\n",
    "                logging.info('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load('best_model_full_train.pth'))\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "best_model, best_train_losses, best_val_losses = train_on_full_train_set(best_params, graph_data)\n",
    "\n",
    "# Test evaluation\n",
    "def evaluate_on_test_set(model, graph_data, criterion):\n",
    "    model.eval()\n",
    "    test_mse, test_rmse, test_mae, test_mape = 0, 0, 0, 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in test_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            output = model(graph_data, sequences)\n",
    "\n",
    "            # Ensure the target shape matches the output shape\n",
    "            targets_expanded = targets.unsqueeze(1).expand(-1, output.size(1), -1)  # Shape should be (batch_size, num_nodes, 1)\n",
    "\n",
    "            mse, rmse, mae, mape = compute_metrics(output, targets_expanded, criterion)\n",
    "            test_mse += mse\n",
    "            test_rmse += rmse\n",
    "            test_mae += mae\n",
    "            test_mape += mape\n",
    "\n",
    "            all_predictions.append(output.cpu().numpy())\n",
    "            all_targets.append(targets_expanded.cpu().numpy())\n",
    "\n",
    "    # Compute overall R-squared\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "\n",
    "    # Flatten the arrays to 2D for r2_score computation\n",
    "    all_predictions_flat = all_predictions.reshape(-1, 1)\n",
    "    all_targets_flat = all_targets.reshape(-1, 1)\n",
    "\n",
    "    test_r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "\n",
    "    test_mse /= len(test_loader)\n",
    "    test_rmse /= len(test_loader)\n",
    "    test_mae /= len(test_loader)\n",
    "    test_mape /= len(test_loader)\n",
    "\n",
    "    logging.info(f'Test MSE: {test_mse}, Test RMSE: {test_rmse}, Test MAE: {test_mae}, Test MAPE: {test_mape}, Test R2: {test_r2}')\n",
    "\n",
    "    return (test_mse, test_rmse, test_mae, test_mape, test_r2), all_predictions, all_targets\n",
    "\n",
    "# Pass criterion as an argument\n",
    "test_metrics, test_predictions, test_targets = evaluate_on_test_set(best_model, graph_data, nn.MSELoss())\n",
    "\n",
    "# Debugging prints\n",
    "print(f'Test Metrics: {test_metrics}')\n",
    "print(\"Shape of test_predictions:\", test_predictions.shape)\n",
    "print(\"Shape of test_targets:\", test_targets.shape)\n",
    "\n",
    "# Plotting the predictions vs. actual values for the last 24 hours\n",
    "last_hours = 24\n",
    "\n",
    "if test_predictions.shape[0] >= last_hours and test_targets.shape[0] >= last_hours:\n",
    "    last_predictions = test_predictions[-last_hours:, :]\n",
    "    last_targets = test_targets[-last_hours:, :]\n",
    "    node_index = 24\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(last_targets[:, node_index], label=f'Actual Node {node_index}')\n",
    "    plt.plot(last_predictions[:, node_index], label=f'Predicted Node {node_index}', linestyle='dashed')\n",
    "\n",
    "    plt.xlabel('Time-Step')\n",
    "    plt.ylabel('Consumption')\n",
    "    plt.title(f'LSTM-GAT Model Predicted vs Actual Consumption for Node {node_index} (Last {last_hours} Hours)')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Not enough samples to plot the last {last_hours} hours.\")\n",
    "\n",
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_train_losses, label='Train Loss')\n",
    "plt.plot(best_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for LSTM-GAT Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18217aab-911f-443b-a425-c532cd35ce46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984587d3-bf92-43f2-b112-896dd55ca121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging prints\n",
    "print(\"Shape of test_predictions:\", test_predictions.shape)\n",
    "print(\"Shape of test_targets:\", test_targets.shape)\n",
    "\n",
    "# Plotting the predictions vs. actual values for a specific 24-hour range for all nodes\n",
    "range_hours = 24\n",
    "\n",
    "# Ensure there are enough samples for the specified range\n",
    "if test_predictions.shape[0] >= range_hours and test_targets.shape[0] >= range_hours:\n",
    "    # Select any 24-hour range\n",
    "    range_start = 0  # Change this to specify different starting points\n",
    "    range_end = range_start + range_hours\n",
    "\n",
    "    selected_predictions = test_predictions[range_start:range_end, :]\n",
    "    selected_targets = test_targets[range_start:range_end, :]\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "    for node_index in range(selected_predictions.shape[1]):\n",
    "        ax.plot(selected_targets[:, node_index], label='Actual Consumption' if node_index == 0 else \"\", color='blue', alpha=0.5)\n",
    "        ax.plot(selected_predictions[:, node_index], label='Predicted Consumption' if node_index == 0 else \"\", linestyle='dashed', color='orange', alpha=0.5)\n",
    "    \n",
    "    ax.set_title(f'Actual vs Predicted Consumption for All Nodes ({range_hours}-Hour Range)')\n",
    "    ax.set_xlabel('Time-Step')\n",
    "    ax.set_ylabel('Consumption (MW)')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Not enough samples to plot the {range_hours}-hour range.\")\n",
    "\n",
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_train_losses, label='Train Loss')\n",
    "plt.plot(best_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for LSTM-GAT Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8283cf-a642-4635-8f33-046166a921e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89029754-3b2f-41e6-b974-66d42668bd95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
